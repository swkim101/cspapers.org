Text style transfer aims to change the style (e.g., sentiment, politeness) of a sentence while preserving its content. A common solu-tion is the prototype editing approach, where stylistic tokens are deleted in the “mask” stage and then the masked sentences are inﬁlled with the target style tokens in the “inﬁll” stage. Despite their success, these approaches still suffer from the content preservation problem. By closely inspecting the results of existing approaches, we identify two common types of errors: 1) many content-related tokens are masked and 2) irrelevant words associated with the target style are inﬁlled. Our paper aims to enhance content preservation by tackling each of them. In the “mask” stage, we utilize a BERT-based keyword extraction model that incorporates syntactic information to prevent content-related tokens from being masked. In the “inﬁll” stage, we create a pseudo-parallel dataset and train a T5 model to inﬁll the masked sentences without introducing irrelevant content. Empirical results show that our method outperforms the state-of-the-art baselines in terms of content preservation, while maintaining comparable transfer effectiveness and language quality.