Social media platforms have been growing at a rapid pace, attracting users engagement with contents due to their convenience facilitated by many usable features. Such platforms provide users with interactive options such as likes, dislikes as well as a way of expressing their opinions in the form of text (i.e., comments). The ability of posting comments on these online platforms has allowed some users to post racist, obscene, as well as to spread hate on these platforms. In some cases, this kind of toxic behavior might turn the comment section from a space where users can share their views to a place where hate and profanity are spread. Such issues are observed across various social media platforms and many users are often exposed to these kinds of behaviors which requires comment moderators to spend a lot of time filtering out such inappropriate comments. Moreover, such textual "inappropriate contents" can be targeted towards users irrespective of age, concerning variety of topics (not only controversial), and triggered by various events. My doctoral dissertation work, therefore, is primarily focused on studying, detecting and analyzing users exposure to this kind of toxicity on different social media platforms utilizing the state-of-art techniques in deep learning and natural language processing. This paper presents one example of my works on detecting and measuring kids exposure to inappropriate comments posted on YouTube videos targeting young users. In the meantime, the same pipeline is being examined for measuring users interaction with mainstream news media and sentiment towards various topics in the public discourse in light of the Coronavirus disease 2019 (COVID'19).