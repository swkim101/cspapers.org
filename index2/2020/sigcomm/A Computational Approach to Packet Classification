Multi-field packet classification is a crucial component in modern software-defined data center networks. To achieve high throughput and low latency, state-of-the-art algorithms strive to fit the rule lookup data structures into on-die caches; however, they do not scale well with the number of rules. We present a novel approach, <italic>NuevoMatch</italic>, which improves the memory scaling of existing methods. A new data structure, <italic>Range Query Recursive Model Index</italic> (RQ-RMI), is the key component that enables NuevoMatch to replace most of the accesses to main memory with model inference computations. We describe an efficient training algorithm that guarantees the correctness of the RQ-RMI-based classification. The use of RQ-RMI allows the rules to be compressed into neural networks that fit into the hardware cache. Further, it takes advantage of the growing support for fast neural network processing in modern CPUs, such as wide vector instructions, achieving a latency of tens of nanoseconds per lookup. Our evaluation using 500K multi-field rules from the standard ClassBench benchmark shows a geometric mean compression factor of <inline-formula> <tex-math notation="LaTeX">$4.9\times $ </tex-math></inline-formula>, <inline-formula> <tex-math notation="LaTeX">$8\times $ </tex-math></inline-formula>, and <inline-formula> <tex-math notation="LaTeX">$82\times $ </tex-math></inline-formula>, and average performance improvement of <inline-formula> <tex-math notation="LaTeX">$2.4\times $ </tex-math></inline-formula>, <inline-formula> <tex-math notation="LaTeX">$2.6\times $ </tex-math></inline-formula>, and <inline-formula> <tex-math notation="LaTeX">$1.6\times $ </tex-math></inline-formula> in throughput compared to CutSplit, NeuroCuts, and TupleMerge, all state-of-the-art algorithms.