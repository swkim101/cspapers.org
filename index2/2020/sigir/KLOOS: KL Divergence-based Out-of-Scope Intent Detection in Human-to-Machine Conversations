User intent is not restricted in human-to-machine conversations, and sometimes overshoots the scope of a designed system. Many tasks for understanding conversations require the elimination of such out-of-scope queries. We propose an out-of-scope intent detection method, called KLOOS, based on a novel feature extraction mechanism that incorporates the information accumulation of sequential word processing. Information is accumulated by KL divergence between the intent distributions of consecutive words. The performance of our approach is compared with the conventional classifiers and state-of-the-art language models fine-tuned for out-of-scope detection on three spoken query collections. The results show that KLOOS statistically significantly improves out-of-scope sensitivity in all cases, while the overall performance is not deteriorated in most cases.