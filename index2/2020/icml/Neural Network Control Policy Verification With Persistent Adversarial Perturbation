Deep neural networks are known to be fragile to small adversarial perturbations, which raises serious concerns when a neural network policy is interconnected with a physical system in a closed loop. In this paper, we show how to combine recent works on static neural network certiﬁcation tools with robust control theory to certify a neural network policy in a control loop. We give a sufﬁcient condition and an algorithm to ensure that the closed loop state and control constraints are satisﬁed when the persistent adversarial perturbation is (cid:96) ∞ norm bounded. Our method is based on ﬁnding a positively invariant set of the closed loop dynamical system, and thus we do not require the continuity of the neural network policy. Along with the veriﬁcation result, we also develop an effective attack strategy for neural network control systems that outperforms exhaustive Monte-Carlo search signiﬁcantly. We show that our certiﬁcation algorithm works well on learned models and could achieve 5 times better result than the traditional Lipschitz-based method to certify the robustness of a neural network policy on the cart-pole balance control problem.