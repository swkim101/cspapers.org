Multi-Task Learning (MTL) is a well established paradigm for jointly learning models for multiple correlated tasks. Often the tasks conﬂict, requiring trade-offs between them during optimization. In such cases, multi-objective optimization based MTL methods can be used to ﬁnd one or more Pareto optimal solutions. A common requirement in MTL applications, that cannot be addressed by these methods, is to ﬁnd a solution satisfying user-speciﬁed preferences with respect to task-speciﬁc losses. We advance the state-of-the-art by developing the ﬁrst gradient-based multi-objective MTL algorithm to solve this problem. Our unique approach combines multiple gradient descent with carefully controlled ascent to traverse the Pareto front in a principled manner, which also makes it robust to initialization. The scalability of our algo-rithm enables its use in large-scale deep networks for MTL. Assuming only differentiability of the task-speciﬁc loss functions, we provide theoretical guarantees for convergence. Our experiments show that our algorithm outperforms the best competing methods on benchmark datasets.