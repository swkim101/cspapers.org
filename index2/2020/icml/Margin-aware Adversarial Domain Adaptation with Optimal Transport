We recall the problem setup of our study with the notations used throughout the paper. We consider a binary classification setting, in which source and target data are respectively drawn from S and T , the joint distributions over the product space of instances and labels X × Y , where X ∈ R and Y = {−1, 1}. We denote their corresponding marginal distributions as DS and DT and use bold upper-case letters for matrices (e.g., D) and bold lower-case letters for vectors (e.g., x). Although both domains are assumed to be labeled, only the labels of the source instances are observable during the learning stage. This settings is often referred to as unsupervised domain adaptation.