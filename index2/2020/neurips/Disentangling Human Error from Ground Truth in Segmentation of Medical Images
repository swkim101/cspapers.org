Recent years have seen increasing use of supervised learning methods for segmenta-1 tion tasks. However, the predictive performance of these algorithms depends on the 2 quality of labels. This problem is particularly pertinent in the medical image domain, 3 where both the annotation cost and inter-observer variability are high. In a typical la-4 bel acquisition process, different human experts provide their estimates of the “true” 5 segmentation labels under the inﬂuence of their own biases and competence levels. 6 Treating these noisy labels blindly as the ground truth limits the performance that 7 automatic segmentation algorithms can achieve. In this work, we present a method 8 for jointly learning, from purely noisy observations alone, the reliability of individual 9 annotators and the true segmentation label distributions, using two coupled CNNs. 10 The separation of the two is achieved by encouraging the estimated annotators to 11 be maximally unreliable while achieving high ﬁdelity with the noisy training data. 12 We ﬁrst deﬁne a toy segmentation dataset based on MNIST and study the properties 13 of the proposed algorithm. We then demonstrate the utility of the method on three 14 public medical imaging segmentation datasets with simulated (when necessary) and 15 real diverse annotations: 1) MSLSC (multiple-sclerosis lesions); 2) BraTS (brain 16 tumours); 3) LIDC-IDRI (lung abnormalities). In all cases, our method outperforms 17 competing methods and relevant baselines particularly in cases where the number 18 of annotations is small and the amount of disagreement is large. The experiments 19 also show strong ability to capture the complex spatial characteristics of annotators’ 20 mistakes, which could be potentially utilised for the purpose of education. 21