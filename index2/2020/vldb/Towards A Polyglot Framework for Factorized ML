Optimizing machine learning (ML) workloads on structured data is a key concern for data platforms. One class of optimizations called “factorized ML” help reduce ML runtimes over multi-table datasets by pushing ML computations down through joins, avoiding the need to materialize such joins. The recent Morpheus system automated factorized ML to any ML algorithm expressible in linear algebra (LA). But all such prior factorized ML/LA stacks are restricted by their chosen programming language (PL) and runtime environment, limiting their reach in emerging data science environments with many PLs (R, Python, etc.) and even cross-PL analytics workﬂows. Re-implementing Morpheus from scratch in each PL/environment is a massive developability overhead for implementation, testing, and maintenance. We tackle this challenge by proposing a novel information sys-tem architecture, Trinity , to enable factorized LA logic to be written only once and easily reused across many PLs/LA tools in one go . To do this in an extensible and eﬃcient manner without costly data copies, Trinity leverages and extends an emerging polyglot compiler/runtime, Oracle’s GraalVM. Trinity enables factorized LA in multiple PLs and even cross-PL workﬂows. Experiments with real datasets show that Trinity is signiﬁcantly faster than materialized execution ( > 10x speedups in some cases), while being largely competitive to a prior single PL-focused Morpheus stack.