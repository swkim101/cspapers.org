Selecting the optimal storage engine and tuning for an application requires comparing the latency of diverse workloads executed on different data structures. In this work, we start to develop an average-case analysis of the performance of storage engines that can achieve significantly more accurate predictions than existing worst-case models. We propose a distribution-aware framework to predict the latency of diverse workloads executed on a vast number of data structures. As a case study, we use our framework to produce cost models for a diverse family of key-value storage engine tunings, and verify our models on RocksDB and WiredTiger.