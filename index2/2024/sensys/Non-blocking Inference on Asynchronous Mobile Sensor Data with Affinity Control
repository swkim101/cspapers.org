The rise of sensor-rich mobile devices has led to the adoption of multi-modal deep intelligence for distributed sensing tasks. However, varying arrival times of mobile sensory data can cause delays or accuracy decline. The diversity and dynamic nature of mobile systems further exacerbate this challenge. To address this, we present an opportunistic inference approach for asynchronous distributed multi-modal data, enabling inference upon partial data arrival. AdaFlow pioneers the formulation of structured cross-modality affinity using a hierarchical analysis-based normalized matrix, accommodating the diversity and dynamics of modalities. Employing an affinity attention-based conditional GAN (ACGAN), AdaFlow facilitates flexible data imputation, adapting to various modalities and tasks without retraining. Experiments show significant reductions in inference latency and enhanced accuracy compared to status quo approaches.