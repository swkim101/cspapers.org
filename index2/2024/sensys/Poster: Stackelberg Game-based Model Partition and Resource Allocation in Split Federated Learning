This paper investigates dynamic model partitioning and resource allocation in split federated learning, aiming to maximize the utility of clients and the Central Server (CS). We first model the interactions between the CS and clients as a Stackelberg game, where the CS acts as the leader to set payment and allocate computation resources, while clients as followers to determine model partitioning strategies. Then, we transform the problem into a bi-level optimization and propose a Nash-Equilibrium-based Stackelberg Algorithm (NESA) to solve it. Finally, the experimental results indicate that a Stackelberg equilibrium exists between the CS and clients, and NESA achieves higher utility and improves accuracy and convergence speed.