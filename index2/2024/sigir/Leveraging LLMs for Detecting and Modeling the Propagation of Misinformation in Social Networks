Recent success in language generation capabilities of large language models (LLMs), such as GPT, Llama, etc., can potentially lead to concern about their possible misuse in inducing mass agitation and communal hatred via generating fake news and spreading misinformation. Traditional means of developing a misinformation ground-truth dataset do not scale well because of the extensive manual effort required to annotate the data. It is crucial to anticipate and counteract potential adversarial fake information to mitigate detrimental effects and promote societal harmony. To this end, this PhD proposal spans three main research directions. The first concerns investigating ways of developing unsupervised models for fake news identification leveraging retrieval augmented generation (RAG) approaches. In our second thread of work, we explore ways of creating synthetic datasets to eventually train supervised or few-shot example-based models. Another direction of research work involves tracking the propagation of fake information through social networks to develop preventive measures against it.