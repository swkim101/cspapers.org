Neural radiance fields (NeRFs) have gained popularity in the autonomous driving (AD) community. Recent meth-ods show NeRFs' potential for closed-loop simulation, en-abling testing of AD systems, and as an advanced training data augmentation technique. However, existing meth-ods often require long training times, dense semantic su-pervision, or lack generalizability. This, in turn, hinders the application of NeRFs for AD at scale. In this paper, we propose NeuRAD, a robust novel view synthesis method tailored to dynamic AD data. Our method features simple network design, extensive sensor modeling for both cam-era and lidar - including rolling shutter, beam divergence and ray dropping - and is applicable to multiple datasets out of the box. We verify its performance on five popular AD datasets, achieving state-of-the-art performance across the board. To encourage further development, we openly release the NeuRAD source code.