Vehicle-to-everything (V2X) is a popular topic in the field of Autonomous Driving in recent years. Vehicle-infrastructure cooperation (VIC) becomes one of the important research area. Due to the complexity of traffic conditions such as blind spots and occlusion, it greatly limits the perception capabilities of single-view roadside sensing sys-tems. To further enhance the accuracy of roadside perception and provide better information to the vehicle side, in this paper, we constructed holographic intersections with various layouts to build a large-scale multi-sensor holo-graphic vehicle-infrastructure cooperation dataset, called HoloVic. Our dataset includes 3 different types of sen-sors (Camera, Lidar; Fisheye) and employs 4 sensor-layouts based on the different intersections. Each intersection is equipped with 6â€“18 sensors to capture synchronous data. While autonomous vehicles pass through these intersections for collecting VIC data. HoloViccontains in to-talon 100k+ synchronous frames from different sensors. Additionally, we annotated 3D bounding boxes based on Camera, Fisheye, and Lidar: We also associate the IDs of the same objects across different devices and consecutive frames in sequence. Based on HoloVIC, we formulated four tasks to facilitate the development of related research. We also provide benchmarks for these tasks.