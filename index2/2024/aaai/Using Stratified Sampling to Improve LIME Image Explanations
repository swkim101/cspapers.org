We investigate the use of a stratified sampling approach for LIME Image, a popular model-agnostic explainable AI method for computer vision tasks, in order to reduce the artifacts generated by typical Monte Carlo sampling.
Such artifacts are due to the undersampling of the dependent variable in the synthetic neighborhood around the image being explained, which may result in inadequate explanations due to the impossibility of fitting a linear regressor on the sampled data.
We then highlight a connection with the Shapley theory, where similar arguments about undersampling and sample relevance were suggested in the past.
We derive all the formulas and adjustment factors required for an unbiased stratified sampling estimator. 
Experiments show the efficacy of the proposed approach.