Around 1970 the study of nonlinear control systems took a sharp turn. In part, this was driven by the hope for a more inclusive theory which would be applicable to various newly emerging aerospace problems lying outside the scope of linear theory, and also by the gradual realization that tools from differential geometry, and Lie theory in particular, could be seen as providing a remarkably nice fit with what seemed to be needed for the wholesale extension of linear control theory into a nonlinear setting. This paper discusses an initial phase of the development of geometric nonlinear control, including material on the broader context from which it emerged. We limit our account to developments occurring up to the early 1980s, not because the field stopped developing at that point but rather to limit the scope of the project to something manageable. Even so, because of the volume and diversity of the literature we have had to be selective, even within the given time frame. Consensus-­‐based	  distributed	  cooperative	  learning	  control	  for	  a	  group	  of discrete-­‐time	  nonlinear	  multi-­‐agent	  systems	  using	  neural	  networks Vol.	  50,	  No.9,	  Page	  2254-­‐2268 • Weisheng Chena, 1, , • Shaoyong Huaa, , • Shuzhi Sam Geb, • a School of Mathematics and Statistics, Xidian University Xi’an, 710071, PR China • b Department of Electrical and Computer Engineering, National University of Singapore, 117576, Singapore Abstract This paper focuses on the cooperative learning capability of radial basis function neural networks in adaptive neural controllers for a group of uncertain discrete-time nonlinear systems where system structures are identical but reference signals are different. By constructing an interconnection topology among learning laws of NN weights in order to share their learned knowledge on-line, a novel adaptive NN control scheme, called distributed cooperative learning control scheme, is proposed. It is guaranteed that if the interconnection topology is undirected and connected, all closed-loop signals are uniform ultimate bounded and tracking errors of all systems can converge to a small neighborhood around the origin. Moreover, it is proved that all estimated NN weights converge to a small neighborhood of their common optimal value along the union of all state trajectories, which means that the estimated NN weights reach consensus with a small consensus error. Thus, all learned NN models have the better generalization capability than ones obtained by the deterministic learning method. The learned knowledge is also adopted to control a class of uncertain systems with the same structure but different reference signals. Finally, a simulation example is provided to verify the effectiveness and advantages of the distributed cooperative learning control scheme developed in this paper. Reachability	  for	  partially	  observable	  discrete	  time	  stochastic	  hybrid	  systems Vol.	  50,	  No.8,	  Page	  1989-­‐1998 • Kendra Lesser1, , • Meeko Oishi • Department of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM 87131, USA Abstract When designing optimal controllers for any system, it is often the case that the true state of the system is unknown to the controller. Imperfect state information must be taken into account in the controller’s design in order to preserve its optimality. The same is true when performing reachability calculations. To estimate the probability that the state of a stochastic system reaches, or stays within, some set of interest in a given time horizon, it is necessary to find a controller that drives the system to that set with maximum probability, given the controller’s knowledge of the true state of the system. To date, little work has been done on stochastic reachability calculations with partially observable states. The work that has been done relies on converting the reachability optimization problem to one with an additive cost function, for which theoretical results are well known. Our approach is to preserve the multiplicative cost structure when deriving a sufficient statistic that reduces the problem to one of perfect state information. Our transformation includes a change of measure that simplifies the distribution of the sufficient statistic conditioned on its previous value. We develop a dynamic programming recursion for the solution of the equivalent perfect information problem, proving that the recursion is valid, an optimal solution exists, and results in the same solution as to the original problem. We also show that our results are equivalent to those for the reformulated additive cost problem, and so such a reformulation is not required. Probabilistic	  model	  validation	  for	  uncertain	  nonlinear	  systems Vol.	  50,	  No.8,	  Page	  2038-­‐2050 • Abhishek Halder1, , • Raktim Bhattacharya • Department of Aerospace Engineering, Texas A&M University, College Station, TX 77843-3141, United States Abstract This paper presents a probabilistic model validation methodology for nonlinear systems in timedomain. The proposed formulation is simple, intuitive, and accounts both deterministic and stochastic nonlinear systems with parametric and nonparametric uncertainties. Instead of hard invalidation methods available in the literature, a relaxed notion of validation in probability is introduced. To guarantee provably correct inference, algorithm for constructing probabilistically robust validation certificate is given along with computational complexities. Several examples are worked out to illustrate its use. The	  Minkowski–Lyapunov	  equation	  for	  linear	  dynamics:	  Theoretical foundations Vol.	  50,	  No.8,	  Page	  2015-­‐2024 • Saša V. Rakovića, b, 1, , • Mircea Lazarc • a St. Edmund Hall, Oxford University, Oxford, UK • b Supélec, Gif Sur Yvette, France • c Eindhoven University of Technology, Eindhoven, The Netherlands Abstract We consider the Lyapunov equation for the linear dynamics, which arises naturally when one seeks for a Lyapunov function with a uniform, exact decrease. In this setting, a solution to the Lyapunov equation has been characterized only for quadratic Lyapunov functions. We demonstrate that the Lyapunov equation is a well-posed equation for strictly stable dynamics and a much more general class of Lyapunov functions specified via Minkowski functions of proper C sets, which include Euclidean and weighted Euclidean vector norms, polytopic and weighted polytopic (1 , ∞ )-vector norms as well as vector semi-norms induced by the Minkowski functions of proper C -sets. Furthermore, we establish that the Lyapunov equation admits a basic solution, i.e., the unique solution within the class of Minkowski functions associated with proper C -sets. Finally, we provide a characterization of the lower and upper approximations of the basic solution that converge pointwise and compactly to it, while, in addition, the upper approximations satisfy the classical Lyapunov inequality. Optimal	  tracking	  control	  of	  nonlinear	  partially-­‐unknown	  constrained-­‐input systems	  using	  integral	  reinforcement	  learning Vol.	  50,	  No.7,	  Page	  1780-­‐1792 • Hamidreza Modares1, , • Frank L. Lewis • University of Texas at Arlington Research Institute, 7300 Jack Newell Blvd. S., Ft. Worth, TX 76118, USA Abstract In this paper, a new formulation for the optimal tracking control problem (OTCP) of continuoustime nonlinear systems is presented. This formulation extends the integral reinforcement learning (IRL) technique, a method for solving optimal regulation problems, to learn the solution to the OTCP. Unlike existing solutions to the OTCP, the proposed method does not need to have or to identify knowledge of the system drift dynamics, and it also takes into account the input constraints a priori. An augmented system composed of the error system dynamics and the command generator dynamics is used to introduce a new nonquadratic discounted performance function for the OTCP. This encodes the input constrains into the optimization problem. A tracking Hamilton–Jacobi–Bellman (HJB) equation associated with this nonquadratic performance function is derived which gives the optimal control solution. An online IRL algorithm is presented to learn the solution to the tracking HJB equation without knowing the system drift dynamics. Convergence to a near-optimal control solution and stability of the whole system are shown under a persistence of excitation condition. Simulation examples are provided to show the effectiveness of the proposed method. 3D	  environmental	  extremum	  seeking	  navigation	  of	  a	  nonholonomic	  mobile robot Vol.	  50,	  No.7,	  Page	  1802-­‐1815 • Alexey S. Matveeva, 1, , • Michael C. Hoyb, , • Andrey V. Savkinb, • a Department of Mathematics and Mechanics, Saint Petersburg University, St. Petersburg, Russia • b School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia Abstract A nonholonomic under-actuated robot with bounded control travels in a 3D region. A single sensor provides the value of an unknown scalar field at the current location of the robot. We present a new kinematic control paradigm to drive the robot to the maximizer of the field, which is different from conventionally trying to align the velocity vector with the field gradient. The proposed strategy does not employ gradient estimation and is non-demanding with respect to both computation and motion. Its mathematically rigorous analysis and justification are provided. Simulation results confirm the applicability and performance of the proposed guidance approach. IEEE	  T-­‐Ro Cooperative	  Visibility	  Maintenance	  for	  Leader–Follower	  Formations	  in Obstacle	  Environments Vol.	  30,	  No.4,	  Page	  831-­‐844 Panagou, D. ; Coordinated Sci. Lab., Univ. of Illinois at Urbana-Champaign, 