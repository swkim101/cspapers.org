Conformal prediction is a powerful tool for uncertainty quantiﬁcation, but its application to time-series data is constrained by the violation of the exchangeability assumption. Current solutions for time-series prediction typically operate in the output space and rely on manually selected weights to address distribution drift, leading to overly conservative predictions. To enable dynamic weight learning in the semantically rich latent space, we introduce a novel approach called Con-formalized Time Series with Semantic Features (CT-SSF). CT-SSF utilizes the inductive bias in deep representation learning to dynamically adjust weights, prioritizing semantic features relevant to the current prediction. Theoretically, we show that CT-SSF surpasses previous methods deﬁned in the output space. Experiments on synthetic and benchmark datasets demonstrate that CT-SSF signiﬁcantly outperforms existing state-of-the-art (SOTA) conformal prediction techniques in terms of prediction efﬁciency while maintaining a valid coverage guarantee.