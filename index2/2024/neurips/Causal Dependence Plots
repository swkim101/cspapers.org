Explaining artiﬁcial intelligence or machine learning models is an increasingly important problem. For humans to stay in the loop and control such systems, we must be able to understand how they interact with the world. This work proposes us-ing known or assumed causal structure in the input variables to produce simple and practical explanations of supervised learning models. Our explanations—which we name Causal Dependence Plots or CDP—visualize how the model output depends on changes in a given predictor along with any consequent causal changes in other predictors . Since this causal dependence captures how humans often think about input-output dependence, CDPs can be powerful tools in the explainable AI or interpretable ML toolkit and contribute to applications including scientiﬁc machine learning and algorithmic fairness. CDP can also be used for model-agnostic or black-box explanations.