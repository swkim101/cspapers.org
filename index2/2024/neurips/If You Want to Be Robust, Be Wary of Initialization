Graph Neural Networks (GNNs) have demonstrated remarkable performance across 1 a spectrum of graph-related tasks, however concerns persist regarding their vul-2 nerability to adversarial perturbations. While prevailing defense strategies focus 3 primarily on pre-processing techniques and adaptive message-passing schemes, this 4 study delves into an under-explored dimension: the impact of weight initialization 5 and associated hyper-parameters, such as training epochs, on a model’s robustness. 6 We introduce a theoretical framework bridging the connection between initializa-7 tion strategies and a network’s resilience to adversarial perturbations. Our analysis 8 reveals a direct relationship between initial weights, number of training epochs and 9 the model’s vulnerability, offering new insights into adversarial robustness beyond 10 conventional defense mechanisms. While our primary focus is on GNNs, we extend 11 our theoretical framework, providing a general upper-bound applicable to Deep 12 Neural Networks. Extensive experiments, spanning diverse models and real-world 13 datasets subjected to various adversarial attacks, validate our findings. We illustrate 14 that selecting appropriate initialization not only ensures performance on clean 15 datasets but also enhances model robustness against adversarial perturbations, with 16 observed gaps of up to 50% compared to alternative initialization approaches. 17