Open-vocabulary semantic segmentation (OVSS) aims to segment unseen classes without corresponding labels. Existing Vision-Language Model (VLM)- based methods leverage VLMâ€™s rich knowledge to enhance additional explicit segmentation-specific networks, yielding competitive results, but at the cost of extensive training cost. To reduce the cost, we attempt to enable VLM to directly produce the segmentation results without any segmentation-specific networks. Prompt learning offers a direct and parameter-efficient approach, yet it falls short in guiding VLM for pixel-level visual classification. Therefore, we propose the R elationship P rompt M odule ( RPM ), which generates the relationship prompt that directs VLM to extract pixel-level semantic embeddings suitable for OVSS. More-over, RPM integrates with VLM to construct the R elationship P rompt N etwork ( RPN ), achieving OVSS without any segmentation-specific networks. RPN attains state-of-the-art performance with merely about 3M trainable parameters (2% of total parameters).