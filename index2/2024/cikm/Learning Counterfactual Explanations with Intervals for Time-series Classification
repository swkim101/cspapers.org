The need for explainability in time-series classification models has been increasing. Counterfactual explanations recommend how to modify the features of an original instance so that the prediction by a given classifier flips to the desired class. Since features in the time series are temporally dependent, interpretability is improved by considering intervals where the counterfactual can deviate from the original instance. In this study, we propose a model-agnostic counterfactual generation method (CEI) that jointly learns these intervals and the counterfactual. Furthermore, CEI can generate a counterfactual tailored to the directly specified limited number of intervals. We mathematically formulate CEI as a continuous optimization and demonstrate its effectiveness on the UCR datasets.