Large language models (LLMs) have shown impressive success in various applications. However, they encounter issues in accurately understanding user intentions, thereby impeding the successful accomplishment of tasks. The pioneering study tackles intention understanding through iteratively interacting with users to enhance response quality; however, it fails to identify the notorious challenges associated with the task, where efficiency and accuracy are paramount for ensuring optimal user experience. To address these challenges, we introduce a new interactive table based intention understanding (ITIU) framework, which refers to and implements non-linear thinking in psychology such that details of intention are parallelly generated. Specifically, in the table interacting design phase, ITIU first brainstorms a more concrete intention table relevant to user instructions and subsequently incorporates a rule-based supervision mechanism to enhance the accuracy of its content. In the specialized model training phase, we obtain the procedural records generated by ITIU to develop a specialized upstream interactive intention understanding model. The specialized model replaces internal steps within the original interaction design for further efficiency improvement. Comprehensive experimental results demonstrate that ITIU significantly outperforms existing intention understanding methods, particularly in terms of interaction efficiency and intention understanding accuracy. Furthermore, whether integrated into the open-source LLaMA or powerful LLMs like GPT-4 and Claude-3, ITIU shows significant performance improvements. All the data and codes are released.