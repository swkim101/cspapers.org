The surge in detecting fake news on social networks leads to increased research attention, particularly in the realm of deep learning models based on graph neural networks (GNNs). However, as research progresses, concerns emerge about the vulnerability of these detection models. In this study, we introduce an attack problem that perturbs user-news engagements by injecting bots to shield the targeted fake news from being detected by GNN-based fake news detection models. We propose a black-box attack method named Query-enhanced Surrogate-based Attack under Assortativity Constraint (QSA-AC) to work for this attack problem. QSA-AC combines surrogate-based and query-based approaches to improve attack effectiveness. At the same time, QSA-AC maintains a balance between attack effectiveness and imperceptibility by adjusting the local fluctuations of the assortativity with respect to the news on the social network. In addition, we introduce an evaluation metric, local strength assortativity perturbation rate (LSAPR), to assess the imperceptibility of the attack from the local perspective. Extensive experiments on two fake news datasets demonstrate that the proposed QSA-AC can achieve the optimal attack effectiveness, and control the trade-off between the attack effectiveness and imperceptibility.