Malevolence detection in dialogues aims to identify harmful or inappropriate utterances, significantly impacting dialogue quality and user satisfaction. Although existing studies have shown promising performance by modeling interaction patterns from dialogue history, various malevolence-invoking factors, such as fine-grained emotions, evolving topics and user profiles, are often overlooked. To comprehensively consider these factors, we propose a hypergraph fusion model by employing multi-view LLM-driven prompts for malevolence detection in dialogues. Our model integrates emotion context, topic context, user profile context and interaction context, utilizing hypergraphs to establish high-order contextual relationships from multi views for deducing malevolence-invoking semantics. Experimental results on two benchmark datasets demonstrate that our model achieves the state-of-the-art performance.