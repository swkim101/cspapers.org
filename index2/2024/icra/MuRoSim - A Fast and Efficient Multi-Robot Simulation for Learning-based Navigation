Multi-robot navigation and dynamic obstacle avoidance are challenging problems in robot learning. Recent advancements in Deep Reinforcement Learning (DRL) have demonstrated great potential in this area. Nonetheless, they often face challenges related to low sample efficiency. To overcome this challenge, some research proposes simulators that incorporate hardware acceleration. Although these simulators improve efficiency, they often lack the flexibility to generate diverse learning scenarios as often needed in multi-robot scenarios, where the different environments have varying numbers of agents.In this paper, we introduce MuRoSim, a multi-robot simulation for lidar-based navigation specifically designed for DRL applications. Due to its high level of abstraction, complete implementation in C++, and rigorous thread pool utilization, MuRoSim achieves high computational performance. We apply MuRoSim for training navigation policies for omnidirectional mobile robots equipped with lidar sensors using DRL. Finally, we conduct extensive Sim-to-Real experiments to confirm the realism of the simulator, by deploying the learned policy for dynamic navigation with up to six robots in numerous of real- world experiments.