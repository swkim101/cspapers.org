Visual topic modeling (VTM) provides key insight into data sets based on learned semantic topic models. The Gaussian-Dirichlet Random Field (GDRF), a state-of-the-art VTM technique, models these semantic topics in continuous space as densities. However, ambiguity in learned topics is a disadvantage of such Dirichlet-based VTM algorithms. We propose the Guided Gaussian-Dirichlet Random Field (GGDRF). Our method applies Dirichlet Forest priors from natural language processing (NLP) to the vision domain as a way to embed visual scientific knowledge into the estimation process. This modification and addition to the GDRF provides a key shift from unsupervised machine learning to semi-supervised machine learning in the robotic VTM domain. We show through simulation and real-world underwater data that the proposed GGDRF outperforms the previous GDRF method both quantitatively and qualitatively by improving alignment between estimated topics and scientific interests.