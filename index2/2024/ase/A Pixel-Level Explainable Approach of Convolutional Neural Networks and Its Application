Convolutional neural network (CNN) currently has been widely used to undertake the task of image classification. Unfortunately, a trained CNN model is a nonlinear system with high complexity, and the implicit decision knowledge carried by the CNN model is often difficult to be comprehended by humans. A feasible method to make human understanding of decision knowledge is to explain the classification basis of the trained CNN model. In order to solve the problem of insufficient interpretation accuracy of the existing methods, this paper presents a novel pixel-level explainable approach based on a guided symbolic execution strategy. A large number of experiments are conducted on the PyTorch team published CNN models, and the experimental results show that the presented approach is a 100% accurate technique for interpreting classification basis of input images on pixel-level compared the existing explainable methods. In addition, a scheme to enhance the adversarial robustness of CNN models is designed based on the presented explainable approach. The evaluation experiments show that the designed scheme provides an effective way to improve the adversarial robustness of the CNN models, and is a transferable technique in the CNN models that hold different structures.CCS CONCEPTS• Computing methodologies → Object recognition; • Software and its engineering • Software design engineering.