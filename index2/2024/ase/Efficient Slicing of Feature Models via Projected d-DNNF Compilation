Configurable systems often contain components from different fields or disciplines that are relevant for distinct stakeholders. For instance, tests or analyses targeting interactions of the software of a cyber-physical system may be only applicable for software components. However, managing such components in isolation is not trivial due, for instance, interdependencies between features. Feature models are a common formalism to specify such dependencies. Feature-model slicing corresponds to creating a subset of the feature model (e.g., with only components relevant to a particular stakeholder) that still preserves transitive dependencies from discarded features. However, slicing is computationally expensive and subsequent analyses often depend on complex computations, such as SAT or #SAT. With knowledge compilation, the original feature model can be translated to a beneficial format (e.g., d-DNNF or BDD) with an initial effort that accelerates subsequent analyses. Consequentially, acquiring a sliced target format depends on two expensive subsequent algorithms. In this work, we merge both steps by proposing projected d-DNNF compilation; a novel way to slice feature models that coincidently performs knowledge compilation to d-DNNF. Our empirical evaluation on real-world feature models shows that our tool pd4 often reduces runtimes substantially compared to existing techniques and scales to more input instances.