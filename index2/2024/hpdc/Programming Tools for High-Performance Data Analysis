In this paper we discuss and compare some of the most popular big data programming frameworks for high performance computing (HPC) systems, such as Hadoop, Spark, Storm, Airflow, MPI, Hive, Pig and UPC++. We highlight here their support to different classes of applications, such as batch, streaming, graph-based, and query-based applications. The main features of such frameworks according to their programming model, type of parallelism, level of abstraction, verbosity, and main classes of applications are summarized. We also discuss the main factors that can influence the choice of the most appropriate framework to process and analyze big data. These include the characteristics of input data, the class of application and the infrastructure requirements.