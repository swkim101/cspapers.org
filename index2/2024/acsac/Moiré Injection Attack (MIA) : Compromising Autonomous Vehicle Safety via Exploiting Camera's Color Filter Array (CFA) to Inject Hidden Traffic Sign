The rapid advancement of autonomous vehicles and AI-powered cameras has raised significant security concerns. This paper introduces the Moiré Injection Attack (MIA), a novel image creation attack capable of remotely injecting hidden attack images into cameras without physical contact while remaining invisible to the human eye. MIA leverages the camera's Moiré effect to automatically demodulate the captured hidden images, thereby deceiving AI models and jeopardizing the safety of autonomous vehicles. Compared to existing attacks, MIA offers several advantages: (i) it is effective in both daylight and nighttime conditions, (ii) it can inject arbitrary images into a camera, and (iii) it can target autonomous vehicles in a black-box manner. This paper details the creation and demodulation process of high-frequency MIA images, defines success metrics, and examines factors influencing MIA's effectiveness. An IRB-approved experiment with 20 college-age participants validates MIA's capability to compromise the front cameras of Tesla vehicles while evading human detection. Experimental results highlight the threat posed by MIA, especially for high-resolution cameras, with successful attacks at distances up to 80 meters. The state-of-the-art AI object detection model detects concealed attack images with an 86% frame-level detection rate at a confidence threshold of 0.7. The paper also proposes a novel software-based defense strategy to protect cameras from MIA. Demo can be seen at https://sites.google.com/view/morieinjection/home [1].