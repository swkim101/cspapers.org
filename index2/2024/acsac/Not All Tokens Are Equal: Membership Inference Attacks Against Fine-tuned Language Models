Membership inference attacks (MIAs), which aim to determine whether a specific sample is included in a machine learning modelâ€™s training set, have been recognized as a major privacy threat in recent years. Recent studies have shown that membership inference attacks can lead to privacy leaks in language models. Among existing methods for language model membership inference attacks, reference-based attacks exhibit good performance but require the attacker to obtain the training data distribution of the target model, which is impractical. Reference-free attacks impose lower requirements on attackers but tend to produce unsatisfactory results due to their excessive reliance on the overfitting of the target model. In this paper, we propose a practical Membership Inference Attack based on Weight-enhanced Likelihood (WEL-MIA). We investigate the membership inference difficulty at the token level and find that there are greater mean discrepancy of membership signals between members and non-members for tokens which are more difficult to predict. We also recognize that unreliable calibration probabilities pose an impediment to reference-based membership inference attacks. Anchored on the observation, we design different weights for tokens in the text, providing a new way of aggregating token-level member-ship signals for individual samples. Our attack uses a reference model to calibrate token-level probabilities, with the reference model fine-tuned on the target dataset, thereby producing more reliable calibration probabilities. In our assumption, attackers do not possess any auxiliary data, eliminating the need for the reference model to have prior knowledge of the same domain or distribution. We validate our method on several language models and datasets, and the results demonstrate that WEL-MIA achieves significant performance without relying on any auxiliary data.