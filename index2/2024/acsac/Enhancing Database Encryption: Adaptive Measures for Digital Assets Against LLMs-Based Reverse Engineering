With the development of large language models (LLMs) technology, generative AI (GAI) has significantly lowered the barriers to software reverse engineering attacks. Traditional database system security controls, face new challenges when confronted with the powerful analytical capabilities of GAI. This paper provides a detailed demonstration of the reverse engineering of database cryptographic functions using GAI tools. It finds that existing encryption mechanisms in embedded DBSs need new approaches to prevent internal data attacks. The main contributions are in two aspects. First, by emulating human reverse engineering and encrypted data theft behaviors, it demonstrates how to perform software reverse engineering using GAI tools. It reveals that LLMs can accelerate analysts in obtaining the keys needed for decryption or in identifying cache extraction points for decrypted data, enabling attackers to access sensitive information. Second, to counteract the strong code generation and analytical capabilities of LLMs, the paper proposes a solution based on random data blocks and timestamp-based decryption mechanisms. This approach aims to increase the cost for attackers using GAI tools to perform software reverse engineering and exploit potential vulnerabilities in database systems.