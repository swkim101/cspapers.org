Event Argument Extraction (EAE) aims to extract arguments for speciﬁed events from a text. Previous research has mainly focused on addressing long-distance dependencies of arguments, modeling co-occurrence relationships between roles and events, but overlooking potential inductive biases: (i) semantic differences among arguments of the same type and (ii) large margin separation between arguments of the different types. Inspired by prototype networks, we introduce a new model named HMPEAE, which takes the two inductive biases above as targets to locate prototypes and guide the model to learn argument representations based on these prototypes. Specifically, we set multiple prototypes to represent each role to capture intra-class differences. Si-multaneously, we use hypersphere as the output space for prototypes, deﬁning large margin separation between prototypes to encourage the model to learn signiﬁcant differences between different types of arguments effectively. We solve the “argument-prototype” assignment as an optimal transport problem to optimize the argument representation and minimize the absolute distance between arguments and prototypes to achieve compactness within sub-clusters. Experimental results on the RAMS and WikiEvents datasets show that HMPEAE achieves state-of-the-art performances.