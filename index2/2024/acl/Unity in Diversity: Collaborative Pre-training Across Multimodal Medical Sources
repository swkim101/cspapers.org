Although pre-training has become a prevalent 001 approach for addressing various biomedical 002 tasks, the current efficacy of pre-trained models 003 is hindered by their reliance on a limited scope 004 of medical sources. This limitation results in 005 data scarcity during pre-training and restricts 006 the range of applicable downstream tasks. In 007 response to these challenges, we develop M ED - 008 CSP, a new pre-training strategy designed to 009 bridge the gap between multimodal medical 010 sources. M ED CSP employs modality-level ag-011 gregation to unify patient data within individ-012 ual sources. Additionally, leveraging tempo-013 ral information and diagnosis history, M ED - 014 CSP effectively captures explicit and implicit 015 correlations between patients across different 016 sources. To evaluate the proposed strategy, we 017 conduct comprehensive experiments, where the 018 experiments are based on 6 modalities from 2 019 real-world medical data sources, and M ED CSP 020 is evaluated on 4 tasks against 19 baselines, 021 marking an initial yet essential step towards 022 cross-source modeling in the medical domain. 023