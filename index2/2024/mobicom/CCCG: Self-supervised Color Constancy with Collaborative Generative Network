Color constancy provides stable color features for high-level computer vision tasks such as target recognition and autonomous driving. Existing deep learning-based color constancy algorithms using convolutional neural networks remove the illumination and obtain images under standard illumination. However, these methods suffer from insufficient training data and poor robustness in complex scenes. To address these issues, we propose a new paradigm: self-supervised color constancy with a collaborative generative network (CCCG). CCCG transforms the illumination estimation problem into a generation problem, reducing the solution space and enhancing algorithm robustness in complex scenes. Additionally, CCCG employs a self-supervised network structure, reducing dependence on light source label data. CCCG comprises two network structures: the Filter Network (FN) and the Illumination Network (IN). FN extracts features from the image and generates an image under standard illumination. IN incorporates the extracted physical light source information into the output results of FN and verifies the generated image. Experimental results on the Gehler-Shi and NUS-8 datasets show that CCCG outperforms current color constancy methods across various evaluation metrics and can be applied to other computer vision tasks requiring color constancy preprocessing.