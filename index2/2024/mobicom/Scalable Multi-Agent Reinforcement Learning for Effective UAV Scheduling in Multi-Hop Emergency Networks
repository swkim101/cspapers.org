Utilizing unmanned aerial vehicles (UAVs) as mobile access points can assist urban communication systems in establishing emergency networks in disaster scenarios. However, in large-scale dynamic environments, the extensive exploration space makes effective collaboration among a large number of UAVs challenging. In this paper, to schedule the deployment of UAVs for networking purposes, we propose a novel approach, MAEN, using multi-agent reinforcement learning. The grouping and information sharing mechanisms in MAEN enable the algorithm to easily scale up the number of UAVs to dozens and address the issue of strategy equilibrium. Additionally, a reward decomposition module is designed to handle coordination and task allocation among UAVs. Experimental results demonstrate that the algorithm outperforms existing algorithms in terms of ground device coverage and communication quality.