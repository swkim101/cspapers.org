Virtual reality (VR) presents a rapidly evolving virtual world with varying types of visual content. Authenticating users periodically across different types of VR content to safeguard private data is a cornerstone in many sensitive VR applications. Previous studies have performed authentication by verifying users' actions or involuntary responses to certain visual stimuli. However, these methods tie users to either a predefined task or a single type of VR content, failing to support periodic authentication in dynamic VR interactions. In this paper, we propose a cross-content authentication framework that verifies users across different VR content by jointly analyzing eye movements and VR content. Specifically, we decouple displayed VR content from eye movements and generate a content-agnostic embedding determined by cognitive and physiological attributes unique to each user. Experiments with video viewing and text reading in VR show that our system achieves an F-score of 0.92 in cross-content user authentication.