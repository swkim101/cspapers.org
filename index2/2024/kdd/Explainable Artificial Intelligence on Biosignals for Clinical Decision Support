Deep learning has proven effective in several areas, including computer vision, natural language processing, and disease prediction, which can support clinicians in making decisions along the clinical pathway. However, in order to successfully integrate these algorithms into clinical practice, it is important that their decision-making processes are transparent, explainable, and interpretable. Firstly, this tutorial will introduce targeted eXplainable Artificial Intelligence (XAI) methods to address the urgent need for explainability of deep learning in healthcare applications. In particular, it focuses on algorithms for raw biosignals without prior feature extraction that enable medical diagnoses, specifically electrocardiograms (ECG) -- stemming from the heart -- and electroencephalograms (EEG) representing the electrical activity of the brain. Secondly, participants are provided with a comprehensive workflow that includes both data processing and an introduction to relevant network architectures. Subsequently, various XAI methods are described and it is shown, how the resulting relevance attributions can be visualized on biosignals. Finally, two compelling real-world use cases are presented that demonstrate the effectiveness of XAI in analyzing ECG and EEG signals for disease prediction and sleep classification, respectively. In summary, the tutorial will provide the skills required for gaining insight into the decision process of deep neural networks processing authentic clinical biosignal data.