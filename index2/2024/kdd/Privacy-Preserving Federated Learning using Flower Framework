AI projects often face the challenge of limited access to meaningful amounts of training data. In traditional approaches, collecting data in a central location can be problematic, especially in industry settings with sensitive and distributed data. However, there is a solution -"moving the computation to the data" through Federated Learning. Federated Learning, a distributed machine learning approach, offers a promising solution by enabling model training across devices. It is a data minimization approach where direct access to data is not required. Furthermore, federated learning can be combined with techniques like differential privacy, secure aggregation, homomorphic encryption, and others, to further enhance privacy protection. In this hands-on tutorial, we delve into the realm of privacy-preserving machine learning using federated learning, leveraging the Flower framework which is specifically designed to simplify the process of building federated learning systems, as our primary tool. Moreover, we present the foundations of federated learning, explore how different techniques can enhance its privacy aspects, how it is being used in real-world settings today and a series of practical, hands-on code examples that showcase how you can federate any AI project with Flower, an open-source framework for all-this federated.