Simultaneous Localization and Mapping (SLAM) technology is a rapidly developing field in robotics. Most existing SLAM algorithms lack robustness in dynamic environments because moving objects can influence mapping and localization accuracy, making it challenging for robots to identify moving objects and understand their surroundings. Though some works proposed semantic SLAM methods, they rely on point-based feature extraction and matching algorithms with semantic information and simply exclude dynamic objects. In this work, we proposed real-time RGB-D SLAM to combine point, line, and plane features with object detection to increase the robustness in dynamic environments. The proposed method combines object detection, feature points, and lines to identify moving objects and uses feature planes and semantic information to identify constrained moving objects. Thus, the localization accuracy can be improved under dynamic environments by excluding or using dynamic objects. Experiments were conducted on a public TUM dataset and in a real-world environment. The result shows that the proposed SLAM algorithm can increase the dynamic object detection speed and the robustness of SLAM performance compared to state-of-the-art in dynamic environments.