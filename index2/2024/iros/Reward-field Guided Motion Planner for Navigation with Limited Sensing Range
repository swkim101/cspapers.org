In this paper, we focus on improving planning efficiency for ground vehicles in navigation and exploration tasks where the environment is unknown or partially known, leading to frequent updates of the navigational goal as new sensory information is acquired. Asymptotically optimal motion planners like RRT* or FMT* can be used to plan the sequence of actions the robot can follow to achieve its current goal. Frequent replanning of the whole action sequence becomes computationally demanding when actions are not executed precisely because of limited information about the foreground terrain. The decoupled approach can decrease the computational burden with separated path planning and path following; however, it might lead to suboptimal solutions. Therefore, we propose a novel approach based on generating a reusable reward function that guides a fast sampling-based motion planner. The proposed method provides improved results in navigation scenarios compared to the former approaches, and it led to about 7% faster autonomous exploration than the decoupled approach. The present results support the suitability of the proposed method in navigation tasks with continuously updated navigation goals.