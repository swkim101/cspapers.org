Topological semantic maps provide a practical solution to enhance indoor navigation for the Partially Sighted or Visually Impaired (PSVI). Segmenting indoor floor plans and extracting boundaries are key to constructing these maps. The existing methods exhibit low accuracy in segmentation. To achieve desired high segmentation accuracy, we introduce a Context-Enhanced Full-Resolution Network (CEFRN) for floor plan segmentation. It is designed to harness the shallow detailed features and inter-category contextual dependencies inherent in floor plans. CEFRN integrates modified residual blocks to capture the low-stage full-resolution features while maintaining its compactness. A position attention module is employed to refine the deep-stage contextual information. We also propose a two-dimensional deep supervision method to merge features from both stages, which significantly boosts the feature representation ability of CEFRN. Finally, a practical topological semantic mapping method for PSVI indoor navigation is introduced. Experimental results demonstrate that CEFRN’s segmentation accuracy well exceeds the state-of-the-art methods’. It can be used to well support accurate topological semantic mapping.