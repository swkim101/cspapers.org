Probabilistic Movement Primitives (ProMPs) and their variants are powerful methods for enabling robots to learn complex tasks from human demonstrations, where motion trajectories are represented as stochastic processes with Gaussian assumptions. However, despite their computational efficiency, these methods have limited expressiveness in capturing the diversity found in human demonstrations, which are typically characterized by the multi-modality of motions. For example, when picking up an object partially obscured by an obstacle, some individuals may opt to go to the right, while others may choose the left side of the object. In this paper, we introduce Stein Movement Primitives (SMPs), a novel approach to probabilistic movement primitives. We formulate motion primitive adaptation as a non-parametric probabilistic inference using Stein Variational Gradient Descent (SVGD), thus avoiding any explicit posterior distribution assumptions and enabling the direct representation of the multi-modality in human demonstrations. We illustrate how our method can adapt robot motion to different scenarios while maintaining high similarity to the original demonstrations, even when the demonstrations are multi-modal. Experimentally, we demonstrate our approach to several domain adaptation problems using the LASA dataset and with a real robotic arm.