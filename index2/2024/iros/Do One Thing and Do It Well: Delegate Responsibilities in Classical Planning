We propose a novel framework and algorithm for solving classical planning problems with an implicit hierarchical solver based on the principle of delegation. This framework, the Markov Intent Process, features a collection of skills that are each specialised to perform a single task well. Skills are aware of their intended effects and are able to analyse planning goals to delegate planning to the best-suited skill. This principle dynamically creates a hierarchy of plans, in which each skill plans for sub-goals for which it is specialised. Our method performs robustly in noisy environments with non-deterministic action effects and features on-demand executionâ€”skill policies are only evaluated when needed. Plans are only generated at the highest level, then expanded and optimised when the latest state information is available. The high-level plan retains the initial planning intent and previously computed skills, effectively reducing the computation needed to adapt to environmental changes. We show this planning approach is experimentally very competitive to classic planning and reinforcement learning techniques on a variety of domains, both in terms of solution length and planning time.