Unmanned aerial vehicles (UAVs), known for their agile flight capabilities, require safe trajectory planning to achieve high-speed flights. This is necessary to swiftly evade obstacles and adapt trajectories under hard real-time constraints. These adjustments are essential to generate viable paths that prevent collisions while maintaining high speeds with minimal tracking errors. This paper addresses the challenge of enhancing the safety of agile trajectory planning. The proposed method combines a supervised learning approach, as teacher policy, with deep reinforcement learning (DRL), as student policy. Initially, we train the teacher policy using a path planning algorithm that prioritizes safety while minimizing jerk and flight time. Then, we use this policy to guide the learning of the student policy in various unknown environments. Testing in simulation demonstrates noteworthy advancements, including an 80% reduction in tracking error, a 31% decrease in flight time, a 19% increase in high-speed duration, and a success rate improvement from 50% to 100%, as compared to baseline methods.