In this paper, we introduce a framework for imitation learning in navigation that enables policy learning from one-shot images without a physical robot and facilitates the transfer of this policy from simulation to reality. Utilizing Neural Radiance Fields (NeRF), our approach generates a simulated environment and simultaneously models expert behavior. This removes the necessity for a physical robot during both the expert teaching phase and the agentâ€™s learning process, allowing for the application of policies learned within the NeRF simulation to real-world robots. We validate our method by demonstrating the navigation with an actual robot using the policy learned by our approach. Moreover, we present a method for adapting to changes in the robot configuration, such as camera parameters and robot dimensions, by simulating adjustments in the robot configuration throughout the learning and assessing its generalizability.