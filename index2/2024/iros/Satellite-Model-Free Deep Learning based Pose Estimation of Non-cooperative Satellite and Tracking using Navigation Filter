One core component of Active Debris Removal (ADR) and On-Orbit Servicing (OOS) missions in space is to estimate and track the relative pose of a non-cooperative satellite in close proximity. Conventionally, Image Processing methods have been popular in pose estimation by employing manual feature extraction techniques. But the performance of such methods plateaus in the challenging illumination conditions and sensor capability constraints in space, because of which Deep Learning (DL)-based approaches have gained traction. This paper aims to provide an improvement over the existing state-of-the-art direct pose estimation methods from a monocular camera, without relying on any 3D model of the target satellite. The main contribution of this work is to develop a general purpose satellite-invariant pose estimation architecture with improved accuracy and implement an adaptive navigation filter over it to track the pose continuously over a stream of images. The pose estimation module includes a modified DenseNet architecture. In order to test the generalization capability, the proposed pose estimation module is tested on the SPEED, SPEED+, SHIRT and URSO datasets and compared with other existing methods. The advantage of the proposed method is that the same model architecture is able to give accurate pose estimation results for different satellite datasets. To perform continuous tracking of the relative pose, an adaptive EKF (Extended Kalman Filter) is implemented on the initial pose estimates. For performance evaluation of the navigation filter, the accuracy goals required for the relative navigation of Hubble Space Telescope SM4 mission are considered while testing on the SHIRT dataset.