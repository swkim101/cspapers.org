Falls and fall risk management are challenges that are increasing in an aging society, exacerbated by the decreasing availability of care professionals to provide suitable fall management plans. Technology may provide a solution to this, with robotics and vision systems receiving increased attention. A pilot study was conducted using a vision system mounted on a Turtlebot 4, MoveNet, and different machine learning algorithms to assess a Timed Up and Go (TUG) test. The system was evaluated on the performance of a previously trained action classifier and by comparing times for the different phases of the TUG test from the output of the model with the output from the QTUG test acquired by IMU sensors worn by the participants. The results showed the system could determine if the person was sitting, in transition, or standing with high accuracy (97.09%) with higher levels of consistency for participants between tests than the QTUG. This demonstrates that the system is not only advantageous requiring minimal user input but also can match the performance of wearable sensors that are considered the "gold standard" for TUG tests.