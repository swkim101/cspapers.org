The expanding use of automated vision, assistance systems, and augmented reality applications in marine settings calls for reliable and accurate horizon detection and locking. Traditional methods utilizing Inertial Measurement Units (IMU) or feature-based computer vision techniques often yield inconsistent results, particularly when unmanned surface vehicles or boats are subject to high-speed movement or choppy waters. Addressing this, our work introduces a computer vision (CV)-based solution for real-time horizon locking. Employing real-time semantic segmentation, we accurately differentiate between sky, land or water in the frame, enabling computational locking of the horizonâ€™s position. This stable visual reference significantly improves the performance and reliability of on-board systems for autonomous navigation, augmented reality overlays, and multi-object tracking. Supported by a dataset collected under various marine conditions, our method has proven to achieve high accuracy with low computational latency, making it a promising avenue for wide-scale implementation on automated and semi-automated systems.