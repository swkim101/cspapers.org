Unmanned Aerial Vehicles (UAVs) with limited computational, perception and power resources face significant challenges when navigating autonomously in unfamiliar environments. While artificial intelligence (AI)-assisted algorithms have been used to address these limitations, transparency of the underlying AI models remains a concern, hindering user trust. To address this limitation, this research study proposes a novel, explainable AI-based navigation approach for UAVs to navigate them through unknown environments autonomously. The soft actor-critic (SAC) algorithm and multilayer perceptron (MLP) policies integrated deep reinforcement learning algorithm is developed to derive control actions. This controller is integrated with a novel moving-window gradient-based explainable artificial intelligence (XAI) framework to shed light on the UAV’s decision-making process. The proposed XAI algorithm provides granular insights into how various factors, such as image segments and UAV state features, influence the UAV’s actions. It lays the groundwork for a novel visual explanation approach that segments input depth images to highlight critical navigational cues, augmented by a dynamic color map for precise obstacle identification. Additionally, the study introduces comprehensive textual explanations to provide an in-depth understanding of the UAV’s decision processes, thereby improving the model’s transparency and explainability. The simulation results indicate that the proposed DRL model achieves over 95% success rate. Moreover, evaluations conducted in two distinct environments demonstrate the model’s capability to generate effective and reliable explanations.