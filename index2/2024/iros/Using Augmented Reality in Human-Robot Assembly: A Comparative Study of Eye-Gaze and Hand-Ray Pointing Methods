Collaborative robots (cobots) are a promising technology for frontline workers in industry. They can support tasks that cannot be fully automated but are repetitive, fatiguing, boring, or dangerous for humans. Although cobots are explicitly designed to work with humans, they remain primarily non-intuitive and difficult to collaborate with. Thus, there is a need for new interaction approaches to facilitate efficient human-robot collaboration. Recently, we could see emerging examples of using augmented reality (AR) to assist a worker in collaborative task execution with a cobot. However, for such an approach to provide truly efficient support for the seamless bimanual task execution, we need to first investigate interaction methods offered by an AR interface. To that end, we performed a study with sixteen participants to compare eye-gaze and hand-ray pointing methods for part selection in collaborative, manual assembly tasks. The results of our study show that both techniques provide similar perceived usability, with the eye-gaze selection leading to significantly shorter completion times.