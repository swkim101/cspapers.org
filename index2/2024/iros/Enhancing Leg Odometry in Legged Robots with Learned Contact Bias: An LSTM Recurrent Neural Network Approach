To address the leg odometry drift caused by the non-stationary foot contact, this paper introduces a novel data-driven based leg odometry technique for legged robots. By leveraging a Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN), the method learns the biases in the robotâ€™s foot contact locations from sequential IMU measurements and ground reaction forces (GRF). This learned contact bias is then incorporated into the state estimation process using a Kalman filter (KF), significantly improving the precision of leg odometry for legged robots operating in real time. This method, which combines deep learning approaches with conventional filtering techniques, is named the Deep Learning Kalman Filter (DLKF). The effectiveness of the DLKF is demonstrated through simulation and experimental trials using a Unitree Go1 robot across various challenging environments, including uneven terrain, slopes, and stairs, where foot slippage occurs frequently. Our results indicate an average 64.93% reduction in translational errors in leg odometry when the learned contact bias is applied. Further improvements are observed in a fused LiDAR and leg odometry state estimation system, especially in feature-deprived areas, indicating that the proposed leg odometry system can be easily fused with other sensor measurements to get a more precise state estimation.