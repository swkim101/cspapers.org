This work presents a machine learning (ML) technique to suppress reference ripple errors in successive approximation register (SAR) analog-to-digital converter (ADC). Reference voltage ripple due to switching in SAR ADC introduces dynamic error which manifests as spurs in the output spectrum and limits ADC resolution. Conventional techniques to suppress reference ripple require large decoupling capacitor and high-speed reference voltage buffer which consume large area and power. The proposed ML approach uses a supervised technique in which a low-speed 10MHz SAR ADC is used for learning and correcting reference ripple error in a 200MHz SAR ADC. Simulated in 28nm CMOS technology, the proposed ML approach reduces overall ADC power consumption by 4.9x without degrading performance.