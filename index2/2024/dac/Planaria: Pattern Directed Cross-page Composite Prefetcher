Given the memory wall, the performance of the memory system significantly influences the user experience of mobile phones. The system cache (SC), located on the memory side, is shared among all CPUs and GPUs within the mobile phone, serving as the last line of defense before resorting to time-consuming off-chip memory access. Managing SC is a challenge due to its large working set and irregular access patterns. Despite occupying a substantial on-chip area, SC's effectiveness in terms of hit rate is relatively low. It has been observed that neither state-of-the-art cache replacement policies nor increasing cache size significantly improve SC performance. Prefetchers designed for higher-level caches cannot be seamlessly applied to SC due to the absence of the required program counter (PC) on the memory side and the violation of stringent power constraints in mobile phones by aggressive prefetch traffic. In this study, we present Planaria, comprising two sub-prefetchers (SLP and TLP) and a coordinator, aiming to achieve high accuracy and coverage simultaneously. The two sub-prefetchers exploit intra- and inter-page regularities through self and transfer learning, respectively. The coordinator explicitly decouples the learning and issuing phases of the sub-prefetchers. Experimental results demonstrate that Planaria has enhanced overall system performance in terms of instructions per cycle (IPC) by an average of 28.9%, 21.9%, and 15.3% over no prefetcher, BOP, and SPP, respectively. Moreover, Planaria proves to be power-efficient, incurring only a 0.5% increase in power consumption, while BOP and SPP increase power consumption by 13.5% and 9.7%, respectively.