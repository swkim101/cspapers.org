Causal reasoning is a key factor that allows human beings to effortlessly draw parallels between two seemingly different tasks. Given access to a limited number of human-generated causal models, if robots could be taught to perform a similar "transfer", then they could potentially generalize to different domains using limited human intervention. The goal is to effectively generate human-like causal models for an unknown task by learning from a small dataset of human-generated causal models on other related tasks. In this paper we propose two different methods to leverage causal models obtained from humans to generalize to a new task. We ran a user study to obtain causal models on how different light-producing objects function. We then explore one-to-one transfer, where we directly use a causal model generated by a participant to infer the causal model of another object. We also explore many-to-one transfer, where we leverage causal models from different objects and users to infer the causal model of an unknown object. Automated transfer of causal models from humans to unrelated domains has the potential to replicate human-like reasoning in an unknown scenario in the absence of an expert. That chain of reasoning represented through causal models can then be used by autonomous agents to guide several downstream tasks such as object assembly, trouble shooting, and repair.