Computing-in-memory (CIM), a promising computing paradigm, has demonstrated great energy-efficiency by integrating computing units into memory. However, previous research on CIM has rarely utilized sparsity in activation and weight concurrently. Moreover, new challenges arise when harnessing sparsity in both activation and weight (two-sided sparsity), such as unbalanced workload and low hardware substrate utilization. To fully unleash the acceleration potential brought by two-sided sparsity, we implemented an accelerator called Dyn-Bitpool which innovates on two fronts: 1) a balanced working scheme called "pool first and cross lane sharing" to maximize the available performance benefiting from bit-level sparsity in activation; 2) dynamic topology of CIM arrays to effectively handle low CIM macro utilization issue stemming from value-level sparsity in weight. All the contributions collaborate to speed up Dyn-Bitpool by 1.89x and 2.64x on average on Googlenet, Mobilenetv3, Resnet50, ResNeXt101 and VGG19, compared with two state-of-the-art accelerators featuring CIM.