Decision trees are an important class of supervised learning algorithms. When multiple entities contribute data to train a decision tree (e.g. for fraud detection in the financial sector), data privacy concerns necessitate the use of a privacy-enhancing technology such as secure multi-party computation (MPC) in order to secure the underlying training data. Prior state-of-the-art (Hamada et al. [18]) construct an MPC protocol for decision tree training with a communication of O( â„ğ‘šğ‘ log ğ‘ ) , when building a decision tree of height â„ for a training dataset of ğ‘ samples, each having ğ‘š attributes. In this work, we significantly reduce the communication complexity of secure decision tree training. We construct a protocol with communication complexity O( ğ‘šğ‘ log ğ‘ + â„ğ‘šğ‘ + â„ğ‘ log ğ‘ ) , thereby achieving an improvement of â‰ˆ min ( â„,ğ‘š, log ğ‘ ) over [18]. At the core of our technique is an improved protocol to regroup sorted private elements further into additional groups (according to a flag vector) while maintaining their relative ordering. We implement our protocol in the MP-SPDZ framework [1, 22] and show that it requires 10 Ã— lesser communication and is 9 Ã— faster than [18].