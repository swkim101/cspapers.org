This paper concerns the design of contracts to incentivize experts to acquire information for predicting a future state when doing so is costly and when this information acquisition is private. This problem may arise in a variety of situations, often when the contract designer expects to make a high-stakes decision---for instance, whether to launch a military attack in response to a perceived threat, whether to make a sizable investment, or whether to approve a risky vaccine to fight a budding pandemic. In these cases, whether a given action is best (e.g., invasion, investment, approval, respectively, for the above examples) may depend on the underlying state, which we will take as binary in this paper for simplicity. Notice that this problem features the combination of moral hazard (since the principal cannot monitor the expert's effort) and endogenous adverse selection (since the expert's actions generate private information). In our model, while the agent has no direct interest in the state or the principal's action, he can be rewarded with a prize on which (i) he places bounded value, but (ii) the principal places no intrinsic value. For example, this reward could be a recommendation or a grade, often much more valuable for early-career workers than any feasible direct payment. Alternatively, this could also reflect budget constraints on the principal, where the residual value of payments is second-order relative to the value of information. Crucially, the rewards given to the expert can depend on the state of interest, where this state is unaffected by the principal's actions. Allowing the reward to depend on the state incentivizes the agent to exert effort to learn about it. Moreover, we consider an information acquisition environment for the expert where learning takes time. Thus, the principal must provide incentives for effort to be exerted repeatedly, with possible interactions between the incentives provided at earlier times and later times. For this dynamic information acquisition problem, we identify conditions that each individually ensure that the principal cannot do better than by eliciting a single report from the agent after all information has been acquired. We also show that such a static contract is suboptimal under sufficiently strong violations of these conditions. We contrast our solution to the case where the agent acquires information "all at once;" notably, the optimal contract in the dynamic environment may provide strictly positive base rewards to the agent even if his prediction about the state is incorrect. A full version of this paper can be found at https://arxiv.org/abs/2310.19147.