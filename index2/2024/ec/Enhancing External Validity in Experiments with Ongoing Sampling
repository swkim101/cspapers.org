Online controlled experiments, often referred to as A/B tests, are extensively conducted by major technology companies to evaluate the effectiveness of product strategies and inform product decision-making. The sampling process in A/B tests is not instantaneous; subjects, such as users of online platforms, arrive at the platform over time and are recruited continuously throughout the experiment. This ongoing nature of sampling can lead to shifts in sample characteristics over the experimental duration, raising issues of external validity. In other words, the causal findings derived from an experiment of a particular duration may not be applicable to the target population, potentially biasing decision-making. In this paper, we propose a framework that dynamically identifies sample representativeness and introduces stage-specific strategies for estimating the Average Treatment Effect (ATE) for the target population. Our framework does not require prior knowledge or continuous monitoring of the distributions of the sample or population, which is often costly to obtain in practice. Specifically, we delineate the sampling process into three distinct stages, each exhibiting varying degrees of sample representativeness and result generalizability for the population. To identify these stages, we develop a heuristic function based on the estimated probability of participation across covariates in real-time, leveraging survival analysis models. Moreover, we create unbiased estimators for Population Average Treatment Effects (PATE) for the target population at each of the stages. Our framework, serving as a white-box heuristic-based tool, aids product decision-makers in balancing sample representativeness and experimental cost upon the termination of experimentation. We also provide an estimation scheme that can be applied at different stages of the experiment to improve the external validity of experiments. We validate our method using both synthetic data and real-world experimental data --- 600 A/B tests from Weixin (WeChat's analog in China) --- demonstrating consistent effectiveness across different scenarios. We showcase that our framework improves the probability of detecting effective treatments by approximately 37--56% without erroneously categorizing ineffective treatments in industry applications. For the full paper, please visit: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4871505.