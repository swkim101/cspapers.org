Private inference using homomorphic encryption has gained a great attention to leverage powerful predictive models, e.g., deep convolutional neural networks (CNNs), in the area where data privacy is crucial, such as in healthcare or medical services. Processing convolution layers, however, occupies a huge portion (more than 85%) of the total latency for private CNN inference. To solve this issue, this paper presents Hyena utilizing a novel homomorphic convolution algorithm that provides speedup, communication cost, and storage saving. We first note that padded convolution provides the advantage of model storage saving, but it does not support output channel packing, thereby increasing the amount of computation and communication. We address this limitation by proposing a novel plaintext multiplication algorithm using the Walsh-Hadamard matrix. Furthermore, we propose the optimization techniques to significantly reduce the latency of the proposed convolution by selecting the optimal encryption parameters and applying lazy reduction. Overall, Hyena achieves 1.6-3.8x speedup and reduces the weight storage by 2000-8000x compared to the conventional convolution. For deep CNNs like VGG-16, ResNet-20, and MobileNetV1 on ImageNet, Hyena reduces the end-to-end latency by 1.3-2.5x, the memory usage by 2.1-7.9x and communication cost by 1.4-1.5x compared to conventional method.