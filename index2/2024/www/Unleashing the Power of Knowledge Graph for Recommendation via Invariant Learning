Knowledge graph (KG) demonstrates substantial potential for enhancing the performance of recommender systems. Due to its rich semantic content and associations among interactive entities, it can effectively alleviate inherent limitations in collaborative filtering (CF), such as data sparsity or cold-start issues. However, most existing knowledge-aware recommendation models indiscriminately aggregate all information in KG, without considering information specifically relevant to the recommendation task. Such indiscriminate aggregation could introduce additional noisy knowledge into representation learning, which can distort the understanding of users' genuine preferences, thereby sacrificing the recommendation quality. In this paper, we introduce the principle of invariance to the knowledge-aware recommendation, culminating in our Knowledge Graph Invariant Learning (KGIL) framework. It aims to discern and harness the task-relevant knowledge connections within KG to enhance the recommendation models. Specifically, we employ multiple environment generators to simulate diverse noisy KG-environments. Then we devise a novel attention learning mechanism for KG and user-item interaction graph, aiming to learn environment-invariant subgraphs. Leveraging an adversarial optimization strategy, we enhance the diversity of the environments, meanwhile, promote invariant representation learning across environments. We conduct extensive experiments on three datasets and compare KGIL with state-of-the-art methods. The experimental results further demonstrate the superiority of our approach.