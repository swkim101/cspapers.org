Performing an object detection task after the restoration of a hazy image, or rather detecting with the network backbone directly, will result in the inclusion of information mixed with dehazing, which tends to interfere with detection performance. To address these issues, we propose a novel framework for detecting objects in dehazed images via Dual Cross-Stage Partial Learning (DCSP). Specifically, we introduce a Cross-Stage Partial (CSP) module for extracting clean feature information after dehazing. Secondly, to enhance data integrity, we employ a skip-input strategy to supplement information related to object detection features that may be lost during the dehazing task, while avoiding the gradient vanishing problem. In addition, CSP is also introduced to facilitate comprehensive learning of multiple feature representations. Finally, to avoid the inclusion of irrelevant dehazing information in detection, we apply a Ground-Truth Flow at detection network (at dark3), for fine feature information calibration. Additionally, we created a synthetic fog dataset to expand the training data for DCSP. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness and accuracy of the proposed method. The code is available at https://github.com/zhaojinbiao/DCSP.