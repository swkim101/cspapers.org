Representation learning remains one of the most important but challenging tasks within industrial music rec-ommendation systems. In the context of the Matthew effect, item exposure frequency demonstrates substantial inequality, leading to the Harry Potter problem for popular items and the long-tail issue for less interacted items, collectively impairing the adequacy and accuracy of representation learning. In this paper, to alleviate the negative impact of bias on representation learning in music recommendation systems, we propose a unified model based on introducing the unbiased Cascading Multimodal Feature, called CMF4Rec. Specifically, with our cascading feature enhancement module, we implement a dual-stage representation enhancement strategy. In the first stage, the pivotal subsequence is extracted from the coarse-grained similarity sequence derived from cascading multimodal features, which is subsequently ag-gregated to generate the enhanced representation of the candidate item. Moreover, in the feature interaction module, the enhanced representation is crossed with user behaviors to capture the diverse and dynamic interests of users. Furthermore, we employ contrastive learning and design an auxiliary contrastive task to provide high-quality gradients for the main recommendation task. We demonstrate the effectiveness of this model with extensive experiments on public and industrial datasets. Moreover, the deployment of CMF4Rec in a real music recommendation system has also yielded significant improvements.