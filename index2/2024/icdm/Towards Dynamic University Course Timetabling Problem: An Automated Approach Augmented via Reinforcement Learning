University Course Timetabling Problem (UCTP) is a significant resource allocation challenge with NP-hard characteristics. As problem sizes increase, finding an optimal solution becomes increasingly complex. To address this, we propose an automated planning method using Reinforcement Learning (RL), which treats UCTP as a series of dynamic decision-making tasks. The RL agent acts as an automated planner, operating in a simulated environment that reflects the complexity and constraints of a university course. It adapts to changes in the timetable by evaluating the outcomes of its actions, continuously refining its strategy to identify and implement the most effective actions. During the explore phase, the agent tests new strategies using a priority-driven reward system and an experience replay mechanism. This approach replays high-value actions, enhancing solution diversity and reducing the search space. In the exploit phase, the agent leverages its accumulated knowledge to apply proven effective strategies. It also incorporates unbiased external evaluations to avoid local optima and ensure global optimization of its strategy. Extensive testing on multiple real-world datasets shows that our automated planning framework consistently outperforms existing methods in various complex scheduling scenarios. This confirms its effectiveness and practicality in meeting diverse scheduling needs.