Multi-instance partial-label learning (MIPL) tackles scenarios where each training sample is represented as a multiinstance bag associated with a candidate label set. This set contains one true label and several false positives. Existing MIPL algorithms have predominantly focused on mapping multiinstance bags to candidate label sets for disambiguation. However, these algorithms may not be adequately generalizable in intricate real-world situations due to their reliance on heuristic methods for identifying true labels. In this paper, we propose PROMIPL, i.e., a PRObabilistic generative model for Multi-instance partiallabel learning, to address these challenges. PROMIPL is the first attempt to explore the probabilistic generative model to infer latent ground-truth labeling information from the data generation process in multi-instance partial-label learning. Besides, the discovered underlying structures also provide improved explanations of the classification predictions. To circumvent the computationally intensive process of training the generative model, we formulate a unified variational lower bound within the stochastic gradient variational Bayesian framework for the model parameters. Experimental results from benchmark and realworld datasets show that our proposed PROMIPL is competitive or superior to the state-of-the-art methods.