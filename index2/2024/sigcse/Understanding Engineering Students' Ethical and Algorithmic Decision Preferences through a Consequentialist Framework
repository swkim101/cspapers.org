As developments in the field of artificial intelligence (AI) continue to rapidly advance its possible applications, it becomes increasingly crucial for those developing AI systems to understand how receptive the general public will be to their work. The overarching goal of this research is to understand human decision-making (HDM) and human perspectives on algorithmic decision-making based on varied payoffs and outcomes. We conducted a pair of surveys, where the participants were asked about their understanding of AI, as well as their thoughts about the application of AI in the context of an autonomous vehicle placed in an ethically challenging situation. Our analysis focuses on participants' responses to two questions characterized by experimental variations, with additional variation in the consequences presented in those same questions between the two surveys. In total, we collected 284 responses from these surveys administered to engineering students of an introductory programming course for two consecutive semesters in 2022. We qualitatively analyzed the data for individual questions using an inductive approach and identified major themes related to the question asked. From this analysis, found that engineering students' perspectives on an ethically complex scenario were greatly impacted by the controlled variance in consequences, and have developed a framework for tracing their decision-making to their decisions and reasoning. Offering valuable insight about how students reason when it comes to ethics to educators in charge of working on developing engineering ethics curricula.