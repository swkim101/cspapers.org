The growth of scale and complexity of interactions between humans and robots highlights the need for new computational methods to automatically evaluate the performance of novel algorithms and applications. Strong evaluation methods should explore the diverse scenarios of interaction between humans and robots. We propose quality diversity (QD) algorithms as a method for simultaneously exploring both environments and human actions to discover diverse failure scenarios. We focus on the shared autonomy domain, where the robot attempts to infer the goal of a human operator. We evaluate our approach by automatically generating scenarios for two published algorithms in this domain: shared autonomy via hindsight optimization and linear policy blending. Some of the generated scenarios confirm previous theoretical findings, while others are surprising and bring about a new understanding of state-of-the-art implementations. Our experiments show that QD outperforms Monte-Carlo simulation and optimization based methods in effectively searching the scenario space, highlighting its promise for automatic evaluation of algorithms in shared autonomy.