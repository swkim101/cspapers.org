A common task in data analysis is to compute an approximate embedding of the data 
in a low dimensional subspace. This is used, for example, for dimensionality reduction.
Robust Subspace Recovery computes the embedding by ignoring a fraction of the data 
considered as outliers.
Its performance can be evaluated by how accurate the inliers (non-outliers) are represented. 
We propose a new algorithm that outperforms the current state of the art
when the data is dominated by outliers.
The main idea is to rank each point by evaluating the change in the global PCA error 
when that point is considered as an outlier.
We show that this lookahead procedure can be implemented efficiently
by centered rank-one modifications.