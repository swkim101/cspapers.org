In this paper we address a variant of the continuous multi-armed bandits problem, called the threshold estimation problem, which is at the heart of many psychometric experiments. Here, the objective is to estimate the sensitivity threshold for an unknown psychometric function Ψ , which is assumed to be non decreasing and continuous. Our algorithm, Dichotomous Optimistic Search ( DOS ), efﬁciently solves this task by taking inspiration from hierarchical multi-armed ban-dits and Black-box optimization. Compared to previous approaches, DOS is model free and only makes minimal assumption on Ψ smoothness, while having strong theoretical guarantees that compares favorably to recent methods from both Psychophysics and Global Optimization. We also empirically evaluate DOS and show that it signiﬁcantly outperforms these methods, both in experiments that mimics the conduct of a psychometric experiment, and in tests with large pulls budgets that illustrate the faster convergence rate.