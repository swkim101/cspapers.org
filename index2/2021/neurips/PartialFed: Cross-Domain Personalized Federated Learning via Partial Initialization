The burst of applications empowered by massive data have aroused unprecedented privacy concerns in AI society. Currently, data conﬁdentiality protection has been one core issue during deep model training. Federated Learning (FL), which enables privacy-preserving training across multiple silos, gained rising popularity for its parameter-only communication. However, previous works have shown that FL revealed a signiﬁcant performance drop if the data distributions are heterogeneous among different clients, especially when the clients have cross-domain characteristic, such as trafﬁc, aerial and in-door. To address this challenging problem, we propose a novel idea, PartialFed , which loads a subset of the global model’s parameters rather than loading the entire model used in most previous works. We ﬁrst validate our algorithm with manually decided loading strategies inspired by various expert priors, named PartialFed-Fix . Then we develop PartialFed-Adaptive , which automatically selects personalized loading strategy for each client. The superiority of our algorithm is proved by demonstrating the new state-of-the-art results on cross-domain federated classiﬁcation and detection. In particular, solely by initializing a small fraction of layers locally, we improve the performance of FedAvg on Ofﬁce-Home and UODB by 4.88% and 2.65%, respectively. Further studies show that the adaptive strategy performs signiﬁcantly better on domains with large deviation, e.g. improves AP50 by 4.03% and 4.89% on aerial and medical image detection compared to FedAvg.