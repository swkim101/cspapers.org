Double Q-learning (Hasselt, 2010) has gained signiﬁcant success in practice due to its effectiveness in overcoming the overestimation issue of Q-learning. However, the theoretical understanding of double Q-learning is rather limited. The only existing ﬁnite-time analysis was recently established in (Xiong et al., 2020), where the polynomial learning rate adopted in the analysis typically yields a slower convergence rate. This paper tackles the more challenging case of a constant learning rate, and develops new analytical tools that improve the existing convergence rate by orders of magnitude. Speciﬁcally, we show that synchronous double Q-learning attains an (cid:15) -accurate global optimum with a time complexity of ˜Ω (cid:16) ln D