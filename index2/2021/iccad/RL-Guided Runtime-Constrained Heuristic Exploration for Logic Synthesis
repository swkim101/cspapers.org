Within logic synthesis, most optimization scripts are well-defined heuristics that generalize over a variety of Boolean circuits. These heuristic-based scripts comprise various optimization algorithms which are applied sequentially in a specific order over a logic graph representation of Boolean circuits (typically in the form of And Inverter Graphs (AIGs) or Majority Inverter Graphs (MIGs)). These heuristics, despite being well-defined generalizations, may not perform well over all kinds of circuits. In order to develop custom heuristics specific to a particular Boolean circuit that performs well, we propose a runtime-constrained reinforcement learning (RL) approach which is able to generate scripts to carry out logic synthesis flows. Within our approach, we incorporate a graph convolution network (GCN) in order to perform a holistic exploration of the search space. To carry out an extensive evaluation, we identify three different classes of environments consisting of different baseline optimization sequences. The experimental results reveal that our model outperforms the prevalent state-of-the-art work [24] and the best heuristic-based scripts of Berkeley-ABC [4]. Our evaluations show that our framework provides up to an average of 8.3 % further reduction in level over the EPFL Benchmark Suite [8] as compared to the Berkeley-ABC scripts. Further, we develop a framework for the EPFL mockturtle [20] logic synthesis libraries and generate custom scripts using our RL-based approach.