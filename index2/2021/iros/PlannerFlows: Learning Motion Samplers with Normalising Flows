Sampling-based motion planning is the predominant paradigm in many real-world robotic applications, but its performance is immensely dependent on the quality of the samples. The majority of traditional planners are inefficient as they use uninformative sampling distributions instead of exploiting structures and patterns in the problem to guide better sampling strategies. Moreover, most current learning-based planners are susceptible to posterior collapse or mode collapse due to the sparsity and highly varying nature of C-Space and motion plan configurations. This work introduces a conditional normalising flow-based distribution learned through previous experiences, which improves existing methodsâ€™ sampling scheme. Our distribution can be conditioned on the current problem instance to provide informative prior to sample configurations within promising regions. When we train our sampler with an expert planner, the resulting distribution is often near-optimal, and the planner can find a solution faster, with less invalid samples and less initial cost. The normalising flow-based distribution uses simple invertible transformations that are very computationally efficient, and our optimisation formulation explicitly avoids mode collapse in contrast to other existing learning-based sampler. Finally, we provide a formulation and theoretical foundation to sample from the distribution efficiently. Experimentally we demonstrate utilising the flow-based distribution in a sampling-based motion planner allows a solution to be found faster, with fewer samples and better overall runtime performance.