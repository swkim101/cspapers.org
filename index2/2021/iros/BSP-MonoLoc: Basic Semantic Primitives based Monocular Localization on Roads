Robust visual localization in traffic scenes is a fundamental problem for self-driving vehicles. However, it is still challenging to achieve accurate localization performance because of drastic viewpoint and illumination changes. To address the issues, we design a novel monocular localization framework based on a light-weight prior map, called BSP-MonoLoc, which leverages the 2D semantic primitives from the monocular images and the 3D basic semantic primitives from the prior map. These primitives are commonly available but lack of distinctive signature. To effectively make associations between the 2D and 3D primitives and refine the vehicleâ€™s pose, we adopt an iterative optimization method, where an efficient hierarchical sample strategy is designed to give a good initial prediction for the associations and the pose. Experimental results on the KAIST dataset and our dataset demonstrate the proposed method can achieve high localization accuracy and run at a real-time performance.