Modern self-driving systems heavily rely on deep learning. As a consequence, their performance is influenced significantly by the quality and richness of the training data. Data collection platforms can generate many hours of raw data on a daily basis, however, it is not feasible to label everything. Therefore, it is critical to have a mechanism to identify "what to label". Active learning approaches identify examples to label, but their interestingness is tied to a fixed model performing a particular task. These assumptions are not valid in self-driving, where we must solve a diverse set of tasks (i.e., perception, motion forecasting, and planning) and models frequently evolve over time. In this paper, we introduce a novel approach to dataset selection that exploits a diverse set of criteria that quantize interestingness of traffic scenes. Our experiments on a wide range of tasks and models demonstrate that the proposed curation pipeline is able to select datasets that lead to better generalization and improved performance.