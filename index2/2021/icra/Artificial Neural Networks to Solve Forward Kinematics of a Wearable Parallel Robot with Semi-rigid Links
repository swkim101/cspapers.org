Wearable robots are designed to provide physical assistance and rehabilitation training. Light-weight designs are desirable for human usage and parallel robots are quite suitable due to low moving inertia. One of the challenges of using wearable parallel robots is to compute the end-effector position/orientation from joint angle measurements, as the forward kinematics problem is computationally difficult. It becomes even more challenging if the kinematic model changes from the nominal model due to deflection of the mechanical members, manufacturing tolerances, or misalignments of the joints between the machine and the user.Artificial neural networks have been used to provide solution of the forward kinematics problem for parallel robots. However, their efficacy has not yet been studied in wearable applications where the linkages of the robots are not fully rigid. In this paper, we conducted a case study to investigate the performance of using neural network models to compute forward kinematics of a wearable robot. Our results show that the performance of neural networks is superior to numerical approaches and produces reasonable solutions even at the boundary of the robot workspace.