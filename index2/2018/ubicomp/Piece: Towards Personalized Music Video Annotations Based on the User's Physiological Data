Our overall goal of our is to provide a personalized method to categorize and find media content of interest based for individual users, especially focusing on implicit feedback (facial expressions, posture and other reactions). This paper presents an initial study to understand tagging and annotation processes for music videos, focusing on Korean Pop videos. We present an initial experimental setup of 10 users watching 5 selected K-Pop Videos. We obtained words, key terms, and phrases users use to describe/search for the music video content in question and recording eye gaze as well as body posture and facial expressions for the participants. In addition we explore Tag identification associated with the video content in a study, to look into cultural and individual differences.