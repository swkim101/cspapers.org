Understanding gestures help better communication between humans and between human and robot/agent because the gestures express various feelings of a speaker. We focus attention on gestures and aim to create a corpus of the relationship between the gestures performed by a speaker and his/her feelings. It is difficult to associate feeling with gestures because it requires subjective evaluation, answering a lot of questions. We propose a system, YUGE, that allows us to collect and evaluate gestures in a playful way. YUGE's visual interaction enables a user to input various gestures with fun. Through the preliminary experiment, we found that our proposed system can classify gestures with almost the same accuracy as the conventional method.