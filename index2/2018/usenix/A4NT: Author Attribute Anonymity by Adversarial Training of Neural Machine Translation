Text-based analysis methods enable an adversary to reveal privacy relevant author attributes such as gender, age and can identify the text's author.
Such methods can compromise the privacy of an anonymous author even when the author tries to remove privacy sensitive content.
In this paper, we propose an automatic method, called the Adversarial Author Attribute Anonymity Neural Translation ($\text{A}^{4}\text{NT}$), to combat such text-based adversaries.
Unlike prior works on obfuscation, we propose a system that is fully automatic and learns to perform obfuscation entirely from the data. This allows us to easily apply the  $\text{A}^{4}\text{NT}$ system to obfuscate different author attributes.
We propose a sequence-to-sequence language model, inspired by machine translation, and an adversarial training framework to design a system which learns to transform the input text to obfuscate the author attributes without paired data.
We also propose and evaluate techniques to impose constraints on our $\text{A}^{4}\text{NT}$ model to preserve the semantics of the input text.
$\text{A}^{4}\text{NT}$ learns to make minimal changes to the input
to successfully fool author attribute classifiers, while preserving the meaning of the input text. Our experiments on two datasets and three settings show that the proposed method is
effective in fooling the attribute classifiers and thus
improves the anonymity of authors.