Deduplication systems for traditional backups have optimized for large sequential writes and reads.  Over time, new applications have
resulted in nonsequential accesses,
patterns reminiscent of primary storage systems.  The Data Domain File System (\ddfs) needs to evolve to support these modern workloads by
providing high performance for nonsequential accesses
without degrading performance for
traditional backup workloads.
Based on our experience with thousands of deployed systems, we have
updated our storage software to distinguish user workloads and apply
optimizations including leveraging solid-state disk (SSD) caches.
Since SSDs are still significantly more expensive than magnetic disks,
we make our system cost-effective by caching metadata and file data
rather than moving everything to SSD.  We dynamically detect access
patterns to decide when to cache, prefetch, and perform numerous other
optimizations.  We find that on a workload with nonsequential
accesses, with SSDs for caching metadata alone, we measured a
5.7$\times$ improvement on input/output operations per second (IOPS)
when compared to a baseline without SSDs.  Combining metadata and data
caching in SSDs, we measured a further 1.7$\times$ IOPS increase.
Adding software optimizations throughout our system added an
additional 2.7$\times$ IOPS improvement for nonsequential
workloads. Overall, we find that both hardware and software changes are necessary to support the new mix of sequential and nonsequential workloads at acceptable cost.  Our updated system is sold to customers worldwide.