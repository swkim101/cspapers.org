Blind deconvolution is a ubiquitous problem aiming to recover a convolution kernel <inline-formula> <tex-math notation="LaTeX">$\boldsymbol a_{0}\in \mathbb R ^{k}$ </tex-math></inline-formula> and an activation signal <inline-formula> <tex-math notation="LaTeX">$\boldsymbol x_{0}\in \mathbb R ^{m}$ </tex-math></inline-formula> from their convolution <inline-formula> <tex-math notation="LaTeX">$\boldsymbol y\in \mathbb R ^{m}$ </tex-math></inline-formula>. Unfortunately, this is an ill-posed problem in general. This paper focuses on the <italic>short and sparse</italic> blind deconvolution problem, where the convolution kernel is short (<inline-formula> <tex-math notation="LaTeX">$k\ll m$ </tex-math></inline-formula>) and the activation signal is sparsely and randomly supported (<inline-formula> <tex-math notation="LaTeX">$\left \|{ \boldsymbol x_{0} }\right \|_{0}\ll m$ </tex-math></inline-formula>). This variant captures the structure of the convolutional signals in several important application scenarios. In this paper, we normalize the convolution kernel to have unit Frobenius norm and then cast the blind deconvolution problem as a nonconvex optimization problem over the kernel sphere. We demonstrate that (i) in a certain region of the sphere, every local optimum is close to some shift truncation of the ground truth, and (ii) for a generic unit kernel <inline-formula> <tex-math notation="LaTeX">$\boldsymbol a_{0}$ </tex-math></inline-formula>, when the sparsity of activation signal satisfies <inline-formula> <tex-math notation="LaTeX">$\theta \lesssim k^{-2/3}$ </tex-math></inline-formula> and number of measurements <inline-formula> <tex-math notation="LaTeX">$m\gtrsim \mathop {\mathrm {poly}}\nolimits \left ({k }\right) $ </tex-math></inline-formula>, the proposed initialization method together with a descent algorithm which escapes strict saddle points recovers some shift truncation of the ground truth kernel.