Modern neural networks have recently been found to be poorly calibrated, primarily in the direction of over-conﬁdence. Methods like entropy penalty and temperature smoothing improve calibration by clamping conﬁdence, but in doing so compromise the many legitimately conﬁdent predictions. We propose a more principled ﬁx that minimizes an explicit calibration error during training. We present MMCE, a RKHS kernel based measure of calibration that is efﬁciently trainable alongside the negative likelihood loss without careful hyper-parameter tuning. Theoretically too, MMCE is a sound measure of calibration that is minimized at perfect calibration, and whose ﬁnite sample estimates are consistent and enjoy fast convergence rates. Extensive experiments on several network architectures demonstrate that MMCE is a fast, stable, and accurate method to minimize calibration error metrics while maximally preserving the number of high conﬁdence predictions.