Evaluation of biases in language models is of-001 ten limited to synthetically generated datasets. 002 This dependence traces back to the need of 003 prompt-style dataset to trigger speciﬁc be-004 haviors of language models. In this paper, 005 we address this gap by creating a prompt 006 dataset with respect to occupations collected 007 from real-world natural sentences present in 008 Wikipedia. We aim to understand the differ-009 ences between using template-based prompts 010 and natural sentence prompts when studying 011 gender-occupation biases in language models. 012 We ﬁnd bias evaluations are very sensitive to 013 the design choices of template prompts, and 014 we propose using natural sentence prompts as 015 a way of more systematically using real-world 016 sentences to move away from design decisions 017 that may bias the results. 018