Extracting roads from multi-source data, such as aerial images and vehicle trajectories, is an important way to maintain road networks in the filed of urban computing. In this paper, we revisit the problem of road extraction and aim to boost its accuracy by solving three significant issues: the insufficient complementarity among multiple sources, rough edges of extracted roads, and many false positives caused by confusing pixels. In particular, we design an end-to-end neural network model to achieve this goal. At first, this model leverages two encoding networks to extract relative information from the inputs of two sources respectively, and then applies the attention mechanism to fuse them for sufficiently capturing the complementary correlation. Next, we introduce an auxiliary task, predicting road edges based on fused representations, to make the extracted roads smooth and continuous. At last, to reduce false positives relative to confusing pixels, we propose a pixel-aware contrastive-learning module to distinguish positive (roads) and negative (objects similar to roads) pixels. In addition, to improve the model's learning effectiveness, we propose a model-agnostic transfer learning method, which first builds auxiliary tasks to pre-train the whole model, and then fine-tunes the model's parameters for the main task. Extensive experiments on real datasets verify the superiority of our method as well as the importance of solving the three issues outlined above.