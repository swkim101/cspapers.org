Estimating optimal transport (OT) maps ( a.k.a. Monge maps) between two measures P and Q is a problem fraught with computational and statistical challenges. A promising approach lies in using the dual potential functions obtained when solving an entropy-regularized OT problem between samples P n and Q n , which can be used to recover an approximately optimal map. The ne-gentropy penalization in that scheme introduces, however, an estimation bias that grows with the regularization strength. A well-known remedy to debias such estimates, which has gained wide pop-ularity among practitioners of regularized OT, is to center them, by subtracting auxiliary problems involving P n and itself, as well as Q n and itself. We do prove that, under favorable conditions on P and Q , debiasing can yield better approximations to the Monge map. However, and perhaps surprisingly, we present a few cases in which debiasing is provably detrimental in a statistical sense, notably when the regularization strength is large or the number of samples is small. These claims are validated experimentally on synthetic and real datasets, and should reopen the debate on whether debiasing is needed when using entropic OT.