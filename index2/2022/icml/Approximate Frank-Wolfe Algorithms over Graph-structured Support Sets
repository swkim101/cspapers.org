In this paper, we consider approximate Frank-Wolfe (FW) algorithms to solve convex optimization problems over graph-structured support sets where the linear minimization oracle (LMO) cannot be efﬁciently obtained in general. We ﬁrst demonstrate that two popular approximation assumptions ( additive and multiplicative gap errors) are not applicable in that no cheap gap-approximate LMO oracle exists. Thus, approximate dual maximization oracles (DMO) are proposed, which approximate the inner product rather than the gap. We prove that the standard FW method using a δ -approximate DMO converges as O ((1 − δ ) √ s/δ ) in the worst case, and as O ( L/ ( δ 2 t )) over a δ -relaxation of the constraint set. Furthermore, when the solution is on the boundary, a variant of FW converges as O (1 /t 2 ) under the quadratic growth assumption. Our empirical results suggest that even these improved bounds are pessimistic, showing fast convergence in recovering real-world images with graph-structured sparsity.