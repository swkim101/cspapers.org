Differential privacy has been accepted as the de facto notion for protecting privacy. Companies and government agencies use differential privacy for privacy-preserving data analysis. For example, the US census bureau applied differential privacy in the 2020 census. One important approach to use a private dataset is to generate a synthetic dataset that is similar to the private dataset in a way that satisfies differential privacy. This enables data analysts to directly apply existing algorithms for performing data analysis. Furthermore, as additional data analysis tasks performed on the published dataset are post-processing, they do not incur additional privacy cost. In recent years, US National Institutes of Standards and Technology ran two competitions on differentially private data synthesis, which drove the development of practically effective data synthesis algorithms. In this talk, I will discuss the current state of the art for private data synthesis, with a focus on those approaches that have performed well in the NIST competitions. One family of approaches uses probabilistic graphical models. My group's approach uses private marginals and a procedure that is similar to Iterative Proportional Fitting, which has been studied in many fields. We also discuss the remaining challenge and open questions.