Session-based recommendation has recently attracted increasing attention from both industry and academic communities. Previous models mostly focus on designing different models to fit the observed data, which can be quite sparse in real-world scenarios. To alleviate this problem, in this paper, we propose a novel generative session-based recommendation framework. The main building block of our idea is to develop a generator to simulate user sequential behaviors, which are leveraged to train and improve the target sequential recommender model. In order to generate high quality samples, we consider two aspects: (1) the rationality as a sequence of user behaviors, and (2) the informativeness for training the target model. To satisfy these requirements, we design a doubly adversarial network. The first adversarial module aims to make the generated samples conform to the underlying patterns of the real user sequential preference (rationality requirement). The second adversarial module is targeted at widening the model experiences by generating samples which can induce larger model losses (informativeness requirement). In our model, the samples are generated based on a reinforcement learning strategy, where the reward is related with both of the above aspects. In order to stable the training process, we introduce a self-paced regularizer to learn the agent in an easy-to-hard manner. We conduct extensive experiments based on real-world datasets to demonstrate the effectiveness of our model.