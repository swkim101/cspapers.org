We focus on learning with limited labelled data (especially meta-learning) in conjunction with so-far under-researched multilingual textual document classification. The core principle in such learning is to achieve transferability of learned knowledge to new datasets and tasks. Currently, factors influencing the success of transfer remain mostly unclear. Their identification from experiments is challenging due to small amounts of labels making results considerably unstable. When instability of the investigated models is not explicitly taken into consideration (as is common in existing benchmarking studies), it may result in randomness possibly even invalidating the findings. We want to remedy this by in-depth exploration of factors that influence the stability and the transferability of learning with limited labelled data in multilingual textual documents classification, such as misinformation detection.