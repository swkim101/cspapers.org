Developing a good control strategy for biomimetic robots is challenging. Robust control methods require an accurate model of the robot. Nowadays, model-free methods are being extensively explored for the control and navigation of terrestrial robots. In this paper, we consider a novel deep reinforcement learning-based model-free swimming control for our bio-inspired robotic tadpole. To realize this, we utilize dynamic motion primitives, which can represent a large range of motion behaviors, and combine them with a decoupled reinforcement learning framework. The proposed architecture optimizes the motion primitives first to develop a travelling wave undulation pattern in the tail and then to navigate the robot along different predefined paths. Through this framework, effective swimming gait emerges, and the robot is able to navigate well on the surface of water. This framework combines the optimization potential of deep reinforcement learning with stability and generalization properties of dynamic motion primitives. We train and test our method on a simulated model of the robot to demonstrate the effectiveness of the method and also conduct experimental testing on the real robot to verify the results.