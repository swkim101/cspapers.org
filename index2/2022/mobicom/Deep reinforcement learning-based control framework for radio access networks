Network performance optimization represents one of the major challenges for mobile network operators, especially with the increasingly use cases that have diverse performance expectations. In this work we propose a novel control framework that maximizes radio resources utilization and minimizes performance degradation in the most challenging part of cellular architecture that is the radio access network (RAN). Based on deep reinforcement learning, we devise two control schemes: centralized and distributed, respectively. Using extensive discrete event simulations, we confirm that our proposed control framework succeeds in optimizing radio resources utilization while minimizing service level agreement (SLA) violations in a multi-slice RAN.