The architecture of all models in this paper is based on EPI-Net [19]. We input four light field view stacks: horizontal, vertical and two diagonals. Each stack is processed by a separate input stream network. The horizontal and vertical stacks behave similar when one is rotated by 90◦. Therefore we effectively share the weights between those two input streams by applying this rotation to the vertical input and revert it before concatenation. Analogously, we also share weights between the two diagonal input streams. Subsequently, we concatenate the inferred features, and feed them to an output stream. All models and streams share the same basic building block which consists of two convolutions with a kernel size of 2 × 2. We use an alternating padding of one and zero and a stride of one to maintain the image dimensions. In addition, we apply a Rectified Linear Unit (ReLU) non-linearity after the first convolution and a Batch Normalization (BN) as well as a ReLU layer after the second convolution. Table A.1 shows the total number of trainable parameters for each model. A small difference between the four methods is caused by the variable number of output channels. In the following sections, we describe details, specific to one of the architectures. All four methods, share the same backbone network. The only differences are the variable number of output channels and one additional output ReLU-layer for DPP. Table A.2 shows the detailed architecture for one input stream. This subnetwork infers features from one light field stack containing nine images with three color channels, thus a total number of 9 × 3 = 27 input channels. Each input stream consists of three basic blocks. Because the architecture is Layer Output Size LF Stack B × 27×H ×W 2× 2 Conv B × 70×H ×W ReLU 2× 2 Conv B × 70×H ×W BatchNorm ReLU Repeat Block (2×)