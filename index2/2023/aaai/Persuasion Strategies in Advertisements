Modeling what makes an advertisement persuasive, i.e., eliciting the desired response from consumer, is critical to the
study of propaganda, social psychology, and marketing. Despite its importance, computational modeling of persuasion
in computer vision is still in its infancy, primarily due to
the lack of benchmark datasets that can provide persuasion-strategy labels associated with ads. Motivated by persuasion literature in social psychology and marketing, we introduce an extensive vocabulary of persuasion strategies and
build the first ad image corpus annotated with persuasion
strategies. We then formulate the task of persuasion strategy prediction with multi-modal learning, where we design
a multi-task attention fusion model that can leverage other
ad-understanding tasks to predict persuasion strategies. The
dataset also provides image segmentation masks, which labels persuasion strategies in the corresponding ad images on
the test split. We publicly release our code and dataset at https://midas-research.github.io/persuasion-advertisements/.