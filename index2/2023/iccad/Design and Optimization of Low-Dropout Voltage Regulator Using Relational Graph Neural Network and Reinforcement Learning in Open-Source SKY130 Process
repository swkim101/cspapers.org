Design automation and optimization for analog integrated circuits (ICs) are challenging, especially for transistor sizing. Given certain design specifications and circuit topology, circuit designers need to size various components to achieve the desired performance, possibly involving many optimization iterations. Recently, reinforcement learning (RL) has been applied to optimize analog circuits. The trained RL agents can achieve very high sample efficiency over evolutionary-based algorithms. By using the ability of transfer learning, the trained agent can be applied to optimize the same circuit across different technology nodes and even the circuits with different topologies. However, a significant bottleneck in applying machine learning (ML) techniques to analog IC design is the non-disclosure agreement (NDA) of the process development kit (PDK), which makes reproducibility of the prior art a big challenge. This work presents an RL framework that leverages the open-source SKY130 PDK to address the limitation above. We apply a novel heterogeneous graph neural network (GNN) called relational graph convolutional network (RGCN) as the function approximator of RL to capture more topological information about a circuit. As a proof-of-concept, low-dropout voltage regulators (LDO) are optimized by our proposed RL circuit optimizer framework to show its feasibility, achieving promising results.