Trojan horses represent a major threat to hardware security and trust. In this work, we propose a novel hardware Trojan detection method based on explainable graph neural networks (GNNs) targeting FPGA netlists. We leverage the rich explicit structural features and behavioral characteristics at LUT, which offers an ideal abstraction level and granularity for Trojan detection. A GNN model with optimized class-balanced focal loss is trained for automated Trojan feature extraction and classification. Based on the Granger causality theory, we develop an interpretable approach to explain the decision mechanism of our GNN model. Experimental evaluations using 927 Trust-Hub hardware Trojan benchmarks and 262 Trojan free open source IP cores show that the proposed method provides promising detection results with accuracy, precision and F1-measure of 98.78%, 99.69% and 99.23% for Xilinx FPGA netlists while 97.93%, 97.87% and 98.51% for Intel FPGA netlists respectively. The experiment results have demonstrated that the proposed explainable approach can successfully identify the essential components that contribute to accurate Trojan classification and provide interpretable explanation for the GNN model.