This paper presents 3DNN-Xplorer, the first machine learning (ML)-based framework for predicting the performance of heterogeneous 3D DNN accelerators. Our ML frame-work facilitates the design space exploration of heterogeneous 3D accelerators with a 2-tier compute-on-memory configuration, considering 3D physical design factors. Our design space encompasses four distinct heterogeneous 3D integration styles, combining 28nm and 16nm technology nodes for both compute and memory tiers. Using extrapolation techniques with ML models trained on 16, 32, and 64 PE accelerator configurations, we estimate the performance of systems featuring 128, 256, 512, 1024, and 2048 PEs, achieving a maximum absolute error of 12.7%. To ensure balanced tier areas in the design, our framework assumes the same number of PEs or on-chip memory capacity across the four integration styles, accounting for area imbalance resulting from different technology nodes. Our analysis reveals that the heterogeneous 3D style with 28nm compute and 16nm memory is energy-efficient and offers notable energy savings of up to 50% and an 8.8% reduction in runtime compared to other 3D integration styles with the same number of PEs. Similarly, the heterogeneous 3D style with 16nm compute and 28nm memory is area-efficient and shows up to 8.3% runtime reduction compared to other 3D styles with the same on-chip memory capacity.