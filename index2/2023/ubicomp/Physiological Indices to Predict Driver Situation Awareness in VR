Understanding driversâ€™ states is essential for providing personalized interventions and adaptive feedback in vehicles, thereby ensuring safer driving and a more comfortable driver experience. As driving tasks necessitate understanding and reaction to the rapidly changing road environment and successful management of working memory to prevent dual-task interference, driver situation awareness (SA) should be primarily considered for such interventions and feedback. However, due to its complex nature, most of the current methods for measuring SA rely on questionnaires. In this work, we aim to develop sensor-based assessments of driver SA, especially towards road signs, which play an important role in immediate decision-making during driving. We collected eye-tracking data and physiological responses from 32 participants during simulated driving and annotated this data according to the levels of SA that drivers achieved. Our ensemble-based machine learning model that uses physiological measures and gaze-related features demonstrated an accuracy of 78.02% in a three-class driver SA prediction. Since SA is a key component in evaluating vehicular interfaces, our VR-based approach holds the potential for the iterative design of in-car infotainment applications and road environments. The method also lays a foundation for SA-adaptive cooperation between human drivers and AI in the context of advanced driver assistance.