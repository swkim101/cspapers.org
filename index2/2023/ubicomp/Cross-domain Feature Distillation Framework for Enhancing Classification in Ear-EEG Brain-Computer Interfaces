Ear-electroencephalography (EEG) holds significant promise as a practical tool in brain-computer interfaces (BCIs) due to its enhanced unobtrusiveness, comfort, and mobility in comparison to traditional steady-state visual evoked potential (SSVEP)-based BCI systems. However, achieving accurate SSVEP classification in ear-EEG faces a major challenge due to the significant attenuation and distorted amplitude of the signal. To address this challenge, this paper focuses on enhancing ear-EEG feature representations by training the model to learn feature representations similar to those of scalp-EEG. We propose a cross-domain feature distillation (CD-FD) framework, which facilitates the extraction of shared features between the two domains. This framework facilitates the identification of crucial features concealed within ear-EEG signals, leading to more effective SSVEP classification. We evaluate the proposed CD-FD framework through single-session decoding and session-to-session transfer decoding, comparing it with EEGNet and canonical correlation analysis (CCA). The results demonstrate that the proposed framework achieves the best classification results in all experiments.