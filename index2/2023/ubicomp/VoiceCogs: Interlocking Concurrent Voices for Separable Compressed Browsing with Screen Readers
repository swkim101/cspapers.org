Ensuring universal accessibility to information cannot be overstated. Unlike visual readers, however, screen reader users are given inefficient and restricted channels to acquire the given information. In particular, we focus on the initial step of information acquisition – quickly scanning the overall structure of a textual document so that the reader makes an informed decision about where to jump and read the details. While this step is inherently quick for visual users, screen reader users passively listen to the slow, sequential list of items read aloud. To close this gap, we call for a technique that accelerates screen reader users’ scanning process. Our system, VoiceCogs, takes multi-itemed text sources and synthesizes audio that concurrently plays multiple text-to-speech from a respective text source while facilitating the discernibility of individual sources. To this end, we devise and implement two interlocking techniques to minimize phonetic interferences between concurrent speeches.