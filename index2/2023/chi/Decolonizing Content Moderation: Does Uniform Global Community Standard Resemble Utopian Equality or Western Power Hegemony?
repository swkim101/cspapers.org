Social media platforms use content moderation to reduce and remove problematic content. However, much of the discourse on the benefits and pitfalls of moderation has so far focused on users in the West. Little is known about how users in the Global South interact with the humans and algorithms behind opaque moderation systems. To fill this gap, we conducted interviews with 19 Bangladeshi social media users who received restrictions for violating community standards on Facebook. We found that the users perceived the underlying human-AI infrastructure to imbibe coloniality in the form of amplifying power relations, centering Western norms, and perpetuating historical injustices and erasure of minoritized expressions. Based on the findings, we establish that the current moderation systems often propagate historical power relations and patterns of oppression, and discuss ways to rethink moderation in a fundamentally decolonial way.