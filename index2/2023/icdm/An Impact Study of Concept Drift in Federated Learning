Federated learning (FL) is a rising distributed machine learning area, which aims to train a high-performing global model with data collected from a number of local clients. Many FL applications receive data over time in the form of data streams. Streaming data are likely to suffer concept drift. It can significantly harm a model’s predictive ability. However, no study has characterized concept drift in FL or investigated how it can affect the global and local models’ performance. This paper aims to provide such understanding by 1) categorizing concept drift in temporal and spatial dimensions with ten features and 2) investigating the impact of the features in depth. We find that: the temporal features degrade FL models to a different extend and do not affect model convergence after the new data concept becomes stable; the spatial features cause data heterogeneity and affect both accuracy and convergence speed.