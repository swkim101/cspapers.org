This paper describes the core concepts and challenges in developing Trinity - a high-assurance neuro-symbolic approach to trustworthy and resilient machine learning for applications in open-world, contested, and rapidly-evolving environments. The two central concepts in Trinity are a neuro-symbolic factored world model that identifies entities, activities, and complex events, and the notion of surprise against this world model that is used for self-adaptation and learning, as well as runtime assurance. The world model is not derived purely as a bottom-up inference from sensors treating each observation as independent uncorrelated input; instead, we iteratively interleave bottom-up inference (conditioned on context) with top-down predictions and context identification using a three-layered hierarchical predictive processing (HPP) stack. Thus, the neuro-symbolic inference in Trinity is bidirectional â€“ learning-based bottom-up pull that is uncertainty-driven and reasoning-based symbolic top-down push that is decision-driven. The progressively symbolic higher layers capture a larger context than the bottom layers finally culminating in the highest layer implemented using large language models. Any surprise arising from the mismatch between the top-down prediction and the bottom-up inference is used for the continual adaptation of Trinity. The inference in Trinity produces a factored temporal world model as the result of perception. The predictions are accompanied by a quantitative measure of surprise from the 3-layered HPP stack. This surprise corresponds to the confidence of the model in its current inference. The continuous monitoring and adaptation accompanied by risk analysis make Trinity robust to semantic adversarial perturbations and more efficiently generalizable to novelties. The hierarchical nature of Trinity also enables adaptation of the architecture to the available compute resources.