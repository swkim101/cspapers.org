As a prevalence data structure in the real world, graphs have found extensive applications ranging from modeling social networks to molecules. However, the existence of diverse biases within graphs gives rise to unfair representations learned by graph neural networks (GNNs). Addressing this issue has typically been approached from a modeling perspective, which not only compromises the integrity of the model structure but also entails additional effort and cost for retraining model parameters when the architecture changes. In this study, we adopt a data-centric standpoint to tackle the problem of fairness, focusing on graph debiasing for Graph Neural Networks. Our specific objective is to eliminate various biases from the input graph by generating a fair synthetic graph. By training GNNs on this fair graph, we aim to achieve an optimal accuracy-fairness trade-off. To this end, we propose FairGraph, which approaches the graph debiasing problem by mimicking the GNN training trajectory of the input graph through an optimization process involving a gradient-matching loss and fairness constraints. Through extensive experiments conducted on three benchmark datasets, we demonstrate the effectiveness of FairGraph and its ability to automatedly generate fair graphs that are transferable across different GNN architectures.