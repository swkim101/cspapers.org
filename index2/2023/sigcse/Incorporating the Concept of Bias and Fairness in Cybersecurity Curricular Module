Although Artificial Intelligence has become an integral part of modern cybersecurity solutions, data bias and algorithmic bias have made it vulnerable to many cyberattacks, in particular, adversarial attacks where the attacker crafts input of the AI system to exploit the existence of possible bias in the data or algorithms. In this paper, we share our experiences with ongoing work to develop and evaluate a cybersecurity curricular module that demonstrates (a) data bias detection, (b) data bias mitigation, (c) algorithmic bias detection, and (d) algorithmic bias mitigation, using a network intrusion detection problem on real-world data. The module includes lectures and hands-on exercises, using state-of-the-art and open-source bias detection and mitigation software on a real-world dataset. The goal is to identify and mitigate the prevailing conscious/unconscious bias in data and algorithms that the attacker might exploit.