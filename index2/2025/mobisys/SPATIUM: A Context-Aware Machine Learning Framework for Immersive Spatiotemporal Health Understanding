Wearable devices have made significant progress in continuous health monitoring by providing time-series physiological data such as heart rate, respiration, and activity levels. However, most lack spatial awareness, limiting their ability to interpret physiological changes within environmental contextâ€”especially indoors where GPS is unreliable. Recent advances in indoor localization, such as Ultra-Wideband (UWB) and visual-inertial odometry, now allow precise spatial positioning in consumer devices. In this paper, we introduce SPATIUM, a context-aware machine learning framework designed to enable immersive spatiotemporal health understanding. SPATIUM integrates multimodal health signals with spatial and environmental data, such as furniture layout, lighting, and temperature, to support more contextually grounded health analysis. We present a proof-of-concept system that combines OmniBuds and UWB localization to collect and visualize spatiotemporal health data in 2D, 3D, and immersive formats. To evaluate the potential impact of spatial features, we conduct a simulation showing that incorporating spatial context improves physiological classification accuracy by up to 26%. Our results highlight the importance of context-aware, spatially grounded modeling in achieving immersive spatiotemporal health understanding.