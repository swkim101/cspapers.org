3D reconstruction plays a critical role in applications such as augmented reality (AR) and robotic systems. However, implicit neural representations (INRs), widely used in modern 3D reconstruction systems, demand substantial communication and computational resources, making the reconstruction process excessively slow and costly. In this paper, we introduce EAR-Mapping, a novel edge-assisted online 3D reconstruction framework designed for latency-sensitive mobile applications. EAR-Mapping incorporates an innovative sampling mechanism that seamlessly integrates explicit and implicit methods, enabling selective processing of camera data to maximize reconstruction performance. In addition, we utilize a value-based representation module to maximize computation resource efficiency. Finally, we design a framework that minimizes communication overhead through ROI-based data transmission. Our prototype implementation on a mobile-edge testbed demonstrates that EAR-Mapping achieves up to a 1.2x reduction in reconstruction latency and a 3.5x reduction in bandwidth usage, offering a significant advancement in the efficiency of 3D reconstruction for mobile-edge systems.