Calibration of a quantum computer is the process of optimizing its control parameters to ensure the accurate implementation of quantum gates. It remains a critical challenge in scaling quantum computers. Existing calibration methods take a generalized approach that focuses on the trade-off between calibration time and fidelity. However, these methods lack the awareness of hardware differences among physical qubits and an elaborate design of parallel calibration. In this paper, we introduce a fine-grained calibration protocol that contains three calibration policies for hardware differences and a method to enable parallel calibration. We begin by profiling qubit pairs to evaluate their responses to different waveform candidates. Based on profiling results, we determine the best calibration policy for the quantum computer, which is the first part of the calibration protocol. The second part of our protocol is to use graph traverse to enable parallel calibration by identifying compatible calibration operations. We validate our protocol through intensive experiments on real quantum machines with up to 127 qubits. Our experimental results demonstrate a 1.84 × reduction in terms of the medium of the two-qubit gate error rate, 1.26 × reduction in pulse duration, an 8 × to 25 × reduction in total calibration overhead compared with sequential calibration, an average of 2.12 × further reduction in total calibration overhead owing to profiling policy, double of the quantum volume, and a 2.0 × to 2.3 × reduction in error per layered gate. The proposed protocol emphasizes the importance of hardware-aware and parallel calibration and advances current quantum computers towards fault-tolerant quantum computing.