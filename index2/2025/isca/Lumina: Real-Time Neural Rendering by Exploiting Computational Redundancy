3D Gaussian Splatting (3DGS) has vastly advanced the pace of neural rendering, but it remains computationally demanding on today’s mobile SoCs. To address this challenge, we propose Lumina, a hardware-algorithm co-designed system, which integrates two principal optimizations: a novel algorithm, \( {\mathcal {S}}^2 \), and a radiance caching mechanism, \( {\mathcal {RC}} \), to improve the efficiency of neural rendering. \( {\mathcal {S}}^2 \) algorithm exploits temporal coherence in rendering to reduce the computational overhead, while \( {\mathcal {RC}} \) leverages the color integration process of 3DGS to decrease the frequency of intensive rasterization computations. Coupled with these techniques, we propose an accelerator architecture, LuminCore, to further accelerate cache lookup and address the fundamental inefficiencies in Rasterization. We show that Lumina achieves 4.5 × speedup and 5.3 × energy reduction against a mobile Volta GPU, with a marginal quality loss (< 0.2 dB peak signal-to-noise ratio reduction) across synthetic and real-world datasets.