Learning-Based Model Predictive Control (LMPC) is a class of algorithms that enhances Model Predictive Control (MPC) by including machine learning methods, improving robot navigation in complex environments. However, the combination of machine learning and MPC computation in LMPC creates a unique workload that cannot be efficiently handled by a simple GPU and CPU integration. We present HiPER, a hierarchically-composed processing array that provides temporal and spatial mapping capabilities, allowing efficient adaptation to workload changes at runtime. To simplify control, HiPER employs a pointer queue hierarchy to compose and orchestrate program execution. Additionally, HiPER utilizes a fractal interconnect topology that combines local systolic interconnects and their hierarchical extensions to efficiently support the workload’s traffic characteristics. To evaluate the performance and efficiency of HiPER, we synthesized a 16.37 mm2 design in 16nm CMOS. The design consists of 6 pointer queue levels and 1024 PEs. The prototype was assessed using a representative LMPC workload, demonstrating 10.75 × improvement in performance compared to a GTX 1080 GPU, 12.80 × improvement in energy efficiency compared to a Jetson Orin Nano embedded GPU, and 11.6 × /22.2 × improvement in performance compared to the RoboX/Plasticine accelerators.