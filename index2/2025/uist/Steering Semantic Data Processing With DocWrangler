Unstructured text has long been difficult to automatically analyze at scale. Large language models (LLMs) now offer a way forward by enabling semantic data processing, where familiar data processing operators (e.g., map, reduce, filter) are powered by LLMs instead of code. However, building effective semantic data processing pipelines presents a departure from traditional data pipelines: users need to understand their data to write effective pipelines, yet they need to construct pipelines to extract the data necessary for that understandingâ€”all while navigating LLM idiosyncrasies and inconsistencies. We present DocWrangler, a mixed-initiative integrated development environment (IDE) for semantic data processing with three novel features to address the gaps between the user, their data, and their pipeline: (i) In-Situ User Notes that allows users to inspect, annotate, and track observations across documents and LLM outputs, (ii) LLM-Assisted Prompt Refinement that transforms user notes into improved operations, and (iii) LLM-Assisted Operation Decomposition that identifies when operations or documents are too complex for the LLM to correctly process and suggests decompositions. Our evaluation combines a think-aloud study with 10 participants and a public-facing deployment (available at docetl.org/playground) with 1,500+ recorded sessions, revealing how users develop systematic strategies for their semantic data processing tasks; e.g., transforming open-ended operations into classifiers for easier validation and intentionally using vague prompts to learn more about their data or LLM capabilities.