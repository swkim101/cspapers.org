In virtual reality (VR), users slip into a variety of roles, represented by a rich diversity of avatars that each exhibit specific visual attributes and motion styles. While users can see their avatar’s motion in VR, they usually cannot feel it. To enhance avatar embodiment, we propose active proprioceptive feedback that aligns users’ physical movements with the expected motion style of their avatar, for instance, by mimicking the avatar’s weight, typical motion speed or motion range. We introduce a conceptual space of relevant motion properties which enable designers to create expressive proprioceptive motion styles for avatars. We instantiate this concept with MotionStyler: a system for designing customized motion styles and rendering them in real-time with an arm-based exoskeleton that is synchronized with the VR avatar. Results from a survey confirmed the expressiveness of the proposed conceptual space. A user study demonstrated the system’s capability to create diverse proprioceptive motion styles which enhance user’s self-identification with their avatar and thereby positively contribute to avatar embodiment in VR.