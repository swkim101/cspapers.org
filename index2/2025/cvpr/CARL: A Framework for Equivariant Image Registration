Image registration estimates spatial correspondences between image pairs. These estimates are typically obtained via numerical optimization or regression by a deep network. A desirable property is that a correspondence estimate (e.g., the true oracle correspondence) for an image pair is maintained under deformations of the input images. Formally, the estimator should be equivariant to a desired class of image transformations. In this work, we present careful analyses of equivariance properties in the context of multi-step deep registration networks. Based on these analyses we 1) introduce the notions of [U, U] equivariance (network equivariance to the same deformations of the input images) and [W, U] equivariance (where input images can undergo different deformations); we 2) show that in a suitable multi-step registration setup it is sufficient for overall [W, U] equivariance if the first step has [W, U] equivariance and all others have [U, U] equivariance; we 3) show that common displacement-predicting networks only exhibit [U, U] equivariance to translations instead of the more powerful [W, U] equivariance; and we 4) show how to achieve multi-step [W, U] equivariance via a coordinate-attention mechanism combined with displacement-predicting networks. Our approach obtains excellent practical performance for 3D abdomen, lung, and brain medical image registration. We match or outperform state-of-the-art (SOTA) registration approaches on all the datasets with a particularly strong performance for the challenging abdomen registration.