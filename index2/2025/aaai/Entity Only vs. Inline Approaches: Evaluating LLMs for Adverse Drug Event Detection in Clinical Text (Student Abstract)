Adverse Drug Events (ADEs) are a major healthcare issue in the United States, contributing to millions of outpatient and emergency department visits and ranking as the fourth leading cause of death. While many ADEs are identified post-market, improved detection methods are crucial for enhancing patient safety. This study explores the application of large language models (LLMs) to the n2c2 task for ADE detection, evaluating optimal prompting techniques without requiring ADE-specific training data. Results indicate that an entity-only extraction approach outperforms the inline method, offering higher precision, recall, and token efficiency. This study highlights the potential of LLMs for accurate ADE detection in clinical text, improving performance while maintaining model efficiency.