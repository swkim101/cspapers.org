There is both great hope and concern about the future of Computer Science practice and education concerning the recent advent of large language models (LLMs). We present the first study to extensively evaluate the ability of such a model to solve problems in Computer Science Theory. Specifically, we tested 165 exam-level problems across 16 specific topics related to computer science theory, ranging from preliminary data structures to algorithm design paradigms to theory of computation (automata and complexity). Our results use the recent popular models (GPT-4 and GPT-4o). This is a rapidly evolving field, with model performance continuously improving. We present our results primarily as an indication of what they can already achieve-equivalently how they can already be useful-today, fully expecting them to improve even further in the near future. Our results show that what was very recently a state-of-the-art model (GPT-4) can solve 77% of free-response problems in data structures and algorithms with little to no guidance. The latest model, GPT-4o, can solve around 46% of the Theory of Computation problems we posed, with predictable categories for which problems it could not solve. When broken down by topic, the model can solve 80% of problems in 4 out of the 15 topics and at least half in 8 other topics. Other problems, namely more visual problems, either require more substantial coaching or seem to still be beyond the capabilities of the language model--for now. By understanding the strengths and limitations of these models for solving theory problems, we can open the door to future work, ranging from human educational assessment on the topic to automated tutors for learners of the subject.