The release of popular generative artificial intelligence (AI) tools like ChatGPT have prompted universities to introduce new policies or update existing ones. Currently, most institutions adapt their policies reactively as challenges arise, often without adopting a systematic framework, with minimal guidance and limited knowledge of the approaches taken by other institutions across the United States (U.S.). This study aims to bridge this gap by identifying core themes surrounding AI policies and guidelines across the top 50 U.S. universities. Given the labor- and time-intensive nature required to manually synthesize multiple policy documents across many institutions, we leverage large language models (LLMs) to identify common and prevalent themes. Our framework first summarizes AI policies at the institutional level, followed by the generation of multiple sets of themes through an iterative process of prompt chaining and self-refinement. Finally, the common themes from these distinct sets were consolidated. This framework is designed to address potential flaws in pre-trained LLMs, such as hallucinations. Seven distinct themes are uncovered: (1) academic integrity and responsible AI use, (2) communication of AI policies, (3) data privacy and security concerns, (4) ethical considerations in AI use, (5) continuous adaptation and policy evolution, (6) documentation and transparency in AI usage, and (7) instructor discretion in AI integration. Our work lays the foundation for future analyses or recommendations in developing comprehensive and equitable AI policies. Furthermore, leveraging LLMs allows us to respond swiftly to developments surrounding AI policies across universities.