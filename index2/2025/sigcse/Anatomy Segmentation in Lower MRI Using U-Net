Translating Magnetic Resonance Imaging (MRI) scans into accurate and individualized models presents significant challenges due to the inherent variability in anatomical structures and the difficulty of distinguishing these structures from surrounding tissues. Low proton density and short transverse relaxation times in bone tissue, combined with challenges such as susceptibility to motion artifacts, long acquisition times, and susceptibility-related distortions, degrade the quality of MRI data and further exacerbate the difficulty of accurately segmenting bone structures in MRI scans. However, the advent of deep learning and Convolutional Neural Networks (CNNs) has driven substantial progress in image segmentation, particularly in overcoming challenges such as blurred boundaries, noise, and limited data. This study presents a novel U-Net-based framework for anatomy segmentation in MRI scans, enhanced by a pre-trained ResNet50 backbone for feature extraction. The framework is comprehensively evaluated across different anatomical planes, optimizing both loss functions and image scales. By combining Dice loss and boundary loss in an optimal ratio, and adjusting the input image scale, the model achieved an average Dice score of 0.92 across 10 diverse datasets, demonstrating its robustness. Furthermore, this model is integrated into MedVis Suite, an open-sourced educational platform designed to facilitate learning in computer vision and machine learning. This hands-on approach bridges theoretical concepts and real-world applications, fostering a stronger comprehension of deep learning techniques in medical imaging.