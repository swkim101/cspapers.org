Self-efficacy is a reliable predictor of academic motivation and achievement across various disciplines and age groups, including computing education. Enhancing self-efficacy through instructional experiences and tools improves motivation and achievement, making it valuable in computing education. To make use of this relationship, educators and researchers must be able to accurately measure how experiences and tools affect self-efficacy. This study replicated and extended the validation of a new self-efficacy measurement for introductory programming students developed by Steinhorst et al. (2020). It replicated features of the original study, such as using other programming-specific self-efficacy measures. The study also introduced measures of general self-efficacy, collected data in new types of courses, collected data for a new programming language, and explored changes in self-efficacy throughout courses to assess validity. The results showed robust internal consistency and construct and convergent validity of the Steinhorst instrument for both introductory programming and data structures courses, aligning with general self-efficacy theory. The findings indicate the Steinhorst instrument's adaptability across different programming languages and contexts. A key insight is the need for researchers and educators to tailor the instrument by excluding items not yet covered in the curriculum to maintain its reliability. This research enhances the understanding of the Steinhorst instrument's robustness for assessing programming self-efficacy across diverse educational settings.