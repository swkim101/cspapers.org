The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.