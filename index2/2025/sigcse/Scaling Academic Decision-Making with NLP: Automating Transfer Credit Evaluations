Manual processes for evaluating external course syllabi for transfer credit in higher education are time-consuming, inconsistent, and prone to bias. This project leverages Natural Language Processing (NLP) and large language models (LLMs) to automate the transfer credit evaluation process. The system processes external syllabi by embedding course content, conducting similarity searches, and providing structured reasoning for each match. Using techniques such as chain-of-thought reasoning and reflection agents, the system generates similarity scores and detailed explanations to support informed, data-driven decision-making by faculty. Validated against faculty decisions, the system promises to significantly improve the efficiency, consistency, and fairness of transfer credit evaluations. Future directions include expanding the system for advanced standing test evaluations and allowing faculty to query specific course components for more targeted analysis.