Online Resource Allocation problem is a central problem in many areas of Computer Science, Operations Research, and Economics. In this problem, we sequentially receive n stochastic requests for m kinds of shared resources, where each request can be satisfied in multiple ways, consuming different amounts of resources and generating different values. The goal is to achieve a (1−є)-approximation to the hindsight optimum, where є>0 is a small constant, assuming each resource has a large budget (at least Ω((1/є))). In this paper, we investigate the learnability and robustness of online resource allocation. Our primary contribution is a novel Exponential Pricing algorithm with the following properties: Firstly, it requires only a single sample from each of the n request distributions to achieve a (1−є)-approximation for online resource allocation with large budgets. Such an algorithm was previously unknown, even with access to polynomially many samples, as prior work either assumed full distributional knowledge or was limited to i.i.d. or random-order arrivals. Secondly, it is robust to corruptions in the outliers model and the value augmentation model . Specifically, it maintains its (1 − є)-approximation guarantee under both these robustness models, resolving the open question posed by Argue, Gupta, Molinaro, and Singla (SODA 2022). Lastly, it operates as a simple item-pricing algorithm that ensures incentive compatibility. The intuition behind our Exponential Pricing algorithm is that the price of a resource should adjust exponentially as it is overused or underused. It differs from conventional approaches that use an online learning algorithm for item pricing. This departure guarantees that the algorithm will never run out of any resource, but loses the usual no-regret properties of online learning algorithms, necessitating a new analytical approach.