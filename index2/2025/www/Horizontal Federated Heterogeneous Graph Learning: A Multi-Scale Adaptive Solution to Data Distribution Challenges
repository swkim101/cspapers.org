Federated heterogeneous graph learning, an extension of federated learning, effectively represents complex multidimensional relationships while maintaining data privacy. In horizontal federated heterogeneous graph learning, data from different parties often vary in topology and semantics, leading to sensitivity to distribution imbalances and increasing topological complexity. These differences hinder models from learning shared representations and cause instability during training. To address these challenges, this paper proposes a novel multi-scale adaptive horizontal federated heterogeneous graph learning method MAFedHGL. A random masking mechanism forces the model to infer missing connections. The model also captures multi-hop and multi-path connections using high-order topology mining, enhancing robustness against structural heterogeneity. Dynamic semantic consistency modeling uses a masking matrix to recover and integrate diverse node attributes, ensuring both global and local semantic consistency. Using clustering coefficients as aggregation weights enables clients with richer structural information to contribute more effectively to the global model, improving adaptability and performance across varying data distributions in horizontal federated heterogeneous graph learning. Extensive experiments on multiple public heterogeneous graph datasets validate that the proposed method outperforms state-of-the-art methods in both performance and robustness across various data distribution scenarios.