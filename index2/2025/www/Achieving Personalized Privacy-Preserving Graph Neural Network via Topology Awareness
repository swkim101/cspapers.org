Graph neural networks (GNNs) with differential privacy (DP) offer a reliable solution for safeguarding sensitive information within graph data. Nonetheless, existing DP-based privacy-preserving GNN learning frameworks generally overlook the local topological heterogeneity of graph nodes and tailor the same privacy budget for all nodes, which may lead to either overprotection or underprotection of some nodes, potentially diminishing model utility or posing privacy leakage risks. To address this issue, we propose a Topology-aware Differential Privacy Graph Neural Network learning framework, termed TDP-GNN, which can achieve personalized privacy protection for each node with improved privacy-utility guarantees. Specifically, TDP-GNN first identifies the topological importance of each node via an adjacency information entropy method. Then, the personalized topology-aware privacy budget is designed to quantify the privacy sensitivity of each node and adaptively allocate the privacy protection strength. Besides, a weighted neighborhood aggregation mechanism is proposed during the message-passing process of GNN training, which can eliminate the impact of the introduced differentiated DP noise on the utility of the GNN model. Since TDP-GNN is based on node-level local DP, it can be seamlessly integrated into any GNN architecture in a plug-and-play manner while ensuring formal privacy guarantees. Theoretical analysis indicates that TDP-GNN achieves Îµ-differential privacy over the entire graph nodes while providing personalized privacy protection. Extensive experiments demonstrate that TDP-GNN consistently yields better utilities when applied to various GNN architectures (e.g., GCN and GraphSAGE) across a diverse set of benchmarks.