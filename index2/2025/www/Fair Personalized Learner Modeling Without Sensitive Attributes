Personalized learner modeling uses learners' historical behavior data to diagnose their cognitive abilities, a process known as Cognitive Diagnosis (CD). This is essential for web-based learning services such as learning resource recommendation and adaptive testing. However, prior studies have shown that CD models may unfairly correlate learners' abilities with sensitive attributes (e.g., gender, region), leading to biased outcomes. While existing approaches mitigate this issue by decorrelating sensitive attributes from the modeling process, privacy concerns make collecting such attributes impractical. Furthermore, the presence of multiple sensitive attributes complicates fairness improvements. In this paper, we explore how to achieve fair personalized learner modeling without relying on any sensitive attribute input. We introduce a novel fairness objective tailored for personalized learner modeling and design a max-min strategy to facilitate both sensitive information inference and fair CD modeling. In the max step, we infer pseudo-labels by maximizing the fairness objective, while in the min step, we retrain the CD model by minimizing it. Additionally, we provide a theoretical guarantee that our framework reduces the upper bound of fairness generalization error. Extensive experiments demonstrate that the proposed framework significantly outperforms existing methods. Our code is available at: https://github.com/HeFei-X/FairWISA.