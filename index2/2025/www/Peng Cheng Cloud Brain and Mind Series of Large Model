As a revolutionary pre-training model, ChatGPT has already had a huge impact on global economic. It is the strong foundation of computing power that enables large models to continuously improve in the process of understanding massive data, resulting in breakthrough innovations. Based on the Peng Cheng Cloud Brain II E-level intelligent computing platform, Peng Cheng Laboratory is training PCL Mind Series of Large Model. Mind is the first fully autonomous, controllable, safe, open-source pre-training foundation model in China, where the performance of the 200 billion parameter base model reaches the international advanced, and the output content conforms to the Chinese core values. Peng Cheng Laboratory is opening up PCL Mind cooperation and work with external partners to continuously build a large model open-source consortium for domestic large model ecosystem. The next generation-Peng Cheng Cloud Brain III will break through key technologies such as high computing power chips, large-scale networking communication, high-performance software stacks, and large-scale parallel training, and support 10,000 chip-level parallel training of trillion-level parameter AI.