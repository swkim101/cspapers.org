This article proposes a $256 \times 128$ in-memory computing array using reconfigurable in-memory analog-to-digital conversion with shared references for high area efficiency (area overhead of 3% is $9 X$ better than traditional). A dual-8T SRAM bitcell is used to achieve read-write decoupling and store ternary weights. Read World Line Under Drive enabled Cascode helps to minimize current variations producing high linearity. Multi-bit input is handled with low latency and high energyefficiency by using bit-slicing (BS) with near-memory chargesharing based binary weighted accumulator (CHA). Using noise resilient training, we show software comparable performance for a MLP on MNIST, VGG-8 on CIFAR-10, and graph attention network on Cora, with respective accuracy reductions of only $0.1 \%, 0.8 \%$ and 0.5% due to non-idealities. The proposed macro demonstrates high energy/area efficiency (1146 TOPS/W, 27 TOPS $/ \mathbf{m m}^{\mathbf{2}}$ at $\mathbf{1} \boldsymbol{/} \mathbf{2} \boldsymbol{/} \mathbf{1 b}$) in $\mathbf{6 5 ~ n m}$ CMOS. It increases throughput (by $1.9 X$) and linearity (by $23 X$) compared to input pulse-width modulation by using BS and CHA. Compared to conventional BS with digital accumulation after ADC, this method has $1.7 X / 6.6 X$ better energy-efficiency/throughput by reducing ADC operations.