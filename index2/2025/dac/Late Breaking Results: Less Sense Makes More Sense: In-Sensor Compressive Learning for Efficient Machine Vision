Integrating deep learning and image sensors has significantly transformed machine vision applications. Yet, conventional highresolution image acquisition schemes enabled by imagers are energyinefficient for deep learning, as they involve excessive data quantization and transmission overhead. To address this challenge, we propose a lightweight in-sensor compressive learning framework that integrates a compressive learning-based encoder within image sensors for taskspecific feature extraction. Our framework encodes raw images into adaptive low-dimensional representations using only a 1-bit encoder by joint optimization with downstream machine vision tasks. It achieves $10 \times$ data compression, a minimum of 1.6% accuracy loss in the task, and $3.93 \times$ energy savings at the sensor-end, outperforming prior arts.