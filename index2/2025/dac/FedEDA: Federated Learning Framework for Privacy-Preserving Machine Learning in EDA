In advanced nodes, the optimization of Power, Performance, and Area (PPA) is becoming increasingly complex, requiring significant resources and time for circuit design and optimization using Electronic Design Automation (EDA). As a key approach to overcome these challenges, Machine Learning (ML) techniques have been widely studied in the field of EDA. However, security concerns around Intellectual Property (IP) limit access to real-world circuit data, making it difficult to gather sufficient data for training ML models. This lack of available circuit benchmarks restricts progress in ML research. In this study, we propose FedEDA, which, to the best of our knowledge, is the first Federated Learning (FL) aggregation algorithm specifically designed for EDA. FedEDA addresses concerns about IP security by exchanging model weights among FL participants instead of sharing raw data. Furthermore, FedEDA leverages Rentâ€™s Rule and circuit size to capture the hierarchical structure of circuits, mitigating issues related to data imbalance among participants and improving the quality of weight aggregation on EDA data. We demonstrate the applicability of FedEDA across various EDA tasks, including routability, parasitic RC, and wirelength prediction. FedEDA outperforms existing FL algorithms in EDA tasks, demonstrating superior performance.