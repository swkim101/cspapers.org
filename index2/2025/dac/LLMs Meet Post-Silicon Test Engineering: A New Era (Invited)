The transformative power of Large Language Models (LLMs) is reshaping the role of AI in post-silicon test engineering. This paper summarizes our experience in leveraging LLMs to develop AI agents specifically tailored for this domain. Central to our approach is a two-stage process: first, we utilize the reasoning capabilities of LLMs to systematically interpret user queries; second, we invoke a grounding process to execute tasks as directed by these queries. This grounding ensures seamless integration of the LLM with existing test engineering infrastructure, enabling the AI agent to autonomously perform tasks within an established framework. Using the Intelligent Engineering Assistant (IEA) as a case study, we demonstrate how domain-specific, LLM-powered AI agents can automate critical aspects of test engineering, and highlight the potential of LLMs to revolutionize post-silicon test engineering through intelligent, context-aware automation.