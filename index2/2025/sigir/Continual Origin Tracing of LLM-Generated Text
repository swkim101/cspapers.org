The rapid development of large language models (LLMs) raises concerns about their potential misuse. Accurately identifying and tracing the origin of LLM-generated content is crucial for accountability and transparency. Previous methods typically frame origin tracing as multi-class classification with a fixed label set, thus struggle to adapt to new LLMs without frequent retraining. This paper introduces a new task, continual origin tracing of LLM-generated text, which frames origin tracing in a continual learning or, more precisely, class-incremental learning manner, where new LLMs continuously emerge, and a model incrementally learns to identify new LLMs without forgetting old ones. A novel training-free method is further devised for the task, which continually extracts prototypes for emerging LLMs using a frozen pre-trained model, and conducts global and local prototype decorrelation to improve prototype matching, thus favoring more accurate tracing. To facilitate evaluation on the new task, we construct a benchmark comprising text generated by 19 recently released LLMs from 12 vendors that simulates a real-world scenario where these LLMs emerge over time and need to be recognized incrementally across 8 diverse domains. Rigorous evaluations on this benchmark highlight the effectiveness and potential of the proposed method in the new task, offering a promising direction for future research.