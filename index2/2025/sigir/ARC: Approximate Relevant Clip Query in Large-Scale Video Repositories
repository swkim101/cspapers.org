The exponential growth of video data highlights the necessity of exploring large-scale video repositories to extract valuable insights. Querying video clips based on content and temporal attributes is a critical task. However, existing solutions face two major challenges: insufficient flexibility in handling complex query conditions involving statistical reasoning and temporal constraints, and low efficiency under high query quality requirements and resource constraints. In this paper, we formally introduce the concept of relevant clip queries for the first time, providing a framework for querying relevant clips in a much more flexible way. To answer such queries efficiently, we propose the approximate query processing system ARC, which aims to maximize the recall and minimize the query overhead while ensuring the confidence of the query results. ARC adopts a proxy model to prune the original video repositories and uses an oracle model to refine the pruned results. Evaluation on real-world video datasets shows that ARC achieves an average speedup of 32.57Ã— compared to naive baselines, while significantly outperforming state-of-the-art methods in almost all performance metrics. Sensitivity and ablation analysis further validate the robustness and effectiveness of the ARC components.