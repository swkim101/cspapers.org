In the Web ecosystem, document authors often strategically modify content to maximize visibility in search rankings. These ranking-incentivized modifications pose challenges to retrieval effectiveness, content diversity, and long-term stability. At the same time, the rise of large language models (LLMs) is transforming IR: queries and documents that were once assumed to be generated exclusively by humans can now also be created by automated agents [5]. These agents can formulate queries, generate documents, and perform ranking. This introduces a variety of new challenges and opportunities in competitive search environments, where interactions between strategic agents can substantially influence outcomes. This research pursues two primary goals. First, it seeks to understand strategic interactions, particularly how different configurations of users (query), authors (document) and systems (ranker) influence competition outcomes. Second, it explores methods for designing systems that foster beneficial outcomes, such as stability and fairness. To this end, this research employs a combination of game-theoretic analysis, empirical ranking competitions between humans, and simulation-based experiments to investigate competitive dynamics in information retrieval systems [1-4]. Our theoretical analysis begins by modeling settings where authors compete to promote their documents across multiple queries as a continuous game in which each author allocates emphasis across different queries. We fully characterize when pure Nash equilibria exist and show that, unlike single-query settings, a stable state almost never exists [4]. To address this instability, we propose a novel method of strategic corpus enrichment. Specifically, we show using theoretical analysis how the mediator, by strategically planting documents in the corpus, can achieve stability in the system [2].