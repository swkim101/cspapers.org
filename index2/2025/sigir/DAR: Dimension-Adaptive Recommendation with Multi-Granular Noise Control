Implicit feedback has become the primary source of training data for modern recommender systems due to its abundance and ease of collection. However, the inherent noise in implicit feedback poses significant challenges to model training. Existing denoising approaches either completely remove suspected noisy interactions (re-sampling) or uniformly adjust their importance (re-weighting). Such coarse-grained treatments fail to capture the complex nature of noise in real-world scenarios, where different aspects of an interaction may have varying noise levels. In this paper, we propose a novel perspective on fine-grained denoising. Our key insight is that noisy interactions often result from simple, impulsive decisions triggered by surface-level aspects and thus require less information to represent, while genuine preferences involve more complex considerations of aspects that need richer representations. Based on this insight, we propose DAR, a dimension-adaptive recommendation framework that dynamically adjusts each interaction's representation dimension to achieve fine-grained denoising control (re-scaling). Grounded on the Information Bottleneck theory, we establish that this dimension-adaptive approach provides a principled solution for preserving useful signals while limiting noise propagation. DAR implements this theoretical insight through three key components: (1) multi-granular noise estimation that considers interaction-level, user-level, and item-level signals (2) dimension adaptation that determines appropriate representation dimensions based on estimated noise levels, and (3) temporal smoothing that ensures stable training. Extensive experiments on real-world datasets demonstrate that DAR consistently outperforms state-of-the-art denoising methods, while providing interpretable insights about interaction noise. The source code is publicly available at https://github.com/Riwei-HEU/DAR.