The continual emergence of new entities and relations drives the dynamic expansion of knowledge graphs (KG). In the face of such growing KG, relearning from scratch wastes acquired knowledge, while learning solely from new snapshots leads to model forgetting of old knowledge. Existing methods focus on lifelong learning in growing KG through transfer and regularize embeddings. However, extensive entity updates to adapt to new snapshots introduce conflicts between old and new knowledge, thereby resulting in the inevitable occurrence of knowledge forgetting. To address these challenges, we propose the Evolutionary Relation Path Passing (ERPP) model for lifelong knowledge graph embedding, aiming to shift from knowledge forgetting to knowledge accumulation, thereby achieving accurate long-term prediction. Specifically, we propose a snapshot conditional relation path passing strategy to generate expressive representations that better adapt to snapshots compared to the transferred embeddings in existing methods. Subsequently, we propose a relation inheritance and evolution mechanism across snapshots and continue relation path passing in next snapshots. This allows ERPP to avoid inevitable catastrophic forgetting from frequent entity embedding updates. ERPP outperforms SOTA models in 35 scenarios, with average improvements of 11.1% in long-term prediction and 12.9% in knowledge transfer. Moreover, ERPP makes a breakthrough in achieving knowledge positive accumulation, in contrast to the negative forgetting of existing models. To the best of our knowledge, ERPP is the first model to realize knowledge accumulation. Our code is available at https://anonymous.4open.science/r/ERPP-6D66.