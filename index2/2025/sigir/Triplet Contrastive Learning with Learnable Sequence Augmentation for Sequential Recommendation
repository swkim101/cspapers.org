The quality of augmented data directly affects the performance of contrastive learning. Low-quality augmentation offers limited benefits for model optimization. Existing contrastive learning-based sequential recommendation works primarily utilize heuristic data augmentation methods, which often exhibit excessive randomness and struggle to generate positive samples that align with users' true intentions. To address this limitation, we propose Triplet Contrastive learning with Learnable sequence Augmentation for sequential Recommendation (TCLARec). Unlike heuristic or rule-based augmentation methods, we train a learnable sequence augmentation module that can automatically leverage the self-supervised information from global context to select appropriate modification positions and augmentation operations, thereby generating positive samples that more accurately reflect user preferences. Furthermore, we design a ranking-based triplet contrastive loss to enhance the positive feedback from augmented sequence generated by the augmentation module, providing more nuanced contrastive signals for model optimization. Extensive experiments on three real-world datasets demonstrate that TCLARec outperforms state-of-the-art sequential recommendation baselines. Our in-depth analyses confirm that both the learnable augmentation and triplet contrastive learning contribute to improving recommendation accuracy. We have released the code at https://github.com/anonymityww/TCLA.