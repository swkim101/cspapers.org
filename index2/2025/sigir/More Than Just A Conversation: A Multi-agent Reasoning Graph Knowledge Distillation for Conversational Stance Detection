Conversational stance detection, which aims to identify stances within conversation threads, has become a research hotspot recently. As the number of dialogue turns increases and the conversation content becomes more complex, existing methods that simply incorporate conversational context are insufficient to effectively capture the nuanced information necessary for accurate stance detection. To address this issue, we introduce a Multi-agent Reasoning Graph Knowledge Distillation (MRGKD) framework, leveraging conversational reasoning among multiple Large Language Models (LLMs) into smaller language models. Specifically, we first construct a multi-agent reasoning graph to infer implicit logical relationships within the conversational history from the diverse perspectives of multiple LLMs. To fully leverage the in-context learning capabilities of LLMs, we design a reasoning knowledge editing mechanism that internalizes new information by aligning the output distribution of smaller language models with both the conversational history and the knowledge derived from the multi-agent reasoning graph. Additionally, we incorporate a contrastive loss to distinguish between correct and incorrect reasoning, alongside a stance detection loss, to fine-tune the smaller language models. This approach not only ensures the accurate acquisition of logical knowledge but also preserves the integrity of the conversational history. Experiments conducted on two public datasets demonstrate that our MRGKD significantly outperforms all baselines.