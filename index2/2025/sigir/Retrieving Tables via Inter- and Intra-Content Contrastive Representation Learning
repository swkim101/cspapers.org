Contrastive learning has emerged as a highly effective and versatile technique in information retrieval. However, its application within table retrieval remains limited, and often neglecting a typical phenomenon in table retrieval: one table can be associated with multiple, distinct queries. Directly applying traditional contrastive learning strategies may lead to semantic contrast conflicts during training, potentially impairing the quality of learned representations. Additionally, many current table retrieval methods still operate on query-table joint encoding, which introduces notable inefficiencies during both the training and retrieval processes. For this issue, this paper proposes ConTR, a tabular semantic contrastive learning method that simultaneously considers both inter-table and intra-table differences. By segmenting table into multiple vector representations and enabling the matching of diverse queries through differentiated vectors, thereby facilitating a more focused contrastive learning process. Retrieval experiments based on two typical table-related tasks validate the feasibility and effectiveness of proposed method.