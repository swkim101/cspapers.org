Personalized news recommendation plays a vital role in mitigating information overload, yet challenges persist in accurately capturing user preferences and fine-grained interests. Leveraging the semantic understanding and extraction capabilities of large language models (LLMs), we propose a Multi-Interest Personalized News Recommendation (MIPNR) model to address these issues. MIPNR separately models user interests at the user, news, and entity levels. Specifically, we introduce a Category-Guided Interest-News Matching (CGIN-Matching) method to identify potential interests, a Local News Entity Graph (LNEG) to model subtle entity relationships, and an entity-wise attention mechanism to extract fine-grained interests. In addition, LLMs are used to generate explicit textual descriptions of user preferences. Extensive experiments on real-world datasets demonstrate the effectiveness of our approach.