Designing effective negative sampling strategies is crucial for training Multi-Modal Recommendation (MMRec) models, as it helps address the issues of sparse user-item interactions and facilitates the learning of high-dimensional modality features. However, most existing methods randomly sample non-interacted items as negative ones, which frequently result in easy negatives. They limit the model's ability to accurately capture user preferences. In this paper, we propose to Generate Difficulty-aware Negative Samples via conditional diffusion for MMRec (denoted as GDNSM). Leveraging the rich semantic and contextual information from multi-modal features, our method generates hard negative samples with varying difficulty levels, tailored to user preferences. They force the model to learn finer-grained distinctions between positive and negative samples, enhancing its ability to inferring user preferences. To avoid unstable training, we design a dynamic difficulty scheduling mechanism that schedules the negative samples from easy to hard for model training, ensuring both stability and effectiveness. Extensive experiments on three real-world datasets demonstrate that the effectiveness of our models.