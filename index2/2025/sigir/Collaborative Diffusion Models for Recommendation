Recently, recommendation models based on collaborative filtering have increasingly leveraged not only primary user-item interactions but also auxiliary information such as implicit relational structures (e.g., user-user or item-item graphs) and multimodal content (e.g., images and textual descriptions) to enhance recommendation performance. A key challenge in this context lies in effectively integrating auxiliary features derived from semantic structures or modality representations into user-item modeling, in a way that enhance performance without incurring detrimental effects. Furthermore, since these features often originate from heterogeneous semantic or modal spaces, they may include redundant or task-irrelevant information that can hinder the learning process. To address these issues, we propose the Collaborative Diffusion Models for Recommendation (CoDMR). CoDMR employs diffusion models in latent feature spaces to filter out task-irrelevant noise embedded in auxiliary features. It introduces task-relevant collaborative signals as conditional guidance during the denoising process, facilitating the generation of auxiliary representations aligned with the recommendation task. These refined features are then incorporated into user-item interaction modeling, resulting in enhanced representations for both users and items. Extensive experiments on three public datasets consistently demonstrate that our CoDMR method outperforms various competitive baselines. The source code of the model implementation is available at the link https://github.com/cmr123456/CoDMR.