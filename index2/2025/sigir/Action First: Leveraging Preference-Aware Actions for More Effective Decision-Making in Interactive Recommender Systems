Interactive recommender systems (IRSs) aim to meet user needs through natural language dialogues, optimizing recommendations with minimal interactions. Typically, IRSs are based on large language models (LLMs). Existing methods generally consist of two stages: decision-making (deciding whether to recommend or ask clarification questions) and action execution (generating recommendations or clarification questions). These methods usually follow a decision-first paradigm, where the model first decides on the action based on past conversations, and then executes the corresponding action. Since LLMs struggle to process a large number of candidate items, the recommendation process is often carried out in collaboration with external recommendation tools, which provide a small candidate set for LLMs to refine. Existing methods face two key information gaps: (1) In the decision-making stage, the decision-first paradigm relies solely on past conversations, leading to incomplete decisions due to the uncertainty of subsequent actions' outcomes. (2) In the action execution stage, there is a unidirectional flow from external recommendation tools to LLMs, where these tools fail to interpret user preferences effectively, thus reducing the recommendation accuracy. To address these challenges, we introduce Action-First Interactive Recommender System(AF-IRS), a novel model that uses preference-aware actions to guide decision-making. Our Action-First paradigm informs decisions with future recommendations, ensuring more accurate decisions. Additionally, we establish a bidirectional interaction loop between LLMs and external recommendation tools, enabling LLMs to interpret and transmit session preferences for more precise recommendations. Experimental results on three benchmark datasets demonstrate that AF-IRS significantly improves both recommendation accuracy and efficiency, addressing the information gaps in both stages.