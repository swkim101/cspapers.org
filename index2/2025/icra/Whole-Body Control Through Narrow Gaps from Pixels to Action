Flying through body-size narrow gaps in the environment is one of the most challenging moments for an underactuated multirotor. We explore a purely data-driven method to master this flight skill in simulation, where a neural network directly maps pixels and proprioception to continuous low-level control commands. This learned policy enables wholebody control through gaps with different geometries demanding sharp attitude changes (e.g., near-vertical roll angle). The policy is achieved by successive model-free reinforcement learning (RL) and online observation space distillation. The RL policy receives (virtual) point clouds of the gaps' edges for scalable simulation and is then distilled into a high-dimensional pixel space. However, this flight skill is fundamentally expensive to learn by exploring in RL due to restricted feasible solution space. We propose to reset the agent as states on the trajectories generated by a model-based trajectory optimizer to alleviate this problem. The presented training pipeline is compared with baseline methods, and ablation studies are conducted to identify the key ingredients of the method. The immediate next step is to demonstrate the sim-to-real transformation, which can be challenging due to the high precision demands by this extreme flight skill.