Heavy-duty glass installation is a high-risk, precision-critical task in modern construction, traditionally performed through labor-intensive and error-prone manual methods. This paper presents a novel robotic framework that leverages diffusion-based self-supervised imitation learning from imperfect visual servoing demonstrations to achieve safe and precise glass installation. Specifically, our approach employs noisy and suboptimal demonstration data obtained via visual servoing to train a Denoising Diffusion Probabilistic Model (DDPM). This model iteratively refines installation trajectories, transforming them into smooth, precise, and collisionfree movements. Extensive experiments demonstrate that our method significantly surpasses conventional visual servoing and standard imitation learning baselines in terms of success rate, precision, and installation efficiency, while markedly improving operational safety. Our results establish a new benchmark for automating complex, high-risk tasks in construction robotics.