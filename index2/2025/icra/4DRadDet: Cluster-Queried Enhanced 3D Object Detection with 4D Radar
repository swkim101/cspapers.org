D object detection plays a critical role in advancing autonomous driving technology. To improve perception capabilities while maintaining low costs and ensuring performance in adverse weather conditions, 4D radar has emerged as a promising alternative for 3D object detection. However, current methods fail to fully exploit raw data and density information of 4 D radar point clouds to tackle challenges like sparse data and noise. To address these limitations and make use of the unique Doppler velocity information provided by 4D radar, we propose a novel approach called 4DRadDet, which uses cross-attention fusion with cluster-queried techniques for 3D object detection. The 4DRadDet model uses a specially designed incremental clustering method to cluster potential object point clouds, reducing measurement errors from limited radar angular resolution and signal multipath effects. The cross-attention feature fusion (CAFF) module enhances network performance by querying the clustered point cloud feature map, allowing the network to leverage reliable prior information from the clustered point cloud to better detect potential objects. Our experimental evaluations on the View-of-Delft (VoD) dataset demonstrate the effectiveness of 4DRadDet, showcasing state-of-the-art performance. Specifically, 4DRadDet achieves a 3D mean average precision ($\text{mAP}_{3 \mathrm{D}}$) of 51.44 % and a bird'seye view mean average precision ($\mathbf{m A P}_{\text {BEV }}$) of $\mathbf{5 7. 0 7 \%}$. Our proposed method demonstrates impressive inference times and achieves real-time detection capabilities.