This paper addresses rock hazard detection for in-situ resource utilization (ISRU) robotic navigation in the challenging visual environment of the lunar south pole (LSP). We evaluate three state-of-the-art instance segmentation mod-els-Mask R-CNN, YOLOv8, and SAM-using a novel, synthetically generated dataset that simulates LSP-specific illumination challenges at sun angles of $2.5^{\circ}, 5^{\circ}$, and 7.5Â°. Additionally, we evaluate these approaches in both up and downsun driving with low solar angle light. This study highlights the potential of deep learning-based approaches for improving ISRU operations by reliably identifying visual surface hazards, such as rocks, which may impede robotic navigation and excavation in future lunar missions.