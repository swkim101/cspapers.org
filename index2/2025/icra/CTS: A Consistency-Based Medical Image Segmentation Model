In medical image segmentation tasks, diffusion models have exhibited significant potential. However, mainstream diffusion models show drawbacks including multiple sampling times and slow prediction results. Recently, as a standalone generative network, consistency models have resolved the existing issue. Compared to diffusion models, consistency models can lower the sampling times to once, not only achieving similar generative effects but also significantly accelerating training and prediction. However, they are not suitable for image segmentation tasks. Meanwhile, their application in the medical imaging field has not yet been investigated. Therefore, this study employs the consistency model to perform medical image segmentation tasks, designing multi-scale feature signal supervision modes and loss function guidance to realize model convergence. Experiments have demonstrated that the CTS model is capable of obtaining better medical image segmentation results with a single sampling during the test phase.