As robots are prone to make errors that undermine trust, effective trust repair strategies are essential in effective human-robot collaboration. Our lab study evaluates three trust repair strategies -apology, denial, and compensation- following two types of trust violations: competence-based and integritybased. Consistent with prior research, integrity-based violations reduced moral trust more, while competence-based violations impacted performance trust. Denial caused greater discomfort than apology or compensation across both violation types. Dispositional trust influenced repair strategies effectiveness, particularly in willingness to engage and re-engage. Notably, individuals with high dispositional trust were more receptive to apologies. These findings underscore the need to consider individual trust differences, suggesting robots should assess human trust disposition to effectively foster continued collaboration.