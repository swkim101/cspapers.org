This article presents an interactive control approach allowing a human user to teleoperate a robotic manipulator located nearby. With this approach, the user keeps his/her hands free, as only head movements are exploited to control the robot. The controller maps the 6 Degrees of Freedom (DoF) user's head position and orientation into the 6 DoF robot endeffector position and orientation. The robot can reach a large workspace thanks to the combination of two features. Firstly, a virtual wand between the user's head and the robot end-effector converts user's head pantilt rotations into large displacements of the robot end-effector center perpendicularly to the wand axis (2 DoF). Secondly, for the remaining 4 DoF (robot end-effector center displacement along the wand axis and robot en-effector orientation), realtime deformation of the virtual wand is triggered when the user reaches uncomfortable configurations due to his/her head workspace limitations. Additionally, the user gets, through an Augmented Reality (AR) Headset, a non-delayed visual feedback of the current virtual wand geometry and location. The paper includes a description of the setup and the proposed controller, detailing how the robot position/orientation is coupled to the user's head position/orientation. A set of elementary experiments with a constant-geometry wand is first presented, showing workspace limitations for some DoF. Then the wand reconfiguration is introduced in the experiments, leading to full control of 6 DoF manipulation tasks throughout a large workspace.