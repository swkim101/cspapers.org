Multi-view image-based BEV (Bird's Eye View) 3D perception is gaining attention as an alternative to highcost LiDAR systems and has achieved notable success. However, there is a significant safety concern for future image-based BEV autonomous driving in low-light conditions (such as nighttime) while the limited research on BEV detectors for these scenes. In this paper, we attempt to enhance low-light BEV perception with illumination-guided feature fusion. We propose Retinex-BEVFormer, which uses illumination information generated by the Retinex theory to enhance the model's robustness to varying lighting conditions and improve detection performance in low-light scenes. Additionally, to address the illumination estimation discontinuity from multi-view images that can adversely affect detection, we propose the MVB-Retinex module, which balances illumination estimation by leveraging overlapping regions between adjacent images. Notably, our proposed method is a plug-and-play module that can be applied to any image-based BEV detector method and does not require any additional ground truth supervision. We conduct extensive experiments on the nuScenes dataset, validating our algorithm in nighttime and daytime scenes. Compared to the baseline, our algorithm achieves a 2.9% increase in mAP on the validation set with minimal computational cost, especially showing a 3.6% improvement in the nighttime scene. The experiments demonstrate that our Retinex-BEVFormer effectively improves detection performance under low light conditions and enhances performance under normal illumination, indicating increased robustness of the BEV detector.