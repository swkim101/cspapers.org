In the realms of autonomous driving and robotics, radar sensors are garnering growing interest. Scene understanding is crucial for the safe navigation of autonomous systems. Panoptic segmentation and tracking tasks enable the dynamic, semantic multilevel description of the environment surrounding vehicles and different instances. However, previous panoptic segmentation and tracking methods have primarily focused on LiDAR. To tackle the complex challenge of panoptic segmentation and tracking for radar data, we introduce RadarMask, an innovative method that addresses this issue for the first time within the radar domain. Our approach is end-to-end, requiring no post-processing. We also introduce simple and effective point cloud feature modules and target motion estimation modules tailored to the unique characteristics of radar points. Finally, we demonstrate the effectiveness of our algorithm on the RadarScenes dataset, achieving state-of-the-art performance in comparisons. The implementation of our method can be found at: https://github.com/yb-guo/RadarMask.