Fire poses significant threats to life and property, necessitating efficient inspection and accurate identification. Although aerial computer vision algorithms hold great promise, the deployment and computational limitations of onboard platforms prevent existing algorithms from meeting high standards of accuracy and real-time performance. To address these challenges, we propose an lightweight aerial fire detection model, LAFNET. This model incorporates the EffiDarknetLight backbone, optimized for both lightweight design and ease of deployment, integrates specially designed LightGhost(LG) block components within the LightGhost-Path Aggregation Network(LG-PAN) neck, resulting in a model Params of only 1.3 M. Experimental results demonstrate that our method attains a good trade-off between lightweight design and detection accuracy. Compared to the smallest standard YOLO series' model YOLOv5n, LAFNET improves MAP by $\mathbf{2. 1 \%}$, while reducing Params and FLOPs by $\mathbf{2 7. 8 \%}$ and $\mathbf{2 9. 3 \%}$, the inference speed on Nvidia Orin Nano edge computing side improves 24.8 %. These experiments indicate that LAFNET offers a highly efficient solution for aerial fire detection, combining speed and accuracy.