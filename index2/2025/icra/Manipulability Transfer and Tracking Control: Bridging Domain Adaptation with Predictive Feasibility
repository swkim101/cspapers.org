This paper introduces a novel framework for improving human-to-robot manipulability transfer and tracking in Learning by Demonstration. Our approach addresses key challenges, including manipulability ellipsoid (ME) domain adaptation between different kinematic structures, ME-IK feasibility checks and optimization across trajectories accounting for the robot's redundancy, and introducing a manipulability-aware control strategy. Leveraging a unified quadratic programming control with vector-field inequalities, our method enables robust tracking and optimization of manipulability, accommodating multiple demonstrations and the inherent variability in task execution. Experimental results demonstrate superior performance in precise tracking and force generation compared to traditional methods, highlighting the advantages of incorporating human implicit information for more effective robot control.