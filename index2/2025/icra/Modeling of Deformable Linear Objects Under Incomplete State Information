The robot-based tracking of highly dynamic end point motions of deformable linear objects (DLO) remains challenging due to its non-linear behavior. Since simple feedback control is infeasible, model-based control offers potential to account for the non-linear effects, but requires computation efficient and accurate models. Promising results have been achieved utilizing data-driven models that introduce a latent kinematic chain as model of the DLO and mapping measurements of the tip position in its latent joint space, in which the dynamic motion model is learned. So far, this approach has the limitation that it can not handle situations of incomplete sensory information, for instance if occlusion occurs. Consequently, this paper introduces a fusion network architecture capable of making predictions even if sensory information is incomplete. We achieve additional state estimation of the latent joint state by learning a data driven inverse kinematics with help of wrench measurements at the DLO base and evaluate our approach by simulating occlusion. We demonstrate the computational effectiveness of our approach for in the loop control tasks.