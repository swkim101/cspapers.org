Advancing technologies enable machine learning applications that replicate the appearance, behavior, and thought patterns of users based on their personal data. Termed as AI self-clones, these digital doppelgangers present introspective opportunities and existential risks, as they might amplify self-awareness or echo problematic self-views. In our study, based on the story completion method, we involved 20 diverse individuals to explore the values and risks they associate with creating AI self-clones. Our participants conceptualized AI self-clones by the roles these clones could assume, such as mirror, probe, companion, delegate, and representative. The perceived values and risks tend to correspond to these roles. For example, using self-clones as representatives could enhance relationship maintenance, yet it might also lead to diminished authenticity in personal connections; utilizing self-clones as probes to explore life scenarios could aid decision-making, but it might amplify regrets about unchosen paths. This research lays the groundwork for an ethical design of AI self-clone applications.