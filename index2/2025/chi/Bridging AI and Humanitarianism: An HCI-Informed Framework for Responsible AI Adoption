Advances in artificial intelligence (AI) hold transformative potential for humanitarian practice. Yet aligning this potential with the demands of humanitarian practice in dynamic and often resource-austere contexts remains a challenge. While research on Responsible AI provides high-level guidance, humanitarian practice demands nuanced approaches for which human-computer interaction (HCI) can provide a strong foundation. However, existing literature lacks a comprehensive examination of how HCI principles can inform responsible AI adoption in humanitarian practice. To address this gap, we conducted a reflexive thematic analysis of 34 interviews with AI technology experts, humanitarian practitioners, and humanitarian policy developers. Our contributions are twofold. First, we empirically identify three cross-cutting themes—AI risks in humanitarian practice, organisational readiness, and collaboration—that highlight common tensions in adopting AI for humanitarian practice. Second, by analysing their interconnectivities, we reveal intertwined obstacles and propose a conceptual HCI-informed framework.