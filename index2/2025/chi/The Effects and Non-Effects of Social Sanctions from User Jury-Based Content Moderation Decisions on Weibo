Between 2012 and 2014, Weibo used a novel crowdsourced user ‘committee’ system to make content moderation decisions. In it, user volunteers were randomly assigned to jury-like committees to vote and comment on whether reported content violated platform rules. The perceived legitimacy of similar systems has been studied in tightly controlled lab and survey experiments, but the causal effects of such jury-like moderation systems on user behavior in the real world have not been studied to the same extent. Leveraging random variation in Weibo case votes due to the assignment of more or less lenient ‘jurors’, we show that, on average, social sanctioning and norm-setting through committee votes was associated with a large but brief decline in reported users’ future posting of offensive terms. However, in line with prior work on the relative ineffectiveness of out-group sanctioning, we observe no such effect among women sanctioned by the largely male committees. This study advances our understanding of the effects of institutionalized social sanctioning on social media user behavior, and the promises and potential shortcomings of crowdsourced moderation systems.