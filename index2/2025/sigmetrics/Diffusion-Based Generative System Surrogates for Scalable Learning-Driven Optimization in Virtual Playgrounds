In this paper, we present DiffNEST, a diffusion-based surrogate framework that enables scalable, learning-driven optimization in complex computing environments. As modern systems become increasingly intricate, traditional optimization methods often fall short, and RL-based approaches are hindered by high data collection costs and hardware limitations. DiffNEST addresses these challenges by training a diffusion model to generate realistic and temporally coherent system traces from high-level workload and configuration inputs, eliminating the need for physical hardware during optimization. We show that DiffNEST produces high-fidelity traces that accurately reflect both spatial and temporal system behaviors. Using these synthetic traces, we optimize DVFS and multi-core cache allocation, demonstrating effective policy learning without relying on actual hardware. In addition, DiffNEST can be fine-tuned across different optimization tasks and workload domains, making it a versatile surrogate modeling framework for system-level optimization.