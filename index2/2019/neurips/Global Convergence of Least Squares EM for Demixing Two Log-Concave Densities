This work studies the location estimation problem for a mixture of two rotation invariant log-concave densities. We demonstrate that Least Squares EM, a variant of the EM algorithm, converges to the true location parameter from a randomly initialized point. We establish the explicit convergence rates and sample complexity bounds, revealing their dependence on the signal-to-noise ratio and the tail property of the log-concave distribution. Moreover, we show that this global convergence property is robust under model mis-specification. 
Our analysis generalizes previous techniques for proving the convergence results for Gaussian mixtures. In particular, we make use of an angle-decreasing property for establishing global convergence of Least Squares EM beyond Gaussian settings, as $\ell_2$ distance contraction no longer holds globally for general log-concave mixtures.