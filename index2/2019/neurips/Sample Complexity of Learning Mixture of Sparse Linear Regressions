Mixture models are widely used to ﬁt complex and multimodal datasets. In this paper we study mixtures with high dimensional sparse latent parameter vectors and consider the problem of support recovery of those vectors. While parameter learning in mixture models is well-studied, the sparsity constraint remains relatively unexplored. Sparsity of parameter vectors is a natural constraint in variety of settings, and support recovery is a major step towards parameter estimation. We provide eﬃcient algorithms for support recovery that have a logarithmic sample complexity dependence on the dimensionality of the latent space. Our algorithms are quite general, namely they are applicable to 1) mixtures of many diﬀerent canonical distributions including Uniform, Poisson, Laplace, Gaus-sians, etc. 2) Mixtures of linear regressions and linear classiﬁers with Gaussian covariates under diﬀerent assumptions on the unknown parameters. In most of these settings, our results are the ﬁrst guarantees on this problem while in the rest, we provide signiﬁcant improvements on existing results in certain regimes.