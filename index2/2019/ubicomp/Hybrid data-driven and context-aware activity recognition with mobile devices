We have designed and implemented a real-time hybrid activity recognition system which combines supervised learning on inertial sensor data from mobile devices and context-aware reasoning. We demonstrate how the context surrounding the user, combined with common knowledge about the relationship between this context and human activities, can significantly increase the ability to discriminate among activities when machine learning over inertial sensors has clear difficulties.