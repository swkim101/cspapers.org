SHL recognition challenge 2019 goal is to recognize eight locomotion and transportation (activities) from the inertial sensor data of a smartphone. The dataset contains information from different mobile-phones placement (torso, bag, hips, hand). Participants must provide their predictions based on test data that contains Hand phone sensors information. Only a small amount of Hand phone labeled data exists in the validation data. Train data consists only of torso, bag and hips placed mobile devices. Team DB proposes to apply deep semi-supervised learning. As the base for our model, we have chosen Adversarial Autoencoder (AAE) and employ Convolutional Networks for feature extraction. We prove that semi-supervised learning gives possibility to utilize test unlabeled data during AAE training with small amount of validation labeled data and achieve high model accuracy for Human Activity Recognition task.