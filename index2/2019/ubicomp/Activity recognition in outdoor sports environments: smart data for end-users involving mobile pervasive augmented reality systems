Activity recognition is an increasingly relevant topic in the context of the most varied end-user services. In outdoor environments, activity recognition based on close-to-real-time information is key in providing awareness to the user about their surroundings in a timely and user-friendly manner, thus allowing to the user to improve its overall use (Quality of Experience). In this context, it is relevant to understand how data extracted from multiple sensors can be fused, interpreted and classified, to best provide feedback to the user. Having as target case Mobile Augmented Reality Systems for outdoor environments, this paper presents a first analysis on how smart data captured via multiple sensors can assist activity recognition and adequate feedback to the user. The paper also debates the existent restrictions imposed by applications' usage in these environments, describing possible use scenarios and presenting results of an experiment for discriminating activities when using common sensors, such as the accelerometer.