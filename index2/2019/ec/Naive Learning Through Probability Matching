We analyze boundedly rational updating in a repeated interaction network model with binary states and actions. We decompose the updating procedure into a deterministic stationary Markov belief updating component inspired by DeGroot updating and pair it with a random probability matching strategy that assigns probabilities to the actions given the underlying boundedly rational belief. This approach allows overcoming the impediments to consensus and naive learning inherent in deterministic updating functions in coarse action environments. We show that if a sequence of growing networks satisfies vanishing influence, then the eventual consensus action equals the realized state with a probability converging to one.