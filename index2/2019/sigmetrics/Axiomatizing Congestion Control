Recent years have witnessed a revival of both industrial and academic interest in improving congestion control designs. The quest for better congestion control is complicated by the extreme diversity and range of (i) the design space (as exemplified by the stark conceptual and operational differences between recent proposals~\citebbr,vivace, COPA ), (ii) the desired properties (ranging from high performance to fairness to TCP-friendliness), (iii) the envisioned operational setting (inter- and intra-datacenter, wireless, the commercial Internet, satellite), and (iv) the application loads and requirements (small vs. large traffic demands, latency- vs. bandwidth-sensitive). Most congestion control research uses simulation and experiments under a limited range of network conditions. This is extremely important for understanding the detailed performance of particular schemes in specific settings, but provides limited insight into the more general properties of these schemes and no information about the inherent limits %of congestion control designs (such as, which properties are simultaneously achievable and which are mutually exclusive). In contrast, traditional theoretical approaches are typically focused on the design of protocols that achieve specific, predetermined objectives (e.g., network utility maximization~\citekelly2009 ), or the analysis of specific protocols (e.g., from control-theoretic perspectives~\citepaganini2003control ), as opposed to exploring the inherent tensions/derivations between desired properties. We advocate an axiomatic approach to congestion control, which is complementary to the experimental and theoretical work currently being pursued. Our approach, modeled on similar efforts in social choice theory and game theory~\citearrow1950difficulty, identifies a set of requirements ("axioms'') and then identifies (i) which of its subsets of requirements can coexist (i.e., there are designs that achieve all of them) and which subsets cannot be met simultaneously (i.e., no design can simultaneously achieve all of them), and (ii) whether some requirements immediately follow from satisfying other requirements. Thus, the axiomatic approach can shed light on the inherent tradeoffs involved in congestion control protocol design, and can be leveraged to classify existing and proposed solutions according to the properties they satisfy. The axiomatic approach has been applied to many computer science environments, e.g. reputation systems, recommendation systems, link prediction, and more. To the best of our knowledge, ours is the first application of this approach to congestion control protocols (though \citeshenker1990theoretical touches on the subject briefly). We introduce a simple network model where we can evaluate congestion control designs and formulate several natural axioms (or requirements) for congestion control protocols, including efficient link-utilization, loss-avoidance, fairness, stability, and TCP-friendliness. Congestion control protocols can be regarded as points in a multidimensional space reflecting the extent to which they satisfy these requirements, and we show how classical families of congestion control protocols (e.g., additive-increase-multiplicative-decrease, multiplicative-increase-multiplicative-decrease, and more) can be mapped to points in this space. We leverage our axiomatic framework to derive basic results on the feasibility of simultaneously achieving different requirements within a single design. Our results formalize and shed light on various empirical/experimental observations about tensions between different desiderata, including (1) the tension between attaining high performance and being friendly to legacy TCP connections~\citelakshman1997performance,padhye1998modeling, (2) the tension between achieving high bandwidth and maintaining low latency under dynamic environments~\citebrakmo1995tcp,mo1999analysis,sprout, and (3) the tension between being robust to non-congestion loss and not incurring high loss upon convergence~\citevivace. From a protocol design perspective, desirable congestion control protocols are those that reside on the Pareto frontier in the multidimensional space induced by our requirements, and this Pareto frontier is characterized by our theoretical results. To be sure, our axiomatic approach has its limitations, as it revolves around investigating these properties in a simplified model. However, we feel that the results, in terms of which axioms can coexist and which cannot, provide insights that apply far beyond the simple model (even if the detailed theoretical results do not). Thus, we contend that the axiomatic approach is a useful addition to the evaluatory arsenal that researchers should apply to congestion control. We view our results as a first step and leave the reader with many research directions relating to the extension of our model and the re-examination of our axioms/metrics. Thus far, axiomatic approaches have been applied to a few, very specific, networking environments~\citeshenker1990theoretical,lev2015axiomatic,cohen2015axiomatic. We believe that applying the axiomatic approach to other networking contexts (e.g., intradomain~\citelev2015axiomatic and interdomain routing, traffic engineering, in-network queueing~\citesivaraman2013no, network security) could contribute to more principled discussions about these contexts.