The apparent contradiction in the title is a word-play on the different meanings attributed to the word reproducible across different scientiﬁc ﬁelds. What we imply is that unreproducible ﬁndings can be built upon reproducible methods . Without denying the importance of facilitating the reproduction of methods , we deem important to reassert that reproduction of ﬁndings is a fundamental step of the scientiﬁc inquiry. We argue that the commendable quest towards easy deterministic reproducibility of methods and numerical results should not have us forget the even more important necessity of ensuring the reproducibility of empirical ﬁndings and conclusions by properly accounting for essential sources of variations. We provide experiments to exemplify the brittleness of current common practice in the evaluation of models in the ﬁeld of deep learning, showing that even if the results could be reproduced, a slightly different experiment would not support the ﬁndings. We hope to help clarify the distinction between exploratory and empirical research in the ﬁeld of deep learning and believe more energy should be devoted to proper empirical research in our community. This work is an attempt to promote the use of more rigorous and diversiﬁed methodologies. It is not an attempt to impose a new methodology and it is not a critique on the nature of exploratory research.