This paper proposes a novel visual Learning from Demonstration (LfD) system that teaches robots to learn tasks in which an object is put into another object, stacked, or transported by a tool. In such tasks, observation targets become invisible owing to occlusion or frame-out. The proposed “Visual Hierarchy-based Function Estimator (Hi-Fes)” is inspired by the knowledge derived from the field of psychology that uses the visual hierarchy relationships to estimate the changes in observation targets. Hi-Fes employs a mechanism to interpolate the features when the targets are unrecognizable and state variables are incalculable directly. This method facilitated visual learning of complex state changes between multiple targets, in which the target becomes invisible or has a long period of invisibility, difficult for conventional learning methods. The proposed method was implemented in a life-sized humanoid robot and was evaluated in learning based on demonstration experiments. The results demonstrated the effectiveness of our approach.