Obtaining accurate data about the environment in which a robot is located is a crucial matter when it comes to autonomous navigation and other robotic applications. A popular method of acquiring this information is to use sonar-rings, where a robot is fitted with multiple simple ultrasound transducers pointed in the directions where an object can appear. However, in a time where accurate 3D data is gaining importance, other sensing modalities are becoming more popular because of the ability to measure dense 3D point clouds. In these point clouds not only the horizontal plane is measured, but objects in the elevation planes can also be registered, which can be very interesting and makes applications such as 3D SLAM or object recognition possible. In this paper we present a way to extract complex 3D point cloud data from the entire surrounding sphere using multiple interconnected eRTIS sensors. These advanced imaging sonar sensors offer the flexibility of the popular sonar-ring in combination with the benefits of some of the competing sensing modalities. The setup presented here uses less sonar sensors (and thus less external hardware) while obtaining more information from the complete frontal hemispheres of each individual sensor. This setup is discussed, along with the issues that arise when using complex imaging sonar sensors in a network, and is tested in an indoor and outdoor environment. At the end of this paper is a discussion of the obtained results.