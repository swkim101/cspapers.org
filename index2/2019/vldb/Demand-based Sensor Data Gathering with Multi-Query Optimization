In the Internet of Things, billions of sensors provide data streams to applications. The data are predominately acquired from devices with constrained computational capabilities, often serving multiple queries simultaneously. Sensor nodes, are typically oblivious to the specific needs of applications. The potential requirements of diverse applications force them to push data at a higher rate than required by a specific, currently running application. That is suboptimal due to 1. constraints in the network bandwidth, 2. expenses for transmissions, and 3. limited computational power. However, decreasing data gathering frequency may reduce the applications' accuracy. In this paper, we demonstrate a technique for minimizing the number of network transmissions while maintaining the desired accuracy. The presented algorithm for read- and transmission-sharing among queries goes hand-in-hand with state-of-the-art machine learning techniques for adaptive sampling. We 1. implement the technique and deploy it on a sensor node, 2. replay sensor-data from two real-world scenarios, 3. provide an interface for submitting custom queries, and 4. present an interactive dashboard. Here, visitors observe live statistics on the read- and transmission savings achieved in real-world use-cases. The dashboard also visualizes optimizations currently performed by the read scheduling procedure and hence conveys real-time insights and a deep understanding of the presented algorithm.