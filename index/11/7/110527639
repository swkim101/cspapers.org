Sensor based perception of the environment is an emerging area of the mobile robot research where sensors play a pivotal role. For autonomous mobile robots, the fundamental requirement is the convergent of the range information in to high level internal representation. Internal representation in the form of occupancy grid is commonly used in autonomous mobile robots due to its various advantages. There are several sensors such as vision sensor, laser rage finder, and ultrasonic and infrared sensors etc. play roles in mapping. However the sensor information failure, sensor inaccuracies, noise, and slow response are the major causes of an error in the mapping. To improve the reliability of the mobile robot mapping multisensory data fusion is considered as an optimal solution. This paper presents a novel architecture of sensor fusion frame work in which a dedicated filter (DF) is proposed to increase the robustness of the occupancy grid for indoor environment. The technique has been experimentally verified for different indoor test environments. The proposed configuration shows improvement in the occupancy grid with the implementation of dedicated filters.