A complete analysis of the statistical issues related to the estimation of a bilinear form, one of the fundamental problems in computer vision, is presented. It is shown why already at moderate noise levels most available techniques fail to provide a satisfactory solution. A new estimation procedure is proposed in which the nonlinear nature of the errors are taken into account and the implementation uses the generalized singular value decomposition for superior numerical behavior. As an example, the ellipse fitting problem is discussed, and the performance of the new algorithm is compared with thecurrent state-of-the-art.