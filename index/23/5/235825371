Deep neural networks are vulnerable to adversarial attacks. Due to their black-box nature, it is rather challenging to interpret and properly repair these incorrect behaviors. This paper focuses on interpreting and repairing the incorrect behaviors of Recurrent Neural Networks (RNNs). We propose a lightweight model-based approach ( RN-NRepair ) to help understand and repair incorrect behaviors of an RNN. Speciﬁcally, we build an inﬂuence model to characterize the stateful and statistical behaviors of an RNN over all the training data and to perform the inﬂuence analysis for the errors. Compared with the existing techniques on inﬂuence function, our method can efﬁciently estimate the inﬂuence of existing or newly added training samples for a given prediction at both sample level and segmentation level. Our empirical evaluation shows that the proposed inﬂuence model is able to extract accurate and understandable features. Based on the inﬂuence model, our proposed technique could effectively infer the in-ﬂuential instances from not only an entire testing sequence but also a segment within that sequence. Moreover, with the sample-level and segment-level inﬂuence relations, RNNRepair could further remediate two types of incorrect predictions at the sample level and segment level.