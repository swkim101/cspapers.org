Meta-learning based recommendation systems alleviate the cold-start problem through a bi-level meta-optimization process. Recommendation borrows prior experience from pre-trained static system-level parameters and fine-tunes the model in user-level for new users. However, it is more natural for the system to sample users in a dynamic online sequence in most real-world recommendation systems, which brings further challenges for existing meta-learning based recommendation: system-level updates begins before user-level recommendation models have converged on the whole time series; stable and randomness-resistant bi-level gradient descent approaches are missing in the current meta-learning framework; evaluation on learning abilities across different users are lacked for exploring the diversities of different users. In this paper, we propose an online regularized meta-leader recommendation approaches named FORM to address such problems. To transfer meta-learning based recommender into the online scenario, we develop follow-the-meta-leader algorithm to learn stable online gradients. Regularized methods are then introduced to alleviate the volatility of online systems and produce sparse weight parameters. Besides, we design a scalable meta-trained learning rate based on the variance and learning-shots of existing users to guide the model to adapt efficiently to new users. Extensive experiments on three public datasets and one commercial online advertisement dataset demonstrate our approaches' effectiveness and stability, which outperform other state-of-the-art methods and achieve a stable and fast adaption on new users.