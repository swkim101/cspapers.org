On par with the human classiﬁcation accuracy, convolutional neural networks (CNNs) have fueled the deployment of many video processing systems on cloud-backed mobile platforms ( e.g. , cell phones and robotics). Nevertheless, these video processing systems often face a tension between intensive energy consumption from CNNs and limited resources on mobile platforms. To address this tension, we propose to accelerate video processing with a widely-available, but not yet well-explored runtime input-level information, namely class skew . Through such runtime-proﬁled information, it strives to automatically optimize CNNs toward the time-varying video stream. Speciﬁcally, we build Palleon, a runtime system that dynamically adapts and selects a CNN model with the least energy consumption based on the automatically detected class skews, while still achieving the desired accuracy. Extensive evaluations on state-of-the-art CNNs and real-world videos demonstrate that Palleon enables efﬁcient video processing with up to 6 . 7 × energy saving and 7 . 9 × latency reduction.