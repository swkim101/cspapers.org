With the popularity of online social medias 001 in recent years, massive-scale multimodal in-002 formation has brought new challenges to tra-003 ditional Named Entity Disambiguation (NED) 004 tasks. Recently, Multimodal Named Entity 005 Disambiguation (MNED) is proposed to link 006 ambiguous mentions with the textual and vi-007 sual contexts to a predeﬁned knowledge graph. 008 Recent attempts handle these issues mainly by 009 annotating multimodal mentions and adding 010 multimodal features to traditional NED mod-011 els. These methods still suffer from 1) lack of 012 multimodal annotation data against the huge 013 scale of unlabeled corpus and 2) failing to 014 model multimodal information at knowledge 015 level. In this paper, we explore a pioneer 016 study on leveraging multimodal knowledge 017 learning to address the MNED task. Specif-018 ically, we propose a knowledge-guided trans-019 fer learning strategy to extract uniﬁed repre-020 sentation from different modalities and enrich 021 multimodal lnowledge in a Meta Learning way 022 which is much easier than collecting ambigu-023 ous mention corpus. Then we propose an Inter-024 active Multimodal Learning Network (IMN), 025 which is capable of fully utilizing the multi-026 modal information in both mention and knowl-027 edge side. To verify the validity of the pro-028 posed method, we implemented comparisons 029 on a public large-scale MNED dataset based 030 on Twitter KB. Experimental results show that 031 our method is superior to the state-of-the-art 032 multimodal methods. 033