In this paper, we propose a scheme to reduce the size of a pre-trained full-scale model with a domain-specific dataset. This scheme combines model compression and transfer learning. First, it identifies the sensitive parts of a full model using the target dataset. Then it applies transfer learning on the identified part of the network to construct a reduced and customized model. Our scheme can correct structure and parameters to prune for a target dataset, which makes the following transfer learning more efficient.We apply our scheme on image classification applications using convolutional neural networks. We observe that different image categories activate different filters, so we can identify sensitive parts of the model for different categories of images.We use VGG-16 (pre-trained by ImageNet dataset) as the full model and we apply transfer learning on two different datasets (Flowers-102 and Cats vs. Dogs). We apply three pruning criteria in our scheme. The accuracy of Flowers-102 dataset by the best criterion drops less than 2% while pruning 60% of the network. We also observe the effects of different settings of our scheme and examine their feasibility by experiments.