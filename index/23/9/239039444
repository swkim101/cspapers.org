We provide a generic framework for the hand– eye calibration of vision-guided industrial robots. In contrast to traditional methods, we explicitly model the uncertainty of the robot in a statistically sound manner. Albeit the precision of modern industrial robots is high, their absolute accuracy typically is much lower. This uncertainty — if not considered — deteriorates the result of the hand–eye calibration. Our proposed framework not only results in a high accuracy of the computed hand–eye pose but also provides reliable information about the uncertainty of the robot. It further provides corrected robot poses for a convenient and inexpensive robot calibration. Our framework is generic in several respects: It supports the use of a calibration target as well as self-calibration without the need for known 3D points. It optionally allows the simultaneous calibration of the interior camera parameters. The framework is also generic with regard to the robot type, and hence supports articulated as well as SCARA robots, for example. Simulated and real experiments show the validity of the proposed methods.