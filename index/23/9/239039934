Curb detection is an essential function of autonomous vehicles in urban areas. However, curbs are difficult to detect in complex urban environments in which many dynamic objects exist. Additionally, curbs appear in a variety of shapes and sizes. Previous studies have been based on the traditional pipeline, which consists of the extraction and aggregation of hand-crafted features that are then fed to classifiers. However, this sequential process is inefficient and designing the hand-crafted features is a complex process. Recently, this kind of process has been replaced by Deep Neural Networks (DNN), in which classifiers and features are learned from large-scale data. Very few works have exploited DNN for the curb detection problem. Most works use multi-modal sensor-based methods that combine images and accumulated 3D point clouds from LIDAR. However, these approaches require synchronization and calibration between sensors. In addition, they do not quantify the uncertainty of their predictions for autonomous system safety. In this paper, we present a two-stage DNN-based curb detection method that includes uncertainty quantification. An autoencoder-based network predicts the curbs, and then conditional neural processes rectify the predictions with uncertainty estimations. The experimental results show that our approach achieves high accuracy and recall in complex areas. We also constructed a large-scale dataset to create benchmarks consisting of approximately 5,224 scans with birdâ€™s-eye view labels collected from urban areas. To the best of our knowledge, there are no public datasets for DNN-based curb detectors. The benchmarks and datasets are publicly available at https://github.com/YounghwaJung/curb_detection_DNN.