Model predictive control (MPC) is a powerful feedback technique that is often used in data-driven robotics. The performance of data-driven MPC depends on the accuracy of the model, which often requires careful tuning. Furthermore, specifying the task with an objective function and synthesizing a feedback policy are not straightforward and typically lead to suboptimal solutions driven by trial and error. To address these challenges, we present a method to jointly optimize the data-driven system identification, task specification, and control synthesis of unknown dynamical systems. We use our method to develop AutoMPC3, a software package designed to automate and optimize data-driven MPC. Empirical evaluation on the pendulum swing-up, cart-pole swing-up, and half-cheetah running demonstrates that our method finds data-driven control policies that outperform offline reinforcement learning, without any hand-tuning.