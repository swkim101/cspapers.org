Anticipating the motion of dynamic objects is critical for making intelligent decisions navigating through an environment while avoiding collisions. In this work, we propose a CNN model that estimates 3D motion of objects using sequences of monocular images. We show that we can train this model without using any manual annotations by using Iterative Closest Points (ICP) to align pointclouds of an object at different points in time. We compare our unsupervised approach to a model that was trained using ground truth supervision, on the KITTI tracking dataset. We further improve our model by training our model on a larger dataset, which would otherwise not be possible due to the lack of ground truth data. We also compare our approach with a 3D object detector that estimates motion using a simple tracking scheme.