In this work, we examine online collective inference , the problem of maintaining and performing inference over a sequence of evolving graphical models. We utilize templated graphical models (TGM), a general class of graphical models expressed via templates and instantiated with data. A key challenge is minimizing the cost of instan-tiating the updated model. To address this, we deﬁne a class of exact and approximate context-aware methods for updating an existing TGM. These methods avoid a full re-instantiation by us-ing the context of the updates to only add relevant components to the graphical model. Further, we provide stability bounds for the general online inference problem and regret bounds for a proposed approximation. Finally, we implement our approach in probabilistic soft logic, and test it on several online collective inference tasks. Through these experiments we verify the bounds on regret and stability, and show that our approximate on-line approach consistently runs two to ﬁve times faster than the ofﬂine alternative while, surprisingly, maintaining the quality of the predictions.