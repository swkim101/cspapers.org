Circuit representations are becoming the lingua franca to express and reason about tractable generative and discriminative models. In this paper, we show how complex inference scenarios for these models that commonly arise in machine learning—from computing the expectations of decision tree ensembles to information-theoretic divergences of sum-product networks—can be represented in terms of tractable modular operations over circuits. Speciﬁcally, we characterize the tractability of simple transformations—sums, products, quotients, powers, logarithms, and exponentials—in terms of sufﬁcient structural constraints of the circuits they operate on, and present novel hardness results for the cases in which these properties are not satisﬁed. Building on these operations, we derive a uniﬁed framework for reasoning about tractable models that generalizes several results in the literature and opens up novel tractable inference scenarios.