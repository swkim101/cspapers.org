To tackle the curse of dimensionality in data analysis and unsupervised learning, it is critical to be able to efﬁciently compute “simple” faithful representations of the data that helps extract information, improves understanding and visualization of the structure. When the dataset consists of d - dimensional vectors, simple representations of the data may consist in trees or ultrametrics, and the goal is to best preserve the distances (i.e.: dissimilarity values) between data elements. To circumvent the quadratic running times of the most popular methods for ﬁtting ultrametrics, such as average, single, or complete linkage, Cohen-Addad et al. (2020) recently presented a new algorithm that for any c ≥ 1 , outputs in time n 1+ O (1 /c 2 ) an ultrametric ∆ such that for any two points u, v , ∆( u, v ) is within a multiplicative factor of 5 c to the distance between u and v in the “best” ul-trametric representation. We improve the above result and show how to improve the above guarantee from 5 c to √ 2 c + ε while achieving the same asymptotic running time. To complement the improved theoretical bound, we additionally show that the performances of our algorithm are signiﬁcantly better for various real-world datasets.