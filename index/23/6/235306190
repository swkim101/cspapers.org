We propose a deep generative framework for multi-view learning
based on a probabilistic interpretation of canonical correlation
analysis (CCA). The model combines a linear multi-view
layer in the latent space with deep generative networks as
observation models, to decompose the variability in multiple
views into a shared latent representation that describes the
common underlying sources of variation and a set of viewspecific
components. To approximate the posterior distribution
of the latent multi-view layer, an efficient variational inference
procedure is developed based on the solution of probabilistic
CCA. The model is then generalized to an arbitrary number of
views. An empirical analysis confirms that the proposed deep
multi-view model can discover subtle relationships between
multiple views and recover rich representations.