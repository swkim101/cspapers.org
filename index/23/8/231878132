Deep neural networks (DNNs) are commonly used for various trafﬁc analysis problems, such as website ﬁngerprinting and ﬂow correlation, as they outperform traditional (e.g., statistical) techniques by large margins. However, deep neural networks are known to be vulnerable to adversarial examples: adversarial inputs to the model that get labeled incorrectly by the model due to small adversarial perturbations. In this paper, for the ﬁrst time, we show that an adversary can defeat DNN-based trafﬁc analysis techniques by applying adversarial perturbations on the patterns of live network trafﬁc. Applying adversarial perturbations (examples) on trafﬁc analysis classiﬁers faces two major challenges. First, the per-turbing party (i.e., the adversary) should be able to apply the adversarial network perturbations on live trafﬁc, with no need to buffering trafﬁc or having some prior knowledge about up-coming network packets. We design a systematic approach to create adversarial perturbations that are independent of their target network connections, and therefore can be applied in real-time on live trafﬁc. We therefore call such adversarial perturbations blind . Second, unlike image