This paper presents a method to estimate a disparity map from a stereo image pair using deep convolutional neural network (CNN), which is mainly divided into three parts, including: feature extraction for each individual view, feature fusion, and disparity regression. We first design 2-D CNN networks to extract the feature maps from both the left and right-view images. Then, we combine the two feature maps into one 4- D feature volume by concatenating and packing them across distinct disparity levels. Finally, we use a 3-D CNN network (modified UNet++) to learn the disparity information from the 4-D feature volume. The whole CNN model is trained end-to-end without any post-processing. In other words, we let our model learn a mapping from input to output. Experimental results show that our method outperforms most of state-of-the-art methods on the publicly available datasets FlyingThings3D and KITTI Stereo 2015, demonstrating the feasibility of our algorithm.