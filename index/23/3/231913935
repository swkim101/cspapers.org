To function effectively in real-world environments, powered wearable robots such as exoskeletons and robotic prostheses must recognize the user’s motion intent by detecting the user’s locomotion modes such as walking, stair ascent and descent or ramp ascent and descent. Traditionally, intent detection is achieved using rule based methods such as state machines or fuzzy logic using data from wearable sensors. Due to the difficulty of manual rule design, these methods are limited to detect certain simple locomotion modes. Machine learning (ML) based methods can perform classification on a large number of classes without manual rule design and recent research has explored several ML methods for locomotion mode classification. However, current ML based methods for locomotion mode detection use classical methods that require use of feature engineering to achieve acceptable accuracies. Additionally, current ML strategies only classify when certain motion events are detected. This strategy, while computationally efficient could result in misclassifications affecting large sections of motion recognition. To overcome these limitations, this paper proposes an end-to-end deep learning based method for locomotion mode detection that eliminates the need for feature engineering and classifies at a fixed sample rate. This paper introduces a new metric called confidence index and proposes a strategy for tuning confidence index thresholds to achieve a stable intent recognition and overall accuracy of greater than 95% on a publicly available benchmark dataset.