Social robots deployed in the therapy of autism is a promising and important research domain. Recently, an increasing amount of work is being conducted utilizing a social robot as a mediator between a therapist and a child with autism. Being able to evaluate how engaged a child is both offline and in real-time would improve the quality of the provided robot-assisted intervention and also provide objective metrics for later analysis by the therapist. The state-of-the-art engagement recognition is challenged by the diverse styles of expressing engagement by this vulnerable population group. To this end, this PhD project aims to explore how transfer learning can improve the recognition accuracy of children's engagement with the robot or another human. We will utilize four publicly available multi-modal datasets to discover a suitable feature representation of engagement during various types of activities with the robot.