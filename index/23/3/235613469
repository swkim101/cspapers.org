The combination of Evolutionary Algorithms (EAs) and Deep Reinforcement Learning (DRL) has been recently proposed to merge the beneﬁts of both solutions. Existing mixed approaches, however, have been successfully applied only to actor-critic methods and present signiﬁcant overhead. We address these issues by introducing a novel mixed framework that exploits a periodical genetic evaluation to soft update the weights of a DRL agent. The resulting approach is applicable with any DRL method and, in a worst-case scenario, it does not exhibit detrimental behaviours. Experiments in robotic applications and continuous control benchmarks demonstrate the versatility of our approach that signiﬁcantly outperforms prior DRL, EAs, and mixed approaches. Finally, we employ formal veriﬁcation to conﬁrm the policy improvement, mitigating the inefﬁcient exploration and hyper-parameter sensitivity of DRL