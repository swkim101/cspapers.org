For many tasks, including table tennis, catching, and sword fighting, a critical step is intercepting the incoming object with a robot arm or held tool. Solutions to robot arm interception via learning, specifically reinforcement learning (RL), have become prevalent, as they provide robust solutions to the robot arm interception problem, even for high degree of freedom robotic systems. Despite numerous solutions, there has been little exploration into the factors of learning that impact solution quality. Thus, there is little insight into what problem features lead to better learning success. In this paper, we explore the parameters that impact solution quality. We find that link position observations outperform joint angle observations in terms of learning speed, performance, ability to utilize more than one frame of observation, and generalization to situations not trained for. These results are immediately applicable to RL for robot arm interception tasks.