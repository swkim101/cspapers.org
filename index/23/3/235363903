To protect the worldâ€™s marshlands, it is of utmost importance to be able to monitor their vegetation composition and coverage. This currently is accomplished by large teams of researchers and volunteers manually looking at the marsh images and labeling randomly selected pixels by what species (or lack thereof) is present at the pixel. This task, however, is extremely labor intensive, limiting the amount of quality environmental monitoring that can be done in the field. If the task was automated, teams would be able to monitor larger swaths of land. In this paper, we propose a novel framework for such automation using deep neural networks. Then, we focus on the key component of this framework: a binary classifier to decide whether a pixel is vegetated or not. To this end, we create a dataset of labeled snippet images out of publicly available photoquadrats of the marshlands in Florida. Finally, we construct LeNet-5 and AlexNet, adjusted to our input snippets, faster training time, networks and experiment to learn them on our dataset for the binary classification task. Our results show that the AlexNet model achieves higher accuracy on the test set than the LeNet-5 model, with 92.41% for AlexNet and 91.34% for LeNet-5.