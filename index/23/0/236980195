Anomaly explanation, also known as anomaly localization, is as important as, if not more than, anomaly detection in many real-world applications. However, it is challenging to build explainable detection models due to the lack of anomaly-supervisory information and the unbounded nature of anomaly; most existing studies exclusively focus on the detection task only, including the recently emerging deep learning-based anomaly detection that leverages neural networks to learn expressive low-dimensional representations or anomaly scores for the detection task. Deep learning models, including deep anomaly detection models, are often constructed as black boxes, which have been criticized for the lack of explainability of their prediction results. To tackle this explainability issue, there have been numerous techniques introduced over the years, many of which can be utilized or adapted to offer highly explainable detection results. This tutorial aims to present a comprehensive review of the advances in deep learning-based anomaly detection and explanation. We first review popular state-of-the-art deep anomaly detection methods from different categories of approaches, followed by the introduction of a number of principled approaches used to provide anomaly explanation for deep detection models. Through this tutorial, we aim to promote the development in algorithms, theories and evaluation of explainable deep anomaly detection in the machine learning and data mining community. The slides and other materials of the tutorial are made publicly available at https://tinyurl.com/explainableDeepAD.