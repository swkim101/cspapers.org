We study human perception of gaze rendered by popular semi-virtual robotic heads, which use a screen to render a robot’s face. It is known that when these heads are stationary, the screen may induce the Mona Lisa gaze effect, which widens the robot’s apparent cone of direct gaze. But how do people perceive gaze when the head can move as well? To study this question, we conducted a laboratory experiment that investigated human perception of robot gaze when a semi-virtual platform looked in different directions. We varied the way in which the robot conveyed gaze, using several behaviors involving 2D eye and head motion. Our results suggest that the interplay between these motions can regulate how wide users perceive the robot’s cone of direct gaze. Also, our findings suggest that the location of observers can affect the perception of gaze by semi-virtual robotic heads. We discuss the implications of our findings for social interaction.