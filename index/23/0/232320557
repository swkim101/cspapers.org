
 In this work, a novel multifidelity machine learning (ML) algorithm, the gradient-enhanced multifidelity neural networks (GEMFNN) algorithm, is proposed. This is a multifidelity extension of the gradient-enhanced neural networks (GENN) algorithm as it uses both function and gradient information available at multiple levels of fidelity to make function approximations. Its construction is similar to the multifidelity neural networks (MFNN) algorithm. The proposed algorithm is tested on three analytical functions, a one, two, and a 20 variable function. Its performance is compared to the performance of neural networks (NN), GENN, and MFNN, in terms of the number of samples required to reach a global accuracy of 0.99 of the coefficient of determination (R2). The results showed that GEMFNN required 18, 120, and 600 high-fidelity samples for the one, two, and 20 dimensional cases, respectively, to meet the target accuracy. NN performed best on the one variable case, requiring only ten samples, while GENN worked best on the two variable case, requiring 120 samples. GEMFNN worked best for the 20 variable case, while requiring nearly eight times fewer samples than its nearest competitor, GENN. For this case, NN and MFNN did not reach the target global accuracy even after using 10,000 high-fidelity samples. This work demonstrates the benefits of using gradient as well as multifidelity information in NN for high-dimensional problems.