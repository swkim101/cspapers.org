Predictable hardware cache coherence is an attractive data communication mechanism between safety-critical tasks deployed on real-time multi-core platforms due to its predictability and high-performance benefits. However, from a worst-case analysis standpoint, alternative data communication mechanisms appear in favorable light for adoption in real-time multi-core platforms. This is because alternative data communication mechanisms such as cache bypassing offer tighter worstcase latency (WCL) bounds for memory requests compared to predictable hardware cache coherence mechanisms. We present a systematic approach towards designing predictable cache coherence mechanisms that offer tight WCL and high-performance. Our approach consists of a formal framework that concisely captures the key reasons behind the high WCL in existing predictable cache coherence mechanisms. Guided by this formal framework, we describe one technique that employs micro-architectural extensions and protocol changes to achieve tight WCL and high-performance. We apply this technique to two existing cache coherence mechanisms. Our evaluation shows that the new cache coherence mechanisms resulting from our technique have the same tight WCL as alternative mechanisms, and still maintain a significant average-case performance advantage (up to 5Ã— speedup) over the alternative mechanisms.