“Fairness” is a multi-faceted concept that is contested within and across disciplines. In machine learning, it usually denotes some form of equality of measurable outcomes of algorithmic decision making. In this paper, we start from a viewpoint of sociology and media studies, which highlights that to even claim fair treatment, individuals and groups first have to be visible. We draw on a notion and a quantitative measure of diversity that expresses this wider requirement. We used the measure to design and build the Diversity Searcher, a Web-based tool to detect and enhance the representation of socio-political actors in news media. We show how the tool's combination of natural language processing and a rich user interface can help news producers and consumers detect and understand diversity-relevant aspects of representation, which can ultimately contribute to enhancing diversity and fairness in media. We comment on our observation that, through interactions with target users during the construction of the tool, NLP results and interface questions became increasingly important, such that the formal measure of diversity has become a catalyst for functionality, but in itself less important.