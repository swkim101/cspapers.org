The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect, previously studied in optimization by analyzing the dynamics of parameter updates. In this paper, we are interested in learning with noisy labels, where we have a collection of samples with potential mislabeling. We show that a previously rarely discussed SGD noise, induced by stochastic label noise (SLN), mitigates the effects of inherent label noise. In contrast, the common SGD noise directly applied to model parameters does not. We formalize the differences and connections of SGD noise variants, showing that SLN induces SGD noise dependent on the sharpness of output landscape and the conﬁdence of output probability, which may help escape from sharp minima and prevent overconﬁdence. SLN not only improves generalization in its simplest form but also boosts popular robust training methods, including sample selection and label correction. Speciﬁcally, we present an enhanced algorithm by applying SLN to label correction. Our code is released 1 .