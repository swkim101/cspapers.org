In many systems, especially in robotic systems, active reasoning and decision making is essential for a successful deployment. The goal of active reasoning is to choose subsequent actions with the highest utility to maximally increase the reward gained by executing the new actions. As a result, this can improve system performance drastically while at the same time decreasing computation time. In general, every multi-action system can benefit this way, but the benefits become more apparent when the system has minimal computational power and only a limited amount of operation time available. This is typically the case for resource-constrained mobile robots such as quadcopters. With regard to single-view object recognition methods, many have been developed over the years, but despite steady improvements, no perfect system has yet been found. Many of the developed systems have complex and computationally expensive feature representations, making them difficult to use on a robotic system with limited computational power. Feature representation is in particular hard, because we need suitable features that generalize well across different object categories but remain expressive enough for accurate object classification. Moreover, especially single-view object recognition is affected by object ambiguity, i.e., two objects which look very similar are hard to tell apart. To overcome those difficulties, we propose a multi-view Bayesian framework that performs active view planning [1] and online feature selection [2]. Furthermore, we show how this multi-view recognition system can be used for object change detection. Given a prior map of the environment, the task is to determine whether objects in the environment have changed. This can either mean that the object has changed completely (i.e., it belongs to a different object class), or the object has changed its orientation only (i.e., it belongs to the same class but its rotation differs in yaw). We extensively evaluate our active reasoning system for the two perception tasks of object recognition and object change detection on a large RGB-D dataset [3] and show first preliminary results from deploying the system on a quadcopter robot.