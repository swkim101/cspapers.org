It is generally agreed that a computer system's CPU utilization means little by itself, but there has been only a limited amount of research to determine the value of CPU utilization when used with other performance measures. This paper focuses on time-sharing systems (or similar systems such as some remote batch systems) as viewed by someone who wants to minimize the mean cost per job run on the system.
 The paper considers cost per job to include both the computer cost (as allocated among all the jobs run on the system) and the user cost (where user cost is the time spent waiting for a response from the system multiplied by the user's wage rate). Given this approach, cost per job is a function of some constants (user wage rate, computer system cost, and mean processing time per job) and only one variable (CPU utilization). The model thus developed can be used to determine the optimum CPU utilization for any system. It can also be used to determine the value of different tuning efforts.