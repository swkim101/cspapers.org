Massive computing systems will be needed to maintain competitiveness in all areas of science, engineering and business, to provide both management efficiency and computing capability. From a systems management perspective, massive installations offer an efficient platform for resource sharing and service-oriented cloud computing; from a capability perspective, they allow unprecedented performance for supercomputing applications. With top supercomputing systems reaching the PetaFlop barrier, the next challenge is to devise technology to reach, and applications to take advantage of, ExaFlop performance. Multicore chips are already here but will grow in the next decade to several hundred cores. Although these chips will be used for general-purpose computing, they will be the tera-device components of future exascale systems. Europe is aware of the importance of having a well-structured supercomputing infrastructure, as well as the need to exchange experiences and know-how across the Union. Infrastructure projects such as the current DEISA (Distributed European Infrastructure for Supercomputing Applications) or the future PRACE (Partnership for Advanced Computing in Europe) aim at setting up such coordinated resources. PRACE, in particular, will create a world-class pan-European high performance computing service and infrastructure, managed as a single European entity. The service will include five superior supercomputing centers, strengthened by regional and national centers, working in collaboration through grid technologies. The BSC-CNS is the Spanish representative, one of five principal partners in the project (the others being Germany, France, UK and the Netherlands). The principal partner countries have agreed to contribute more to the PRACE budget, and to host the tier-0 machines which will form part of the distributed infrastructure. Having hit the power wall, the computing market is now undergoing a shaky era of dispersion, where many kinds of multicore alternatives are being proposed as the way to develop chips with ever increasing performance capabilities. In this time of confusion we have built a tight Gordian knot, where excitement at the potential performance shown by different hardware platforms is counteracted by the fear of wasted effort in targeting applications to each and every one of those platforms. We believe that the programming model is the key component that should break the knot. With increased scale, hierarchical levels of granularity should be considered, providing the programmer with an abstract model that will be mapped to the different target platforms by their specific runtimes. Asynchrony, decoupling between logical and physical resources of all types (cores, memory, etc.), load balancing, fault tolerance, and actual understanding of the behavior of our systems are issues that will have to be addressed and supported when targeting exascale performance. Holistic approaches with a global vision for the design of such systems should coordinate experience and techniques at all levels, from application to programming model design, runtime implementation, and architecture, both at the node and interconnect level. The talk will first describe how the BSC and the Spanish distributed infrastructure of computers (RES) around it was set up, and discuss experiences with its operation. Then some of the European activities will be described, finishing with the BSC's vision on the major issues in designing and using the upcoming systems of the ExaFlop era.