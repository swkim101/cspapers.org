The dimensionality of a set of 160 face images of 10 male and 10 female subjects is reduced from 4096 to 40 via an autoencoder network. The extracted features do not correspond to the features used in previous face recognition systems (Kanade, 1973), such as ratios of distances between facial elements. Rather, they are whole-face features we call holons. The holons are given to 1 and 2 layer back propagation networks that are trained to classify the input features for identity, feigned emotional state and gender. The automatically extracted holons provide a sufficient basis for all of the gender discriminations, 99% of the identity discriminations and several of the emotion discriminations among the training set. Network and human judgements of the emotions are compared, and it is found that the networks tend to confuse more distant emotions than humans do.