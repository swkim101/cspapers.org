In multiagent systems (MAS) the outcome of the actions of an agent usually depends on the actions of other agents, which may have conflicting goals. Moreover, since the other agents may be unknown and may not be benevolent, an agent generally cannot assume the other agents would be willing to help without getting anything in return. If each agent would simply take those actions that are individually best, the result will often be sub-optimal for each of them, like in the well known prisoner’s dilemma. Therefore, agents in a MAS need to negotiate on what actions each will take. Maximizing a utility function for a set of independent agents is also the goal of Distributed Constraint Optimization Problems (DCOP), but these problems are fundamentally different from negotiation problems, since DCOPs assume there is one global function to be optimized and the agents co-operate in order to find a good solution. In cases where the agents have their own private utility function, are selfish, and are unknown, one cannot apply a DCOP algorithm. One could suggest to apply an optimization algorithm to find the solution for which the the sum of the individual utility functions is maximized. However, since agents are selfish and autonomous, there is no guarantee that all agents will agree with such a solution, as a strict subset of the agents may come to a solution in which each agent achieves higher utility than it would obtain from the socially optimal solution. Moreover, agents may disagree on what is the most fair solution. Most existing negotiation algorithms assume simple scenarios where the utility of each agent is modeled as a linear function that is easy to calculate. They mostly work only for bilateral negotiations [Lai et al., 2008] and assume the range of options is small, or they require the presence of a trusted, impartial mediator [Klein et al., 2003]. They assume that for any given utility value it is always possible to find a proposal that indeed yields this utility value [Faratin et al., 2000]. These assumptions are rarely satisfied in real-world situations. In this thesis we focus on complex problems and address a number of realistic assumptions that make the application of existing negotiation algorithms unfeasible: • The space of solutions is huge. • Utility is non-linear and difficult to calculate. • The environment is only partially observable. • The environment changes due to actions of others. • Decisions have to be made within a limited time frame. • Solutions may involve many agents, possibly human.