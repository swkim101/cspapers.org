Most research in data mining and knowledge discovery relies heavily on the availability of datasets. With the rapid growth of user generated content on the internet, there is now an abundance of sources from which data can be drawn. Compared to the amount of work in the field on techniques for pattern discovery and knowledge extraction, there has been relatively little effort directed at the study of effective methods for collecting and evaluating the quality of data. 
 
Human computation is a new research area that studies the process of channeling the vast internet population to perform tasks or provide data towards solving difficult problems that no known efficient computer algorithms can yet solve. There are various genres of human computation applications available today. Games with a purpose (e.g., the ESP Game) specifically target online gamers who, in the process of playing an enjoyable game, generate useful data (e.g., image tags). Crowdsourcing marketplaces (e.g. Amazon Mechanical Turk) are human computation applications that coordinate workers to perform tasks in exchange for monetary rewards. In identity verification tasks, users need to perform some computation in order to access some online content; a recent example of such a human computation application is reCAPTCHA, which leverages millions of users who solve CAPTCHAs every day to correct words in books that optical character recognition (OCR) programs fail to recognize with certainty. 
 
While there has been active work in this area, there is no dedicated forum to discuss these research ideas. The Human Computation Workshop (HCOMP 2009), held in conjunction with the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), is the first workshop bringing together academic and industry researchers to discuss existing human computation applications and future directions of this new subject area. An integral part of this workshop is a demo session where participants can showcase their human computation applications. 
 
Our call for papers resulted in 33 high-quality submissions from a wide variety of perspectives. All papers were thoroughly reviewed by the program committee and external reviewers. Given the short, half-day duration of the workshop, only one-third of the submissions could be accommodated and appear in the proceedings. The accepted papers have been divided into four sessions: "Games", "Human Computation In Practice", "Game Theory" and "Labeling Cost and Efficiency".