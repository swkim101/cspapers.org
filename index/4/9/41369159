Attempts at automatic speech recognition have known several waves. Early efforts were based on the faith that speech is a string of phonemes that can be isolated and recognized one by one. This wave broke when it became clear that the physical realization of a phoneme is smeared in time and mingled with that of its neighbors, and also context and speaker-dependent. Next came the invention of the highly successful time-warping DP-matching methods, in which whole words are matched by templates. This wave is still going strong, at least in Japan, but it may have reached a high mark. To probe this question, we investigate the case of the "jion'', a subset of character readings that "generates" a large subset of Japanese. This set has low redundancy and contains many minimal pairs. Error analysis of DP-matching shows that most errors occur between pairs that differ only in their initial consonant, especially if it belongs to groups such as plosives or nasals. Combining DP-matching with limitedscope phoneme recognition could break through present limits.