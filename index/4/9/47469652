In the mid 1980's the power growth that accompanied scaling forced the industry to focus on CMOS technology, and leave nMOS and bipolars for niche applications. Twenty years later, CMOS technology is facing power issues of its own. After first reviewing the "cause" of the problem, it will become clear that there are not easy solutions this time -- no new technology or simple system/circuit change will rescue us. Power, and not number of devices is now the primary limiter of chip performance, and the need to create power efficient designs is changing how we do design. In the past, we would turn to specialized computation (ASICs) to create the needed efficiency, but the rising NRE costs for chip design (now over $10M/chip) has caused the number of ASIC design starts to fall not rise. To get out of this paradox, we need to change the way we think about chip design. For many reasons I don't believe that either the current SoC, or high-level language effort will solve this problem. Instead, we should acknowledge that working out the interactions in a complex design is complex, and will cost a lot of money, even when we do it well. So once we have worked it out, we want to leverage this solution over a broader class of chips. We can accomplish this by creating a "fixed" system architecture, but of very flexible components. That is, instead of building a programmable chip to meet a broad class of application needs, you create a virtual programmable chip, that is MUCH more flexible than any real chip. The application designer (the new chip designer) will then configure this substrate to optimize for their application and then create that chip. To demonstrate how this might work, we use a multiprocessor generator to create a customized CMP which executes H.264 encode with an energy efficiency comparable to an ASIC. As we show in this example for very low energy computation, DRAM energy can be an issue, and we will end the talk describing how to address this final energy frontier.