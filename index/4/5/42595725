Currently speech recognition is accomplished by matching spoken utterances with reference patterns of words that were spoken by an individual at an earlier time. Recognition is highly dependent upon background noise. The purpose of this study was to assess the extent to which subjects “manner” of speaking in noise, as separate from the noise itself, affected recognition. Subjects generated reference patterns in quiet and in noise and then spoke lists of digits in quiet and in noise for the speech system to recognize. Noise was delivered over earphones so it would not go into the speech recognition system through the microphone. Training and recognition were done from tape recordings, with the playback level of the tape was always set to the same, intermediate level. The data suggest that manner of speaking, for about half of the subjects is very different in noise compared with quiet. The data also imply that if recognition will be done in both quiet and noise, the safest alternative is to start out with patterns generated in noise.