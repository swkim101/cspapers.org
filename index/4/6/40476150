Recently there has been increasing attention to character recognition/graphical user interfaces under the name of “gesture input”. This technique actually has a long history: “sketch recognition” interfaces of 15 or more years ago were highly praised [Applicon 73], and user interfaces using handwriting input before the wide use of text keyboards were one of the first research goals in computer science [Bledsoe 59]. The underlying character and symbol recognition technologies have been a major research area in their own right since the early 1950s [Suen 80].
The last two years have seen an upsurge in the number of developments in this area, both from commercial companies attempting to exploit new character and symbol recognition technologies, [CIC 85] [Pencept 84] [Cooper 82] and from researchers starting from fundamental questions in user interactions [Buxton 86] [Wolf 86]. However, one question still remains: “Why has this set of techniques had so little impact on user interface design practice, despite its long history and promise?” This panel discussion should give many answers to this question.
Panelists include the leading commercial developers of handwriting input products, well-known researchers in the psychological aspects of graphical user interactions, and representatives of the research community for character recognition.
The issue of supporting this type of interface is very timely: recent standardization efforts such as PHIGS and GKS for graphics interactions are known to have the unfortunate side effects of excluding some of the current user interface designs using this class of technology [10].