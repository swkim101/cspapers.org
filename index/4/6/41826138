The aim of this paper is to discuss and present a navigation architecture for an autonomous mobile robot, based on the integration of ultrasonic sensors and stereo vision. The distinctive features are the integration of a "classical" planning approach and subsumption architecture for obstacle avoidance, and the fusion of visual and ultrasonic sensory data. The goal of the experiment is to plan missions between two user defined points in the environment, autonomously avoiding static and dynamic obstacles along the planned path.<<ETX>>