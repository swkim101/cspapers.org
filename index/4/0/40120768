In this paper, we present bird's-eye (BE) viewer - a sensor-based navigation system intended to assist motor-impaired people driving their mobility aids to a specified goal. The BE-viewer is built around a vision-based 2D localization system based on a monocular image system composed of one web-camera, and endowed with real-time capability of estimating the location of active light-emitting markers. The 2D localization system is integrated in a human-machine-interface, which provides the user with a "top-view" sketch of the current and desired configurations. We introduce a protocol for the functional assessment of the docking procedure, here interpreted as a pursuit tracking task. The protocol allows to characterize how subjects use their resources to achieve a balance between speed, accuracy and control effort, depending on whether the perceptual enhancement by the BE-viewer is available or not. The benefits of the BE-view approach are presented and discussed on preliminary experiments where normal subjects perform docking procedures using a motorized anterior walker.