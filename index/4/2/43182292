In SLAM, the size of the state vector tends to grow when exploring unknown environments, causing the ever-increasing computational complexity. To reduce the computational cost, one needs to continuously marginalize part of previous states (features and/or poses). This can be achieved by using either the null-space operation or Schur complement based marginalization. The former was originally developed particularly for visual-inertial odometry (VIO), while the latter is the standard approach to reduce the state vector in bundle adjustment (BA). In this paper, for the first time ever, we prove that under mild assumptions (i.i.d. white Gaussian noise model and same linearization points) these two techniques retain the same amount of information about the state, which is validated with real-world experiments. Moreover, based on this key insight, we derive analytically the left null-space expressions for multi-state constraint Kalman filter (MSCKF)-based VIO, which is verified through Monte-Carlo simulations.