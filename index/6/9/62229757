There is always a deviation between a model prediction and the reality that the model intends to represent. The deviation is largely caused by the model uncertainty due to ignorance, assumptions, simplification, and other sources of lack of knowledge. Quantifying model uncertainty is a vital task and requires the comparison between model prediction and observation. This exercise is generally computationally intensive on the prediction side and costly on the experimentation side. In this work, a new methodology is proposed to provide an alternative implementation of model uncertainty quantification. With the new methodology, the experimental results are reported with expanded uncertainty terms around the experimental results for both model input and output. In other words, the experimental results are expressed as intervals. Then the model takes the experimental results of the input intervals and produces an interval prediction. The model uncertainty is then quantified by the difference between the model prediction and experimental observation, represented by an interval as well. By employing the standards for measurement uncertainty, the new methodology is easy to implement and could serve as a common framework for both model builders and experimenters.Copyright Â© 2011 by ASME