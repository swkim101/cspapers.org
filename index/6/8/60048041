It is our great pleasure to welcome you to the first Workshop on Large-scale System and Application Performance -- LSAP2009. We have initiated this workshop as we think it addresses a very important and timely subject. Over the last decade, computer systems and applications in everyday use have grown to unprecedented scales. Large clusters serving millions of search requests per day, grids executing large workflows and parameter sweeps consisting of thousands of jobs, and supercomputers running complex e-science applications, have now hundreds of thousands of processing cores. In addition, clouds are quickly emerging as a large-scale computing infrastructure. Peer-to-peer systems and centralized video distribution systems that dominate the internet and complicated internet applications such as massive multiplayer online games are used by millions of people every day. 
 
In view of this tremendous growth, understanding the performance of large-scale computer systems and applications has become vital to institutional, commercial, and private interests. This workshop intends to be a venue for papers on performance evaluation methods, tools, and studies focusing on the challenges of large scale, such as decentralization, predictable performance, reliability, and scalability. It aims to bring together system designers and researchers involved with the modeling and performance evaluation of large-scale systems and applications. 
 
The call for papers of the workshop attracted 7 submissions, out of which the program committee accepted 4 papers that cover a variety of topics, ranging from modular data centers and grid meta-brokers to the MapReduce programming model and peer-to-peer systems. In addition, the workshop program features a keynote presentation by Douglas Thain of the University of Notre Dame, USA, on scaling up data-intensive scientific applications.