In this paper, I develop a higher-order statistical theory of matching models against images. The basic idea is not only to take into account {\em how much} of an object can be seen in the image, but also {\em what parts} of it are jointly present. I show that this additional information can improve the specificity (i.e., reduce the probability of false positive matches) of a recognition algorithm. I demonstrate formally that most commonly used quality of match measures employed by recognition algorithms are based on an independence assumption. Using the Minimum Description Length (MDL) principle and a simple scene-description language as a guide, I show that this independence assumption is not satisfied for common scenes, and propose several important higher-order statistical properties of matches that approximate some aspects of these statistical dependencies. I have implemented a recognition system that takes advantage of this additional statistical information and demonstrate its efficacy in comparisons with a standard recognition system based on bounded error matching. We also observe that the existing use of grouping and segmentation methods has significant effects on the performance of recognition systems that are similar to those resulting from the use of higher-order statistical information. Our analysis provides a statistical framework in which to understand the effects of grouping and segmentation on recognition and suggests ways to take better advantage of such information.