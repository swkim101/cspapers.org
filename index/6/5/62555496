We are pleased to report that the 28th Conference on Research and Development in Information Retrieval drew a record number of paper submissions representing the work of IR researchers in more than 50 countries. There were 368 paper submissions with 71 (19%) accepted for the conference. There were 120 posters submitted, of which, 53 (44%) were accepted. In addition, the conference included 7 tutorials, 7 workshops, and 12 demonstrations. Taken together, these contributions represent the state of the art in information retrieval research including theoretical models; novel techniques for text and multimedia retrieval in WWW and controlled collections; applications of IR techniques to summarization, question answering, and personal collections; formal evaluation methods; and empirical evaluations of human behavior in retrieval setting.The selection of quality contributions for SIGIR is dependent on a thorough and equitable two-tier reviewing process. All reviewing in SIGIR is double-blind. The program committee consists of three chairs representing geographical regions and two area coordinators for each of the thirteen areas of emphasis, plus four ad hoc area coordinators (the conference and program chairs for next year). More than 200 first-tier reviewers were assigned 3 to 7 papers by the PC chairs according to the expressed expertise of reviewers and topical categories authors gave their papers. Given the number of papers this year, most reviewers were assigned 7 papers. Each paper received at least three first tier reviews. The roles of the area coordinators were to resolve differences among reviews and produce a metareview based on the first-tier reviews. Area coordinators were selected based on their expertise in the area with geographic balance also taken into account. Most area coordinators were responsible for 15 or more papers. A two-week discussion period was allocated for this purpose and more than 800 discussion messages were logged. The area coordinators attended the PC meeting and led the discussion on the papers for which they were responsible. Posters were assessed by three reviewers each, demos by two reviewers, and workshops and tutorials were reviewed and discussed by the entire program committee.