Camera calibration is an indispensable step for augmented reality or image guided applications. In the context of three-dimensional machine vision, camera calibration is the process to determine the internal camera geometry and optical characteristics and/or the 3-D position and orientation of the camera frame relative to a certain world coordinate system. Usually, a camera calibration procedure exhibits typical steps, including feature point location in the acquired images, camera model fitting, correction of distortion introduced by the optics and finally an optimization of the model's parameters. Thus, the components required for designing new calibration procedures show a high degree of similarity, so that reuse of the processing steps plays an important role. For this reason, we present fundamental design issues of a component-based calibration framework, which guides and supports the researcher in writing reusable software components and therefore, improves the efficiency of his work. The modularity enables him to modify only aspects of a given calibration procedure allowing to deepen the understanding on how the different steps influence its overall performance.