Understanding of uncertainty in the data and models used in design simulations matures during the design process as the design progresses from vague requirements through to its full embodiment and detail. Failure to take account of uncertainty in the information that is used in and generated from simulation processes poses risks to decisions based upon these. This paper presents a classification scheme based on the extent and nature of uncertainty in the correlations between simulation predictions and the evidence for a specific performance criterion. The classification allows development of a confidence scale and associated error functions for characterizing the discrepancy between the correlations of design performance parameters and evidence, in the presence of uncertainty. Together, the confidence scale and error functions may provide a greater understanding of uncertainty and errors in simulation processes. In the context of parametric design, the approach provides a mechanism for building up greater understanding of the simulation performance across a feasible design space. A case study on the design of shrink-fits is used to illustrate the framework for handling uncertainty in a systematic and organized manner. The theoretical and practical limitations and further work will be discussed.