Recently we presented several disk array architectures designed to increase the data rate and II0 rate of supercomputing applications, transaction processing, and file systems [Patterson 881. In this paper we present a hardware performance measurement of two of these architectures, mirroring and rotated parity. We see how throughput for these two architectures is affected by response time requirements, request sizes, and read to write ratios. We find that for applications with large accesses, such as many supercomputing applications, a rotated parity disk array far outperforms traditional mirroring architecture. For applications dominated by smaU accesses, such as trmaction processing, mirroring architectures have higher performance per disk than rotated parity architectures. 1. The I/O Crisis Over the past decade, processing speed, memory speed, memory capacity, and disk capacity have all grown tremendously: l Single chip processors have increased in speed at the rate of 40%-100% per year [Bell 84. Joy 851. l Caches have increased in speed 40% to 100% per year. l Main memory has quadrupled in capacity every two or three years [Moore 75. Myers 861. In contrast, disk access times have undergone only modest performance improvements. For example, seek time has improved only about 7% per year [Harker 811. This imbalanced system growth has already led to many I/O bound supercomputer applications [Kim 871. If the imbalance is not remedied, Amdabl's Law tells us that much of the astounding processor speedup and memory growth will be wasted [Amdahl 671. Continued improvement in system performance depends in a large part on I/O systems with higher data and I/O rates. One way to increase I/O performance is by using an array of many disks [Kim 86, Salem 861. By using many disks, both throughput (MB per second) and I/O rate (I/O's per second) can be increased. Throughput can be increased by having many disks cooperate in transferring one block of information; the I/O rate can be increased by having multiple independent disks service multiple independent requests. With multiple disks, however, comes lower reliability. According to the commonly used exponential model for disk failures [Schulze 881, 100 disks have a combined failure rate of 100 times the failure rate of a single disk. If every disk failure caused data loss, a 100 disk array would lost data every few hundred hours. This is intolerable for a supposedly stable storage system. To protect against data loss in the face of a single disk â€¦