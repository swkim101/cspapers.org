One of the major tasks today is to create information from data. We do not mean to define information in terms of Shannon or indeed any other mathematical definition but information in terms of the subjective experience of a viewer of the data. People (and probably animals) are very good at pattern recognition; we are far more robust pattern matchers than any current computer programs. Increasingly however, we are dealing with high dimensional (and often high volume) data so to gain intuitions about a data set, we often project data onto low dimensional manifolds. One question which arises then, is what projections to low dimensional manifolds are best in order to present the projected data to a human user. We illustrate several projections which have been found by artificial neural network extensions of Hebbian learning. 
 
We then show examples of similar projections found by reinforcement learning; our rationale in this case is that we have agents interacting proactively with a database examining different projections and, without human intervention, getting rewards when the projections reveal some interesting structure. We then give examples of the same projections found by other computational intelligence methods such as the cross entropy method and artificial immune systems. 
 
We then examine projections to nonlinear manifolds and show that with a particular model of an underlying latent space, we may identify clusters in data sets when such clusters are not visible in any low dimensional linear projection. 
 
Finally we review different data representation techniques: we begin with parallel coordinates and point out some difficulties with this method before reviewing Andrews' Curves, a method from the 1970s which has only become truly practicable with the advent of modern desktop computers. An extension to this method came from Wegman and his colleagues in the 1990s. We also discuss a more recent extension and illustrate three dimensional projections of data samples dancing together.