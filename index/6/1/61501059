Quality and performance are two important customer requirements in vehicle design. Driveline clunk negatively affects the perceived quality and must be therefore, minimized. This is usually achieved using engine torque management, which is part of engine calibration. During a tip-in event, the engine torque rate of rise is limited until all the driveline lash is taken up. However, the engine torque rise, and its rate can negatively affect the vehicle throttle response which determines performance. Therefore, the engine torque management must be balanced against throttle response. In practice, the engine torque rate of rise is calibrated manually. This paper describes an analytical methodology for calibrating the engine torque, considering uncertainty, in order to minimize the clunk disturbance, while still meeting throttle response constraints. A set of predetermined engine torque profiles which span the practical range of interest, are used and the transmission turbine speed is calculated for each profile using a bond-graph vehicle model. The turbine speed quantifies the clunk disturbance. Using the engine torque profiles and the corresponding turbine speed responses, a time-dependent metamodel is created using principal component analysis and Kriging. The metamodel predicts the turbine speed response due to any engine torque profile and is used in a deterministic and reliability-based optimization which minimizes the clunk disturbance while still meeting the throttle response target. Compared with commonly used production calibration, the clunk disturbance is reduced substantially without negatively affecting the vehicle throttle response.Copyright Â© 2008 by ASME