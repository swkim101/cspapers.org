As programmability and extensibility have become the key factors of network equipment, software routers running on commodity servers are gaining momentum. However, the performance of current software routers is limited to 1â€“10 Gbps, which is not enough to handle fast growing internet traffic. The bottleneck lies in CPU because it takes all the burden of I/O, packet processing, and control plane operations (e.g. BGP protocol daemon). In order to tackle the performance problem of software routers, we offload packet processing to graphics processing units (GPUs). Over the last decade, the GPU has become programmable and flexible enough to handle general workloads beyond graphics rendering. The peak performance of GPUs now reaches to 1 TFLOPS, which is roughly 10 times faster than current general-purpose CPUs. We believe that GPU is a cheap, ubiquitous, flexible, and scalable alternative to ASIC, FPGA, or network processors. The processing power of GPUs comes from its hundreds of cores. The key insight of our work is that such a massive array of cores matches the inherent parallelism in stateless packet processing. To exploit parallelism, we process multiple packets in parallel. The following figure compares the throughput of IPv6 routing table lookup (longest prefix matching) done by CPU and GPU. Its promising result confirms that GPU acceleration for core packet processing functions with enough parallelism can significantly boost the performance of software routers.