The video discusses Machine Rhythm, a program which emulates human rhythm perception. Given a musical performance represented as a MIDI stream, the program determines the program’s rhythm that is, it decides the meter of the performance, the rhythmic value of each note, and the location of barlines. The basic orientation of the video is to demonstrate applications of the program; more theoretical aspects are treated in (Rosenthal 1992). Machine rhythm-finding is a difficult problem for several reasons. First, the timing of downbeats, which are heard by human listeners as a regular pulse, actually varies quite wildly; in certain cases the period can vary by a factor of two in adjacent beats. This can happen even when tempo variation is not being used as an expressive device. Second, not all downbeats correspond to actual musical events in other words, one sometimes taps to a beat that doesn’t correspond to a note in the music. Syncopations are particularly difficult instances of this, but the problem occurs even in unsyncopated music. Third, there is no straightforward method by which the location of downbeats can be extracted from a performance; downbeats are not reliably louder than other notes, for example. Finally, the rhythm of a piece of music is not a single pulse, but rather an interlocking hierarchy or pulses with periods of different sizes; hence the nomenclature of “measure,” “half-note,” “quarter-note,” and so on. Despite these apparent difficulties, human listeners have little trouble arriving at an unambiguous interpretation; in this sense rhythm finding is as well-defined a problem as, say, speech understanding. Humans apparently compensate for the problems mentioned in the last paragraph by integrating a variety of acoustic and musical cues, such as texture, melodic pattern, relative time between onsets, length of notes, and others. Humans also have the ability to fluently change their interpretations, either because of an initial interpretation is incorrect or because of a change in the music. Humans apparently track the various-size periods simultaneously, and use them to confirm each other. In an effort to build a machine rhythm tracker with performance approaching that of a human, we integrated many of these methods into our system: The system integrates evidence from a variety of cues, some of which involve subtle analyses of the music from the MIDI data. The system achieves the flexibility to handle difficult situations by maintaining a hierarchy of hypotheses. The