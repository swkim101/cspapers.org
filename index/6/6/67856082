This paper proposes an approach for fusing direct radiometric data from a thermal camera with inertial measurements to extend the robotic capabilities of aerial robots for navigation in GPS–denied and visually degraded environments in the conditions of darkness and in the presence of airborne obscurants such as dust, fog and smoke. An optimization based approach is developed that jointly minimizes the re–projection error of 3D landmarks and inertial measurement errors. The developed solution is extensively verified against both ground– truth in an indoor laboratory setting, as well as inside an underground mine under severely visually degraded conditions.