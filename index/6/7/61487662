In a number of microprocessor-based real time control and instrumentation systems interrupt service routines are used to record the time at which an event occurs. There are several applications of this technique. For example, if hardware is provided so that a voltage waveform of interest generates an interrupt once each cycle and an interrupt service routine is used to record the times at which these interrupts occur, the time difference between successive interrupts can be used to measure the period or frequency, of the voltage waveform. An examination is made of the accuracy of interrupt driven time measurements, and in particular of the accuracy of measurement of the time difference between successive interrupts. It is found that the primary source of error in this measurement arises from the way in which a microprocessor responds to interrupts. For a given microprocessor running a real time control program, if the probabilities of the occurrence of instructions of different length is known, it is possible to calculate the probability distribution function of the errors that can result. From this function, the error can readily be expressed as a standard deviation of error or as the confidence level that the error will be less than a given value. >