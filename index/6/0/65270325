Tests of dependence are an important tool in statistical analysis, and are widely applied in many data analysis contexts. For many problems in data analysis, however, the question of whether dependence exists is secondary: there may be multiple dependencies, and the question becomes which dependence is the strongest. We present a novel non parametric statistical method which describes hypothesis test of relative dependence between a source variable and two candidate target variables. Such a test enables one to answer whether one source variable is significantly more dependent on the first target variable or the second. Dependence is measured via the Hilbert-Schmidt Independence Criterion (HSIC), resulting in a pair of empirical dependence measures (source-target 1, source-target 2). Modeling the covariance between these HSIC statistics leads to a provable more powerful test than the construction of independent HSIC statistics by sub-sampling. The resulting test is consistent and unbiased, and (being based on U-statistics) has favorable convergence properties. The test can be computed in quadratic time, matching the computational complexity of standard empirical HSIC estimators. The effectiveness of the test is demonstrated on several real-world problems: we identify language groups from a multilingual corpus, and we prove that the tumor location is more dependent to gene expression than chromosomal imbalances.