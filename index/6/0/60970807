Many scientific codes consist of memory bandwidth bound kernels — the dominating factor of the runtime is the speed at which data can be loaded from memory into the Arithmetic Logic Units. Generally Programmable Graphics Processing Units (GPGPUs) and other accelerator devices such as the Intel Xeon Phi offer an increased memory bandwidth over CPU architectures. However, as with CPUs, the peak memory bandwidth is often unachievable in practice and so benchmarks are required to measure a practical upper bound on expected performance. We present GPU-STREAM as an auxiliary tool to the standard STREAM benchmark to provide cross-platform comparable results of achievable memory bandwidth between multiand many-core devices. I. MEASURING MEMORY BANDWIDTH The STREAM Benchmark [1] measures the time taken for each of four simple kernels to be run (α is a scalar constant): 1) Copy: c[i] = a[i] 2) Multiply: b[i] = αc[i] 3) Add: c[i] = a[i] + b[i] 4) Triad: a[i] = b[i] + αc[i] It is simple to calculate how many bytes each of these kernels requires to be read from and written to memory, assuming perfect caching. Let β be the number of bytes to represent one element — for double precision β = 8. For an array of length N , copy and multiply move 2Nβ bytes, and add and triad move 3Nβ bytes. The ordering of the kernels ensures caches are invalidated, and as long as the arrays are large enough the data must be reloaded from main memory. The achieved sustained memory bandwidth can be found by dividing these numbers by the time to execute the corresponding kernel. GPU-STREAM implements these kernels in both the OpenCL and CUDA programming frameworks. This allows the benchmark to be used across a wide range of hardware from a wide range of vendors.