Planning how to use a system to accomplish a particular goal? l What are the general approaches towards addressing those problems ? For example, one might approach the understandability issue by trying to broaden the range of inputs handled so that users can get by with less knowledge, or by building in more self-knowledge so that systems could generate justifications of their own reasoning and behavior as done in expert systems. l How can particular AI techniques help realize those approaches? This question is not to be answered at the cliche level of “natural language would save users from having to learn a command language”, but rather at the level of particular solutions in particular systems. l How can the intelligence that is built into knowledgebased systems be exploited to provide a better user interface? It would seem that sharing intelligence between the interface and the system would reduce cost and enhance consistency. Is this true? Are there special concerns that must be addressed when interfacing to intelligent systems ? Many expert system designers have added explanation capabilities based on the belief that users need to build confidence in the system and to learn from it. Are there other needs or other consequences? Are there other kinds of knowledge-based systems that have distinctive interface needs?