Massively-parallel systems are coming: core counts keep rising whether conventional cores as in multicore and manycore systems, or specialized cores as in GPUs. Conventional wisdom has been to utilize this parallelism by reducing synchronization to the minimum required to preserve determinism in particular, by eliminating data races. However, Amdahl's law implies that on highly-parallel systems even a small amount of synchronization that introduces serialization will limit scaling. Thus, we are forced to confront the trade-off between synchronization and the ability of an implementation to scale performance with the number of processors: synchronization inherently limits parallelism. This workshop focuses on harnessing parallelism by limiting synchronization, even to the point where programs will compute inconsistent or approximate rather than exact answers.