Bayesian optimization is an efﬁcient way to optimize expensive black-box functions such as designing a new product with highest quality or tuning hyperparameter of a machine learning al-gorithm. However, it has a serious limitation when the parameter space is high-dimensional as Bayesian optimization crucially depends on solving a global optimization of a surrogate utility function in the same sized dimensions. The surrogate utility function, known commonly as acquisition function is a continuous function but can be extremely sharp at high dimension - having only a few peaks marooned in a large terrain of almost ﬂat surface. Global optimization algorithms such as DIRECT are infeasible at higher dimensions and gradient-dependent meth-ods cannot move if initialized in the ﬂat terrain. We propose an algorithm that enables local gradient-dependent algorithms to move through the ﬂat terrain by using a sequence of gross-to-ﬁner Gaussian process priors on the objective function as we leverage two underlying facts - a) there exists a large enough length-scales for which the acquisition function can be made to have a signiﬁcant gradient at any location in the parameter space, and b) the extrema of the consecutive acquisition functions are close although they are different only due to a small difference in the length-scales. Theoretical guarantees are provided and experiments clearly demonstrate the utility of the proposed method on both benchmark test functions and real-world case studies.