An effective yet simple approach for text-dependent speaker verification is presented in this paper. The basic idea employs the fundamentals of Gaussian Mixture Model, which is a popular technique for speaker recognition in modern state-of-the- art systems. In this paper we introduce a novel technique for creating unique speaker models using spectral and prosodic features of speech signals which are further boosted to get the final robust discriminating speaker identity. Multi-class Adaptive Boosting (AdaBoost) algorithm is used for the classification of each speaker model. The Gaussian distributions of the Mel- Frequency Cepstral Coefficients (MFCC) of each speaker are pre- emphasized using the pitch information in the speech signals. The GMM combines the individual speaker models according to the set of mixing weights but our approach categorizes the speaker models in weak-learned sets which then linearly and optimally combine to form a strong classifier. The results of our algorithm show 98% correct speaker verification for the set of 16 speakers. On the average the percentage of false acceptance is 2% while the false rejection rate is 0%.