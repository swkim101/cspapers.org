The use of immersive Virtual Reality (VR) for studying Human-Robot Interaction (HRI) offers many benefits, including decreased cost and risk as well as increased experimental control and repeatability. Previous work has shown that people reliably underestimate distances in VR; however, the effect of this underestimation on gesture recognition has not been characterized. This work contributes to the validation of immersive VR as a platform for HRI investigation and simulation for training in industry. A matched pair of studies compared the location preferences of human participants when viewing gestures generated by a robot in both virtual and physical environments. Participants were asked to select up to three optimal locations within a bounded region at which they perceived the robot's gesture to be the clearest. We found that the use of VR did increase the preferred proxemic distance (χ2 (1) = 18.046, p < 0.001) by approximately 642 ± 96mm. The difference in viewing angle between the virtual and physical environments was not significant, with a 95% confidence interval limiting the difference within −8.6° to +7.9°. Observations relating gesture features to optimal viewing locations are also presented.