Linguists seek to understand the semantics of expressions in human languages. Certainly there are many natural language expressions--operators in the wild, so to speak--that control evaluation in ways that are familiar from programming languages: just think of the natural-language counterparts of if, unless, while, etc. But in general, how well-behaved are control operators found in the wild? Can we always understand them in terms of familiar programming constructs, or do they go significantly beyond the expressive power of programming languages?
 As an example where operators from a programming langauge can provide an insightful analysis of a natural language construction, consider the difference in meaning between the following two sentences:
 (1) a. & John only drinks PERRIER. (emphasis on Perrier)
 b. John only DRINKS Perrier. (emphasis on drinks)
 The first sentence entails that John never drinks, say, Evian, but the second sentence entails instead that John never does anything (relevant) with Perrier except drink it. I will suggest that we can understand this difference by expressing the meanings of these sentences in terms of Sitaram's fcontrol and run operators (variants on throw and catch).
 But not all wild operators are so easily captured. I will discuss in some detail the meaning of the word same in English as it occurs in the following sentence:
 (2) & John and Bill read the same book.
 This sentence has a prominent interpretation on which it means (roughly) 'there is some book x such that John read x and Bill read x. I provide a preliminary analysis based on Danvy and Filinski's shift and reset. However, the shift reset approach does not generalize to the full range of related sentences in English. I give a more general solution expressed in a Type Logical Grammar (a certain kind of substructural logic) with explicit continuations. But even this is inadequate: I go on to discuss additional, only slightly less ordinary uses of same that remain untamed by any known compositional semantics.