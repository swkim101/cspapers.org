Planetary rovers face mobility hazards associated with various classes of terrains they traverse: sand, bedrock, and rock-strewn terrain. This work develops visual classifiers for these 3 terrain types for single monochrome navigation images from the NASA Mars Exploration Rover missions. The classifiers are based primarily on visual texture, captured in histograms of edges filter responses at various scales and orientations. Monochrome image intensity is further used to distinguish between confusing rock and bedrock cases. Three approaches are investigated: a gradient-based simplified HOG descriptor, a simplified GIST descriptor, and MR8 textons. Local rotational invariance is implemented in each approach, as validation tests demonstrate its benefit to performance. K-Nearest Neighbors is used for the final classification. No major differences in performance are observed between the three approaches, leading to the adoption of the HOG approach due to its lower computational complexity and thus highest applicability to planetary missions. Final tests demonstrate an accuracy between 70% and 93% (81% average) for the 3-way classification using the simplified HOG descriptor.