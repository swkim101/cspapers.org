Could we help people have healthier lives and better experiences if computers could measure and help communicate our emotion? Years ago, my students at MIT and I began to design, build, and test both wearable and other sensors for recognizing emotion. We designed studies, gathered data, and developed signal processing and machine learning techniques to see what could be reliably extracted. In this talk I will highlight several of the most surprising findings during this adventure. These include new insights about the "true smile of happiness," discovering that regular cameras (and your smartphone, even in your handbag) can compute some of your biosignals, finding electrical signals on the wrist that give insight into deep brain activity, and learning surprising implications of wearable sensing for autism, anxiety, depression, sleep-memory consolidation, epilepsy, and more.