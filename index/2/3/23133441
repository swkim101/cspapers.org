Reliable lane detection is a fundamental necessity for driver assistance, driver safety functions and fully automated vehicles. Based on other detection and classification tasks, deep learning based methods are likely to yield the most accurate outputs for detecting lane markers, but require vast amounts of labeled data. We propose to train a deep neural network for detecting lane markers in camera images without manually labeling any images. To achieve this, we project high definition maps for automated driving into our image and correct for misalignments due to inaccuracies in localization and coordinate frame transformations. The corrections are performed by calculating the offset between features within our map and detected ones in the images. By using detections in the actual image for refining the projections, our labels become close to pixel perfect. After a fast, visual quality check, our projected lane markers can be used for training a fully convolutional network to segment lane markers in images. A single worker can easily generate 20,000 of those labels within a single day. Our fully convolutional network is trained only on automatically generated labels. All of our detections are based solely on gray-scale mono camera inputs without any additional information. The resulting network regularly detects clean lane markers at distances of around 150 meters on a 1 Megapixel camera.