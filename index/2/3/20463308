Q-Learning is a type of reinforcement learning which learns how to optimize an agent's choice of actions in a given environment based on experience. Typically, Q-Learning is implemented using a lookup table indexed by state/action tuples. For many applications, this approach can be difficult or impossible, as their state space is too large or cannot accurately be captured in a table. A neural network can act as a function approximator for the Q-Learning Table. This reduces learning time and allows for generalization on unvisited states The neural network can be trained using the Back propagation algorithm with the state/action tuple as input and the output of the update rule as the new target value. The weights of the network are updated to produce the correct output value for inputs in the training set. We have implemented this technique in a 2-D simulation of soccer, where agents learn how to maneuver the ball in order to score a goal.