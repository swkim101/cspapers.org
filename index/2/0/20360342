Modern data analytics workloads process large datasets on shared-nothing clusters, and heavily rely on user-defined functions (UDFs) to express complex operations. These UDFs can bottleneck workloads even when executing in a perfectly parallel fashion. For example, when analyzing Magnetic Resonance Imaging (MRI) data from the Human Connectome Project [14] using Apache Sparkâ€™s [1] Python API, Pyspark, as much as 85% of the 1.7 hour execution time is spent in a perfectly parallel image denoising step. These UDFs in turn spend much of their execution time inside methods from external libraries. These libraries, such as NumPy [2] and SciPy [3] in Python, have already been heavily optimized and execute critical methods in C for performance. They additionally provide tuning parameters and method alternatives to allow users to optimize performance for their specific workload. For example, a linear algebra method may allow tuning the numerical precision used or the in-memory layout of a matrix. In many cases the tuning decisions that minimize runtime depend on the nature of the data and the system hardware, but certain tuning decisions may risk introducing numerical instability and other approximation errors. The denoising operation mentioned above, which comes from the computational neuroanatomy library Dipy [10], is a form of blockwise nonlocal means denoising [6] and allows tuning the block size. Shrinking the block size can improve performance by orders of magnitude, but introduces some approximation error. Tuning such library calls is key to improving the performance of UDF-bottlenecked workloads. Unfortunately, even if users of a library method are aware it can be tuned, there is no clear tuning rule of thumb for speeding up execution. It can be even more challenging for users to reason about how much approximation error tuning decisions introduce. To address this problem we introduce Talpidae: an extension to Apache Spark that statically analyzes Python UDFs, detects tunable library calls, and adaptively alters them for optimal performance while respecting any user-specified tolerances on approximation error. It does so by treating the