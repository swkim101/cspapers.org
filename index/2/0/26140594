With the widespread availability of massive amounts of student programming data, we are witnessing a digital gold rush as researchers attempt to make sense of students' programming behaviors. In prior research, we incorporated programming data into a statistical model that accounted for a significant amount of a student's course performance. In a separate line of research, we explored how online social networking tools might be leveraged for pedagogical purposes. Rather than treating our explorations of students' programming and social behaviors as separate research spaces, we are next considering the interplay between social behavior, programming behavior, and course performance. As a first step, we incorporated online social participation into our statistical model of programming behaviors. The outcome was quite promising: we witnessed a 30% increase in our model's effect size. This result would seem to indicate that neither programming behavior nor social behavior alone can fully account for student performance. Encouraged by this result, we are now considering how social interaction influences programming decisions and vice versa. In particular: After receiving help on a social network, what changes are made to code? Are these changes more or less likely to move the student closer to a correct solution? How do students address coding problems when their questions are left unanswered? At what points in the programming process are students more likely to pose questions? Similarly, when are students more willing to offer help? How can we use this knowledge to better identify students who are struggling?