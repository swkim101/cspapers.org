Two observations motivate our work: (a) modelbased diagnosis programs are powerful but do not learn from experience, and (b) one of the long-term trends in learning research has been the increasing use of knowledge to guide and inform the process of induction. We have developed a knowledge-guided learning method, based in EBL, that allows a model-based diagnosis program to selectively accumulate and generalize its experience. 
 
Our work is novel in part because it produces several different kinds of generalizations from a single example. Where previous work in learning has for the most part intensively explored one or another specific kind of generalization, our work has focused on accumulating and using multiple different grounds for generalization, i.e., multiple domain theories. As a result our system not only learns from a single example (as in all EBL), it can learn multiple things from a single example. Simply saying there ought to be multiple grounds for generalization only opens up the possibility of exploring more than one domain theory. We provide some guidance in determining which grounds to explore by demonstrating that in the domain of physical devices, causal models are a ric? source of useful domain theories. We also caution that adding more knowledge can sometimes degrade performance. Hence we need to select the grounds for generalization carefully and analyze the resulting rules to ensure that they improve performance. We illustrate one such quantitative analysis in the context of a model-based troubleshooting program, measuring and analyzing the gain resulting from the generalizations produced.