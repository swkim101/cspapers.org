The ability to manipulate objects is the primary purpose of any robotic hand. However, when executing a grasp, the object and fingers rarely move exactly as planned. These unobserved deviations in the pose of the object or the contact configuration can make it impossible to solve a given task. In this paper, we presents a new approach to estimate the state of the grasp using only position and torque measurements from the joints of the hand. Based on the popular extended Kalman filter framework, the algorithm estimates the pose of the manipulated object, as well as the contact forces and positions on the surface of the object. It is able to reliably detect new and the loss of contacts and to incorporate this information in the estimation filter. The validity of this new method is shown in different grasp and manipulation tasks using David, a humanoid platform of DLR.