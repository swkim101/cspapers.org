The problem of estimating the camera displacement in eye-in-hand visual servoing is considered, and a simple strategy based on the idea that the estimates accuracy can be improved if the fact that the point correspondences used throughout the visual servoing are relative to the same 3D points is taken into account is presented. In particular, an accurate scaled euclidean reconstruction of the object is built in the first steps of the visual servoing by suitably using existing linear methods, and from this reconstruction the camera displacement is suitably estimated. Extensive proves performed in random conditions have shown that the proposed approach provides significantly better results with respect to the existing linear methods actually used in visual servoing.