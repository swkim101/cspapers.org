Insufficient training data poses a great challenge to acoustic modeling in automatic speech recognition. The problem becomes more severe when presented in the context of under-resourced languages and several specific domains which lack attention from research. This paper explores the role of under-resourced acoustic models in speech-based soccer event retrieval. An event is defined as the spatiotemporal entity interesting to users, which is remarked by the announcer's spoken words. By mining out spoken information from the video, soccer events are detected using a speech recognition system. To resolve the issue of limited training data, subspace Gaussian mixture models are employed. Experimental evaluations are conducted on the first round of World Cup 2010 and the Vietnamese AFF Suzuki-cup 2008 databases. In the best case, transcription performance reaches 74.3% accuracy rate, and an average event detection rate of 60.62% can be obtained.