Automatic question answering is a central topic in information retrieval. Web search engines have made great progress at answering factoid queries, such as “how many people live in Australia?”. These can provide a succinct answer, up to a few words in length, and sometimes offer additional information such as related facts or entities. However, for deeper questions which could benefit from a longer response (e.g., “history of Australia”), current search engine resort to returning a link to a detailed web document. Alternatively, such a question might be posted on a Community Question Answering (CQA) site (“Visiting Australia in May, what should I see?”), hoping to get a human authored and detailed response. In this workshop we aim to explore the boundaries of Web question answering to better understand the spectrum of approaches and possible responses that are more detailed than a short fact, yet are more useful than a full document result. Is it possible to automatically answer diverse questions ranging from advice on fixing a broken sink to requests for opinions on the best basketball player of all time. In addition, questions submitted on the Web can be either short and ambiguous (such as Web queries to a search engine), or long and detailed (such as CQA questions). This workshop is particularly timely for two additional reasons: (1) there still exist many disagreements regarding the goals and nature of Web question answering services, mostly relating to the questions of “question intent” (what kind of queries benefit from question answering compared to other methods); and (2) leading search engines are eager to provide