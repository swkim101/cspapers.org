AI and collective intelligence systems universally suffer from a deficiency of context. There are innumerable possible contexts that may possibly change the interpretation of some signal, that may change the proper response to some stimulus. For example, an image understanding system that does not recognize an arrest event in a zoomed image of a person's face. How is it possible to know there is more information, outside of what the system can access, that affects the interpretation of data The solution to the context problem in practice today is a pragmatic, engineering one: analyze errors (in recommendations, question answers, image recognition, etc.), classify the kinds of contextual information that caused the wrong behavior, find the most common type of context that causes errors, and add information about that kind of context to the system. Clearly this approach is neither general nor scalable, and ignores the infamous long tail of possible contextual information that may affect a system's understanding and its behavior. In this paper we outline a new, more general, approach to recognizing context. The approach is grounded in a fairly simple intuition: the mathematics underlying quantum mechanics is far more appropriate for modeling, and therefore simulating, human cognitive behavior than the standard toolset from classical statistics. Notions such as Heisenberg's uncertainty principle, superpositions of states, and entanglement have direct and measurable analogs in collective intelligence.