Traditionally, data storage systems provide errorcorrection and data integrity techniques in an independent layer, with the goal of protecting all the data equally regardless of the application. In the context of machine learning systems, this strategy is not appropriate: errors in a few features may prove to be critically important (with respect to the algorithm output), while many errors may have little or no effect. This work takes a different direction: we allow ML algorithms to talk to error-correction schemes, with the goal of making algoritms robust to storage noise. We introduce several novel problems, provide an efficient solution to estimate the noiseinduced change in the algorithm output for linear models, and show how to optimize errorcorrection codes to minimize error effects for fixed overhead.