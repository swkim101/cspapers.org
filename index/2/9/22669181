When you talk to a person, it's safe to assume that you both share large bodies of "common sense knowledge." But when you converse with a programmed computer, neither of you is likely to know much about what the other one knows. Indeed, in some respects this is desirable - as when we're concerned with our privacy. We don't want strangers to know our most personal goals, or all the resources that we may control. However, when we turn to our computers for help, we'll want that relationship to change - because now it is in our interest for those systems to understand our aims and goals, as well as our fears and phobias. Indeed, the extents to which those processes "know us as individuals". Issues like these will always arise whenever we need a new interface - and as one of my teachers wrote long ago, "The hope is that, in not too many years, human brains and computing machines will be coupled together very tightly, and that the resulting partnership will think as no human brain has ever thought and process data in a way not approached by the information-handling machines we know today."1 Indeed, the '60s and '70s saw substantial advancestowars this but it seems to me that then progress slowed down. If so, perhaps this was partly because the AI community moved from semantic and heuristic methods towards more formal (but less flexible) statistical schemes. So nowI'd like to see more researchers remedy this by developing systems that use more commonsense knowledge.