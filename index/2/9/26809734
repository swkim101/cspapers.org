This session is a compendium of the emerging performance and price/performmce metics for database systems and transaction processing systems. Each kenchmark tries to answer the question: " What computer should I buy? " Clearly, the answer question is " The system that does the job with the lowest cost-of-ownership. " Cost-of-ownership includes project risks, programming costs, operations costs, hardware costs, and software costs. It's difficult to quantify project risks, programming costs, and operations costs. In contrast, computer performance can be quantified and compared. Generic benchmarks are often used in this way as a rough estimate of the relative system performance because the cost of implementing and measuring a specific application on many different systems is usually prohibitive. Certain genetic benchmarks have become so widely recognized that vendors announce the performance of new products in terms of those benchmarks. For example, DEC, HP, and IBM state the relative performance and price/performance of new machines and system releases by stating their ratings on the Transaction Processing Performance Council's benchmark TPC BM A. This practice is becoming increasingly common. No single metric can measure the performance of computer systems on all applications. System performance varies enormously from one application domain to another. Each system is typically designed for a few problem domains and may be incapable of performing other tasks. For example, most supercomputers lack database and transaction processing software and so are inappropriate for most business applications. Domain-specific benchmarks are a response to this diversity of computer system use. Each such benchmark specifies a synthetic workload characterizing typical applications in that problem domain. The performance and of this workload on various computer systems then gives a rough estimate of their relative performance on that problem domain. This handbook contains seven domain-specific benchmarks covering database and transaction processing systems. To be useful, a domain-specific benchmark must meet four important criteria. It must be Relevant It must measure the peak performance and price/performance of systems when performing typical operations within that problem domain. Portable: It should be easy to implement the benchmark on many different systems and architectures. Scaleabkx The benchmark should apply to small and large computer systems. It should be possible to scale the benchmark up to larger systems, and to parallel computer systems as computer performance and architecture evolve. Simple The benchmark must be understandable, otherwise it will lack credibility. This session presents three such benchmarks. 1. The Transaction Processing Performance â€¦