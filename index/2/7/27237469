Recent work on argument persuasiveness has focused on determining how persuasive an argument is. Oftentimes, however, it is equally important to understand why an argument is unpersuasive, as it is difﬁcult for an author to make her argument more persuasive unless she ﬁrst knows what errors made it unpersuasive. Motivated by this practical concern, we (1) annotate a corpus of debate comments with not only their persuasiveness scores but also the errors they contain, (2) propose an approach to persuasiveness scoring and error identiﬁcation that outperformscompeting baselines, and (3) show that the persuasiveness scores computed by our approach can indeed be explained by the errors it identiﬁes.