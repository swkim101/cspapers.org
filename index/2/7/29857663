Algorithm selection approaches have achieved impressive performance improvements in many areas of AI. Most of the literature considers the offline algorithm selection problem, where the initial selection model is never updated after training. However, new data from running algorithms on instances becomes available while an algorithm selection method is in use. In this extended abstract, the online algorithm selection problem is considered. In online algorithm selection, additional data can be processed, and the selection model can change over time. This abstract details the online algorithm setting, shows that it is a contextual multi-armed bandit, proposes a solution methodology, and empirically validates it. 1 Online Algorithm Selection Many AI-problems are NP-complete: there exists no general efficient algorithm to solve them with. Nevertheless, the problems are often solved efficiently using heuristics. Such heuristics work well in some cases, but not in others. The idea of algorithm selection is to compose a set of complementary algorithms, with each algorithm performing well on different kinds of instances, and to predict for each new instance which algorithm is best suited to solve it. This problem of predicting which algorithm is best for each instance is known as the algorithm selection problem. Algorithm selection methods use supervised learning techniques to build a selection mapping (λ), which maps each instance to the algorithm believed to be best for it. To do so, instances are characterised by a set of cheaply-computable features, correlated with their difficulty. The selection mapping is initialised based on offline training data, consisting of the performance of the algorithms on a set of training instances. Once created, the selection mapping is consulted to make predictions for new online problem instances, but it is never modified. If the training data did not accurately capture the problem, poor selections will be made, resulting in poor performance that will always remain poor. ∗Work supported by the Belgian Science Policy Office (BELSPO) in the Interuniversity Attraction Pole COMEX (http://comex.ulb.ac.be) Every time a prediction for a new online instance is made, the performance of the selected algorithm on that instance becomes known. Offline algorithm selection methods throw away this free data. The idea of online algorithm selection is to process it, aiming to improve the selection mapping. Online algorithm selection is most useful when training data is expensive to obtain or fails to accurately capture the problem. Online algorithm selection is a generalisation of the offline problem, allowing the selection mapping to change when new data becomes available. A solution strategy for online algorithm selection (β) defines how to choose the selection mapping, based on all data available so far (H): both the training data and the online data. This data consists of records {i, φ, a, p}, with i an instance, φ its feature values, a an algorithm, and p the observed performance. Algorithm 1 shows the general procedure for online algorithm selection. Algorithm 1 Online algorithm selection 1: Input: training data HT 2: Input: online strategy β 3: H = HT 4: for instance i do 5: λ = β(H) //Get selection map, based on all data 6: a = λ(i) //Make selection 7: Solve i with a, observing performance p 8: H = H ∪ {i, φ, a, p} //Add newly generated data A common approach to offline algorithm selection is to learn a regression model for each algorithm in the portfolio. These regression models predict the performance of the corresponding algorithm on an instance, based on the instance’s feature values. The algorithm with best predicted performance is then selected. These methods can easily take the online data into account, by updating the regression model of the selected algorithm after each online instance. This makes them a good candidate for an online strategy. A popular alternative is to use a classifier to directly predict the best algorithm for a new instance. However, such a method cannot be directly applied to online algorithm selection, because it cannot process the online data, which consists of the performance of only one algorithm for each instance. Based on such incomplete data, it is impossible to know which algorithm is best, which is a requirement for the Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17)