Systems that reason about actions, whether they do plan generation [1] or plan recognition [2] typically model the effects of actions that occur in a plan. Simple declarative schemata allow the specification of assertions to be added/deleted to model the primary effects of actions. Side-effects of actions are those that are conditional on properties of the state in which the action is taken. When representing actions which have side-effects, conventional wisdom suggests adopting a procedural representation for they allow detailed specification of side-effects. However the procedural representation hides this knowledge from other parts of the system, thereby hindering the system in reasoning about side-effects. We use a STRIPS like declarative schema for actions that has parameters, preconditions, assertional forms for goal and outcomes and investigate three methods of representing knowledge about side-effects and discuss how the system computes side-effects without running into severe combinatorics. The following discussion and examples deal with knowledge representation as implemented in the AIMDS system which forms the AI framework for the BELIEVER project. Examples Consider a normal input of the form "John walked from the office to the bus station" interpreted in a world model where "John is at the office" is true. The conclusions drawn include "John is at the bus station". This can be handled using an act schema with three variables P, FL and TL as shown below. (Each WALK act has (agent [a PERSON [refer: P]]) (fromloc [a LOCATION (refer: FL]]) (toloc [a LOCATION [refer: TL]]) (goal (PROPOSITION [P loc TL])) (precond (PROPOSITION [P loc FL)))) We have extended the interpreter to deal with some simple cases of partial act instance descriptions and incomplete world models. The incomplete description "John walked to the bus station" can be filled in using the world model, so that the system now can conclude "John walked from the office". Similarly, if in the world model "John's location is unknown" then from the normal input "John walked from the office to the bus station" the system concludes "John was at the office before walking to the bus station". Dealing with side-effects requires additional knowledge. For example, consider the world model "John is at the office; John is holding a package; The package is at the office". To update the world model properly, the location of the package must be changed to the same location as John. We explain three methods in which this knowledge about side-effects â€¦