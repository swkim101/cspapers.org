The quest for ever more powerful computers has bumped up hard against the limits imposed by nature such as speed of light and electrons. However, scientists and industry agree that there is still a great potential for further speed-up by distributing computations among many processors rather than a single one. This is apparent for problems that can easily be broken down into many independent parts such as those to be tackled in graphics, signal processing (which includes radar, speech and vision analysis), structural analysis, fluid-flow dynamics, particle physics, and many others. First experiences with the new breed of parallel computers justify this optimism. It is less obvious whether a multi-processor would bring a significant improvement in performance for problems such as inferencing. Finding a correct chain of inferences requires searching through a space of different possible chains, a problem known to be hard (NP-complete) and requiring exponential recources in worst cases according to our present knowledge. Therefore one might argue that one thousand processors would provide relatively little improvement over a single one in worst (exponential) cases. From a more practical point of view, experiments seem to indicate that the possibilities for exploiting parallelism in rule-based systems might be rather limited. There are more problems of detail arising in an attempt to parallelize inferencing. The different possible chains in the search space partially coincide in a way not known at compile time hence making it difficult to break the whole task down into many parts and distribute these in a well-balanced way. Also (but not only) because of this overlap it seems attractive to exploit the parallelism inherent in each of these chains. But at present it is not clear at all whether this really pays since it might cause too much overhead in communication and anyway might have only a marginal effect in view of the more severe problem of NP-completeness mentioned above. Some even put forward reasonable arguments to the effect that inferencing in practice is not needed at all. Part of it could be substituted by exploiting database techniques even in the presence of recursion. Or, machine reasoning could be founded on episodes from the past stored in a massively parallel memory rather than on rules and facts thus leading to a memory-based reasoning with a parallelism radically different from the one discussed above; with this remark we scratch on the current discussion about connectionism. Much of â€¦