Sterility restrictions in surgical settings make touch-less interaction an interesting solution for surgeons to interact directly with digital images. In this demo, we present a system for gesture-based interaction with medical images based on a wristband inertial sensor and capacitive floor sensors, allowing for hand and foot gesture input. Hand gesture commands have been designed for interacting with 3D and 2D medical images in two different displays, while foot gestures can enable, disable, and switch interaction between different systems. The gestures are recognized in real time with the help of a neural network classifier, which is based on a given training set and extracts different features of accelerometer and gyroscope. For displaying the medical images a simple image viewer for 2D images is used while 3D images are presented with the open-source software InVesalius.