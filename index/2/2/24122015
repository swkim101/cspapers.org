Robotic mapping and localization are two large areas in robotics research that focus on how robots know and navigate within an environment. The current methods used to complete these tasks are not extremely accurate due to errors that are compounded as the robot moves. Since robots are often used in situations where precise navigation is a necessity, there is a strong motivation for the mapping and localization processes to be as accurate as possible. This project hopes to reduce the accumulated error which occurs during the mapping and localization processes through the integration of a Kinect sensor, which provides both visual and depth data about objects in front of a mobile robot and a sonar sensor which provides depth information about objects on the sides of the robot. The Kinect's images and depth information will be used to form an occupancy grid map of the environment, while the sonar data will track the walls as the robot moves throughout the environment in order to assist in keeping track of both position and orientation of the robot. These two sensors will allow the robot to reduce the errors accumulated during localization and navigation within the map being created and in navigating the subsequently completed map. When the occupancy grid map is completed, the cells in it will be combined into a topological map, which will hold information about the rooms such as doorway locations. The topological map will then be used as the robot plans a path to its goal.