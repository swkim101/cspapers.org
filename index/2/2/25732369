This paper will present computer models of three robotic motion planning and learning systems which use a multi-sensory learning strategy for learning and control. In these systems machine vision input is used to plan and execute movements utilizing an algorithmic controller while at the same time neural networks learn the control of those motions using feedback provided by position and velocity sensors in the actuators. A specific advantage of this approach is that, in addition to the system leaming a more automatic behavior, it employs a computationally less costly sensory system more tightly coupled from perception to action.