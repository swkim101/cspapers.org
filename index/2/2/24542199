With the development of applications called "intelligent", one of the challenges of research on multimodality in ambient intelligence environments is the elaboration of architectural solutions that respond and adapt to different types of constraints in the human robotic interaction. These architectures must continually adapt to changes due to external disturbances or user actions. They are therefore subject to restrictions in use (in real time) when the robot interacts with the user and the environment. The main objective of this paper is to propose a model of adaptive software architecture, which allows the robot to use several modalities and make the fusion of the data to increase its interaction with the environment while considering the context. We also introduce fuzzy logic in the processing of data from input modalities. This multimodal software architecture that considers the context is modeled by colored, timed and stochastic Petri nets (CTSPN) simulated in CPNTools.