: Statistical Relational Learning (SRL) is an interdisciplinary research area that combines first­order logic and machine learning methods for probabilistic inference. Although many Natural Language Processing (NLP) tasks (including text classification, semantic parsing, information extraction, coreference resolution, and sentiment analysis) can be formulated as inference in a first­order logic, most probabilistic first­order logics are not efficient enough to be used for large­scale versions of these tasks. In this tutorial, we provide a gentle introduction to the theoretical foundation of probabilistic logics, as well as their applications in NLP. We describe recent advances in designing scalable probabilistic logics, with a special focus on ProPPR. Finally, we provide a hands­on demo about scalable probabilistic logic programming for solving practical NLP problems