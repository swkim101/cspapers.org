Generic control of wheel-on-leg robots on arbitrary uneven terrains is a challenging task due to the complexity of the robot dynamics, surface interactions, and environmental structures. This paper deals with the control of a wheel-on-leg robot with passive and active internal compliance that enables estimation of wheel-ground interaction forces. The proposed method is based on a continuous state space Q-learning approach that uses the contact forces estimates to learn, through trial and error, the appropriate control policy from a set of predefined behaviors. Without any prior knowledge of the ground geometry, the robot is able to react to unanticipated obstacles. The learned policy proves to be generic and allows the robot to negotiate complex obstacles that had not been considered during learning phase.