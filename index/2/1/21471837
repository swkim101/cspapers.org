It is well known that parameter optimization and dimension reduction strategies play an important role in improving the performance of clustering algorithms. Recently, Yang et at. (2011) proposed an interesting and effective local discriminant model and global integration (LDMGI) clustering algorithm for image databases. We observed this LDMGI approach suffers from the curse of dimensionality. We then show that the effectiveness of this approach could be substantially enhanced with parameter selection and dimensionality reduction approach. We thus experimentally observed the enhanced performance of LDMGI algorithm in terms of clustering accuracy (ACC) and normalized mutual information (NMI). In the first stage, the optimal values of the clustering parameters, nearest neighbours (k) and regularization parameter (Î») are computed. In the second stage, minimum Redundancy and maximum-Relevance (mRMR) technique is utilized to select discriminant image features. During simulation, mRMR based LDMGI model have given an overall 18.7% (ACC) and 11.8% (NMI) higher performance than LDMGI model.