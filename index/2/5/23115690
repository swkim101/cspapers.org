In this demonstration, a novel human-computer interaction device is proposed to realize finger touching for large display and mobile device control, without a touchscreen or a touch pad. In this method, interaction commands are input in a same way as traditional touchscreen and touchpad, which is convenient to develop applications for long-distance operation of display and mobile devices. An embedded module is designed to collect bone-conducted friction sound, acceleration and gyroscope sensor data, corresponding to the behavior and direction of interaction commands. For algorithm, modified MFCC and SVM are applied in sound processing and probability calculation.