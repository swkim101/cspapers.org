Recent years have witnessed the rapid development of machine learning in solving artiﬁcial intelligence (AI) tasks in many domains, including translation, speech, image, etc. Within these domains, AI tasks are usually not independent. As a specific type of relationship, structural duality does exist between many pairs of AI tasks, such as translation from one language to another vs. its opposite direction, speech recognition vs. speech syntheti-zation, image classiﬁcation vs. image generation, etc. The importance of such duality has been mag-niﬁed by some recent studies, which revealed that it can boost the learning of two tasks in the dual form. However, there has been little investigation on how to leverage this invaluable relationship into the inference stage of AI tasks. In this paper, we propose a general framework of dual inference which can take advantage of both existing models from two dual tasks, without re-training, to conduct inference for one individual task. Empirical studies on three pairs of speciﬁc dual tasks, including machine translation, sentiment analysis, and image processing have illustrated that dual inference can signiﬁcantly improve the performance of each of individual tasks.