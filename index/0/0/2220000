Written exams are a common form of assessment in introductory programming courses. Creating exam questions is normally the responsibility of the course instructor, however the process of authoring such questions may be a useful learning activity in itself. We explored this idea with a randomized controlled experiment (n > 700) in which a group of first-year programming students generated practice questions prior to an exam. Even though all questions were available to every student in the course for practice, the group that generated the questions performed significantly better on the exam. The effects were most pronounced when students answered exam questions on topics that were targeted by questions they had generated. We suggest that some existing tools for computer science education may benefit from incorporating related activities.