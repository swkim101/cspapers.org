In this work, we consider the problems of testing whether adistribution over (0,1<sup>n</sup>) is <i>k</i>-wise (resp. (ε,k)-wise) independentusing samples drawn from that distribution.
 For the problem of distinguishing <i>k</i>-wise independent distributions from those that are δ-far from <i>k</i>-wise independence in statistical distance, we upper bound the number ofrequired samples by Õ(n<sup>k</sup>/δ<sup>2</sup>) and lower bound it by Ω(n<sup>k-1/2</sup>/δ) (these bounds hold for constant<i>k</i>, and essentially the same bounds hold for general <i>k</i>). Toachieve these bounds, we use Fourier analysis to relate adistribution's distance from <i>k</i>-wise independence to its biases, a measure of the parity imbalance it induces on a setof variables. The relationships we derive are tighter than previouslyknown, and may be of independent interest.
 To distinguish (ε,k)-wise independent distributions from thosethat are δ-far from (ε,k)-wise independence in statistical distance, we upper bound thenumber of required samples by O(k log n / δ<sup>2</sup>ε<sup>2</sup>) and lower bound it by Ω(√ k log n / 2<sup>k</sup>(ε+δ)√ log 1/2<sup>k</sup>(ε+δ)). Although these bounds are anexponential improvement (in terms of <i>n</i> and <i>k</i>) over thecorresponding bounds for testing <i>k</i>-wise independence, we give evidence thatthe time complexity of testing (ε,k)-wise independence isunlikely to be poly(n,1/ε,1/δ) for k=Θ(log n),since this would disprove a plausible conjecture concerning the hardness offinding hidden cliques in random graphs. Under the conjecture, ourresult implies that for, say, k = log n and ε = 1 / n<sup>0.99</sup>,there is a set of (ε,k)-wise independent distributions, and a set of distributions at distance δ=1/n<sup>0.51</sup> from (ε,k)-wiseindependence, which are indistinguishable by polynomial time algorithms.