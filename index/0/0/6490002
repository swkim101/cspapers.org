Many servers, such as web and database servers, receive a continual stream of requests. These requests may require an amount of processing time that varies over several orders of magnitude. The servers should schedule these requests to provide the “best” and ‘fairest” po5 sible service to users. However, it is difficult to quantify this objective. In this paper, we isolate and study the problem of scheduling a continuous stream of requests of varying sizes. More precisely, assume a request or job j has arrival time oj and requires processing time tj. We aim to schedule these jobs with a guaranteed quality of service (QoS). QoS is interpreted in many ways (e.g., throughput, avoiding jitter or delay, etc.). Here we adopt the widely-accepted requirement that the schedule be responsive to each job and avoid starvation of any job [ 11. In this paper, we propose two novel scheduling metrics, namely, maz-stretch and mar-flow. These metrics gauge the responsiveness of the scheduler to each job. Surprisingly, despite the extensive research on scheduling algorithms in the past few decades, these metrics seem to be new. We initiate the study of optimizing these metrics under varying circumstances (offline/online, preemptive/nonpreemptive, etc.). We prove positive and negative theoretical results. We also report experiments with several scheduling heuristics on real data sets (HTTP server log requests at U.C. Berkeley). We present our observations on the overall “fairness” of various metrics and scheduling strategies. In what follows, we describe our metrics and results in detail.