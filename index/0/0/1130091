Numerous logics have been developed for reasoning about inconsistency which differ in (i) the logic to which they apply, and (ii) the criteria used to draw inferences. In this paper, we propose a general framework for reasoning about inconsistency in a wide variety of logics including ones for which inconsistency resolution methods have not yet been studied (e.g. various temporal and epistemic logics). We start with Tarski and Scott’s axiomatization of logics, but drop their monotonicity requirements that we believe are too strong for AI. For such a logic L, we deﬁne the concept of an option. Options are sets of formulas in L that are closed and consistent according to the notion of consequence and consistency in L. We show that by deﬁning an appropriate preference relation on options, we can capture several existing works such as Brewka’s subtheories. We also provide algorithms to compute most preferred options.