The connection between vision and natural language systems in AI research relies on what is often called reference semantics. In the situation of a radio reporter for soccer games, an utterance must be perceptually anchored and coherent in order to be understandable to a listener not able to see the scene. Accordingly, the speaker must be able to anticipate the listeners' understanding by means of mental images. In this paper, we demonstrate the comparison of mental images and visual perception on the level of spatial relations and show how to employ the results for cooperatively filling optional deep cases, and for controlling the use of underspecific definite descriptions.