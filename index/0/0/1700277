To deal with inference and reasoning problems, Gaussian process has been considered as a promising tool due to the robustness and flexibility features. Especially, solving the regression and classification, Gaussian process coupling with Bayesian learning is one of the most appropriate supervised learning approaches in terms of accuracy and tractability. Unfortunately, this combination tolerates high complexity from computation and data storage. Obviously, this limitation makes Gaussian process ill-equipped to deal with the systems requiring fast response time. In this paper, the research focuses on analyzing the performance issue of Gaussian process, developing a method to reduce the complexity and implementing to predict CPU utilization, which is used as a factor to predict the status of computing node. Subsequently, a migration mechanism is applied so as to migrate the system-level processes between CPU cores and turn off the idle ones in order to save the energy while still maintaining the performance.