Navigating through unknown outdoor environments requires a robot to be able to see and model the far field terrain. In recent years this problem of seeing beyond reliable stereo readings into the far field has gained attention. Many proposed solutions involve using near field obstacle and ground plane regions labeled using stereo, to learn models which classify far field image regions. In this work we offer an alternative which exploits coherent image regions as determined by image segmentation to propagate obstacle and ground labels from the near and mid field to the image far field. Rather than relying on local features to classify individual pixels we model and compare appearance across the whole segment. New labels are determined by proximity in both image space and appearance space. Since both traversable and non-traversable surfaces can vary in appearance across the image, our approach has the advantage that each labeled segment acts as a distinct appearance model, which allows us to label similar neighbours. We evaluate our system using a publicly available dataset and compare its performance to a typical learning-based near-to-far labeling scheme.