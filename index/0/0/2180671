Image retrieval is a common problem in many computer vision applications and the literature abounds with techniques with impressive retrieval accuracies. Several of these techniques use probability distributions to represent the "objects" they intend to retrieve. We present a novel approach to search such collections of distributions efficiently. Like many standard data structures, our method uses an "average" to represent a large set (Le., cluster) of objects, thus allowing the search to disregard an unpromising subset with only one comparison to its average. Our contribution lies in choosing the average: Inspired by information theory, we choose a representative that is optimally "close" in a minimax sense to all members of its set when measured using the Kullback-Liebler (KL) divergence. We present a texture retrieval system and test it on the CUReT database, measuring accuracy and efficiency. We find that using the KL-center yields speed ups of more than a factor of three over an exhaustive search while guaranteeing identical accuracy. The KL-center also out-performs other commonly used representatives such as the arithmetic mean. Although we present results only in texture retrieval, our approach will likely aid image and shape retrieval as well.