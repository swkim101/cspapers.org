A new human-machine interface is introduced for "hands-free" tele-operation of mobile robots. This interface consists of tracking tongue movement by monitoring changes in airflow that occur in the ear canal. Tongue movements within the human oral cavity create unique, subtle pressure signals in the ear that can be processed to produce commands signals in response to that movement. Once recognized, said movements can in turn be used in for robotic tele-operation. The complete strategy is tested on 4 tongue actions: touching the tongue to the left and right corners of the mouth, and to the top and bottom center of the mouth. Through extensive experiments, it is shown that the pressure signals due to tongue movements are distinct and can be detected with over 97% accuracy. A case study to control the Whegs II robotic platform has specifically been investigated. Based on simulation results, it is concluded that this unique strategy will make hands-free robotic tele-operation a practical reality.