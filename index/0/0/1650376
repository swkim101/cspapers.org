We propose a novel real-time algorithm for estimating the local scale correction of a monocular SLAM system, to obtain a correctly scaled version of the 3D map and of the camera trajectory. Within a Bayesian framework, it integrates observations from a deep-learning based generic object detector and landmarks from the map whose projection lie inside a detection region, to produce scale correction estimates from single frames. For each observation, a prior distribution on the height of the detected object class is used to define the observation's likelihood. Due to the scale drift inherent to monocular SLAM systems, we also incorporate a rough model on the dynamics of scale drift. Quantitative evaluations are presented on the KITTI dataset, and compared with different approaches. The results show a superior performance of our proposal in terms of relative translational error when compared to other monocular systems based on object detection.