In this paper, we present a solution to the Simultaneous Localization and Mapping problem by combining a novel 3D in-air sonar sensor with techniques for estimating the egomotion of a mobile platform (called acoustic flow odometry) and a bio-inspired mapping module (called BatSLAM). This combination eliminates the need for odometric information originating from the robot's motor controller, enabling applications where that information is difficult to obtain, e.g. many electric wheelchairs. The proposed method exploits the programmable spatial sampling capabilities of the 3D sonar system to derive from the same set of received echo signals both an accurate representation of reflectors in the horizontal plane (2D energyscape) and a more coarse representation of reflectors in the frontal hemisphere (3D energyyscape). Using a mapping experiment we demonstrate that the motion estimates originating from the acoustic flow module combined with the coarse frontal hemisphere data provide sufficient information for the mapping module to reconstruct the robot's trajectory.