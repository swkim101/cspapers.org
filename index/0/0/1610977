During the past decade, information technology has evolved to store and retrieve multimedia data (e.g., audio, video). Multimedia information systems utilize a variety of human senses to provide an effective means of conveying information. Already, these systems play a major role in educational applications, entertainment technology, and library information systems. A challenging task when implementing these systems is to support a continuous retrieval of an object at the bandwidth required by its media type. This is challenging because certain media types, in particular video, require very high bandwidths. For example, the bandwidth required by NTSC (the US standard established by the National Television System Committee) for "network-quality" video is about 45 megabits per second (mbps). Recommendation 601 of the International Radio Consultative Committee (CCIR) calls for a 216 mbps bandwidth for video objects. A video object based on the HDTV (High Definition Television) quality images requires approximately a 700 mbps bandwidth. Compare these bandwidth requirements with the typical 10 mbps bandwidth of a magnetic disk drive, which is not expected to increase significantly in the near future. Currently, there are several ways to support continuous display of these objects: 1) sacrifice the quality of the data by using either a lossy compression technique or a low resolution device, 2) employ the aggregate bandwidth of several disk drives by declustering an object across multiple disks [2], and 3) use a combination of these two techniques. Lossy compression techniques encode data into a form that consumes a relatively small amount of space, however, when the data is decoded, it yields a representation similar to the original (some loss of data). While it is effective, there are applications that cannot tolerate loss of data. As an example consider the video signals collected from space. This data may not be compressed using a lossy compression technique. Otherwise, the scientists who later uncompress and analyze the data run the risk of either observing phenomena that may not exist due to a slight change in data or miss important observations due to some loss of data.