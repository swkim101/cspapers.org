In this paper, we first provide a new theoretical understanding of the Evidence Pre-propagated Importance Sampling algorithm (EPIS-BN) (Yuan & Druzdzel 2003; 2006b) and show that its importance function minimizes the KL-divergence between the function itself and the exact posterior probability distribution in Polytrees. We then generalize the method to deal with inference in general hybrid Bayesian networks consisting of deterministic equations and arbitrary probability distributions. Using a novel technique called soft arc reversal, the new algorithm can also handle evidential reasoning with observed deterministic variables.