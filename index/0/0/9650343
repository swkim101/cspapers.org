Learning algorithms from the fields of artificial neural networks and machine learning, typically, do not take any costs into account or allow only costs depending on the classes of the examples that are used for learning. As an extension of class dependent costs, we consider costs that are example, i.e. feature and class dependent. We derive a cost-sensitive perceptron learning rule for nonseparable classes, that can be extended to multi-modal classes (DIPOL). We also derive aa approach for including example dependent costs into an arbitrary cost-insensitive learning algorithm by sampling according to modified probability distributions.