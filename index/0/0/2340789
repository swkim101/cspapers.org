We introduce a generic model of emergence of musical categories during the listening process. The model is based on a preprocessing and a categorization module. Preprocessing results in a perceptually plausible representation of music events extracted from audio or symbolic input. The categorization module lets a taxonomy of musical entities emerge according to a cognitively plausible online learning paradigm. We show the advantages of using a conceptual clustering method in the musical domain. The system extracts multi-level hierarchies and can be tuned to clustering at various resolutions. The potential of the model is exemplified by exposing it to three different datasets resulting in musical categories of scales, motives, and harmonies consistent with music theory.