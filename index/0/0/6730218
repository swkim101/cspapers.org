Human answer patterns in psychological reasoning experiments systematically deviate from predictions of classical logic. When interactions between any artificial reasoning system and humans are necessary this difference can be useful in some cases and lead to problems in other cases. Hence, other approaches than classical logic might be better suited to capture human inference processes. Evaluations are rare of how good such other approaches, e.g., non-monotonic logics, can explain psychological findings. In this article we consider the so-called Suppression Task, a core example in cognitive science about human reasoning that demonstrates that some additional information can lead to the suppression of simple inferences like the modus ponens. The psychological findings for this task have often been replicated and demonstrate a key-effect of human inferences. We analyze inferences of selected formal approaches and compare them by their capacity to cover human inference observed in the Suppression Task. A discussion on formal properties of successful theories conclude the paper.