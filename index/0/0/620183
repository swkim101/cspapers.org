In this theoretical contribution we provide mathematical proof that two of the most important classes of network learning - correlation-based differential Heb-bian learning and reward-based temporal difference learning - are asymptotically equivalent when timing the learning with a local modulatory signal. This opens the opportunity to consistently reformulate most of the abstract reinforcement learning framework from a correlation based perspective that is more closely related to the biophysics of neurons.