Within a simple test-bed, application of feed-forward neurocontrol for short-term planning of robot trajectories in a dynamic environment is studied. The action network is embedded in a sensory-motoric system architecture that contains a separate world model. It is continuously fed with short-term predicted spatio-temporal obstacle trajectories, and receives robot state feedback. The action net allows for external switching between alternative planning tasks. It generates goal-directed motor actions - subject to the robot's kinematic and dynamic constraints - such that collisions with moving obstacles are avoided. Using supervised learning, we distribute examples of the optimal planner mapping over a structure-level adapted parsimonious higher order network. The training database is generated by a Dynamic Programming algorithm. Extensive simulations reveal, that the local planner mapping is highly nonlinear, but can be effectively and sparsely represented by the chosen powerful net model. Excellent generalization occurs for unseen obstacle configurations. We also discuss the limitations of feed-forward neurocontrol for growing planning horizons.