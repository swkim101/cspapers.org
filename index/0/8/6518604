We envision augmented-reality applications in which an individual looks at other people through her camera-enabled glass (e.g., Google Glass) and obtains information about them. While face recognition would be one approach to this problem, we believe that it may not be always possible to see a person’s face. Our technique is complementary to face recognition, and exploits the intuition that human motion patterns and clothing colors can together encode several bits of information. Treating this information as a “temporary fingerprint”, it may be feasible to recognize an individual with reasonable consistency, while allowing her to turn off the fingerprint when privacy is of concern. We develop InSight, a system implemented using Android Galaxy smartphones and videos taken from Google Glasses. Results from real world experiments involving up to 21 people show that 8 seconds of their motion patterns together with their clothing colors can discriminate them. These results suggest that face recognition may not be the only option for recognizing humans; human diversity lends itself to sensing and could also serve as an effective identifier.