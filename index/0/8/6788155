This paper summarizes recent advances in the application of multiagent coordination algorithms to air traffic flow management. Indeed, air traffic flow management is one of the fundamental challenges facing the Federal Aviation Administration (FAA) today. This problem is particularly complex as it requires the integration and/or coordination of many factors including: new data (e.g., changing weather info), potentially conflicting priorities (e.g., different airlines), limited resources (e.g., air traffic controllers) and very heavy traffic volume (e.g., over 40,000 flights over the US airspace). 
 
The multiagent approach assigns an agent to a navigational fix (a specific location in 2D space) and uses three separate actions to control the airspace: setting the separation between airplanes, setting ground holds that delay aircraft departures and rerouting aircraft. Agents then use reinforcement learning to learn the best set of actions. Results based on FACET (a commercial simulator) show that agents receiving personalized rewards reduce congestion by up to 80% over agents receiving a global reward and by up to 85% over a current industry approach (Monte Carlo estimation). These results show that with proper selection of agents, their actions and their reward structures, multiagent coordination algorithms can be successfully applied to complex real world domains.