This paper addresses the coordination of a decentralised robot team for target tracking. In many approaches to coordination, robots jointly plan their actions through negotiation, which incurs communication costs. Previous work examined the use of learning to reduce the need for negotiations in a network of static robots. Robots incrementally learn how each team member impacts the team utility and can thus make coordinated, team-wide decisions. In this paper, we extend the concept of learning utility models to a team of mobile robots. We also propose a mechanism by which robots switch between negotiating and using the learnt model. This mechanism reduces the communications required for coordination whilst maintaining the same level of tracking performance. Hardware experiments demonstrated that our approach resulted in coordinated behaviours while only negotiating intermittently. Simulation results show that our approach reduced the data communicated for negotiations by up to 70%, without making a statistically significant impact on the tracking performance.