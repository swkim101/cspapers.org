In this paper we investigate the integration of object detection algorithms with eye-tracking data. The emerging technology of lightweight mobile eye-trackers enables realistic in-the-wild user experience experiments. Unfortunately, mobile eye-trackers generate a large amount of video data, which up to now requires manual analysis. This time-consuming and repetitive task renders processing large datasets economically infeasible. Our main contribution is the use of object detection algorithms to perform this analysis task automatically. We compare several object detection algorithms with regard to both speed and accuracy. To prove their functionality, we have recorded an eye-tracker shopping experiment and processed the data using object detection techniques.