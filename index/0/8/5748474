Decision-theoretic reasoning and planning algorithms are increasingly being used for mobile robot navigation, due to the signi cant uncertainty accompanying the robots' perception and action. Such algorithms require detailed probabilistic models of the environment of the robot and it is very desirable to automate the process of compiling such models by means of autonomous learning algorithms. This paper compares experimentally four learning methods in combination with four heuristic decision-theoretic planning algorithms for the purpose of learning a probabilistic model of the environment of a mobile robot and using this model for navigation. One of the learning methods is novel and presents an approach to probabilistic model learning based on merging states by clustering trajectories of observation/action pairs. The strengths and weaknesses of each combination of learning and planning method is explored in a sample environment for mobile robot navigation.