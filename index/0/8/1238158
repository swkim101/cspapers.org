Many elderly and disabled people today experience difficulties when maneuvering an electric wheelchair. In order to help these people, several robotic assistance platforms have been devised in the past. These platforms' architectures usually consist of separate assistance modes that each realise a specific navigation behaviour, such as "avoid-obstacles", or "drive-through-door". In most cases, heuristic rules are used to decide automatically which assistance mode should be selected in each time step. These decision rules are often hard coded and therefore not very adaptable to different user's actual plans do not correspond to the assistive system's behaviour. Moreover, navigation algorithms are used that take the wheelchair's kinematic and dynamic constraints only approximately into account. Consequently, these robotic wheelchairs may and do fail in executing the very same maneuvers with which elderly and disabled people have problems. In contrast with previous approaches, this paper presents a user-centered architecture for shared wheelchair control. The framework continuously estimates the user's intention explicitly before trying to assist him or her. The actual navigation assistance is performed by a fine motion planner that takes the kinematic and dynamic constraints into account. The paper presents experimental results and an evaluation of the architecture.