Consider a sequence <i>S</i> of <i>n</i> symbols drawn from an alphabet <i>A</i> = {1, 2,. . .,σ}, stored as a binary string of <i>n</i>log σ bits. A <i>succinct</i> data structure on <i>S</i> supports a given set of primitive operations on <i>S</i> using just <i>f (n)</i> = <i>o</i>(<i>n</i> log σ) extra bits. We present a technique for transforming succinct data structures (which do not change the binary content of <i>S</i>) into <i>compressed</i> data structures using <i>nH</i><inf><i>k</i></inf> + <i>f(n)</i> + <i>O</i>(<i>n</i> log σ + log log<inf>σ</inf> <i>n</i> + <i>k</i>)/ log<inf>σ</inf> <i>n</i>) bits of space, where <i>H</i><inf><i>k</i></inf> ≤ log σ is the <i>k</i>th-order empirical entropy of <i>S</i>. When <i>k</i> + log σ = o(log <i>n</i>), we improve the space complexity of the succinct data structure from <i>n</i> log σ + <i>o</i>(<i>n</i> log σ) to <i>n</i> <i>H</i><inf><i>k</i></inf> + <i>o</i>(<i>n</i>log σ) bits by keeping <i>S</i> in compressed format, so that any substring of <i>O</i>(log σ <i>n</i>) symbols in <i>S</i> (i.e. <i>O</i>(log <i>n</i>) bits) can be decoded on the fly in constant time. Thus, the time complexity of the supported operations does not change asymptotically. Namely, if an operation takes <i>t</i>(<i>n</i>) time in the succinct data structure, it requires <i>O</i>(<i>t</i>(<i>n</i>)) time in the resulting compressed data structure. Using this simple approach we improve the space complexity of some of the best known results on succinct data structures We extend our results to handle another definition of entropy.