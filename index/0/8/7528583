Real time computer vision techniques, like OCR, on mobile platforms is opening new opportunities [4]. Image based locationing has traditionally focused on identifying well-known landmarks, like Eiffel Tower, in an image captured using a smartphone. However consider a user lost in the sprawling bazaars of a big city where a well-known landmark may be difficult to spot. We propose a technique where texts appearing in names of shops, billboards, and road signs act as pseudo-markers to identify the location. Collection of different signs, which are keywords for the area, is often unique. For example, in Figure 1, the presence of “Indian Home Industries” and “Jain Gift House” together can be unique to an area. The texts in the image clicked by the user are extracted from the image to create a location signature. The signature is matched against a repository of signatures. The repository of signatures is generated using geo-tagged images from online sources, like Flickr and Pinterest. Cities with CCTV or webcams, such as in Seoul or Singapore, can also feed images of different areas with geo-tag. The database of well-known signatures are populated by analyzing these pictures. Unlike previous work on image based matching [1, 2], we are using hints embedded in the image. The cost of querying the location is minimized as few text strings need to be uploaded. Response time to the query will be faster as text matching may yield response quicker than image matching.