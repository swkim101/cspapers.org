DNF systems divide the input space into decision surfaces, defined by conjunctions of conditions based on attribute-value pairs. This means that the decision surfaces are orthogonal to the axis of the tested attribute and parallel to all the other axes. In this paper, we present the system Ltree, that is able to define decision surfaces both orthogonal and oblique to the axes defined by the attributes of the input space. This is done by combining a decision tree with a linear discriminant by means of constructive induction. At each decision node Ltree defines a new instance space by the insertion of new attributes. Those are projections of the instances that fall at this node over the hyper-planes given by a linear discriminant function. This new instance space propagates downwards through the tree. Tests based on those new attributes are oblique in the input space. We have carried out experiments on sixteen benchmark datasets and compared our system with other well known decision tree systems (oblique and orthogonal) like C4.5, Oc1, and LMDT. From these experiments, we claim that our system has advantages concerning accuracy and tree size at statistically significant confidence levels.