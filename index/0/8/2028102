A method for probabilistic registration of stereo vision and sonar sensor data within 2.5D maps is presented. Both sensor modalities have characteristics which can limit available localisation information. Resulting localisation estimates can be inaccurate and can also vary widely within and between samples. Such errors are not so prohibitive in pure localisation problems, but prove catastrophic in SLAM applications. Fusion of vision and sonar data while considering height of objects in the environment is implemented to reduce such noise by taking advantage of localisation cues from both modalities. In addition, an approximation of the variance within localisation estimates is used to form a measure of localisation confidence. This measure of belief can inform the mapping task so sensor data sampled from uncertain robot poses can be integrated into the map with a reduced probability. This process not only results in improved maps, but subsequently in more accurate localisation estimates.