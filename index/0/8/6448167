Texts and dialogues often express information indirectly. For instance, speakers’ answers to yes / no questions do not always straightforwardly convey a ‘yes’ or ‘no’ answer. The intended reply is clear in some cases ( Was it good? It was great! ) but uncertain in others ( Was it acceptable? It was unprecedented. ). In this paper, we present methods for interpreting the answers to questions like these which involve scalar modiﬁers. We show how to ground scalar modiﬁer meaning based on data collected from the Web. We learn scales between modiﬁers and infer the extent to which a given answer conveys ‘yes’ or ‘no’. To evaluate the methods, we collected examples of question–answer pairs involving scalar modiﬁers from CNN transcripts and the Dialog Act corpus and use response distributions from Mechanical Turk workers to assess the degree to which each answer conveys ‘yes’ or ‘no’. Our experimental results closely match the Turkers’ response data, demonstrating that meanings can be learned from Web data and that such meanings can drive pragmatic inference.