Our research goal is to realize a robust navigation in indoor and outdoor environment for autonomous vehicle. An omnidirectional vehicle driven by four Mecanum wheels was chosen for our research platform. Mecanum wheel has 16 tilted rollers (45 degrees against the direction of wheel rotation) around the wheel, so the vehicle moves omnidirectionally by controlling these wheels independently. However, it has a disadvantage in odometry because of wheel slippage. Particularly, when the robot moves laterally, same wheels' rotations generate different traveling distance depending on friction of ground surface. To cope with the problem, we estimate robot's position by detecting optical flow of ground image using vision sensor (visual dead-reckoning). The estimation method is inaccurate comparing with odometry, but it is independent from friction of ground surface. Therefore, the estimated vehicle position can be improved by fusing odometry and visual dead-reckoning based on maximum likelihood technique. This paper describes an odometry method and a visual dead-reckoning method for omnidirectional vehicle, and fusion technique to improve the estimated position of the vehicle. Finally, experimental results support above technique.