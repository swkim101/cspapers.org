This paper examines burstiness and jitter in real-time communications. In this paper, we make so assumptions about the arrival patterns of the incoming traffic but characterize the traffic with two parameters. We assume that the synchronization process is adaptive, so that the traffic stream can be divided into smaller synchronization units. The jitter is defined with the delay experienced by the first packet in a synchronization unit as the target delay. We present the results on the relationship between burstiness and jitter, and on the upper bounds of burstiness and jitter.