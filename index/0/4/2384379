Many NLP tasks have at their core a subtask of extracting the dependencies---who did what to whom---from natural language sentences. This task can be understood as the inverse of the problem solved in different ways by diverse human languages, namely, how to indicate the relationship between different parts of a sentence. Understanding how languages solve the problem can be extremely useful in both feature design and error analysis in the application of machine learning to NLP. Likewise, understanding cross-linguistic variation can be important for the design of MT systems and other multilingual applications. The purpose of this tutorial is to present in a succinct and accessible fashion information about the structure of human languages that can be useful in creating more linguistically sophisticated, more language independent, and thus more successful NLP systems. 
 
While many kinds of linguistic structure can be relevant to different NLP tasks, the focus of this tutorial will be on morphosyntax. The tutorial will take an explicitly typological perspective as an understanding of cross-linguistic variation can facilitate the design of more portable (language-independent) NLP systems. In order to help participants retain the information better, the tutorial will be structured interactively. I will ask participants for examples of tasks and data sets they work with, and then as a group we will brainstorm ways in which each of the linguistic properties discussed can related to feature design and/or error analysis for those tasks.