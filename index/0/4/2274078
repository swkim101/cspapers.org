DTGolog, a decision-theoretic agent programming language based on the situation calculus, was proposed to ease some of the computational difficulties associated with Markov Decision Processes (MDPs) by using natural ordering constraints on execution of actions. Using DTGolog, domain specific constraints on a set of policies can be expressed in a high-level program to reduce significantly computations required to find a policy optimal in this set. We explore whether the DTGolog framework can be used to evaluate different designs of a decision making agent in a large real-world domain. Each design is understood as combination of a template (expressed as a Golog program) for available policies and a reward function. To evaluate and compare alternative designs we estimate the probability of goal satisfaction for each design. As a domain, we choose the London Ambulance Service (LAS) case study that is well known in software engineering, but remains unknown in AI. We demonstrate that DTGolog can be applied successfully to quantitative evaluation of alternative designs in terms of their ability to satisfy a system goal with a high probability. We provide a detailed axiomatization of the domain in the temporal situation calculus with stochastic actions. The main advantage of this representation is that neither actions, nor states require explicit enumeration. We do an experimental analysis using an on-line implementation of DTGolog coupled with a simulator that models real time actions of many external agents. Introduction and Motivation There is a significant amount of work done in AI related to planning under uncertainty when a certain high level goal must be satisfied with a high probability (Hanks & McDermott 1994; Kushmerick, Hanks, & Weld 1995; Haddawy, Doan, & Goodwin 1995; Boutilier, Dean, & Hanks 1999; Majercik & Littman 2003; Madani, Hanks, & Condon 2003; Younes et al. 2005). Most of the proposed approaches are related to solving a decision-theoretic planning problem in relatively small domains (with less than 10 states). However, there are many practical domains where the task of designing a decision making agent (that guarantees goal satisfaction with a sufficiently high probability) is difficult due to a very large number of the state features and (ground) actions with uncertain effects. In these domains, the main ∗A preliminary short version of this paper has been accepted (with another title) as a poster by the 17th European Conference on AI, Riva del Garda, Italy (Aug 28th Sept 1st, 2006) and will be also published in the proceedings of the ECAI06 W/Sh on Planning, Learning and Monitoring with Uncertainty and Dynamic Worlds. problem is that state of the art planners cannot scale up to compute (or approximate) an optimal policy due to extremely large size of the state space. Even the task of computing the value of a single policy can be prohibitively difficult in these domains. The second common problem is that in some domains the goal of interest is characterized in terms of quality of an on-going process driven by external agents. To deal with the first problem (scalability), one can try to use a logical representation that avoids explicit state and action enumeration. In addition, one can try to elaborate alternative designs of a decision making agent by goal-means analysis, e.g., using goal regression, a mechanism well studied in AI (Waldinger 1977) (see also (Manna & Waldinger 1987)). By careful refining a goal that must be (at least partially) satisfied into sub-goals, and then by identifying subtasks to solve and primitive actions that must be executed to solve these sub-tasks, it is possible to ease to some degree the computational burden of designing such an agent. Indeed, a gradual refinement process can identify useful sequences, loops, conditional or recursive structures of actions that provide together important constraints on the set of policies that need to be considered, and as a consequence, significantly reduce the number of potential policies that ever need to be analyzed. One can imagine also that such analysis can identify where search between alternative actions must concentrate: this can be indicated by nondeterministic choices between actions. In realistic domains, this refinement process can lead to different designs depending on how stakeholder goals will be captured in this process (i.e., how they will be modeled using reward functions) and depending on the degree of nondeterminism. Because a variety of designs will need precise evaluation and comparison, the problem of designing a decision making agent can be reduced to quantitative evaluation of those different designs of an agent which have been elaborated during the goals-means refinement process. To deal with the second problem (representation of an ongoing interaction with external agents), one can build a simulator of exogenous actions and evaluate all identified alternative designs with respect to the same simulator. We discuss an expressive framework that provides a tool for reasoning about different designs. This framework, a decision-theoretic extension of Golog (DTGolog), was first introduced in the context of designing efficient controllers for mobile robots (Boutilier et al. 2000; Soutchanski 2001). Later, it was extended to the multi-person games (Finzi & Lukasiewicz 2004), was successfully adapted to program robots playing soccer (Ferrein, Fritz, & Lakemeyer 2005), and was also extended with preferences to personalize Semantic Web services (Fritz & McIlraith 2006). DTGolog is somewhat similar in spirit to Hierarchical Task Network (HTN), but relies on problem-specific search control knowledge expressed as Golog programs. In addition, HTN plans can be encoded in generalized form as Golog programs, and consequently, one can build domain-specific (but task independent) Golog programs similar to HTN “methods” (taskdecomposition templates) (Sirin et al. 2004). All previous approaches applied DTGolog to the task of computing a policy in a finite horizon decision-theoretic planning problem. To the best of our knowledge, there were no attempts to use the DTGolog framework as a tool for quantitative evaluation of alternative designs of a decision making agent functioning in a large-scale domain characterized by on-going interaction with many external agents. DTGolog is a natural choice for this type of problems because domain specific constraints elaborated during the refinement process can be easily expressed in Golog. Golog provides all standard programming constructs as well as several nondeterministic choice constructs that can be used to specify alternative decisions to be resolved at the moment of decision making. Goals of stakeholders can be captured using rewards functions, but because mapping of qualitative goals of many agents to quantitative rewards is not unique and can lead to several reward functions, the decision maker is faced with several different designs that represent goals of stakeholders differently. The semantics of DTGolog (based on directed value iteration) guarantees that the nondeterministic choices (if any), mentioned in a program, will be resolved to compute an optimal policy (optimal in the set of all policies that are specified by a Golog program). We would like to do extensive analysis of applicability of DTGolog to evaluation of designs using a real case study (each design is represented as a combination of a Golog program and a reward function). In particular, we explore a well-known case study London Ambulance Service Computer Aided Dispatch System (LAS-CAD) that received a significant attention in the software engineering literature, but remains unknown to the AI community (The Communications Directorate 1993; Kramer & Wolf 1996; Letier & van Lamsweerde 2000; 2004). It is an excellent example of a problem with probabilistic goals. This case study comes from an investigation into a software development project that failed in October 1992 with dramatic consequences. We suggest this case study as a grand challenge for research on planning under uncertainty. We try to keep our presentation as generic as possible to indicate how our modeling framework can be applied or extended to other decision-making environments. In particular, we clearly show the main features of DTGolog model that can be applied to other domains as well (Reiter 2001; Soutchanski 2003): actions, fluents, precondition axioms, successor-state axioms, initial database, transition probabilities, rewards, Golog procedures for expressing natural constraints on decision making. We illustrate all these main features of the specification framework using the case study. The main contributions of our paper are the following. First, we developed an extensive logical formalization of a non-trivial domain. Second, we demonstrated that DTGolog is well suited to the task of evaluation of alternative designs of a decision making agent. Third, we did experimental analysis of three different designs of a decision making agent using the same simulator for a fair comparison. The methodology for quantitative evaluation of designs (in terms of probability of goal satisfaction) has been proposed in (Letier & van Lamsweerde 2004), but it is not based on MDPs and it has never been implemented. All the other previous work in requirements engineering related to the LAS case study, approached this case study in qualitative terms only(Kramer & Wolf 1996; Wang & Lesperance 2001; You 2003).