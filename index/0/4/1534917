Statistical shape-and-texture appearance models employ image metamorphosis to form a rich, compact representation of object appearance. They achieve their efficiency by decomposing appearance into simpler shape-and-texture representations. In general, the shape and texture of an object can vary nonlinearly and in this case the conventional shape-and-texture mappings using principle component analysis (PCA) may poorly approximate the true space. In this paper we propose two nonlinear techniques for modelling shape-and-texture appearance manifolds. Our first method uses a mixture of Gaussians in image space to separate the different parts of the shape and texture spaces. A linear shape-and-texture model is defined at each component to form the overall model. Our second approach employs a nearest-neighbor method to find a local set of shapes and images that can be morphed to explain a new input. We test each approach using a speaking-mouth video sequence and compare both approaches to a conventional active appearance model (AAM).