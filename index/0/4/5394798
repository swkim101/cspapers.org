Recent research on multiprocessor interconnection networks has primarily focussed on wormhole switching, virtual channel flow control and routing algorithms. These architectural features are aimed at enhancing the network performance by reducing the network latency, which in turn should improve the overall system performance. Many research results support this design philosophy by claiming significant reduction in average message latency. However, these conclusions are drawn using synthetic workloads that may not necessarily capture the behavior of real applications. In this paper, we have used parallel applications for a closer examination of the network behavior. In particular, the performance benefit from enhancing a 2-D mesh with virtual channels (VCs) and a routing algorithm (oblivious or fully adaptive) is examined with five shared memory applications using an execution-driven simulator, SPASM. In order to analyze the performance implications in greater detail, we also consider other parameters that have a direct bearing on network traffic. These are the number of processors used to solve a problem, problem size and memory consistency model. Simulation results show that VCs can reduce the network latency to varying degrees depending on the application. Similar gain is possible with a fully adaptive routing algorithm compared to the oblivious routing. However, with respect to the overall execution time, the performance benefit using these enhancements is negligible. Moreover, this benefit is negated when we consider the cost of implementing the VCs. These results suggest that the performance rewards may not justify the cost of these enhancements. Rather, we need to emphasize on improving the raw network bandwidth by simpler and improved router designs.