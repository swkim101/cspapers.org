Trace-driven simulation is a popular method of estimating the performance of cache memories, translation lookaside buffers, and paging schemes. Because the cost of trace-driven simulation is directly proportional to trace length, reducing the number of references in the trace significantly impacts simulation time. This paper concentrates on trace driven simulation for cache miss rate analysis. Previous schemes, such as cache filtering, exploited temporal locality for compressing traces and could yield an order of magnitude reduction in trace length. A technique called blocking and a variant called blocking with temporal data are presented that compress traces by exploiting spatial locality. Experimental results show that blocking filtering combined with cache filtering can reduce trace length by nearly two orders of magnitude while introducing about 10% error in cache miss rate estimates.