Deep learning has revolutionized vision sensing applications in terms of accuracy comparing to other techniques. Its breakthrough comes from the ability to extract complex high level features directly from sensor data. However, deep learning models are still yet to be natively supported on mobile devices due to high computational requirements. In this paper, we present DeepMon, a next generation of DeepSense [1] framework, to enable deep learning models on conventional mobile devices (e.g. Samsung Galaxy S7) for continuous vision sensing applications. Firstly, DeepMon exploits similarity between consecutive video frames for intermediate data caching within models to enhance inference latency. Secondly, DeepMon leverages approximation technique (e.g. Tucker decomposition) to build up approximated models with negligible impact on accuracy. Thirdly, DeepMon offloads heavy computation onto integrated mobile GPU to significantly reduce execution time of the model.