Autonomous navigation of generic monocular quadcopter in the natural environment requires sophisticated mechanism for perception, planning and control. In this work, we have described a framework which performs perception using monocular camera and generates minimum time collision free trajectory and control for any commercial quadcopter flying through cluttered unknown environment. The proposed framework first utilizes supervised learning approach to estimate the dense depth map for video stream obtained from frontal monocular camera. This depth map is initially transformed into Ego Dynamic Space and subsequently, is used for computing locally traversable way-points utilizing binary integer programming methodology. Finally, trajectory planning and control module employs a convex programming technique to generate collision-free trajectory which follows these way-points and produces appropriate control inputs for the quadcopter. These control inputs are computed from the generated trajectory in each update. Hence, they are applicable to achieve closed-loop control similar to model predictive controller. We have demonstrated the applicability of our system in controlled indoors and in unstructured natural outdoors environment.