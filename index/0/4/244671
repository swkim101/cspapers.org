Let <i>S</i> be a string of length <i>N</i> compressed into a context-free grammar <i>S</i> of size <i>n</i>. We present two representations of <i>S</i> achieving <i>O</i>(log <i>N</i>) random access time, and either <i>O</i>(<i>n</i> · α<sub><i>k</i></sub>(<i>n</i>)) construction time and space on the pointer machine model, or <i>O</i>(<i>n</i>) construction time and space on the RAM. Here, α<sub><i>k</i></sub>(<i>n</i>) is the inverse of the <i>k</i><sup><i>th</i></sup> row of Ackermann's function. Our representations also efficiently support decompression of any substring in <i>S</i>: we can decompress any substring of length <i>m</i> in the same complexity as a single random access query and additional <i>O</i>(<i>m</i>) time. Combining these results with fast algorithms for uncompressed approximate string matching leads to several efficient algorithms for approximate string matching on grammar-compressed strings without decompression. For instance, we can find all approximate occurrences of a pattern <i>P</i> with at most <i>k</i> errors in time <i>O</i>(<i>n</i>(min{|<i>P</i>|<i>k, k</i><sup>4</sup> +|<i>P</i>|} +log <i>N</i>) + occ), where occ is the number of occurrences of <i>P</i> in <i>S</i>. Finally, we are able to generalize our results to navigation and other operations on grammar-compressed <i>trees</i>.
 All of the above bounds significantly improve the currently best known results. To achieve these bounds, we introduce several new techniques and data structures of independent interest, including a predecessor data structure, two "biased" weighted ancestor data structures, and a compact representation of heavy-paths in grammars.