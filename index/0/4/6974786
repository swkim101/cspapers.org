Query expansion [12] refers to the process of including related terms in the original query to produce expanded queries, while query relaxation [8] refers to the dropping or down-weighting of terms from the original query to produce sub-queries. The automatic versions of both query expansion (AQE) and query relaxation (AQR) are known to fail in a large fraction of queries, and overall (average) improvements in performance can be attributed to high gains on a smaller fraction [7]. The potential to address the mistakes made by automatic techniques by involving the user [6] motivates interactive versions of these techniques (IQE, IQR). Previous research has shown that involving users in selection [4, 5, 10, 1] or rejection of terms or sets of terms [8] suggested by an automatic method has the potential to further improve performance. However, the same problems that plague automatic techniques are prevalent in interactive techniques: i.e. user interaction has the potential to lead to improvements only for a subset of queries. Further, a second problem has generally been ignored: frequently none of the options selected by the automatic procedures and presented to the user are any better than the original query. In this paper we develop and present procedures for determining when to interact with a user to obtain explicit feedback in the IQR and IQE settings. We show that by using these procedures we can avoid interaction for almost 40% of TREC queries without compromising significant improvements over the baseline. We also develop procedures to rank queries by their potential for improvement through user interaction, enabling systems to interact with users working under time and cognitive load constraints.