Human interfaces are usually designed to respond only tointentional human behaviors. However, humans show unintentionalbehaviors as well. They can convey useful information to realizeuser-friendly human interfaces. This paper presents how to combineobservations of both types of behaviors by taking two human-machine systems: a gesture-based interface and an intelligentwheelchair. In the first system, intentional hand gestures arechosen using unintentional behaviors. In the second system, nearunintentional behaviors following intentional behaviors can be usedto control the wheelchair motion. Experimental systems working inreal time have been developed. Operational experiments prove ourapproach promising.