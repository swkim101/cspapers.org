Most AI simulations have modeled memory retrieval separately from comprehension, even though both activities seem to use many of the same processes. We have developed REMIND, a model that performs both episodic memory retrieval and language understanding with a single spreading-activation mechanism. This approach has a number of advantages over retrieval-only models. First, because the comprehension process makes inferences about actors* plans and goals, REMIND is able to get abstract remindings that would not be possible without an integrated model. It also allows a more psychologically-plausible model of reminding than previous approaches, since all aspects of a text's interpretation affect what is retrieved through the spreading-activation process, as in human reminding. An inferencing-based retrieval model such as REMIND also has several computational advantages over pure retrieval models. The effects of the understanding process eliminate the need for the separate, purely structural comparisons used in most analogical retrieval models. Further, it potentially explains how the explicit indexing of case-based reasoning models can be eliminated, while retaining its benefits as an emergent property of the comprehension process.