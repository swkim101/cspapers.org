Process variations - which affect critical electrical parameters and lead to both random and systematic changes in circuit performance - have always posed significant challenges to semiconductor design. In the past, within-die process variation was relatively small, and methods such as corner-based analysis were sufficient. This allowed timing analysis tools to calculate delays, slew times, coupling and power in a straightforward way. Today, the International Technology Roadmap for Semiconductors suggests that the semiconductor industry's historical ability to control process variations is under siege, for both devices and interconnects. As statistical variation increases, will corner-casing lead to too much conservatism, and hence a requirement for new statistical timing and noise analysis tools? In other words, is the design flow inevitably moving to "delay is no longer a number; it's a distribution"? Or are the urgency and the advantages of statistical timing analysis overstated.