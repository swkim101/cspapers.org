Most decision tree algorithms focus on uni variate i e axis parallel tests at each inter nal node of a tree Oblique decision trees use multivariate linear tests at each non leaf node This paper reports a novel approach to the construction of non linear decision trees The crux of this method consists of the gen eration of new features and the augmenta tion of the primitive features with these new ones The resulted non linear decision trees are more accurate than their axis parallel or oblique counterparts Experiments on sev eral arti cial and real world data sets demon strate this property