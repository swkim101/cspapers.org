We show that any approach to develop optimum retrieval functions is based on two kinds of assumptions: first, a certain form of representation for documents and requests, and second, additional simplifying assumptions that predefine the type of the retrieval function. Then we describe an approach for the development of optimum polynomial retrieval functions: request-document pairs (ƒ<italic><subscrpt>l</subscrpt>, d<subscrpt>m</subscrpt></italic>) are mapped onto description vectors <italic>@@@@</italic>(ƒ<italic><subscrpt>l</subscrpt>, d<subscrpt>m</subscrpt></italic>), and a polynomial function of the form <italic>@@@@<supscrpt>T</supscrpt> · @@@@</italic>(<italic>@@@@</italic>) is developed such that it yields estimates of the probability of relevance <italic>P</italic>(<italic>R</italic>|<italic>@@@@</italic>(ƒ<italic><subscrpt>l</subscrpt>, d<subscrpt>m</subscrpt></italic>)) with minimum square errors. We give experimental results for the application of this approach to documents with weighted indexing as well as to documents with complex representations. In contrast to other probabilistic models, our approach yields estimates of the actual probabilities, it can handle very complex representations of documents and requests, and it can be easily applied to multi-valued relevance scales. On the other hand, this approach is not suited to log-linear probabilistic models, and it needs large samples of relevance feedback data for its application.