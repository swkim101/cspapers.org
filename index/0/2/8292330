A learning method capable of empowering a robot to successfully grasp a novel object through vision has recently been demonstrated, and generated much interest in the robotics community. In this paper we carefully analyze this new approach and apply dimensionality reduction techniques to decrease the number of features that need to be computed in order to classify whether a given pixel in an image is associated with a good or bad grasping point. Exploiting the ideas behind principal component analysis, we formulate two hypotheses about possible ways to eliminate certain features from training and classification. We then experimentally verify that the feature reduction significantly improves speed while retaining classification accuracy. Overall, the combination of the two hypotheses leads to a speedup factor of almost ten. The hypotheses are validated on third party synthetic data and also demonstrated on a seven degrees-of-freedom manipulator.