Outdoor robotic systems rely on perception modules that must be robust to variations in environmental conditions. In particular, vision-based perception systems are affected by illumination variations caused by occlusions. We propose an approach to calculate the lighting distribution of outdoor scenes. The new approach enables us to compensate for shadows and therefore obtain images which are invariant to the sun position and scene geometry, while also retaining the dimensionality of the original data. The method combines images with geometric information provided by range sensors to infer shadows. We select a pair of points on a shadow boundary from a single material and estimate a terrestrial sunlight-skylight ratio. Individual scaling factors are then calculated for all points based on their orientation and incident illumination sources. The result is a coloured point cloud that is independent of illumination variation due to occlusions and geometry. To demonstrate the effectiveness and generalisation of the approach, we present evaluations using two datasets with different cameras. The first uses a hyperspectral sensor that allows us to analyse the results for a large number of wavelengths, while the second dataset uses a standard RGB camera. The approach is shown to consistently provide good illumination compensation in both scenarios.