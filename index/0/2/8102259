With the aggressive scaling of integrated circuit technology, analog performance modeling is facing enormous challenges due to high-dimensional variation space and expensive transistor-level simulation. In this paper, we propose a kernel density based sparse regression algorithm (KDSR) to accurately fit analog performance models where the modeling error is not simply Gaussian due to strong nonlinearity. The key idea of KDSR is to approximate the non-Gaussian likelihood function by using non-parametric kernel density estimation. Furthermore, we adopt Laplace distribution as our prior knowledge to enforce a sparse pattern for model coefficients. The unknown model coefficients are finally determined by using an EM type algorithm for maximum-a-posteriori (MAP) estimation. Our proposed method can be viewed as an iterative and weighted sparse regression algorithm that aims to reduce the estimation bias for model coefficients due to outliers. Our experimental results demonstrate that our proposed KDSR method can achieve superior accuracy over the conventional sparse regression method.