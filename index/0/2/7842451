Robust integration of robotic and human perception abilities can greatly enhance the execution of complex informationdriven tasks like search and rescue. Our goal is to formally characterize and combine diverse information streams obtained from multiple autonomous robots and humans within a unified probabilistic framework that naturally supports autonomous perception, human situational awareness, and cooperative human-robot task execution under stochastic uncertainties. This approach requires welldesigned human-robot interfaces, flexible and accurate probabilistic models for exploiting “human sensor” data, and sophisticated Bayesian inference methods for efficient learning and online dynamic state estimation. We review some of recent theoretical developments and insights from experiments using real human-robot teams, and discuss some open challenges for future research.