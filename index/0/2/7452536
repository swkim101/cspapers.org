We consider an old optimization technique andâ€™apply it to the approximation of collections of discrete items. The technique is local improvement search: attempt to extend a collection by adding some items while removing others. shown: for given instances and starting solutions, there is no sequence of improvements ending with a locally optimal solution that is less than exponential length [28]. This is in the case of weighted problems; for unweighted PCS-complete problems, obtaining local optimality is P-complete. (See [26, 14, 281.) We obtain a (k + 1)/2 performance ratio for kDM, k-SET PACKING, and INDEPENDENT SET in k+ lclaw-free graphs by an NC algorithm or in nearly-linear sequential time. It can be extended to kc/2 + E (when k > 4), and to (k + 1)/3 + E when maximum degree is bounded. We also obtain improved performance ratios for induced subgraph problems, INDEPENDENT SET in bounded-degree graphs, VERTEX COVER in claw-free graphs, SET COVER, and GRAPH COLORING under a complementary objective function, What really brings home the point about the weakness of local search under worst-case criteria are the proven weaknesses of several popular heuristics with good average-case behavior on relatively easy problems. For instance, the Metropolis algorithm, the heart of Simulated Annealing, not only cannot find large cliques [12] (which is hard), but also fails badly for MAXIMUM MATCHING [25] (which is not). And for METRIC TSP, which is probably the most popular testbed for heuristics, there are instances where the popular t-opt heuristics obtain solutions that are Sl(n1/(2t)) longer than optimal [3].