This paper develops a theory for learning compositional models of objects. It gives a theoretical basis for explaining the effectiveness of recent learning algorithms which exploit compositionality in order to perform structure induction of graphical models. It describes how compositional learning can be considered as learning either probability models or efficient codes for objects.