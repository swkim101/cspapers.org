Developing dialogue systems is a complex process. In particular, designing efficient dialogue management strategies is often difficult as there are no precise guidelines to develop them and no sure test to validate them. Several suggestions have been made recently to use reinforcement learning to search for the optimal management strategy for specific dialogue situations. These approaches have produced interesting results, including applications involving real world dialogue systems. However, reinforcement learning suffers from the fact that it is state based. In other words, the optimal strategy is expressed as a decision table specifying which action to take in each specific state. It is therefore difficult to see whether there is any generality across states. This limits the analysis of the optimal strategy and its potential for re-use in other dialogue situations. In this paper we tackle this problem by learning rules that generalize the state-based strategy. These rules are more readable than the underlying strategy and therefore easier to explain and re-use. We also investigate the capability of these rules in directing the search for the optimal strategy by looking for generalization whilst the search proceeds.