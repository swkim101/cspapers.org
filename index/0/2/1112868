In this study, we evaluate a new electronic mobile application, PGA (Programming Grading Assistant). It was designed to make grading paper-based exams easier for graders and professors. Not only does it facilitate grading, but PGA also provides students with more meaningful (semantic) feedback than non-PGA grading. We outline the PGA grading process, the execution of a user study, and the results from that study that prove the effectiveness of PGA technology. Other results indicate that PGA awarded grades are equivalent to red-pen awarded grades and that PGA grades are more consistent across the board.