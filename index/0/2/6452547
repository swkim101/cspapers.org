The ability to generate effective evaluative arguments is critical for systems intended to advise and persuade their users. We have developed a system that generates evaluative arguments that are tailored to the user, properly arranged and concise. We have also devised an evaluation framework in which the effectiveness of evaluative arguments can be measured with real users. This paper presents the results of a formal experiment we performed in our framework to verify the influence of user tailoring on argument effectiveness.