In this paper, we propose a novel approach to generate a temporal consistent semantic map for 3D indoor scenes. In contrast to previous techniques which generate the semantic map on the whole global scene immediately or smooth the semantic predictions by a graph model, we intend to discover temporal information over RGB-D images and leverage it to enforce the label consistency. Our method contains two key components: a low-level component and a high-level component. On the low level, temporal segmentation method is adopted to find the correspondence of the superpixels incrementally. On the high level, temporal information is treated as the higher order cliques and a higher-order Dense Conditional Random Fields (CRF) is utilized to jointly infer the object category and structural class of the global point cloud. On the experiments, we compare our temporal consistent segmentation algorithm with the state-of-the-art approach and generate the semantic maps from the NYU v2 dataset. Our experiments demonstrate that temporal consistent constraints are significant for the semantic mapping procedure and can improve the precision of the semantic mapping results.