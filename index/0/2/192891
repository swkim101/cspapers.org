Computer generation of natural language requires the ability to make reasoned choices from a large number of possible things to say as well as from a large number of expressive possibilties. This paper examines in detail how one influence on a generated text, focus of attention, can be used to constrain the many possibilities that a generation system must consider. A computational treatment of focus of attention is presented that can be used to constrain what the system needs to consider when deciding what to say next. In this process, information is produced that provides constraints on which words and syntactic structures best express the system's intent, thus ensuring that its resulting text is coherent. This analysis has been used in the fully implemented TEXT system which generates paragraph length responses to questions about database structure.