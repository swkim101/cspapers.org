Abstract Speculative service implies that a client''s request for a document is serviced by sending, in addition to the document requested, a number of other documents that the server speculates will be requested by the client in the near future. This speculation is based on statistical information that the server maintains for each document it serves. The notion of speculative service is analogous to prefetching, which is used to improve cache performance in distributed/parallel shared memory systems, with the exception that servers (not clients) control when and what to prefetch. Using trace simulations based on the logs of our departmental HTTP server http://cs-www.bu.edu, we show that both server load and service time could be reduced considerably, if speculative service is used. This is above and beyond what is currently achievable using client-side caching and server-side dissemination. We identify a number of parameters that could be used to fine-tune the level of speculation performed by the server based on the level of lookahead, the state of the network, the tradeoffs between bulk and individual transmission of documents, and the relative popularity of documents, among other factors.