We investigate the problem of monotonicity reconstruction, as defined in [3], in a parallel setting. We have oracle access to a nonnegative real-valued function <i>f</i> defined on domain [<i>n</i>]<sup><i>d</i></sup> = {1,…,<i>n</i>}<sup><i>d</i></sup>. We would like to closely approximate <i>f</i> by a monotone function <i>g.</i> This should be done by a procedure (a <i>filter</i>) that given as input a point x ∈ [<i>n</i>]<sup><i>d</i></sup> outputs the value of <i>g</i>(<i>x</i>), and runs in time that is highly sublinear in <i>n.</i> The procedure can (indeed must) be randomized, but we require that all of the randomness be specified in advance by a single short random seed. We construct such an implementation where the the time and space per query is (log <i>n</i>)<sup><i>O</i>(1)</sup> and the size of the seed is polynomial in log <i>n</i> and <i>d.</i> Furthermore the distance of the approximating function <i>g</i> from <i>f</i> is at most a constant multiple of the minimum distance of any monotone function from <i>f.</i>
 This implementation allows for parallelization: one can initialize many copies of the filter with the same short random seed, and they can autonomously handle queries, while producing outputs that are consistent with the same approximating function <i>g.</i>