In multi-label classiﬁcation tasks, labels are commonly related with each other. It has been well recognized that utilizing label relationship is essential to multi-label learning. One way to utilizing label relationship is to map labels to a lower-dimensional space of uncorrelated labels, where the relationship could be encoded in the mapping. Previous linear mapping methods commonly result in regression subproblems in the lower-dimensional label space. In this paper, we disclose that mappings to a low-dimensional multi-label regression problem can be worse than mapping to a classiﬁcation problem, since regression requires more complex model than classiﬁcation. We then propose the binary linear compression (BILC) method that results in a binary label space, leading to classiﬁcation subproblems. Experiments on several multi-label datasets show that, employing classiﬁcation in the embedded space results in much simpler models than regression, leading to smaller structure risk. The proposed methods are also shown to be superior to some state-of-the-art approaches.