Recognizing human actions represented by 3D trajectories of skeleton joints is a challenging machine learning task. In this paper, the 3D skeleton sequences are regarded as multivariate time series, and their dynamics and multiscale features are efﬁ-ciently learned from action echo states. Speciﬁcal-ly, ﬁrst the skeleton data from the limbs and trunk are projected into ﬁve high dimensional nonlinear spaces, that are randomly generated by ﬁve dynamic, training-free recurrent networks, i.e., the reservoirs of echo state networks (ESNs). In this way, the history of the time series is represented as non-linear echo states of actions. We then use a single multiscale convolutional layer to extract multiscale features from the echo states, and maintain multi-scale temporal invariance by a max-over-time pooling layer. We propose two multi-step fusion strategies to integrate the spatial information over the ﬁve parts of the human physical structure. Finally, we learn the label distribution using softmax. With one training-free recurrent layer and only layer of convolution, our Convolutional Echo State Network (ConvESN) is a very efﬁcient end-to-end model, and achieves state-of-the-art performance on four skeleton benchmark data sets.