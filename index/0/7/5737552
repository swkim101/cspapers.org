Interpretations of TF-IDF are based on binary independence retrieval, Poisson, information theory, and language modelling. This paper contributes a review of existing interpretations, and then, TF-IDF is systematically related to the probabilities <i>P</i>(<i>q</i>|<i>d</i>) and <i>P</i>(<i>d</i>|<i>q</i>). Two approaches are explored: a space of <i>independent</i>, and a space of <i>disjoint</i> terms. For <i>independent</i> terms, an "extreme" query/non-query term assumption uncovers TF-IDF, and an analogy of <i>P</i>(<i>d</i>|<i>q</i>) and the probabilistic odds <i>O</i>(<i>r</i>|<i>d</i>, <i>q</i>) mirrors relevance feedback. For <i>disjoint</i> terms, a relationship between probability theory and TF-IDF is established through the integral + 1/<i>x</i> d<i>x</i> = log <i>x</i>. This study uncovers components such as divergence from randomness and pivoted document length to be inherent parts of a document-query independence (DQI) measure, and interestingly, an integral of the DQI over the term occurrence probability leads to TF-IDF.