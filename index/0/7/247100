k-Tails is a popular algorithm for extracting a candidate behavioral model from a log of execution traces. The usefulness of k-Tails depends on the quality of its input log, which may include too few traces to build a representative model, or too many traces, whose analysis is a waste of resources. Given a set of traces, how can one be confident that it includes enough, but not too many, traces? While many have used the k-Tails algorithm, no previous work has yet investigated this question. In this paper we address this question by proposing a novel notion of log completeness. Roughly, a log of traces, extracted from a given system, is k-complete, iff adding any new trace to the log will not change the resulting model k-Tails would build for it. Since the system and its full set of traces is unknown, we cannot know whether a given log is k-complete. However, we can estimate its k-completeness. We call this estimation k-confidence. We formalize the notion of k-confidence and implement its computation. Preliminary experiments show that k-confidence can be efficiently computed and is a highly reliable estimator for k-completeness.