A recent development in advanced interface technologies is the virtual acoustic display, a system that presents threedimensional auditory information over headphones [20]. The utility of such a display depends on the accuracy with which listeners can localize the virtual, or simulated, sound sources. Synthesis of virtual sources involves the digital filtering of stimuli using filters based on acoustic HeadRelated Transfer Functions (HRTFs) measured in human ear-canals. In practise, measurement of the HRTFs of each potential user of a 3-D display may not be feasible. Thus, a critical research question is whether listeners from the general population can obtain adequate localization cues from stimuli based on non-individualized filters. In the present study, 16 inexperienced listeners judged the apparent spatial location (azimuth and elevation) of wideband noisebursts that were presented either over loudspeakers in the fkee-field (an anechoic or non-reverberent environment) or over headphones. The headphone stimuli were synthesized using HRTFs from a representative subject in a previous study [23]. Localization of both t%efield and virtual sources was quite accurate for 12 of the subjects, 2 showed poor elevation accuracy in both free-field and headphone conditions, and 2 showed degraded elevation accuracy only with virtual sources. High rates of confusion errors (reversals in judgments of azimuth and elevation) were also observed for some of the subjects and tended to increase for the virtual sources. In general, the data suggest that most listeners can obtain useful directional information from an auditory display without requiring the use of individually-tailored HRTFs, particularly for the dimension of azimuth. However, the high rates of confusion errors remain problematic. Several stimulus characteristics which may help to minimize these errors are discussed.