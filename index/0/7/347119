There is a lot of practical and theoretical interest in designing algorithms to process digital pictures. Of particular interest are problems arising when one starts with an nxn array of pixels and stores it, one pixel per processor, in some sort of array-like parallel computer. In this paper we give an optimal &thgr;(n) time solution, based on a simpler &thgr;(n) time solution for a more powerful computer called a mesh computer. Beyer suggested that this problem was a prime candidate for a non-linear recognition problem, but our result shows that this is not true.