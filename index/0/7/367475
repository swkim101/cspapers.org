This paper investigates an algorithm for the construction of decisions trees comprised of linear threshold umts and also presents a novel algorithm for the learning of nonlinearly separable boolean functions using Madaline style networks which are isomorphic .to decision trees. The construction of such networks is discussed, and theIr performance in learning is compared with standard Back-Propagation on a sample problem in which many irrelevant attributes are introduced. Littlestone's Winnow algorithm is also explored within this architecture as a means of learning in the presence of many Irrelevant attributes. The learning ability of this Madaline-style architecture on non-optimal (larger than necessary) networks is also explored.