We present a real time non-invasive system that infers user stress level from evidences of different modalities. The evidences include physical appearance (facial expression, eye movements, and head movements) extracted from video via visual sensors, physiological conditions collected from an emotional mouse, behavioral data from user interaction activities with the computer, and performance measures. We provide a Dynamic Bayesian Network (DBN) framework to model the user stress and these evidences. We describe the computer vision techniques we used to extract the visual evidences, the DBN model for modeling stress and the associated factors, and the active sensing strategy to collect the most informative evidences for efficient stress inference. Our experiments show that the inferred user stress level by our system is consistent with that predicted by psychological theories.