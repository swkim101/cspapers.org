This paper is concerned with alleviating the choice of learning biases via a two-step process: (cid:0) The set of all hypotheses that are consistent with the data and cover at least one training example, is given an implicit characterization of polynomial complexity. The only bias governing this induction phase is that of the language of hypotheses. (cid:0) Classi(cid:12)cation of further examples is done via interpreting this implicit theory; the interpretation mechanism allows one to relax the consistency requirement and tune the speci(cid:12)city of the theory at no extra induction cost. Experimental validations demonstrate very good results on both nominal and numerical datasets.