The opto-acoustic scene analysis is an extremely important as well as a challenging task for a humanoid robot. By the opto-acoustic scene analysis, the guided and autonomous exploration of the environment by means of acoustic and/or visual perception is meant. On the one hand, the perception ability is necessary to interact with humans in a humanoid way. On the other hand, the proximity of the robot has to be analyzed continuously, in order to enable the robot to fulfill its everyday tasks. Thereby, the greatest challenge lies in the wide variety of different perception tasks, e.g. detection, tracking, and identification of persons and different types of objects. This leads to the need of adapted, both, task- and context-dependent perception modules with specific requirements and abilities.