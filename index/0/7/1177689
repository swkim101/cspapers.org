We describe a new paradigm for exploration of unknown spaces based on maximizing the understanding of obstacles rather than the exposure of free space. We look at the interaction between multiple sensor readings and how they combine to resolve obstacles. Taking a next best view approach, we generate an inverse sensor model that identifies regions in space where a new sensor reading has maximal utility with respect to increasing the resolution of that reading. Fusion of multiple models is exploited to generate regions of interest that direct exploration in such a way as to maximize the robots understanding of its space. These techniques are applied to a team of small robots called Millibots.