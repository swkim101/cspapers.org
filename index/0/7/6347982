In many application areas, there exists a crucial need for capturing 3D videos of fast moving and/or deforming objects. A 3D video is a sequence of 3D representations at high time and space resolution. Although many 3D sensing techniques are available, most cannot deal with dynamic scenes (e.g. laser scanning), can only deal with textured surfaces (e.g. stereo vision) and/or require expensive specialized hardware. This paper presents a technique to compute high-resolution range maps from single images of moving and deformable objects. A camera observes the deformation of a projected light pattern that combines a set of parallel colored stripes and a perpendicular set of sinusoidal intensity stripes. While the colored stripes allow recovering absolute depths at coarse resolution, the sinusoidal intensity stripes give dense relative depths. This twofold pattern makes it possible to extract a high-resolution range map from each image captured by the camera. This approach is based on sound mathematical principles, but its implementation requires giving great care to a number of low-level details. In particular, the sensor has been implemented using commercial off the shelf hardware, which distorts sensed and transmitted signals in many ways. A novel method was developed to characterize and compensate for distortions due to chromatic aberrations. The sensor has been tested on several moving and deforming objects.