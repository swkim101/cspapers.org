User interfaces are very important for the success of many computer-based applications these days. However, their development takes time, requires experts for user-interface design as well as experienced programmers and is very expensive. This problem becomes even more severe through the ubiquitous use of a variety of devices such as PCs, mobile phones, PDAs etc., since each of these devices has its own specifics that require a special user interface.Therefore, we developed a tool-supported approach to automatically synthesize multi-device user interfaces from high-level specifications in the form of models. In contrast to previous approaches focusing on abstracting the user interface per se, we make use of communicative acts derived from speech act theory for the specification of desired user intentions in interactions. In this way, we approach a solution to the given problem, since user interfaces can be efficiently provided without experience in implementing them.