It is well known that a real-time visual servoing task which employs a Visual Tracking Algorithm (VTA) imposes high computational cost to robotic system, which consequently results in higher energy consumption and lower autonomy. Motivated by this fact, this paper presents a novel Image Based Visual Servoing-Model Predictive Control (IBVS-MPC) scheme which is combined with a mechanism that decides when the VTA needs to be triggered and new control inputs must be calculated. Between two consecutive triggering instants, the control input trajectory is applied to the robot in an openloop fashion, i.e, no visual measurements and calculation of the control inputs are required during that period. This results in the reduction of the computational effort, energy consumption and increases the autonomy of the system. These factors are of utmost importance in the case of small autonomous robotic systems which perform vision based tasks, such as surveillance and inspection of indoors and outdoors environments. The visibility and inputs constraints, optimality rate of the MPC, as well as the external disturbances, are being considered during the control design. The efficiency of the proposed scheme is demonstrated through a set of real-time experiments using an eye-in-hand mobile robotic system.