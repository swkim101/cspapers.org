<i>Multi-view learning</i> has become a hot topic during the past few years. In this paper, we first characterize the sample complexity of multi-view <i>active learning</i>. Under the α-<i>expansion</i> assumption, we get an exponential improvement in the sample complexity from usual <i>Õ</i>(1/<i>ε</i>) to <i>Õ</i>(log 1/<i>ε</i>), requiring neither strong assumption on data distribution such as the data is distributed uniformly over the unit sphere in R<i><sup>d</sup></i> nor strong assumption on hypothesis class such as linear separators through the origin. We also give an upper bound of the error rate when the α-<i>expansion</i> assumption does not hold. Then, we analyze the combination of multi-view active learning and semi-supervised learning and get a further improvement in the sample complexity. Finally, we study the empirical behavior of the two paradigms, which verifies that the combination of multi-view active learning and semi-supervised learning is efficient.