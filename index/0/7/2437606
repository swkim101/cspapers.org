Analyzing human motion, including tracking and pose estimation, is a major topic in computer vision. Many methods have been developed in the past and will be developed in the future. To have a systematic and quantitative evaluation of such methods, ground truth data of the 3D human motion is scientifically required. Some publicly available data sets exist, like HumanEva, that provide synchronized video sequences with detailed ground truth 3D data for scenes limited to only a single person. However, for multiple persons, such a data set currently does not exist. In this paper, we present the Utrecht Multi-Person Motion (UMPM) benchmark, which includes synchronized motion capture data and video sequences from multiple viewpoints for multi-person motion including multi-person interaction. The data set is available to the research community to promote research in multi-person articulated human motion analysis. This paper describes the design of the benchmark, the technical problem solutions, and the resulting data sets.