The proposed work deals with robotic unfolding of a garment that has been placed flat on a table and folded over a certain axis. The algorithm combines image and depth data to detect the bottom and top (folded) layer of the garment. The detection is formulated as a labeling of the garment surface and solved in an energy minimization framework. Once the garment pose is known, several candidate folding axes are generated and used to unfold the garment virtually. The correct folding axis is selected from these candidate axes. The method does not set any constraints on the garment shape; thus it can deal with various types of garments including jackets, pants, shorts, skirts or T-shirts of any sleeve lengths. The garment is unfolded by the dual-arm robot. One arm grasps boundary of the top layer and brings it over the estimated folding axis, while the second arm is holding the bottom layer to prevent the garment from slipping. The perception procedure was tested on the annotated dataset that we are making publicly available. The experimental evaluation of the robotic manipulation is also provided.