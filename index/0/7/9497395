Early research into emoji in textual communication has focused largely on high-frequency usages and ambiguity of interpretations. Investigation of a wide range of emoji usage shows these glyphs serving at least two very different purposes: as content and function words, or as multimodal affective markers. Identifying where an emoji is replacing textual content allows NLP tools the possibility of parsing them as any other word or phrase. Recognizing the import of non-content emoji can be a a signiﬁcant part of understanding a message as well. We report on an annotation task on English Twitter data with the goal of classifying emoji uses by these categories, and on the effectiveness of a classiﬁer trained on these annotations. We ﬁnd that it is possible to train a classiﬁer to tell the difference between those emoji used as linguistic content words and those used as par-alinguistic or affective multimodal markers even with a small amount of training data, but that accurate sub-classiﬁcation of these multimodal emoji into speciﬁc classes like attitude, topic, or gesture will require more data and more feature engineering.