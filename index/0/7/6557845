Targeted online advertising now accounts for the largest share of the advertising market, beating out both TV and print ads. While targeted advertising can improve users’ online shopping experiences, it can also have negative e ﬀ ects. A plethora of recent work has found evidence that in some cases, ads may be discriminatory, leading certain groups of users to see better o ﬀ ers (e.g., job ads) based on personal characteristics such as gender. To develop policies around advertising and guide advertisers in making ethical decisions, one thing we must better understand is what concerns users and why. In an e ﬀ ort to answer this question, we conducted a pilot study and a multi-step main survey (n = 2,086 in total) presenting users with different discriminatory advertising scenarios. We ﬁnd that overall, 44% of respondents were moderately or very concerned by the scenarios we presented. Respondents found the scenarios signiﬁcantly more problematic when discrimination took place as a result of explicit demographic targeting rather than in response to online behavior. However, our respondents’ opinions did not vary based on whether a human or an algorithm was responsible for the discrimination. These ﬁndings suggest that future policy documents should explicitly address discrimination in targeted advertising, no matter its origin, as a signiﬁcant user concern, and that corporate responses that blame the algorithmic nature of the ad ecosystem may not be helpful for addressing public concerns.