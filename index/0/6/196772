Performance studies of various R-tree algorithms, have used the number of nodes accessed as the primary metric. In real databases some portion of the tree is buffered in main memory. Since such buffering can significantly affect performance, we postulate that performance prediction should be baaed on number of 1/0s required to satisfy a query. To this end we present an analytical model that predicts the number of disk accesses for an LRU buffer manager given the minimum bounding rectangles (MBRs) of the R-tree nodes and a buffer size. Our model can be used to evaluate the quality of any R-tree update operation, such as node splitting policies [3] or packing algorithms [4, 6, 8], asmeasured by query performance of the resulting tree. The model is very accurate and simple to understand, making it easy for researchers to integrate it into their studies. It can eerily be modified to accommodate different buffer management policies â€“ for example, keeping the top few levels of the R-tree in the buffer. Furthermore, the model ia not only applicable to R-trees, but can easily be modified to predict B-tree performance.