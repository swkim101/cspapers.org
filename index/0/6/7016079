An algorithm is proposed for matching data from different sensing modalities. The problem is formalised as a kidnapped robot problem, where Bayesian fusion is used to find the most likely location where both modalities agree. The key idea of our algorithm is to model the correlation between the two modalities as a likelihood used to update a location prior. Data, in this case, is represented as 2.5D thickness maps from a laser scanner and a Remote Field Eddy Current (RFEC) tool, used in non-destructive testing to assess the condition of infrastructures. The laser data is limited, while RFEC data is continuous. Given some prior in location, the aim is to find the 2.5D thickness map from the laser that corresponds to the RFEC data, which should be noted is highly noisy. Real data from CCTV inspections of water pipes are used to validate the proposed approach.