Automatons and other robotic applications which are designed to move around and interact with their physical environment need a computer vision system for recognizing and understanding the spatial relationships of objects in real world scenes. The perceptual system must be able to identify salient objects in a scene, develop an understanding of their spatial relationships, and maintain continuity from one view to the next as either the objects or the system's camera moves through the scene. 
 
Outlined here and described in more detail in Douglass, 1977, is a system which has been implemented in SIMULA and tested on hand coded outdoor scenes of simple subjects such as houses and automobiles. It uses a recognition cone, a segmentation algorithm for dividing a scene into similar regions and a routine for constructing a three dimensional world model. Visual inference routines interpret perspective, shadows, highlights, occlusions, shading and texture gradients, and monocular motion parallax. Other visual knowledge is added with long term models and short term object representations. 
 
The final program will be tested on color photographs of outdoor scenes using as input a series of views of the same scene from different angles which approximates what an automaton would "see" as it moves down a street.