This paper presents an omnidirectional distributed vision system that learns to navigate a robot in an office-like environment without any knowledge about the calibration of the cameras or the robot control law. The system is composed of several omnidirectional vision agents (implemented with an omnidirectional camera and a computer). The first vision agent learns to control the robot with SARSA(/spl lambda/) reinforcement learning, using the LEM strategy to speed-up learning. Once the first vision agent learnt the correct policy, it transfers its knowledge to the other vision agents. The other vision agents might have different intrinsic and extrinsic camera parameters (that are unknown), so a certain amount of re-learning is needed. Reinforcement learning is well suited for this. In this paper, we present the structure of the learning system and the discussion about the optimal values for the learning parameters. During the experimentation the learning phase of the first agent has been carried out, then the knowledge propagation and the re-learning stage of three different agents have been tested. The experimental results demonstrate the feasibility of the approach and the possibility to port the system on the actual robot and cameras.