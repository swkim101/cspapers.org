Sensing of environment geometry and texture is a key requirement for mobile robotic systems. In the underwater domain, difficult environmental conditions restrict the applicability of many existing methods for 3D sensing. A new method is proposed, which uses a visible laser line projected onto a monocular camera image to perform 3D scene reconstruction. The method fuses Structured Light with Structure from Motion in an integrated process, which allows for the capturing of dense 3D point clouds on moving systems in situations with low texture and minimal scene structure. The system is evaluated in three experiment scenarios and provides an average translation error of 2% in the KITTI Benchmark for monocular visual odometry and an average model error of 1:7mm when compared with a tabletop structured light system.