Video is one of the fastest-growing sources of data and is rich with interesting semantic information. Furthermore, recent advances in computer vision, in the form of deep convolutional neural networks (CNNs), have made it possible to query this semantic information with near-human accuracy (in the form of image tagging). However, performing inference with state-of-the-art CNNs is computationally expensive: analyzing videos in real time (at 30 frames/sec) requires a $1200 GPU per video stream, posing a serious computational barrier to CNN adoption in large-scale video data management systems. In response, we present N O S COPE , a system that uses cost-based optimization to assemble a specialized video processing pipeline for each input video stream, greatly accelerating subsequent CNN-based queries on the video. As N O S COPE observes a video, it trains two types of pipeline components (which we call ﬁlters) to exploit the locality in the video stream: difference detectors that exploit temporal locality between frames, and specialized models that are tailored to a speciﬁc scene and query (i.e., exploit environmental and query-speciﬁc locality). We show that the optimal set of ﬁlters and their parameters depends signiﬁcantly on the video stream and query in question, so N O S COPE introduces an efﬁcient cost-based optimizer for this problem to select them. With this approach, our N O S COPE prototype achieves up to 120-3,200 × speed-ups (318-8,500 × real-time) on binary classiﬁcation tasks over real-world webcam and surveillance video while maintaining accuracy within 1-5% of a state-of-the-art CNN.