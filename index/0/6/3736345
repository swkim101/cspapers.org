Frieze et al. [17] proved that a small sample of rows of a given matrix <i>A</i> contains a low-rank approximation <i>D</i> that minimizes ||<i>A - D</i>||<i>F</i> to within small additive error, and the sampling can be done efficiently using just two passes over the matrix [12]. In this paper, we generalize this result in two ways. First, we prove that the additive error drops exponentially by iterating the sampling in an adaptive manner. Using this result, we give a pass-efficient algorithm for computing low-rank approximation with reduced additive error. Our second result is that using a natural distribution on subsets of rows (called <i>volume</i> sampling), there exists a subset of <i>k</i> rows whose span contains a factor (<i>k</i> + 1) relative approximation and a subset of <i>k</i> + <i>k</i>(<i>k</i> + 1)/ε rows whose span contains a 1+ε relative approximation. The existence of such a small certificate for multiplicative low-rank approximation leads to a PTAS for the following projective clustering problem: Given a set of points <i>P</i> in R<sup><i>d</i></sup>, and integers <i>k, j</i>, find a set of <i>j</i> subspaces <i>F</i><inf>1</inf>, . . ., <i>F</i><inf><i>j</i></inf>, each of dimension at most <i>k</i>, that minimize Σ<inf><i>p</i>∈P</inf>min<inf><i>i</i></inf> <i>d(p, F</i><inf><i>i</i></inf>)<sup>2</sup>.