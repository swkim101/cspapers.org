Percutaneous needle insertion guided by ultrasound imaging is routinely performed in hospitals today. Automating these procedures could increase placement accuracy and lower time usage of health care personnel to perform these procedures. An important step in the automation is the estimation of the needle orientation and position in the ultrasound image. One approach to estimate the needle orientation and position is to have the needle aligned with the image plane of the ultrasound probe. Aligning the needle with the plane is difficult, even with accurate measurements and calibration of both needle and probe. In this paper we propose a visual servoing method to move the ultrasound probe, using a robot to align the image plane of the probe with the needle. The method segments the needle and updates a set of visual features based on a model of the needle. A state machine is used to keep track of the alignment process, and different visual features are used to control the probe in the different states. Both simulation using simple synthetic images and experiments in a water tank are conducted to validate the proposed method. The simulation shows that the proposed method manages to align the probe plane with the needle. The alignment process is slower in the actual robot experiment, but still aligns the probe plane with the needle. The method is shown to work under simplified conditions, and is a step towards a method that could be applied in a clinical setting.