The Virtual Interface (VI) Architecture provides pr otected userlevel communication with high delivered bandwidth a nd low permessage latency, particularly for small messages. The VI Architecture attempts to reduce latency by eliminat ing user/kernel transitions on routine data transfers and by allowi ng direct use of user memory for network buffering. This results in significantly lower latencies than those achieved by network prot ocols such as TCP/IP and UDP. In this paper we examine the low-le vel performance of two VI implementations, one implemen ted in hardware, the other implemented in device driver so ftware. Using a set of low-level benchmarks, we measure bandwidth , la ency, and processor utilization as a function of message siz for the GigaNet cLAN and Tandem ServerNet VI implementation s. We report that both VI implementations offer significa nt performance advantage relative to the corresponding UDP impleme ntation on the same hardware. We also investigate the problem s associated with delivering this performance to distributed app lications running on clustered multiprocessor workstations. Using an existing MPI library implemented using UDP as a bas eline, we explore several performance and implementation issu es that arise when adapting this library to use VI instead of UDP . Among these issues are memory registration costs, polling vs. blocking, reliability of delivery, and memory-to-memory copyi ng. By eliminating explicit acknowledgements, reducing mem ory-tomemory copying, and choosing the most appropriate synchronization primitives, we reduced the message l tency seen by user applications by an average of 55% across al l message sizes. We also identify several areas that offer t h potential for further performance enhancement.