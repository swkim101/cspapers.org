In recent years, the multiclass and mutlilabel classiﬁcation problems we encounter in many applications have very large ( 10 3 − 10 6 ) number of classes. However, each instance belongs to only one or few classes, i.e., the label vectors are sparse. In this work, we propose a novel approach based on group testing to solve such large multilabel classiﬁcation problems with sparse label vectors. We describe various group testing constructions, and advocate the use of concatenated Reed Solomon codes and unbalanced bi-partite expander graphs for extreme classiﬁcation problems. The proposed approach has several advantages theoretically and practically over existing popular methods. Our method operates on the binary alphabet and can utilize the well-established binary classiﬁers for learning. The error correction capabilities of the codes are leveraged for the ﬁrst time in the learning problem to correct prediction errors. Even if a linearly growing number of classiﬁers mis-classify, these errors are fully corrected. We establish Hamming loss error bounds for the approach. More importantly, our method utilizes a simple prediction al-gorithm and does not require matrix inversion or solving optimization problems making the algo-rithm very inexpensive. Numerical experiments with various datasets illustrate the superior performance of our method.