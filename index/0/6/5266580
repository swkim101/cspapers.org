In this paper, we present a method for obtaining Visual Odometry (VO) estimates using a scanning laser rangefinder. Though common VO implementations utilize stereo camera imagery, cameras are dependent on ambient light. In contrast, actively-illuminated sensors such as laser rangefinders work in a variety of lighting conditions, including full darkness. We leverage previous successes by applying sparse appearance-based methods to laser intensity images, and address the issue of motion distortion by considering the estimation problem in continuous time. This is facilitated by Gaussian Process Gauss-Newton (GPGN), an algorithm for non-parametric, continuous-time, nonlinear, batch state estimation. We include a concise derivation of GPGN, along with details on the extension to three-dimensions (3D). Validation of the 3D laser-based VO framework is provided using 1.1km of experimental data, which was gathered by a field robot equipped with a two-axis scanning lidar.