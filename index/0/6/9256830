In real-time environment, data usually has a lifespan associated with it. The semantics and the importance of the data depend on the time when data is utilized. Hence, the process of getting a consensus data from a group of replicated units must not take longer time than the lifespan of the data. However, in real environment, every unit, faulty or non-faulty, may encounter delays when processing and sending their data which inevitably increases the time of acquiring a consensus. The latency for obtaining a valid data hence depends not only on the time when individual replicas make their votes, but also on the accuracy and credibility of the votes. Thus, a new metric, i.e. a credibility function, needs to be taken into account when evaluating expected time and deciding upon data replications. This paper presents analytical solutions for the expected time when dependable data can be obtained under different voting schemes. We show that if not all replicas are truthful, increasing replication does not reduce the time for obtaining valid results. When different types of resources are used to ensure the quality of the data, we show that the allocation of the resource plays an important role in satisfying both data availability and consistency constraints. We further demonstrate that when point-based constraints may be intrinsically impossible to satisfy, a more general interval-based constraint can be used to obtain statistical solutions