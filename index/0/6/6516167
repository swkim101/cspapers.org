An experimental study of four different schemes for parallelisation of FORTRAN codes is presented. One scheme is manual (performed by the programmer), the other three are automatic (performed entirely by software). The performance of code generated for two parallel computers from seven different test cases is compared, and reasons for differences in achieved performance between the four parallelisation schemes are analysed. It is concluded that, even using sophisticated techniques, high performance parallelised code cannot be generated by automatic tools unless they take into account feedback about execution-time behaviour. Both post-execution performance analysis and interaction with the programmer are necessary for success. This observation argues for user-centred, feedback-driven parallelisation tools that aid the manual process.