Locally weighted learning techniques, in particular LWPR [Vijayakumar et al., 2002], have successfully been used for high-dimensional regression problems. Their robustness and efficient online versions are crucial in robotic domains where, for instance, an inverse model of an articulated dynamic robot has to be learned in real-time. Such models map a highdimensional state (e.g., joint angles and velocities) and a desired change of state to the required motor signals (torques). While typically such mappings are assumed to be smooth, in real world scenarios, there are many interesting cases where the functions of interest are truly discontinuous. Some examples include contacts with other objects (in particular the ground), with other parts of the body, or with “joint limits”. In fact, many interesting interactions with the environment manifest themselves through discontinuities in the sensorimotor data. In this paper, we show how discontinuous switching between local regression models can be learned. The general topic of switching models has been discussed before, e.g., in the context of state space models [Ghahramani and Hinton, 1998; Pavlovic et al., 2000] or multiple inverse models [Wolpert and Kawato, 1998]. Generally, the question of which particular model receives responsibilities for a given input can be modeled as a hidden variable i in a generative mixture model. In our case, we assume that the responsibility index i can be predicted from the input (the robot state). Thus, inferring a model for i corresponds to classifying the input domain into regions for each sub-model. Since in robotic domains, local learning is crucial to prevent interference and allow for online adaptation techniques, we propose a model of the responsibility index i which is itself a composition of local classifiers. Multiple pairwise classifiers are concatenated to construct a complete model in the form of a product-of-sigmoids, which is capable of learning complex, sharply bounded domains for each local model in lieu of the typical Gaussian kernels.