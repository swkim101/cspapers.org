In this paper, we discuss why, in designing multiparty mediatedsystems, we should focus first on providing non-verbal cues whichare less redundantly coded in speech than those normally conveyedby video. We show how conveying one such cue, gaze direction, maysolve two problems in multiparty mediated communication andcollaboration: knowing who is talking to whom, and who is talkingabout what. As a candidate solution, we present the GAZE GroupwareSystem, which combines support for gaze awareness in multipartymediated communication and collaboration with small and linearbandwidth requirements. The system uses an advanced, desk- mountedeyetracker to metaphorically convey gaze awareness in a 3D virtualmeeting room and within shared documents.