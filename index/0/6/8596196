By encoding information as digital signal propagation delay, rather than conventional logic levels, some basic processing operations become exceedingly energy efficient to implement. The result of such a computation can then be observed by relative timing differences between injected signals. We demonstrate the embodiment of such an approach utilizing current starved inverters as delay elements and characterize application-level artifacts of circuit-level variance. Specifically we chose the well-studied DNA sequence alignment problem for comparison and we show that, for the synthesized design, asynchronous races are 10x more energy efficient and 4x denser at comparable speeds as compared to prior approaches.