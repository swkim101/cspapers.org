Simulation can be an effective training method if the simulation environment is as realistic as possible. An ‘important part of the training for Navy pilots involves flying against computer-controlled agents in simulated tactical scenarios. In order for such a situation to be realistic, the computer-controlled agents must be indistinguishable from human-piloted agents within the simulated environment. The primary goal of the SoarIFOR project (Jones et al. 1993; Rosenbloom et al. 1994) is to provide such believable agents for flight training simulations. To achieve this goal, we have constructed the TACAIR-SOAR system.’ Developing this system requires us to address a number of core research issues within artificial intelligence, including reasoning about interacting goals, situation interpretation, communication, explanation, planning, learning, natural language understanding and generation, temporal reasoning, and plan recognition. This report focuses on two particular issues required to function reasonably within the tactical air domain: a system must be able to generate behavior in response to complex goals and situations, and it must be able to do so dynamically, in response to extremely rapid changes in the agent’s situation. On the surface, these two capabilities seem to be at odds to each other. Approaches to real-time or reactive behavior have generally not been used within complex domains, and systems that focus on complex goals do not usually do so in real time. Our solution has been to encode knowledge within the Soar production architecture (Rosenbloom et al. 1991) in order to take advantage of state-