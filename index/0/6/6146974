This paper describes the application of Distributional Clustering [20] to document classi(cid:12)cation. This approach clusters words into groups based on the distribution of class labels associated with each word. Thus, unlike some other unsupervised dimensionality-reduction techniques, such as Latent Semantic Indexing, we are able to compress the feature space much more aggressively, while still maintaining high document clas-si(cid:12)cation accuracy. Experimental results obtained on three real-world data sets show that we can reduce the feature dimensionality by three orders of magnitude and lose only 2% accuracy|signi(cid:12)cantly better than Latent Semantic In-dexing [6], class-based clustering [1], feature selection by mutual information [23], or Markov-blanket-based feature selection [13]. We also show that less aggressive clustering sometimes results in improved classi(cid:12)cation accuracy over classi(cid:12)cation without clustering.