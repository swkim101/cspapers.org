It is a great challenge to perform robust tracking for a mobile robot owing to dynamic environments. Also, fast motion or abrupt jerk of the robotic camera poses a severe threat for continuous tracking. To address these problems, a novel attention model is proposed motivated by human attention mechanism which consists of low level salient feature and high level scene semantics. The low level layer extracts color and motion feature to obtain combined feature probability map. In semantic level, the ADM(attention distribution map) is computed by applying an attenuation function on the combined feature map which is motivated by human's foveal vision. The object position is found using CAMSHIFT algorithm in ADM. And this layer also generates a region-based SSG(scene semantics graph). When robot moves abnormally, the model detects candidate regions in color saliency map and then attention shifts from one region to the next and check it by elastically matching SSG until the target is recovered. Experiments in several kinds of environments give promising results and show that this model is robust for mobile robotic tracking. When camera moves steadily, a little fast or even jerks very abruptly, it can keep continuous tracking.