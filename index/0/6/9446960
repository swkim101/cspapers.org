Most work in Distributed AI has dealt with agents that cooperate to achieve common high level goals. The assumption of cooperative behavior allows agents to use static models of one another to predict their future actions in order to promote coherent system behavior. Our research extends the domain of problems to include noncooperative, multi-agent interactions where cooperation cannot be assumed but needs to be dynamically induced during problem solving. This necessitates the development of mechanisms to purposefully modify the plans, goals and behavior of other agents to increase agent cooperativeness in order to bring about convergence to a global solution. We advocate persuasive argumentation as such a mechanism for cohering the group problem solving of non fully cooperative agents. We present a model of persuasive argumentation that has been implemented as part of the PERSUADER, a multi-agent computer program that operates in the domain of labor negotiations.