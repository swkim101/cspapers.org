An experiment was conducted to investigate differences in performance between virtual pointing, where a 2-D computer image representing the hand and targets was superimposed on the workspace, and physical pointing with vision of the hand and targets painted on the work surface. A detailed examination of movement kinematics revealed no differences in the initial phase of the movement, but that the final phase of homing in on smaller targets was more difficult in the virtual condition. These differences are summarised by a two-part model of movement time which also captures the effects of scaling distances to, and sizes of, targets. The implications of this model for design, analysis, and classification of pointing devices and positioning tasks are discussed.