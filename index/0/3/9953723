Data prefetching that brings data close to the processor before it is actually used, can be done in parallel with computation, thus hiding the memory access latency and avoiding the need for the processor to stall. For maximum effectiveness it is necessary to adapt the prefetching parameters, such as prefetch offset and prefetch degree, to match programs and system conditions. Prefetch adaptability is the ability to change when to issue prefetching requests and the amount of data to be prefetched. We propose an adaptive mechanism of data prefetching using cache produced information, such as the usage of prefetched data and the rate of replacement of prefetched data. In this adaptive mechanism, the prefetch parameters are dynamically adjusted to reflect run-time variations of system behaviour. We use program driven simulation of scientific applications in the context of shared-memory multiprocessors to show that the proposed adaptive method can reduce memory access latency by reducing pending stall to a greater extent than can be achieved without an adaptive mechanism.