Conducting an independent life is probably the most important issue for visually impaired people. In this paper, we suggest a contribution to the solution of this problem using wearable computer technology. We present a visual support system that provides acoustic information about the objects in the surrounding environment, obtained by remotely reading barcode tags sticked on significant objects and surrounding elements, such as doors, windows and so on. The user, walking in an indoor environment, is informed in realtime about the location (direction, distance and pose) of the available objects. Barcode tags deployed in the environment can act as reliable stimuli that trigger local navigation behaviours to achieve global navigation objectives. The proposed system is expected to be useful in the real-time interaction with dynamic environments. To illustrate our work, we introduce a proof-of-concept multimodal, sensorbased application and discuss its implementation and the obtained experimental results.