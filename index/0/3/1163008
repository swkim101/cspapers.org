We describe two deterministic algorithms for constructing the arrangement determined by a set of (algebraic) curve segments in the plane. They both use a divide-and-conquer approach based on derandomized geometric sampling and achieve the optimal running time O(n log n + k), where n is the number of segments and k is the number of intersections. The first algorithm, a simplified version of one presented in [I], generates a structure of size O(nloglogn + k) and its parallel implementation runs in time O(log 2 n). The second algorithm is better in that the decomposition of the arrangement constructed has optimal size O(n + k) and it has a parallel implementation in the EREW PRAM model that runs in time O(log a/2 n). The improvements in the second algorithm are achieved by means of an approach that adds some degree of globality to the divide-and-conquer approach based on random sampling. The approach extends previous work by Dehne et al.[7], Deng and Zhu [8] and Kiihn [9], that use small separators for planar graphs in the design of randomized geometric algorithms for coarse grained multicomputers. The approach simplifies other previous geometric algorithms [1, 2], and also has the potential of providing efficient deterministic algorithms for the external memory model. 1 Problem and Previous Work We consider a classical problem in computational geometry: computing the arrangement determined by a set of curve segments in the plane. There has been a considerable amount of work on this problem in the computational geometry community, particularly for line segments. Starting with a first efficient algorithm by -----t'T~as A&M University, College Station, TX. E-malh amato@cs.tamu.edu. This work was supported in part by NSF CAREER Award CCR-9624315, NSF grants IIS-9619850, ACI9872126, EIA-9805823, and EIA-9810937, by DOE (ASCI ASAP, Level 2 and 3) grant B347886, and by the Texas Higher Education Coordinating Board grant ARP-036327-017. ?The Johns Hopkins University, Baltimore, MD. E-maih goodrich@cs .jhu.edu. This work was partially supported by U.S. Army Research Office MURI Grant DAAH04-96-1-0013 and by U.S. National Science Foundation Grant CCR-9732300. SMax-Planck-Institut ftir Informatik, Saarbr/icken, Germany. E-malh ramesGmpi-sb.mpg, de Bentley and Ottman [4], optimal output sensitive algorithms algorithms were obtained using a deterministic approach by ChazeUe and Edelsbrunner [5] and using randomized approaches by Clarkson and Shor [6] and by Mumuley [10]. These optimal algorithms perform O(n logn + k) work, where n is the number of segments and k is the number of pairwise intersections. They can be adapted so that they are output sensitive even when multiple intersection points are allowed (a point where many segments intersect is counted only once). On the other hand, unlike its randomized counterparts in [6, 10], the deterministic algorithm in [5] can only handle line segments. An alternative deterministic algorithm by Amato et a/.[1], which follows a divide-andconquer approach based on derandomization of geometric sampling, has the advantage of being parallelizable. However, it can only handle line segments and pairwise intersection points, and the decomposition of the arrangement that it constructs has size O(n log log n + k), as opposed to the optimal O(n+ k). One more variation on the problem is to report all the intersections while using only a linear amount of work space. The solutions in [6] and [1] can be adapted to achieve this. Alternatively, Balaban [3] proposed an elementary deterministic algorithm to achieve this; however, it does not construct the arrangement, it does not seem to parallelize, and it cannot handle multiple intersection points. The algorithm in [1] uses an approach based on random sampling that refines iteratively by using small samples to divide the problem. This divide-and-conquer approach and also the well-known random incremental construction (RIC) approach date from work by Clarkson and Shor [6]. Unfortunately, unlike the RIC approach, divide-and-conquer most often leads to nonoptimal algorithms, at least as far as the most basic analysis can tell, because the dividing step creates spurious boundaries that increase the complexity of the constructed decomposition of the arrangement. In fact, the literature is plagued with running times that are a factor n e or log c n away from optimal. Some techniques have been used to correct this and obtain optimal algorithms: sparse cuttings, pruning and biased sampling. In particular, the algorithm in [1] achieves optimality through