As databases for real-world problems increase in size, there is a need in many situations to select and keep relevant training data for efficient storage and processing reasons. Support vector machines (SVMs) reportedly exhibit certain desirable properties in selecting and preserving useful training data as support vectors. This paper attempts to quantify the extent to which SVM training behaves like a model independent example selection procedure. Using several common machine-learning training databases, we compare the prediction results obtained by different classifiers, trained with data selected by SVMs and by two other example selection methods (IB2 and random sampling). Some interesting observations are made with explanations.