This paper describes an explanation-based approach lo learning plans despite a computationally intractable domain theory. In this approach, the system learns an initial plan using limited inference. In order to detect plans in which the limited inference causes a faulty plan the system monitors goal achievement in plan execution. When a plan unexpectedly fails to achieve a goal (or unexpectedly achieves the goal) a refinement process is triggered in which the system constructs an explanation for the expectation violation. This explanation is then used to refine the plan. By using expectation failures to guide search the learner avoids a computationally intractable exhaustive search involved in constructing a complete proof of the plan. This approach has the theoretical property of convergence upon a sound plan.