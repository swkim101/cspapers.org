Clustering is an important problem, with applications in areas such as data mining and knowledge discovery [6], data compression and vector quantiation [8], and pattern recognition and pattern classification [5]. One important class of clustering problems is given a set of n data points in real d-dimensional space, R, and an integer k. The problem is to determine a set of k points R, called centers, that minimizes the mean squared distance from each data point to its nearest center. This problem is closely related to other clustering problems, such as the k-medians problem [2], in which the objective is to minimize the sum of distances, and the k-center problem [1], in which the objective is to minimize the maximum distance. The results of Arora, Raghavan and Rao [2] can be extended to this problem, implying the existence of a polynomial time approximation scheme, but this algorithm is quite complex. Also see Hochbaum [9] and Jain and Dubes [11] for a more general description of clustering problems. One of the most popular heuristics for computing centers for minimizing the squared-error distortion is called the k-means algorithm [12, 7]. It is a simple iterative algorithm, and it may be used either for computing an initial set of centers or for producing a local improvement to a given set of centers. Here is how it works. Given any set of k centers, for each center ci, let Ri denote the set of data points for which ci