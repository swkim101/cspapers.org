Team-partitioned, opaque-transition reinforcement learning (TPOT-RL) is a distributed reinforcement learning technique that allows a team of independent agents to learn a collaborative task. TPOT-RL was first successfully applied to simulated robotic soccer (Stone & Veloso, 1999). This paper demonstrates that TPOT-RL is general enough to apply to a completely different domain, namely network packet routing. Empirical results in an abstract network routing simulator indicate that agents situated at individual nodes can learn to efficiently route packets through a network that exhibits changing traffic patterns, based on locally observable sensations.