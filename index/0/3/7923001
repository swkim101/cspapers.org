Any gantral model-based vision system must somehow select a few serious candidates from its model base before applying model-directed processing. This is necessary for both efficiency and recognising 'similar' models (i.e. handling data errors, generic models and previously unseen objects). This paper shows how one can Integrate knowledge of object properties, structural and generic relations to create a network computation that performs model invocation. The paper demonstrates successful invocation in a scene containing a self and externally obscured PUMA robot.