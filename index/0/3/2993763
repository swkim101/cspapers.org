We present two components of a vision-based approach to autonomous driving on and near rural and desert roads. The first component comprises fast processing of live vehicle camera video to robustly extract linear direction and midline estimates of marginal roads. The second uses satellite imagery immediately surrounding the vehicle’s GPS position to trace the road ahead for curve and corner anticipation, and to inform the vehicle planner of a nearby road when traveling cross-conalysis: on-board, they are employed to ?nd ruts and trauntry. The algorithms are built upon Gabor wavelet filters for texture acks from which the road vanishing point can be inferred via Houghstyle voting, and aerially, they localize the edges of low-contrast road contours. Mechanisms for both modules to determine whether the vehicle is currently on- or off-road are also explained. Our system’s efficacy is illustrated for several difficult datasets, including a log from one vehicle’s run during the 2004 DARPA Grand Challenge.