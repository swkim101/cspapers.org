Interactions among agents can be conveniently described by game trees. In order to analyze a game, it is important to derive optimal (or equilibrium) strategies for the different players. The standard approach to finding such strategies in games with imperfect information is, in general, computationally intractable. The approach is to generate the normal form of the game (the matrix containing the payoff for each strategy combination), and then solve a linear program (LP) or a linear complementarity problem (LCP). The size of the normal form, however, is typically exponential in the size of the game tree, thus making this method impractical in all but the simplest cases. This paper describes a new representation of strategies which results in a practical linear formulation of the problem of two-player games with perfect recall (i.e., games where players never forget anything, which is a standard assumption). Standard LP or LCP solvers can then be applied to find optimal randomized strategies. The resulting algorithms are, in general, exponentially better than the standard ones, both in terms of time and in terms of space. ∗Computer Science Division, University of California, Berkeley, CA 94720; and IBM Almaden Research Center, 650 Harry Road, San Jose, CA 95120 †IBM Almaden Research Center, 650 Harry Road, San Jose, CA 95120; and School of Mathematical Sciences, Tel Aviv University, Tel Aviv, Israel. ‡Informatik 5, University of the Federal Armed Forces at Munich, 85577 Neubiberg, Germany. Research supported in part by ONR Contract N00014-91-C-0026, by the Air Force Office of Scientific Research (AFSC) under Contract F49620-91-C-0080, and by the Volkswagen Foundation. Some of the work was performed while the first author was at Stanford University. The United States Government is authorized to reproduce and distribute reprints for governmental purposes. In: Proceedings of the 26th ACM Symposium on the Theory of Computing, 1994, 750–759