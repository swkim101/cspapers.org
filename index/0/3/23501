This paper examines the effects of tool design on student testing behavior in an introductory course. Two tools are considered: BlueJ and WebCAT. A small modification was made to the BlueJ test recording interface to encourage students to engage more deeply in the testing process. A larger percentage of tests submitted by students using the modified BlueJ interface were correct. Further, the solutions they submitted contained fewer lines of code while being similarly complete and correct. Evidence is given that students using both BlueJ versions often rely on Web-CAT to validate their solution methods before testing the methods themselves. In response a new Web-CAT grading plug-in is proposed that we believe will better promote an incremental code-a-little test-a-little development style.