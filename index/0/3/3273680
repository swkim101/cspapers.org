Evidence grids are a popular representation for fused data from multiple sensors. Previous attempts at back-ground subtraction within evidence grids either do so prior to sensor fusion or do so naively, simply ignoring any cells with a high background occupancy probability. A key weakness of these approaches is that they cannot reason about interiors of objects or other unobserved regions. Recognizing and removing solid object interiors is important for any application that must be able to differentiate between occupied and unknown space after background subtraction. In this paper, we propose accessibility analysis as a method for the removal of interior regions. We then present and compare two approaches for performing background subtraction with accessibility analysis in evidence grids. Performance is measured using a 3D evidence grid in a test bed for a sensing system designed for use in safety monitoring of an automated assembly workcell. Within the parameters of the present study, both techniques allow for precise detection of foreground objects while fully removing background objects. Subtraction runs in near real-time, even for large grids.