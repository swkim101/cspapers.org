This paper introduces a new approach to adaptively learn the dynamics of a robotic system. The methodology is based on maximizing the information gain from new observations while modeling the dynamics with a Multiple Output Gaussian Process (MOGP). High-dimensional state-action spaces with unknown dependencies between inputs and outputs can be highly computationally expensive to learn. Gaussian process modeling is a Bayesian technique that naturally overcomes one of the most difficult problems in machine learning known as over-fitting. This makes it very appealing for on-line problems where testing multiple hypothesis is difficult. The computational cost of the learning task is reduced by having a smaller dataset of informative training points. Therefore we introduce a learning strategy capable of determining the most informative training set for the MOGP. This method can be implemented for learning the behavior of dynamic systems where due to their complexity and disturbances are infeasible to be analytically defined. The benefits of our approach are verified in two experiments: learning the dynamics of a cart-pole system in simulation and the dynamics of a robotic blimp.