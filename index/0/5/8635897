The current research is a complex, 5 day, training experimentinvestigating several questions about the learning and use ofsoftware methods. Central issues concern the situation in which asoftware user knows more than one obvious method for accomplishinga task at hand. We call this situation "multiple methods". Multiplemethods seem to arise most often from the creation of commands orfunctions specialized for a subclass of tasks. For example, in aword processing application there are often several ways to movethe cursor, with arrow keys, by word, by line, by page, to end ofline, to start of line, to top of document, and to bottom, to namesome common methods. Designers and users typically assume that theexistence and use of multiple methods in an application increasesuser efficiency. We tested that assumption directly. In thisexperiment we investigated the effects of multiple methods duringlearning and performance measuring task time, planning time, anderror rates and types. In addition, we also investigated strategiessubjects employed when choosing between their methods.
In a rigorous training regime using the spreadsheet softwareLotus 123, subjects learned one or two ways to move the cursor andone or two ways to sum the contents in a section of cells. Duringthe 5 day experiment, subjects repeatedly moved the cursor to anindicated location and entered a formula summing an adjacent groupof numbers. Cursor movements were of varying distances and sumsinvolved various numbers of addends.
On the first day, subjects were taught their method set whichthey practiced to a criterion of 24 consecutive correctrepetitions. On days 2 and 3 (practice), subjects performed taskscomprised of 128 repetitions of their method set. On every task,the best method was assigned in the instructions and used by thesubjects. The best method was determined by constructingtheoretical keystroke models of the methods (see Olson &amp;Nilsen, 1988) and assigning the most rapid method. During practice,the order in which the methods were used was counter-balanced.
On days 4 and 5 (testing), subjects performed 338 similar tasksbut selected the method themselves on every task. These 338 taskswere comprised of thirteen different cursor task distances andthirteen sizes of sums sampled thirteen times each. During bothpractice and testing, subjects used the &lt;enter&gt; keyto toggle between task instructions and the spreadsheet on whichthe tasks were performed. During a cursor task, the target cell wasnot indicated until the subject removed the instruction screenstating: "move the cursor to the target cell using the X method".Similarly, during a summation task, the addends were apparent onlyafter the instruction screen was removed. This allowed partitioningof the total task time into planning time and typing times.
During both practice and testing, and on both cursor andsummation tasks, subjects who knew two methods for a task made moreerrors on that task type (matched tasks) only. That is, knowing twosum methods increased the number of sum task errors, but did notincrease the number of cursor task errors. Similarly, knowing twocursor movement methods increased the number of cursor task errors,but not summation task errors. In addition, two method subjectswere no faster on matched tasks than were one method subjects,despite their specialized methods. In fact, the two method subjectshad <u>longer</u> planning times on matched tasks thandid one method subjects. Once again, these effects of knowing twomethods were segregated to matched tasks.
It is interesting to compare the two groups of subjects thateach knew three methods as a way of controlling for effects ofworkload imposed purely by the number of methods known. Thesubjects with two cursor methods and one sum method (2-1 subjects)were compared to those with one cursor method and two sum methods(1-2 subjects). Consonant with the results above, 2-1 subjects mademore cursor task errors than did the 1-2 subjects who made more sumtask errors. Increases in planning time at the start of the taskfollowed this same pattern.
Although error rates were low and task time differences modest---between 500 to 3000 msec---in a population of "real users" whoknow more commands and do not undergo such rigorous practice thedifferences are expected to be much larger. These resultscontradict the common assumption that specialized methods forsubclasses of tasks increase a user's efficiency. In addition,these results demonstrate the costs of multiple methods even in animpoverished repertoire of only four commands.