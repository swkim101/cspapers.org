In the context of the Internet of Things, an increasing number of platforms like Xively or ThingSpeak are available to manage ubiquitous sensor data. Strict data formats allow interoperability and informative visualizations, supporting the development of custom user applications. Yet, these strict data formats as well as the common device-centric approach limit the flexibility of these platforms: there are no means to incorporate people and their subjective impressions about the collected data. In order to build the Internet of Things and People and ultimately the Internet of Everything, we aim at providing an extendable concept of data which allows to enrich existing data points with any kind of additional information. This enables us to gain semantic and user specific context by attaching subjective data to objective values. For this end we support data ranging from text-based formats like JSON to images and video footage. This paper provides an overview of our architecture including concept, implementation details and present applications. We distinguish our approach from several other systems and describe two sensing applications namely AirProbe and WideNoise that were implemented for our platform.