This paper presents a distributed, end-to-end congestion control protocol for use in high-traffic packet switched networks. The network is represented as a stochastic single-server queue, with arrival rates being the control variables. A time-stamp based measure of network state called warp is defined, and it is shown to be an estimator of network utilization. Congestion is modeled explicitly using unimodal load-service rate functions, and its monotonicity property is exploited to yield characterizations of stability and optimality. A protocol based on "perfect" information is analyzed, whose prowess is then shown to be emulated by one which only uses locally computable, delayed information. The main effect of a unimodal load-service function is to induce a division of the phase space into stable and unstable regions, the optimal operating point being its "boundary." Protocols are devised for dealing with each regime separately, rate adjustment protocol being the control that guides the system to the optimal operating point. Proactive rate protocol and reactive rate protocol deal with the issue of the optimal operating point being near to the unstable zone. Protocols for handling fairness and structural perturbation augment the basic suite. The analysis is supported by simulations showing the global dynamical properties of the system.