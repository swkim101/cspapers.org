Word sense disambiguation for unrestricted text is one of the most difficult tasks in the fields of computational linguistics. The crux of the problem is to discover a model that relates the intended sense of a word with its context. This paper describes a general framework for adaptive conceptual word sense disambiguation. Central to this WSD framework is the sense division and semantic relations based on topical analysis of dictionary sense definitions. The process begins with an initial disambiguation step using an MRD-derived knowledge base. An adaptation step follows to combine the initial knowledge base with knowledge gleaned from the partial disambiguated text. Once the knowledge base is adjusted to suit the text at hand, it is then applied to the text again to finalize the disambiguation result. Definitions and example sentences from LDOCE are employed as training materials for WSD, while passages from the Brown corpus and Wall Street Journal are used for testing. We report on several experiments illustrating effectiveness of the adaptive approach.