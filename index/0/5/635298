As processor microarchitectures continue to increase in complexity, so does the time required to explore the design space. Performing cycle-accurate, detailed timing simulation of a realistic workload on a proposed processor microarchitecture often incurs a prohibitively large time cost. We propose a method to reduce the time cost of simulation by dynamically varying the complexity of the processor model throughout the simulation. In this paper, we give first evidence of the feasibility of this approach. We demonstrate that there are significant amounts of time during a simulation where a reduced processor model accurately tracks important behavior of a full model, and that by simulating the reduced model during these times the total simulation time can be reduced. Finally, we discuss metrics for detecting areas where the two processor models track each other, which is crucial for dynamically deciding when to use a reduced rather than a full model.