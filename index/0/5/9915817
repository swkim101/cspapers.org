For generating motions of robots, global search in configuration space is time consuming although it is sometimes indispensable (e.g. collision avoidance in complex environment). Our idea is to use global sampling algorithm not in the state space but in the task nullspace, which is the redundant degrees of freedom of the state space with respect to the task space. Because the task nullspace is smaller than the original search space (state space), fast global sampling is possible. For embedding this hidden task nullspace parameters, we propose a new deep-auto-encoder-based neural network structure. Our approach learns the map from task and task nullspace towards robot's state (Task-State Map, TSM). As the demonstration, the relationship between 28-dof joint angles (state) and the end-effector coordinates of all limbs (task) is learned, and egress postures and reaching postures are generated.