To determine object geometry in unstructured environments, sensors must be mechanically robust, must exert only low forces on objects during exploration, and must be able to scan large regions efficiently without risk of damaging objects or sensors. Joint-angle sensors on compliant joints provide an appealing option for this task. An algorithmic framework is presented that allows them to be used for contact detection and to determine object geometry without requiring tactile arrays or other complicated contact location sensors. This volumetric approach to using proprioceptive sensors provides improvements in accuracy over other existing approaches based on the intersection of planes and lines.