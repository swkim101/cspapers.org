Â© Copyright 2014. Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Self-play reinforcement learning has proved to be succ essful in many perfect information two-player games. However, research carrying over its theoretical guaranI ces and practical success to games of imperfect inform ation has been lacking. In this paper, we evaluate self- play Monte-Carlo Tree Search (MCTS) in limit Texas Hold'em and Kuhn poker. We introduce a variant of the established UCB algorithm and provide first empinc al results demonstrating its ability to find approximate Nash equilibria.