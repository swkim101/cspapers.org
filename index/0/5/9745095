This paper reports progress in the development of a humanoid robot designed for real-time face-to-face interaction with humans. An essential component for face-to-face interaction with humans is being able to find faces, tracking them, and smoothly moving back and forth between gazing to a face and other objects of interest. In this paper we propose a system that integrates peripheral vision and foveal vision in a principled manner using particle filters. The developed system generates hypotheses about face position by using peripheral vision and verifies them by integrating peripheral vision and foveal vision. Even though a face may not be present in foveal vision, while the robot is gazing at another object, it keeps plausible hypotheses about the location of the human face with peripheral vision and restarts the face-following by verifying the hypothesis later. Moreover, this fundamental function provides more rich sensory information for human-robot interaction, such as a human's facial expression and lip motions during utterances.