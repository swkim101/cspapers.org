We consider the problem of approximating a signal <i>P</i> with another signal <i>F</i> consisting of a few piecewise constant segments. This problem arises naturally in applications including databases (e.g., histogram construction), speech recognition, computational biology (e.g., denoising aCGH data) and many more. Specifically, let <i>P</i> = (<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub>,..., <i>P</i><sub><i>n</i></sub>), <i>P</i><sub><i>i</i></sub> ∈ R for all <i>i</i>, be a signal and let <i>C</i> be a constant. Our goal is to find a function <i>F</i>: [<i>n</i>] → R which optimizes the following objective function:
 [EQUATION]
 The above optimization problem reduces to solving the following recurrence, which can be done using dynamic programming in <i>O</i>(<i>n</i><sup>2</sup>) time:
 [EQUATION]
 This recurrence arises naturally in several applications where one wants to approximate a given signal <i>P</i> with a signal <i>F</i> which ideally consists of few piecewise constant segments. Such applications include histogram construction in databases, determining DNA copy numbers in cancer cells from micro-array data, speech recognition, data mining and many others.
 In this work we present two new techniques for optimizing dynamic programming that can handle cost functions not treated by other standard methods. The basis of our first algorithm is the definition of a constant-shifted variant of the objective function that can be efficiently approximated using state of the art methods for range searching. Our technique approximates the optimal value of our objective function within additive ε error and runs in <i>Õ</i>(<i>n</i><sup>4/3+Δ</sup> log (<i>U</i>/ε)) time, where Δ is an arbitrarily small positive constant and <i>U</i> = max{√<i>C</i>, (|<i>P</i><sub><i>i</i></sub>|)<sub><i>i</i>=1,..., <i>n</i></sub>}. The second algorithm we provide solves a similar recurrence that's within a multiplicative factor of (1+ε) and runs in <i>O</i>(<i>n</i> log <i>n</i>/ε). The new technique introduced by our algorithm is the decomposition of the initial problem into a small (logarithmic) number of Monge optimization subproblems which we can speed up using existing techniques.