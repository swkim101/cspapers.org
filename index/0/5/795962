The online learning problem requires a player to iteratively choose an action in an unknown and changing environment. In the standard setting of this problem, the player has to choose an action in each round before knowing anything about the corresponding loss. However, there are situations in which it seems possible for the player to spend efforts or resources to collect some prior information before her actions. This motivates us to study a variant of the online learning problem, in which the player is allowed to query <i>B</i> bits from the loss vector in each round before choosing her action. Suppose each loss value is represented by <i>K</i> bits and distinct loss values differ by at least some amount Δ, and suppose there are <i>N</i> actions to choose and <i>T</i> rounds to play. We provide an algorithm for this problem which achieves a regret of the following form. Before <i>B</i> approaching <i>B</i><sub>1</sub> = <i>NK</i>/2, the regret stays at <i>O</i>(√<i>T</i> ln <i>N</i>), and after <i>B</i> exceeding <i>B</i><sub>1</sub> but before approaching <i>B</i><sub>2</sub> = <i>NK</i>/2 + 3<i>K</i>/2-1, the regret drops slightly to <i>O</i>(√(<i>T</i> ln <i>N</i>)/<i>N</i>), while after <i>B</i> exceeding <i>B</i><sub>2</sub>, the regret takes a dramatic drop to (<i>N</i> ln <i>N</i>)/Δ. Our algorithm is in fact close to optimal as we also provide regret lower bounds which almost match the regret upper bounds achieved by our algorithm.