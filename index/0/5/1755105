Several Text Categorization applications require a representation beyond the standard bag-of-words paradigm. Kernel-based learning has approached this problem by (i) considering information about syntactic structure or by (ii) incorporating knowledge about the semantic similarity of term features. We propose a generalized framework consisting of a family of kernels that jointly incorporate syntactic and semantic similarity and demonstrate the power of this approach in a series of experiments.