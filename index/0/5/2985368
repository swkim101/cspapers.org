We present an explicit construction of linear-time encodable and decodable codes of rate r which can correct a fraction (1&mdash:r&egr;ε)/2 of errors over an alphabet of constant size depending only on ε, for every 0 < r < 1 and arbitrarily small ε> 0. The error-correction performance of these codes is optimal as seen by the Singleton bound (these are "near-MDS" codes). Such near-MDS linear-time codes were known for the decoding from erasures [2]; our construction generalizes this to handle errors as well. Concatenating these codes with good, constant-sized binary codes gives a construction of linear-time binary codes which meet the so-called "Zyablov bound". In a nutshell, our results match the performance of the previously known explicit constructions of codes that had polynomial time encoding and decoding, but in addition have linear time encoding and decoding algorithms.We also obtain some results for list decoding targeted at the situation when the fraction of errors is very large, namely (1—ε) for an arbitrarily small constant ε > 0. The previously known constructions of such codes of good rate over constant-sized alphabets either used algebraic-geometric codes and thus suffered from complicated constructions and slow decoding, or as in the recent work of the authors [9], had fast encoding/decoding, but suffered from an alphabet size that was exponential in 1/ε. We present two constructions of such codes with rate close to &OHgr;(ε2) over an alphabet of size quasi-polynomial in 1/ε. One of the constructions, at the expense of a slight worsening of the rate, can achieve an alphabet size which is polynomial in 1/ε. It also yields constructions of codes for list decoding from erasures which achieve new trade-offs. In particular, we construct codes of rate close to the optimal &OHgr;(ε) rate which can be efficiently list decoded from a fraction (1—ε) of erasures.