The automation of surgical tasks has great potential for improving the performance of robotic surgery. The learning-from-demonstration approach has thus far been employed by many researchers when planning the trajectories of robotic instruments for automated surgical tasks. However, previous methods are applicable only when the demonstrations and trajectory generation are performed under the same initial conditions. In this paper, we propose an algorithm that learns through demonstrations and generates a trajectory regardless of the initial conditions. The variance of the demonstrated trajectories over the initial conditions is modeled and learned using a statistical method, and the learned trajectories are generalized and used to generate a trajectory. As an example, the bi-manual looping task of a surgical thread was demonstrated by changing the initial positions of the robot arms, and a trajectory was then planned given these initial arbitrary positions. The proposed algorithm was verified through simulations and experiments using an actual robotic surgical system.