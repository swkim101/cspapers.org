The performance of any cooperative task that involves two or more robots will be determined by their capacity to recognize common information of the environment. Vision sensors are very effective for this particular goal, but the cost of transmitting the visual information represents a real issue, even more if communication must be performed in narrow bandwidth networks and/or over a multi-hop path. Visual vocabularies provide a dimensionality reduction that has been effectively used in computer vision to reduce the computational load of performing searches in large volumes of data. In this paper we propose to exploit the same technique to decrease the volume of information that is exchanged in the network. This way, robots do not need to send the full descriptors associated to the features they observe, but only the word indices of the corresponding features in the vocabulary. Experiments with a wide variety of vocabularies are used to evaluate the quality of the association given by the algorithm. Finally, real experiments in a wireless network with a limited bandwidth are reported, showing the advantages of the proposed method compared to the communication of full images or feature descriptors.