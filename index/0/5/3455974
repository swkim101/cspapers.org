Open-source course projects offer students a glimpse of real-world projects and opportunities to learn about architectural design and coding style. While students often have more difficulties with these projects than with traditional "toy" projects, instructors are also spending excessive time on grading miscellaneous projects. There is an improvising need for means to help students and instructors with their difficulties. This poster presents our work on predicting which course projects are likely to fail at an early stage with machine learning approaches. We collected metadata from 247 course projects in a graduate-level Object-Oriented Design and Development course over the past 5 years, built models to fit the course projects and use the classifier to help instructors to identify potential failing projects, thus to help students to salvage their works. By assuming that the project acceptances are related to the working patterns of project teams, we made innovations of adding temporal-based patterns into the training data, and achieved 86.36% classification accuracy with the addition of those features. We also proved several observations, such as most of the rejected projects are those begun relatively late during the project period, and the projects which modified more files/code does not result in better possibility of being accepted. By contrast, accepted projects tend to deliver a volume of code that is neither very small nor very large, compared to rejected ones. Our results also suggest that setting milestone checkpoints at roughly a week before the submission deadlines would enable more students to succeed in their OSS projects.