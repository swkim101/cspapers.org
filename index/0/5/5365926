This paper presents a vision-based human-computer interface system that enables the user to move a target object in 3D CG world by moving his/her hand. Unlike conventional systems, the system does not need any camera calibration. In addition, it uses a user-centered frame so that the user can control the object by hand motions matched with human intuition. For example, the user can move the object forward by moving his/her hand forward even if he/she has changed his/her body position. The system is based on the multiple view affine invariance theory. It calculates hand positions as invariant coordinates in the basis derived from four points on the user's body. Actual system implementation and experimental results show the usefulness of the system.<<ETX>>