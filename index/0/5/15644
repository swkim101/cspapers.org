The main objective of compiler and processor designers is to effectively exploit the instruction-level parallelism (ILP) available in applications. Although most of the times their research activities have been conducted separately, we believe that a stronger co-operation between them will make effective the increase of potential ILP coming from future architectures. Nowadays, most computer architecture achievements proceed towards the overcoming of the hurdle imposed by dependencies in the code, by means of extracting parallelism from large instruction windows. However, implementation constraints limit the size of this window and therefore the visibility of the program structure at run-time. In this paper we show the existence of distant parallelism that future compilers could detect. By distant parallelism we mean parallelism that can not be captured by the processor instruction window and that can produce threads suitable for parallel execution in a multithreaded processor. Although this parallelism also exists in numerical applications (going far beyond classical loop parallelism and usually known as task parallelism), we focus on non-numerical applications, where the data and computation structures make difficult the detection of concurrent threads of execution. Some preliminary but encouraging results are presented in the paper, reporting speed-ups in the range of 1.2 to 2.65. These results seem promising and want to show a new insight in the detection of threads for current and future multithreaded architectures. It is important to notice at this point that the benefits described herein are totally orthogonal to any other architectural techniques targeting a single thread.