The traditional guardbanding approach to ensure processor reliability is becoming obsolete because it always over-provisions voltage and wastes a lot of energy. As a next-generation alternative, adaptive guardbanding dynamically adjusts chip clock frequency and voltage based on timing margin measured at runtime. With adaptive guardbanding, voltage guardband is only provided when needed, thereby promising significant energy efficiency improvement. In this paper, we provide the first full-system analysis of adaptive guardbanding's implications using a POWER7+ multicore. On the basis of a broad collection of hardware measurements, we show the benefits of adaptive guardbanding in a practical setting are strongly dependent upon workload characteristics and chip-wide multicore activity. A key finding is that adaptive guardbanding's benefits diminish as the number of active cores increases, and they are highly dependent upon the workload running. Through a series of analysis, we show these high-level system effects are the result of interactions between the application characteristics, architecture and the underlying voltage regulator module's loadline effect and IR drop effects. To that end, we introduce adaptive guardband scheduling to reclaim adaptive guardbanding's efficiency under different enterprise scenarios. Our solution reduces processor power consumption by 6.2% over a highly optimized system, effectively doubling adaptive guardbanding's original improvement. Our solution also avoids malicious workload mappings to guarantee application QoS in the face of adaptive guardbanding hardware's variable performance.