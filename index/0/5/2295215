Time series forecasting aims at improving energy efficiency in wireless sensor networks (WSNs) by reducing the amount of data traffic. One such technique has each node generate a model that predicts the sampled data. When the actual, sensed data deviates from the model, a new model is generated and transmitted to the sink. Reductions in application data traffic as high as two orders of magnitude can be achieved. However, our experience in applying such forecasting in a real world deployment shows that the actual lifetime improvement is significantly less due to networking overheads. The study reported here reveals that careful, coordinated network parameter tuning can leverage the reduced traffic of forecasting techniques to increase lifetime without compromising application performance.