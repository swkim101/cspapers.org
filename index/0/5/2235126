Image keypoints are broadly used in robotics for different purposes, ranging from recognition to 3D re-construction, passing by SLAM and visual servoing. Robust keypoint matching across different views is problematic because of the relative motion between camera and scene that causes significant changes in feature appearance. The problem can be partially overcome by using state-of-the-art methods for keypoint detection and matching, that are resilient to common affine transformations such as changes in scale and rotation. Unfortunately, these approaches are not invariant to the radial distortion present in images acquired by cameras with wide field-of-view. This article proposes modifications to the Scale Invariant Feature Transform (SIFT), that improve the repeatability of detection and effectiveness of matching in the presence of distortion, while preserving the characteristics of invariance to scale and rotation. These modifications require an approximate modeling of the image distortion, and consist in using adaptative gaussian filtering for detection and implicit gradient correction for description. Extensive experiments, with both synthetic and real images, show that our method outperforms explicit distortion correction using image rectification.