We propose a human action recognition algorithm by capturing a compact signature of shape dynamics from multi-view videos. First, we compute â„œ transforms and its temporal velocity on action silhouettes from multiple views to generate a robust low level representation of shape. The spatio-temporal shape dynamics across all the views is then captured by fusion of eigen and multiset partial least squares modes. This provides us a lightweight signature which is classified using a probabilistic subspace similarity technique by learning inter-action and intra-action models. Quantitative and qualitative results of our algorithm are reported on MuHAVi a publicly available multi-camera multi-action dataset.