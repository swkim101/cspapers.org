For many robotic systems, automated data acquisition is an important part of detecting and recognizing objects. This is true especially for robots like the PR2 which are supposed to operate in human environments like our homes. Human living environments are usually highly cluttered. Thus, oftentimes, a scene can not be fully observed from one position only. For scenes like this, data acquisition is treated as a sensor placement problem, also known as the Next-Best-View (NBV) problem. The NBV approach seeks a single additional sensor placement in order to improve the knowledge of the environment. However, the set of possible NBV positions is constrained by the robots abilities. For instance, if the sensor is mounted on the head of the robot, the position of the sensor can only be changed by driving the robot around. In environments like kitchens this can make information gathering difficult, as countertops are only accessible from one side, making it difficult for the robot to observe the objects on the countertop from a different angle. We address automatic data acquisition in scenarios like this in this work. To enable the PR2 to handle constrained positioning settings like this, we equip it with a camera system mounted on the high dimensional manipulator. The camera system we are using for our system is the Microsoft Kinect, which provides us a point cloud representation of the scene. The increase in degrees of freedom allows the robot to choose from a bigger set of possible viewing positions allowing it to observe an area which would otherwise be inaccessible. Additionally, we consider the possibility of planning the trajectory to the NBV position such that the movement can be used to collect even more data. In the following section we introduce the main ideas of our approach. Then we illustrate and discuss first results obtained through this approach.