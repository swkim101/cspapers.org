In this paper, we propose a new method for object tracking, which is primarily based on the results from prof. Shinagawa's image matching. We provide a method that tracks an object and follows it in real-time through a sequence of images which are given, for example, by a robotic camera. The main feature of the method is that it is not affected by the movements (within a certain reasonable range) of the camera or the object; such as, translation, rotation or scaling. The algorithm is also insensible to regular changes of the object's shape. For real-time applications, the algorithm allows the tracking of an object through a sequence of 64*64 images, at a rate of over 8 frames/second.