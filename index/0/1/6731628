Die-stacked DRAMs have been proposed that combine multiple layers of dense memory cells with a base logic layer to implement peripheral circuitry (decoders, sense amps), interface logic, and test structures. Even after implementing these various features, the base logic layer still contains significant unutilized space, providing an opportunity to add more functionality to the memory stack. One seemingly obvious approach is to add a cache to the base layer, which can potentially provide faster memory access while reducing the number of slow and power-hungry row buffer activations and closings. However, once the details of the internal DRAM buses are properly modeled, along with the timing constraints imposed by modern DRAM technologies, a conventional cache only provides a modest performance benefit. This work proposes a “file-managed” row buffer cache (FM-RB$) approach inspired by traditional register allocation and peep-hole optimization ideas from compiler design. By explicitly managing the allocation and deallocation of the row buffer “registers,” the FM-RB$ can deliver performance benefits beyond a conventional cache approach.