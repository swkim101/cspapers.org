We extend previous work on texture mapping video streams into virtual environments by introducing awareness driven video QoS. This uses movements within a shared virtual world to activate different video services. In turn, these services have different settings for underlying QoS parameters such as frame-rate, resolution and compression. We demonstrate this technique through a combined conferencing! mediaspace application which uses awareness driven video for facial expressions and for views into remote physical environments. We reflect on the issues of spatial consistency, privacy, seamless shifts in mutual involvement and making underlying QoS mechanisms more visible, malleable and flexible.