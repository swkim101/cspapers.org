Developing automated agents that intelligently perform complex real world tasks is time consuming and expensive. The most expensive part of developing these intelligent task performance agents involves extracting knowledge from human experts and encoding it into a form useable by automated agents. Machine learning from a sufficiently rich and focused knowledge source can significantly reduce the cost of developing intelligent performance agents by automating the knowledge acquisition and encoding process. Potential knowledge sources include instructions from human experts, experiments performed in the task environment and observation of an expert performing the task. Observation is particularly well suited to learning hierarchical performance knowledge for tasks that require realistic, human-like behavior. Our learning by observation system, called KnoMic (Knowledge Mimic), extracts knowledge from observations of an expert performing a task and generalizes this knowledge into rules that an agent can use to perform the same task. Learning performance knowledge by observation is more efficient than hand-coding the knowledge in a number of ways. Knowledge can be encoded directly from the expert without the need for a knowledge engineer to act as an intermediary. Also, the expert only needs to demonstrate the task rather than organize and communicate all the relevant information. This paper will describe the knowledge required for task performance, describe how this knowledge is learned by KnoMic, and report on our efforts to learn performance knowledge in the tactical air combat domain and the computer game Quake II.