A fundamental problem in Natural Language Processing is the integration of syntactic and semantic constraints. In this paper we describe a new approach for the integration of syntactic and semantic constraints which takes advantage of a learned memory model. Our model combines localist representations for the integration of constraints and distributed representations for learning semantic constraints. We apply this model to the problem of structural disambiguation of noun phrases and show that a learned connectionist model can scale up the underlying memory of a Natural Language Processing system.