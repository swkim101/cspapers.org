Robots are often equipped with 2D laser-rangefinders (LRFs) and cameras since they complement well to each other. In order to correctly combine measurements from both sensors, it is required to know their relative pose, that is, to solve their extrinsic calibration. In this paper we present a new approach to such problem which relies on the observations of orthogonal trihedrons which are profusely found as corners in human-made scenarios. Thus, the method does not require any specific pattern, which turns the calibration process fast and simpler to perform. The estimated relative pose has proven to be also very precise since it uses two different types of constraints, line-to-plane and point-to-plane, as a result of a richer configuration than previous proposals that relies on plane or V-shaped patterns. Our approach is validated with synthetic and real experiments, showing better performance than the state-of-art methods.