Many models of natural language understanding make inference decisions as they process a text, but few models can correct their interpretation when later text reveals that earlier inference decisions are wrong. This paper describes how ATLAST, a markerpassing model of text understanding, addresses this problem. The keys to ATLAST's error recovery capability are a means for remembering the choices it could have made but did not, and a means for initiating the re-evaluation of those previously rejected choices at the appropriate times. This paper also discusses some of the arguments for and against the psychological validity of a theory of inference retention in human text understanding.