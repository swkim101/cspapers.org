The accurate and effective measurement of graph-similarity has proved to be a challenging problem in structural pattern recognition. In this paper we extend the node coverage approach for graph indexing, which outperforms entropic manifold alignment. The proposed extension relies on replacing the Henze-Penrose divergence by a Total Bregman Divergence (TBD) which relies on error free distances (Frobenius norms) for the tensors of the common tangent space. To that end we exploit linear combinations of Gaussians which can be computed faster than the minimum spanning trees needed for obtaining the Henze-Penrose divergence. In the paper we also propose several divergences for these variables (linear combinations): Jeffreys TBD, Jensen-Shannon TBD and Jensen-RÃ©nyi. In our experiments we show that all of these divergences are highly discriminative: all of them improve the retrieval-recall results obtained with the Henze-Penrose divergence within the node coverage approach, being the Jeffreys TBD divergence the best.