We investigate the relevance of surface haptic rendering techniques for tactile devices. We focus on the two major existing techniques and show that they have complementary benefits. The first one, called textsc{S}urface textsc{H}aptic textsc{O}bject (textsc{SHO}), which is based on finger position, is shown to be more suitable to render sparse textures; while the second one, called textsc{S}urface textsc{H}aptic textsc{T}exture (textsc{SHT}), which is based on finger velocity, is shown to be more suitable for dense textures and fast finger movements. We hence propose a new rendering technique, called textsc{L}ocalized textsc{H}aptic textsc{T}exture (textsc{LHT}), which is based on the concept of textit{taxel} considered as an elementary tactile information that is rendered on the screen. By using a grid of taxels to encode a texture, textsc{LHT} is shown to provide a consistent tactile rendering across different velocities for high density textures, and is found to reduce user textit{error rate} by up to 77.68% compared to textsc{SHO}.