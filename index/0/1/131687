The goal of transfer learning algorithms is to utilize knowledge gained in a source task to speed up learning in a different but related target task. Recently, several transfer methods for reinforcement learning have been proposed. A lot of them require a mapping that relates features from the source task to those of the target task, and most of the time it is the task of a domain expert to hand code these mappings. This paper proposes a method to learn such a mapping automatically from interactions with the environment, using a probability tree to represent the probability that the optimal action learned in the source task is useful in the target task. Preliminary experiments show that our approach can learn a meaningful mapping that can be used to speed up learning through the execution of transferred actions during exploration.