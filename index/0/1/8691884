There has been much progress recently on improved approximations for problems involving submodular objective functions, and many interesting techniques have been developed. However, the resulting algorithms are often slow and impractical. In this paper we develop algorithms that match the best known approximation guarantees, but with significantly improved running times, for maximizing a monotone submodular function f: 2[n] â†’ R+ subject to various constraints. As in previous work, we measure the number of oracle calls to the objective function which is the dominating term in the running time. 
 
Our first result is a simple algorithm that gives a (1--1/e -- e)-approximation for a cardinality constraint using O(n/e log n/e) queries, and a 1/(p + 2e + 1 + e)-approximation for the intersection of a p-system and e knapsack (linear) constraints using O (n/e2 log2 n/e) queries. This is the first approximation for a p-system combined with linear constraints. (We also show that the factor of p cannot be improved for maximizing over a p-system.) The main idea behind these algorithms serves as a building block in our more sophisticated algorithms. 
 
Our main result is a new variant of the continuous greedy algorithm, which interpolates between the classical greedy algorithm and a truly continuous algorithm. We show how this algorithm can be implemented for matroid and knapsack constraints using O(n2) oracle calls to the objective function. (Previous variants and alternative techniques were known to use at least O(n4) oracle calls.) This leads to an O(n2/e4 log2 n/e)-time (1--1/e -- e)-approximation for a matroid constraint. For a knapsack constraint, we develop a more involved (1--1/e -- e)-approximation algorithm that runs in time O(n2(1/e log n)poly(1/e)).