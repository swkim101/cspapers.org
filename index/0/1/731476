While there has been recent successes in learning single control policies, there are several several open challenges in robot motor skill learning. Firstly, many motor tasks can be solved in multiple ways, and, hence, we need to be able to learn each of these solutions as separate options from which the agent can choose from. Furthermore, we need to learn how to adapt an option to the current situation. Finally, we need to be able to combine several options sequentially in order to solve an overall-task. As we want to use our method for real robots, a high data efficiency is a natural additional requirement for motor skill learning. In this paper we summarize our work on information-theoretic motor skill learning. We show how to adapt the relative entropy policy search (REPS) algorithm for learning parametrized options and extend the algorithm in a mathematical sound way such that it can meet all these requirements. Finally, we summarize our experiments conducted on real robots.