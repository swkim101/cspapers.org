Estimating questions’ di culty levels is an important task in community question answering (CQA) services. Previous studies propose to solve this problem based on the question-user comparisons extracted from the question answering threads. However, they su er from data sparseness problem as each question only gets a limited number of comparisons. Moreover, they cannot handle newly posted questions which get no comparisons. In this paper, we propose a novel question di culty estimation approach called Regularized Competition Model (RCM), which naturally combines question-user comparisons and questions’ textual descriptions into a unified framework. By incorporating textual information, RCM can e ectivelydeal with data sparseness problem. We further employ a K-Nearest Neighbor approach to estimate di culty levels of newly posted questions, again by leveraging textual similarities. Experiments on two publicly available data sets show that for both well-resolved and newly-posted questions, RCM performs the estimation task significantly better than existing methods, demonstrating the advantage of incorporating textual information. More interestingly, we observe that RCM might provide an automatic way to quantitatively measure the knowledge levels of words.