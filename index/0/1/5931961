Multi-label learning deals with ambiguous examples each may belong to several concept classes simultaneously, In this learning framework, the inherent ambiguity of each example is explicitly expressed in the output space by being associated with multiple class labels. While on the other hand, its ambiguity is only implicitly encoded in the input space by being represented by only a single instance. Based on this recognition, we hypothesize that if the inherent ambiguity can be explicitly expressed in the input space appropriately, the problem of multi-label learning can be solved more effectively. We justify this hypothesis by proposing a novel multi-label learning approach named INS-DIF. The core of INSDIF is instance differentiation that transforms an example into a bag of instances each of which reflects the example's relationship with one of the possible classes. In this way, INSDIF directly addresses the inherent ambiguity of each example in the input space. A two-level classification strategy is employed to learn from the transformed examples. Applications to automatic web page categorization, natural scene classification and gene functional analysis show that our approach outperforms several well-established multi-label learning algorithms.