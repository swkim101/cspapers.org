We address the problem of computing dense range maps of indoor locations using only intensity images and partial depth. We allow a mobile robot to navigate the environment, take some pictures and few range data. Our method is based on interpolating the existing range data using statistical inferences learned from the available intensity image and from those (sparse) regions where both range and intensity information is present. The spatial relationships between the variations in intensity and range can be efficiently captured by the neighborhood system of a Markov random field (MRF). In contrast to classical approaches to depth recovery (i.e. stereo, shape from shading), we can afford to make only weak assumptions regarding specific surface geometries or surface reflectance functions since we compute the relationship between existing range data and the images we started with. Experimental results show the feasibility of our method.