Language engineers often point to tight connections between their systems' linguistic representations and accumulated sensor data as a sign that their systems really mean what they say. While we believe such connections are an important piece in the puzzle of meaning, we argue that perceptual grounding alone does not suffice to explain the specific, stable meanings human speakers attribute to each other. Instead, human attributions of meaning depend on a process of societal grounding by which individual language speakers coordinate their perceptual experience and linguistic usage with other members of their linguistic communities. For system builders, this suggests that implementing a strategy of societal grounding would justify the attribution of bona fide linguistic meaning to a system even if it had little perceptual experience and only modest perceptual accuracy. We illustrate the importance and role of societal grounding using an implemented dialogue system that collaboratively identifies visual objects with human users.