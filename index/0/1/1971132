In many online learning problems we are interested in predicting local information about some universe of items. For example, we may want to know whether two items are in the same cluster rather than computing an assignment of items to clusters; we may want to know which of two teams will win a game rather than computing a ranking of teams. Although finding the optimal clustering or ranking is typically intractable, it may be possible to predict the relationships between items as well as if you could solve the global optimization problem exactly. Formally, we consider an online learning problem in which a learner repeatedly guesses a pair of labels (ℓ(x), ℓ(y)) and receives an adversarial payoff depending on those labels. The learner's goal is to receive a payoff as good as the best fixed labeling of the items. We show that a simple algorithm based on semidefinite programming can achieve asymptotically optimal regret in the case where the number of possible labels is constant, resolving an open problem posed by Hazan, Kale, and Shalev-Schwartz [10]. Our main technical contribution is a novel use and analysis of the log det regularizer, exploiting the observation that log det (Σ + I) upper bounds the entropy of any distribution with covariance matrix Σ.