Introduction Either directly or indirectly, the lexicon for a natural language specifies complementation frames or valences for open-class words such as verbs and nouns. Constructing a lexicon of complementation fram<:~s for larg<-'! vocabularies constitutes a challenge of scale, with the further complication that frame usage, like vocabulary, varies with genre and undergoes ongoing: innovation in a living language. This paper addresses this problem by means of a learning tech·· niquc baswi on probabilistic lexicalized context free grammars and the expectation-maximi~";ation (EM) algorithm. Given a hand-written grammar and a text corpus, frequencies of a head word accompanied by a frame are estimated using the inside-outside algorithm, and such frequencies are used to compute probability para.meters characterizing subcategorization. The procedure can be iterated for improved models. \Nc show that the scheme is practical for large vocabularies and accurate enough to capture differences in usage, such as those characteristic of different domains.