Prefetching is a commonly used technique of improving low-level cache usage that predicts memory requests ahead of time and thus, improves performance by hiding memory latency. Several prefetching algorithms are implemented in hardware. For example, the Intel Core2 processor has 4 different prefetchers, each of which serves a different type of data access pattern. These prefetchers are enabled by default, based on the assumption that the prefetch unit will be triggered when it can successfully prefetch data. However, we have discovered that this assumption is incorrect and can at times hurt performance by up to 11%. We present a simple and easy-to-use framework that determines which hardware-prefetching configuration should be used for a specific workload. The guiding principle of this work that sets it apart from other similar ones is that it fits well within the development process of an average programmer possessing no detailed hardware specific knowledge. For two programs in the PARSEC benchmark, on an Intel Core2 machine, our framework results in an effective speedup of 19% compared to the baseline default setting of using all available prefetchers.