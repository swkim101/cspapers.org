One of the major 'weaknesses of current automated reasoning systems is that they lack the ability to control inference in a sophisticated, context-directed fashion. General strategies such as the set-of-support strategy are useful, but have proven inadequate for many individual problems. A strategy component is needed that possesses knowledge about many particular domains and problems. Such a body of knowledge would require a prohibitive amount of time to construct by hand. This leads us to consider means of automatically acquiring control knowledge from example proofs. One particular means of learning is explanation-based learning. This paper analyzes the basis of explanations -- finding weakest preconditions that enable a particular rule to fire -- to derive a representation within which explanations can be extracted from examples, generalized and used to guide the actions of a problem-solving system.