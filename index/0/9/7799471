All projects in AI begin by selecting or devising knowledge representations suitable for the projectâ€™s functional requirements. Interactive systems (including games) have semiotic considerations on top of their functional requirements: they must be legible to users, players, and their own designers. AI working within or around interactive systems must acknowledge and support the concerns of human users. These concerns are generally phrased as inductive bias or domain knowledge and handled in an ad hoc way; I argue that it is possible and useful to represent them explicitly within a unifying approach. This work refines and extends operational logics, an interpretive framework describing how interactive systems communicate their own mechanisms to users. Making this move yields formal notations for interactive systems that are useful for humans and machines, with applications in modeling, verification, general game-playing, reverseengineering, and automatic self-documentation.