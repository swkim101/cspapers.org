We present an analysis of how the generalization performance (expected test set error) relates to the expected training set error for nonlinear learning systems, such as multilayer perceptrons and radial basis functions. The principal result is the following relationship (computed to second order) between the expected test set and training set errors: 〈etest(λ)〉ξξ′ ≈ 〈etrain(λ)〉ξ + 2σeff2 peff(λ)/n (1) Here, n is the size of the training sample ξ, σeff2 is the effective noise variance in the response variable(s), λ, is a regularization or weight decay parameter, and Peff(λ) is the effective number of parameters in the nonlinear model. The expectations 〈 〉 of training set and test set errors are taken over possible training sets ξ and training and test sets ξ′ respectively. The effective number of parameters peff(λ) usually differs from the true number of model parameters p for nonlinear or regularized models; this theoretical conclusion is supported by Monte Carlo experiments. In addition to the surprising result that peff(λ) ≠ p, we propose an estimate of (1) called the generalized prediction error (GPE) which generalizes well established estimates of prediction risk such as Akaike's F P E and AIC, Mallows Cp, and Barron's P S E to the nonlinear setting.