As the price of cameras and computing elements continue to fall it becomes increasingly feasible to consider the deployment of smart camera networks. Such networks would be composed of small, networked computers equipped with inexpensive image sensors. Consider, for example, the proliferation of camera equipped cell phones. Such camera networks could be used to support a wide variety of applications including environmental modeling, 3D model construction and surveillance. A number of research efforts at a variety of institutions are currently directed towards realizing aspects of this vision. One critical problem that must be addressed in such systems is the issue of localization. That is, in order to take full advantage of the images gathered from multiple vantage points it is helpful to know where the cameras are located with respect to each other. In our system each of the smart cameras is equipped with a co-located controllable light source which it can use to signal other smart cameras in the vicinity. By analyzing the images that it acquires over time, each smart camera is able to locate and identify other smart cameras in the scene. This arrangement makes it possible to directly determine the epipolar geometry of the camera system from image measurements and, hence, recover the relative positions and orientations of the smart camera nodes. We will demonstrate a small scale version of an auto configuring camera network consisting of 3 to 5 smart cameras, we will show how they can accurately localize each other in real time and how they adapt to changes in the configuration.