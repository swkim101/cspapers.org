We propose a novel generative learning framework for activity categorization. In order obtain statistical insight into the underlying patterns of motions in activities, we propose a supervised dynamic, hierarchical Bayesian model which connects low-level visual features in videos with poses, motion patterns and classes of activity. Our proposed generative model harnesses both the temporal ordering power of dynamic Bayesian networks such as Hidden Markov Models (HMMs) and the automatic clustering power of hierarchical Bayesian models such as the Latent Dirichlet Allocation (LDA) model. We demonstrate the strength of this model by profiling different activities in scenes of varying complexities, by clustering visual events into poses which in turn are clustered into motion patterns. The model also correlates these motion patterns over time in order to define the signatures for classes of activities. We test our model on several publicly available datasets and achieve high accuracy rates.