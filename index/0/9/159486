By sharing processor resources among threads at a very fine granularity, a simultaneous multithreading processor (SMT) renders thread-level parallelism (TLP) and instruction-level parallelism (ILP) operationally equivalent. Under what circumstances are they performance equivalent? In this paper, we show that operational equivalence does not imply performance equivalence. Rather, for some codes they perform equally well, for others ILP outperforms TLP, and for yet others, the opposite is true. In this paper, we define the performance characteristics that divide codes into one of these three circumstances. We present evidence from three codes to support the factors involved in the model.