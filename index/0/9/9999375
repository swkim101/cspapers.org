Biped walking control based on simplified models relies much on online feedback stabilizers to compensate the zero-moment point (ZMP) error which partially comes from the model inconsistency of pattern generation. Inspired by the fact that human improves the performance by practicing a task for multiple times, this paper presents an online learning control framework for improving the robustness during the dominant repetitive phases of walking. The key idea is to learn a compensative feedforward ZMP term from previous ZMP error trajectories in order to achieve better ZMP tracking. Based on the iterative learning control theory, the learning process is conducted online continuously with minimal iteration of two footsteps, which can practically run in parallel with state-of-the-art walking controllers. A varying forgetting factor is designed to reduce the influence of the landing impact. Convergence of the learning control algorithm and improved ZMP tracking performance is verified both in dynamics simulation and experiment on the DLR humanoid robot TORO.