An important issue in multiprogrammed multiprocessor systems is the scheduling of parallel jobs. Most research in the area has focussed solely on the allocation of processors to jobs. However, since memory is also a critical resource for many parallel jobs, the allocation of memory and processors must be coordinated to allow the system to operate most effectively.To understand how to design such coordinated scheduling disciplines, it is important to have a theoretical foundation. To this end, we develop bounds on the achievable system throughput when both memory and processing time are in demand. We then propose and simulate a simple discipline and relate its performance to the throughput bounds. An important result of our work is for the situation in which the workload speedup is convex (from above), but the speedup characteristics of individual jobs are unknown. It shows that an equi-allocation strategy for processors can achieve near-maximum throughput, yet offer good mean response times, when both memory and processors are considered.