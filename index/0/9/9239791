1. PROBLEM AND MOTIVATION A variety of systems for data analytics are available as cloud services today, including Amazon Elastic MapReduce (EMR), Amazon Redshift, Azure’s HDInsight, and several others. While these services greatly facilitate access to compute resources and data analytics software, they remain hard for users to tune in terms of cost and performance. Users choose a price-performance trade-off by selecting a desired number and type of service instances. It is well-known, however, that users have difficulty determining their resource needs and often attempt many configurations before finding a suitable one. Performance-centric service level agreements (SLAs) have recently been proposed in response to the above limitations. In our previous work, we’ve developed Personalized Service Level Agreements (PSLAs), an approach where users purchase service tiers (representing different performance levels) with query time guarantees. However, the challenge behind selling performance-focused SLAs for data analytics is in guaranteeing the query runtimes advertised in the SLAs. To address this problem, we developed the PerfEnforce system. PerfEnforce works with a cloud service to meet the goals of a performance-based SLA. PerfEnforce is designed for sharednothing data management systems (e.g., Myria, Spark, Impala, EMR) supporting data analytic workloads. In Figure 1, we show how PerfEnforce interacts with the PSLAManager system to provide SLAs with performance guarantees. As such, PerfEnforce is designed to support SLAs that guarantee specific query runtimes. Once the user selects a service tier, the cloud service instantiates the corresponding cluster. As the user executes queries, prediction inaccuracies and interference from other tenants using the service can cause query times to differ from the estimated ones purchased by the user. To meet the terms of the performance-based SLA, the system automatically resizes the cluster allocated to the user. PerfEnforce seeks to minimize the cluster size subject to satisfying the query runtime guarantees in the SLA. A second challenge is determining when resources should be terminated or whether new ones should be provisioned. In a cloud setting, provisioning resources is not trivial. Turning resources on or off comes with a time delay that could potentially impact tenant SLAs. In addition, user behav-