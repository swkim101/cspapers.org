Batch gradient descent, Δw(t) = -νdE/dw(t), converges to a minimum of quadratic form with a time constant no better than 1/4λmax/λmin where λmin and λmax are the minimum and maximum eigenvalues of the Hessian matrix of E with respect to w. It was recently shown that adding a momentum term Δw(t) = -νdE/dw(t) + αΔw(t - 1) improves this to 1/4√λmax/λmin, although only in the batch case. Here we show that second-order momentum, Δw(t) = -νdE/dw(t) + αΔw(t -1) + βΔw(t - 2), can lower this no further. We then regard gradient descent with momentum as a dynamic system and explore a non quadratic error surface, showing that saturation of the error accounts for a variety of effects observed in simulations and justifies some popular heuristics.