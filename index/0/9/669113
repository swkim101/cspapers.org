Humans are adept at grasping different objects robustly for different tasks. Robotic grasping has made significant progress, but still has not reached the level of robustness or versatility shown by human grasping. It would be useful to understand what parameters (called grasp measures) humans optimize as they grasp objects, how these grasp measures are varied for different tasks, and whether they can be applied to physical robots to improve their robustness and versatility. This paper demonstrates a new way to gather human-guided grasp measures from a human interacting haptically with a robotic arm and hand. The results revealed that a human-guided strategy provided grasps with higher robustness on a physical robot even under a vigorous shaking test (91%) when compared with a state-of-the-art automated grasp synthesis algorithm (77%). Furthermore, orthogonality of wrist orientation was identified as a key human-guided grasp measure, and using it along with an automated grasp synthesis algorithm improved the automated algorithm's results dramatically (77% to 93%).