Due to recent advances in robot hardware, there is a great demand for vision-based robot localisation techniques [DeSouza and Kak, 2002]. We present a probabilistic sensor model for camera-pose estimation in hallways and other known structured environments. Given a 3D geometrical map of the environment, we want to find an approximate measure of the probability that a given camera image has been obtained at a certain place in the robot's operating environment. Our sensor model is based on feature matching techniques that are simpler than state-of-the-art photogrammetric approaches. This allows the model to be used in probabilistic robot localisation methods, such as Monte Carlo localisation (MCL) [Dellaert et al, 1999]. We have combined photogrammetric techniques for feature projection with the flexibility and robustness of MCL. Moreover, our approach is sufficiently fast to allow for sensor fusion. That is, by using distance measurements from sonars and laser in addition to the visual input, we may be able to improve localisation accuracy. We have used our sensor model with MCL to track the position of a Pioneer 2 robot navigating in a hallway. Possibly, our approach can be used also for localisation in cluttered environments and for shape-based object detection. In the next section, we briefly describe the components of the visual-sensor model. We conclude with a discussion of experimental results.