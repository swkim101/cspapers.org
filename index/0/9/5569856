We present a novel neuromorphic robot that interacts through touch sensing and visual signaling on its surface. The robot's form factor is a convex, hemispheric shell containing trackballs for sensing touch, and LEDs for communication with users. In this paper, we explore tactile sensory decoding by constructing a spiking neural network (SNN) of somatosensory cortex. The SNN uses a biologically inspired, unsupervised learning rule, known as spike timing dependent plasticity, to classify a user's hand movements. In an evaluation of the network's ability to categorize hand movements, both rate and temporal neural coding performed well. Because of its unique form factor and means of interaction, this robot, which is called CARL-SJR, may be useful for exploring the neural coding of touch, and also for Human-Robot Interaction studies.