Many current AI systems assume that the reasoning mechanisms used to manipulate their knowledge may be fixed ahead of time by the designer. This assumption may break down in complex domains. The focus of this research is developing a model of introspective reasoning and learning to enable a system to improve its own reasoning as well as its domain knowledge. Our model is based on the proposal of (Birnbaum et al. 1991) to use a model of the ideal behavior of a case-based system to judge system performance and to refine its reasoning mechanisms; it also draws on the research of (Ram & Cox 1994) on introspective failure-driven learning. This work examines introspection guided by expectation failures about reasoning performance. We are developing a vocabulary of failures for the case-based system, an introspective reasoner which uses a hierarchical model of system behavior, and a method of reusing CBR for parts of the case-based planner itself. The system we are developing combines a modelbased introspective reasoner with a case-based planning system. The planner generates high-level plans for navigating city streets, and is similar in structure to the planner CHEF (Hammond 1989). However, we implement components of the planner using the casebased reasoning mechanisms of the planner as a whole. Our primary interest in this approach is the advantage it offers for developing the model for introspective reasoning. We can reuse expectations that apply to the planner as a whole for its case-based parts. During the planning process, the introspective reasoner compares the planner’s reasoning to its assertions about ideal behavior. When a failure is detected, for instance if the system judges that the retrieved case is not the “best” case in memory, the introspective reasoner considers related assertions to pinpoint the source of the failure and to suggest a solution. In this case our system creates a new index to distinguish the true best case from the bad retrieved case. Determining what information to include in the model and how to structure it are central issues. Birnbaum’s model is a set of high-level assertions applicable to many case-based planners (Birnbaum et al. 199 1).