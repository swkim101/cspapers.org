The goal of saliency detection is to highlight objects in image data that stand out relative to their surrounding. Therefore, saliency detection aims to capture regions that are perceived as important. The most recent bottom-up approaches for saliency detection measure contrast based on visual features in 2D scenes, ignoring depth value. This work presents an effective method to measure saliency by mapping pixels into foreground and background regions in RGB-D images. Namely, we first segment an image into regions to evaluate the object uniqueness and consistency using graph-based segmentation. Then, we utilize the region color, depth, layout and boundary information to produce robust foreground and background saliency measures. Finally, we combine the two saliency maps based on Gaussian weights. As a result, our approach produces high-quality saliency maps, which may be used for further processing like object detection or recognition. Experimental results on two datasets compare our method with the state of the art and highlight its effectiveness.