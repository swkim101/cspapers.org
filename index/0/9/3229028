The mobile robot domain challenges policy-iteration reinforcement learning algorithms with diicult problems of structural credit assignment and uncertainty. Structural credit assignment is particularly acute in domains where \real-time" trial length is a limiting factor on the number of learning steps that physical hardware can perform. Noisy sensors and eeectors in complex dynamic environments further complicate the learning problem, leading to situations where speed of learning and policy exibility may be more important than policy optimality. Input generalization addresses these problems but is typically too time consuming for robot domains. We present two algorithms, YB-learning and YB ? , that perform simple and fast generalization of the input space based on bit-similarity. The algorithms trade oo long-term optimal-ity for immediate performance and exibil-ity. The algorithms were tested in simulation against non-generalized learning across different numbers of discounting steps, and YB was shown to perform better during the earlier stages of learning, particularly in the presence of noise. In trials performed on a sonar-based mobile robot subject to uncertainty of the \real world," YB surpassed the simulation results by a wide margin, strongly supporting the role of such \quick and dirty" generalization strategies in noisy real-time mobile robot domains.