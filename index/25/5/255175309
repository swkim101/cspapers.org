Recognizing human partners is an essential social skill for building personalized and long-term human-robot interactions. However, robots deployed in complex, real-world environments have to face several challenges, such as managing unstructured interactions with multiple users, limited computational resources, and intrinsic and continuous variability of their sensory evidence. To cope with these challenges, we propose a framework to perform autonomous incremental learning for open-set face recognition suitable for unconstrained HRI scenarios. We validated the proposed framework in a real-world experiment, demonstrating its suitability to let the robot autonomously interact with multiple people while creating a labeled database of their faces across various encounters. Furthermore, we evaluated how an off-the-shelf model performed with data gathered from the HRI setting and proposed a fine-tuned model obtained with a transfer learning technique. Analyses about automatic threshold determination and rehearsal methods for memory sampling were also proposed. Our preliminary results suggest that exploiting the first-hand robot's experience could be crucial to ensure better models' performance and, therefore, could be advantageous for the acceptance and effectiveness of social robots in the long run. With this work, we aim to provide insights on continual learning approaches in the HRI field to promote autonomous and personalized solutions meaningful for real-world applications.