Partial computation offloading offers lower latency, privacy (by processing data close to the source), and higher performance. In partial offloading, some of the processing is performed on the less capable Internet-of-Things (IoTs), and more complex computation is performed in more capable cloud computers. Though many well-established security protocols are available to address external intrusion, it introduces significant overhead for large data sample. This overhead is becoming a challenging problem with the recent trend and promises of on-device deep neural network (DNN) inference. This paper studies how much prior data distribution knowledge is required by an intruder to retrieve the input from a partially computed vector. We explore simple and complex DNN tasks, which are unknown to the intruder. We show that for simple datasets, Auto-Encoder(AE) and Variational Auto Encoder(VAE) can retrieve the original input image with a 4% accuracy drop on average. However, the same is not valid for complex data distribution.