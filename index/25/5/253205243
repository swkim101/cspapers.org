Online shopping in the home category enables quick and convenient access to large catalog of products. In particular, users can simultaneously browse for functional requirements, such as size and material, while evaluating aesthetic fit, such as color and style, across hundreds of product offerings. However, the typical user flow requires navigating to an e-commerce retailer’s website first, setting the search/filter parameters that may be generic, and then landing on product pages, one at a time, to make a decision. Upon purchase, ”does not fit” is among the top reasons for returning a product. Amalgamating the above information, we present Search with Space, a novel interactive approach that a) inputs the user’s space as a search parameter to b) filter for product matches that will physically fit, and c) visualize these matches in the user’s space at true scale and in a format that facilitates simultaneous comparison. Briefly, the user leverages augmented reality (AR) to set a proxy 3d product in the desired location, updates the proxy’s dimensions, and takes photos from preset angles. Using spatial information captured with AR, a web-based gallery page is curated with all the product matches that will physically fit and products are shown at true scale in their original photos. The user may now browse products visualized in the context of their space and evaluate based on their shopping criteria, share the gallery page with designers or partners for asynchronous feedback, re-use the photos for a different product class, or re-capture their space with different criteria altogether. Search with Space inverts the typical user journey by starting with the user’s space and maintaining that context across all touch points with the catalog.