Deep learning (DL) is quickly becoming a core technology to process sensor data from IoT devices. Nowadays, data is usually sent to remote Cloud services where GPU-based ML platforms process it. In contrast, our vision is to have IoT devices with local, on-device DL. This can increase privacy and accessibility as well as reduce processing costs. To do so, specialized hardware accelerators are needed to perform ML operations efficiently without high performance CPUs. In this paper we introduce our approach for a generator for ML hardware accelerators in the IoT. We focus specifically on the inference of ML algorithms for a typical class of IoT use cases, i.e., processing time-series data under real-time constraints. Additionally our optimization techniques rely on the co-design of hardware and ML algorithms to explore the most specialized and efficient corners of the design space. In this work we analyze the requirements for our generator, discuss optimization stages and techniques and show a case study based on an LSTM model for traffic flow prediction.