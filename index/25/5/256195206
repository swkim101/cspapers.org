The advancement of semiconductor and battery technologies popularized tiny acoustic wearable devices such as bone conduction wireless headsets. However, this small form factor poses inconvenience when controlling these devices, as they cannot equip large footprint intuitive interfaces such as volume sliders and touch screens. This paper presents a technique using acoustic responses measured by a bone conduction speaker and a microphone to utilize the ear as a touch input interface. We discovered that a finger placed on different parts of the ear affects the acoustic radiation characteristic of the ear, modulating the leaked sound, and by leveraging this effect, the touch position can be estimated. Experimental results show that five distinct frequency responses with five different finger positions can be obtained, which indicates that our method could allow bone conduction headsets to capture continuous finger positions without additional hardware.