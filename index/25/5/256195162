Recent advancements in deep learning techniques have shown great potential for smart Internet of Things (IoT) applications. However, the edge devices of IoT applications often collect and store only limited data, which is insufficient for training modern deep learning models. Collaborative training methods such as cloud computing and federated learning set steps to build robust models for IoT applications, yet these methods bring the concern of data privacy (e.g., untrusted central server, model inversion). On the other hand, directly applying privacy-preserving techniques such as differential privacy can dramatically degrade the performance of IoT applications. Inspired by the development of model personalization, we aim to design a federated learning framework in a personalized fashion to reduce the accuracy loss caused by privacy-preserving techniques. In this paper, we present PFed-LDP, a private and accurate federated local differential privacy (LDP) framework for IoT sensing data. We first design a dynamic layer sharing mechanism to separate the local model into global layers and personalized layers. Second, we apply LDP noise to the global layers and transmit them to the federated learning framework for aggregation. Third, each local client updates their model with local personalized layers and aggregated global layers to perform IoT tasks. Our experiments on real-world datasets show that we only sacrifice 1.6% of accuracy to achieve privacy-preserving IoT applications. We also observe that our method has the smallest accuracy range, which means we can achieve the best performance for the worst performed client.