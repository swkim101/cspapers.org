The challenge of dynamic mapping and Human-Machine Co-adaptation (HMCo) is solved by the proposed Co-Adaptive Policy Gradient Algorithm (Co-PGA), a modified version of the Policy Gradient Algorithm (PGA). In this paper, the algorithm is applied to solve a problem where a human is using a joystick to control an object, but the joystick is twisted, which results in a mismatch between the human's desired movements and the machine's output. The results show that the algorithm is successful in compensating for the twisting mismatch by co-adapting to human behavior and determining the best policy to follow the moving target on the screen. The algorithm is model-free and works under the assumption that humans are rational in their behavior. The fact that there is no direct communication between the machine and the human is significant and emphasizes the efficiency of the suggested algorithm. The novel Co-PGA contributes significantly to the field of Human Machine Interaction (HMI) and has the potential to improve the performance of human-machine systems in a wide range of applications.