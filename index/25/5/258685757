While birdâ€™s-eye-view (BEV) perception models can be helpful in building high-definition maps (HD maps) with less human labor, their results are often unreliable and demonstrate noticeable inconsistencies in the predicted HD maps from different viewpoints. This is because BEV perception is typically set up in an "onboard" manner, which restricts the computation and prevents algorithms from simultaneously reasoning multiple views. This paper overcomes these limitations and advocates a more practical "offboard" HD map generation setup that removes the computation constraints, based on the fact that HD maps are commonly reusable infrastructures built offline in data centers. To this end, we propose a novel offboard pipeline called MV-Map that capitalizes multi-view consistency and can handle an arbitrary number of frames with the key design of a "region-centric" framework. In MV-Map, the target HD maps are created by aggregating all the frames of onboard predictions, weighted by the confidence scores assigned by an "uncertainty network." To further enhance multi-view consistency, we augment the uncertainty network with the global 3D structure optimized by a voxelized neural radiance field (Voxel-NeRF). Extensive experiments on nuScenes show that our MV-Map significantly improves the quality of HD maps, further highlighting the importance of offboard methods for HD map generation. Our code and model are available at https://github.com/ZiYang-xie/MV-Map.