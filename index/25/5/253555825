The rising advancement in deep learning (DL) techniques has enabled machine learning (ML) models to assist practitioners in performing medical tasks with high accuracy. However, it also poses privacy concerns regarding how such models will proceed with medical data containing protected patient health information. Therefore, some efforts have been made to anonymize medical data to preserve data privacy while keeping the model performance high enough to avoid wrong decisions in the medical field. Nevertheless, the adversary can develop an ML model to re-identify a patient's identity by matching an arbitrary chest X-ray image with a public or leaked image dataset with high accuracy. This paper aims to find a trade-off between our privacy protection method and data utility for medical images. Specifically, we propose a solution to anonymize chest X-ray images by directly adding noise to the images to prevent verification attacks and evaluate how well those images can maintain good performance in the lung disease classification task. Simulation results on real-world datasets show that the proposed solution achieved a good trade-off between privacy protection and data utility.