Dialogue state is a key information in traditional task-oriented dialogue systems, which represents the user's dialogue intention at each moment through a set of (slot, value). The recent methods model the slot and the dialogue context to keep track of the state, but there is a lack of refinement of context information. They do not consider the influence of dialogue context in different scenarios. Our proposed approach utilizes a fine-grained representation of each slot at multiple levels and incorporates an interaction mechanism to obtain a weight of past memory, present utterance and relevance of the slots. Besides, to address the problem that the dialogue utterance is semantically distant from the corresponding slot value, we introduce the contrastive learning to make the utterance embedding mapped under each slot name more suitable with the ground truth value and away from other slot values. This improves the accuracy of mapping between feature space and semantic space. In the predefined ontology-based approaches, our model achieves leading results with both MultiWOZ2.0 and MultiWOZ2.1 datasets.