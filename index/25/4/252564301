We examine the behaviour of an aspect-based 001 sentiment classiﬁer built by ﬁne-tuning the 002 BERT BASE model on the SemEval 2016 En-003 glish dataset. In a set of masking experiments, 004 we examine the extent to which the tokens 005 which express the sentiment towards the as-006 pect are being used by the classiﬁer. The en-007 hanced performance of a classiﬁer that only 008 sees the relevant sentiment expressions sug-009 gests that they are not being used to their full 010 potential. Furthermore, sentiment expressions 011 which are not directly relevant to the aspect 012 in focus also appear to be used. We then use 013 a gradient-based method to identify the most 014 salient words. A comparison of these salient 015 words, or rationales, with the sentiment expres-016 sions reveals only a moderate level of agree-017 ment. Some disagreements are related to the 018 ﬁxed length of the rationales and the tendency 019 of the rationales to contain content words re-020 lated to the aspect itself. 021