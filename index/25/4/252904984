We observe significant interest in reinforcement learning methods for real-world sensing-control scenarios driven by the sensor data streams. However, the delay introduced to the data by the communication channels may degrade the system's performance. It is especially crucial in the internet of things (IoT), where devices with constraint resources and low throughput networks are used. We demonstrate TinyRL framework, a different approach to this problem, by transferring RL algorithms knowledge to resource-limited devices. Our initial experiments point towards a successful demonstration of our technique using common microcontrollers used in IoT systems. Such devices have limited resource capability, and their regulation by processing data directly on devices without their transmission to the cloud can play a crucial role in their lifespan and usefulness.