Fuzz testing is an active area of research with proposed improvements published at a rapid pace. Such proposals are assessed empirically : Can they be shown to perform better than the status quo? Such an assessment requires a benchmark of target programs with well-identiﬁed, realistic bugs. To ease the construction of such a benchmark, this paper presents F IX R EVERTER , a tool that automatically injects realistic bugs in a program. F IX R EVERTER takes as input a bugﬁx pattern which contains both code syntax and semantic conditions. Any code site that matches the speciﬁed syntax is undone if the semantic conditions are satisﬁed, as checked by static analysis, thus (re)introducing a likely bug. This paper focuses on three bugﬁx patterns, which we call conditional-abort , conditional-execute , and conditional-assign , based on a study of ﬁxes in a corpus of Common Vulnerabilities and Exposures (CVEs). Using F IX R EVERTER we have built R EV B UG B ENCH , which consists of 10 programs into which we have injected nearly 8,000 bugs; the programs are taken from FuzzBench and Binutils, and represent common targets of fuzzing evaluations. We have integrated R EV B UG B ENCH into the FuzzBench service, and used it to evaluate ﬁve fuzzers. Fuzzing performance varies by fuzzer and program, as de-sired/expected. Overall, 219 unique bugs were reported, 19% of which were detected by just one fuzzer.