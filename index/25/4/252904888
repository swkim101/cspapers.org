Argumentative Zoning (AZ) is a tool to obtain informative summaries of scientific articles. Using AZ assumes the definition of the main rhetorical structure in scientific articles, which are, then, used for the summary creation. The unavailability of large AZ annotated benchmark datasets is a bottleneck to training AZ-based summarization algorithms. In this work, we present an annotation platform for an AZ that defines four categories (zones), Claim, Method, Result and Conclusion, that are used to label sentences selected from scientific articles. The proposed tool can be used both for collecting benchmark datasets, and to help the researchers to create their own sub-corpora.