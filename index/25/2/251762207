This work addresses the design of cancer therapy for tumour reduction using adaptive optimal control based on reinforcement learning. The approach proposed consists of defining a decreasing reference trajectory for the tumour size, that drives it to zero with a convenient rate, together with a regulation algorithm that adjusts the drug dose so that the tumor size tracks this reference. The motivation to use adaptive methods stems from the high variability of biomedical dynamics, both inter and intra-patient, together with the aim of providing the regulation controller with the ability to tune to the optimal solution when the tumor size decreases. The adaptation mechanism uses Q-learning and a quadratic cost, resulting in a model-free linear quadratic controller. Directional forgetting recursive least squares is used to estimate the coefficients of the quality function. Simulation results, with a logistic tumor model that incorporates the the effect of immunotherapy are presented.