In few-shot image classification, it is challenging for deep neural networks to infer the true class of an image when it contains multiple class-unrelated objects and its label carries no semantic meanings, such as Class 1 or Class 2. In contrast, knowing what are not important in a typical classification task, humans can quickly identify the right class objects with very few images. In this paper, we propose to extract semantic features from a given dataset to filter out class-unrelated objects in a few-shot task. Each semantic feature is meta-learned and represents a common object or pattern shared by many tasks. The strengths of these features in a given image are adjusted by an importance kernel encoding the meta-learned knowledge such that class-unrelated objects can be suppressed, and the few-shot classification performance can be improved. To facilitate learning and identifying semantic features in an image, we further propose an image representation decomposition module to decouple complex correlations between objects in an image embedding. The experimental analysis demonstrates the effectiveness of our method, especially in the extremely low-shot cases.