For real-world graph data, the node class distribution is inherently imbalanced and long-tailed, which naturally leads to a few-shot learning scenario with limited nodes labeled for newly emerging classes. There are many carefully designed solutions for such a few-shot learning problem via methods such as data augmentation, learning transferable initialization, learning prototypes, and many more. However, most, if not all, of them are based on a strong assumption that all the test nodes exclusively come from novel classes, which is impractical in real-world applications. In this paper, we study a broader and more realistic problem named generalized few-shot node classification , where the test samples can be from both novel classes and base classes. Compared with the standard few-shot node classification, this new problem imposes several unique challenges, including asymmetric classification and inconsistent preference . To counter those challenges, we propose a shot-aware neural node classifier ( Stager ) equipped with an uncertainty-based weight assigner module for adaptive propagation. As the existing meta-learning solutions cannot handle this new problem, we propose a novel training paradigm named imbalanced episodic training to ensure the label distribution is consistent between the meta-training and meta-test scenarios. Comprehensive experiments on four real-world datasets demonstrate the effectiveness of our proposed model and training paradigm.