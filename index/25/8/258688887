Computational metaphor processing is an important task for linguistic and psycho-linguistic research. Metaphor identification and interpretation are two major tasks in this domain. Although metaphor identification has been widely studied, the development of metaphor interpretation techniques is much slower. This is likely because of the lack of large annotated datasets and effective pre-trained language models (PLMs) that can support the learning of metaphor interpretation. Thus, we propose a dataset with over 10,000 sequences with token-level metaphor paraphrases and a metaphor processing-oriented PLM with a novel anomalous language modeling (ALM) method. We benchmark our proposed ALM-based PLM with comparable PLM baselines on the new dataset, finding that the ALM method largely improves model performance on metaphor identification and interpretation.