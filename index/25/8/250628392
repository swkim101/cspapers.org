The demand for machine learning systems that can provide both transparency and fairness is constantly growing. Since the concept of fairness depends on the context, studies in the literature have proposed various formalisation and mitigation strategies. In this work, we propose a novel, flexible, discrimination-aware classifier that allows the user to: (i) select and mitigate the desired fairness criterion from a set of available options; (ii) implement more than one fairness criterion; (iii) handle more than one sensitive attribute; and (iv) specify the desired level of fairness to meet specific business needs or regulatory requirements. Our approach is based on an optimised extension to the decision-tree classifier, and aims to provide transparent and fair rules to the final users.