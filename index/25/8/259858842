Unsupervised domain adaptation of machine translation, which adapts a pre-trained translation model to a speciﬁc domain without in-domain parallel data, has drawn extensive attention in recent years. However, most existing methods focus on the ﬁne-tuning based techniques, which is non-extensible. In this paper, we propose a new method to perform unsupervised domain adaptation in a non-parametric manner. Employing only in-domain monolingual data, this method jointly perform nearest neighbour inference on both forward and backward translation directions. The forward translation model creates nearest neighbour datastore for the backward direction, and vice versa, strengthening each other in an iterative style. Experiments on multi-domain datasets demonstrate that our method signiﬁcantly improves the in-domain translation performance and achieves state-of-the-art results among non-parametric methods.