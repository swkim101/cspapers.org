The traditional interaction method for smart eyewear is by touching a control panel located at the temple front of the eyeglass. This method can be unnatural since the control panel and the display are not within the same plane. In this paper, we propose a new and natural interaction technology for smart eyewear that allows users to interact with the rim of the eyeglass without adding additional hardware to the rim. This design is based on an observation that a finger touch would slightly alter the channel frequency response (CFR) of the eyeglass. We use one pair of piezoelectric (PZT) transducers to measure the CFR, and we recognize the tiny CFR changes by analyzing the complex representation of the CFR. The system detects five touch locations using a deep learning classifier. We recruit ten subjects to evaluate the system and the result shows that the system can recognize the five touch locations with an F1 score of 0.91.