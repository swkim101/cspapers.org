Machine Reading Comprehension (MRC) models easily learn spurious correlations from complex contexts such as tabular data. Counter-factual training—using the factual and coun-terfactual data by augmentation—has become a promising solution. However, it is costly to construct faithful counterfactual examples because it is tricky to maintain the consistency and dependency of the tabular data. In this paper, we take a more efficient fashion to ask hypothetical questions like “in which year would the net profit be larger if the revenue in 2019 were $38,298?” , whose effects on the answers are equivalent to those expensive coun-terfactual tables. We propose a hypothetical training framework that uses paired examples with different hypothetical questions to super-vise the direction of model gradient towards the counterfactual answer change. The superior generalization results on tabular MRC datasets, including a newly constructed stress test and MultiHiertt, validate our effectiveness.