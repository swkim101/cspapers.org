Federated Learning (FL) is a widely adopted distributed learning paradigm for to its privacy-preserving and collaborative nature. In FL, each client trains and sends a local model to the central cloud for aggregation. However, FL systems using neural network (NN) models are expensive to deploy on constrained edge devices regarding computation and communication. In this demo, we present FedHD, a FL system using Hyperdimensional Computing (HDC). In contrast to NN, HDC is a brain-inspired and lightweight computing paradigm using high-dimensional vectors and associative memory. Our measurements indicate that FedHD is 3.2×, 3.2×, 5× better on performance, energy and communication efficiency respectively compared to NN-based FL systems whilst maintaining similar accuracy to the state of the art. Our code is available on GitHub1.