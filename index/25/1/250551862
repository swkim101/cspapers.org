When we execute the typical fine-tuning 001 paradigm on continuously sequential tasks, the 002 model will suffer from the catastrophic for-003 getting problem (i.e., they forget the param-004 eters learned in previous tasks when training 005 the model on newly emerged tasks). Exist-006 ing replay-based methods need extra storage 007 for old data to update the parameters of the 008 previous classifier to overcome catastrophic 009 forgetting. Our work aims to achieve the se-010 quential/continual learning of knowledge with-011 out accessing the old data. The core idea is 012 to calibrate the parameters and logits (output) 013 so that preserving old parameters and general-014 ized learning on new concepts can be solved 015 simultaneously. Our proposed framework in-016 cludes two major components, the Logits Cal-017 ibration (LC) and Parameter Calibration (PC). 018 The LC focuses on calibrating the learning of 019 novel models with old models, and PC aims to 020 preserve the parameters of old models. These 021 two operations can maintain the old knowledge 022 while learning new tasks without storing previ-023 ous data. We do experiments on 9 scenarios of 024 the GLUE (the General Language Understand-025 ing Evaluation) benchmark. The experimental 026 results show that our model achieves state-of-027 the-art performance on all scenarios. 028