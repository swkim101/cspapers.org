In recent years, vector representations of words have proven to be extremely useful across a wide range of NLP applications. Because of the broad interest in the topic, it became essential to answer the following question: is it possible to align different embeddings, in order to compare terms belonging to different vector spaces and their relations? While embedding alignment received considerable attention in the literature, how to find the best anchors for this process is still an open problem; in this paper, we propose an unsupervised, automatic method to select words belonging to different corpora that are close from a semantic point of view, and can be used as anchors for aligning their respective embedding spaces.