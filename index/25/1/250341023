Active learning has become a prevalent technique for designing label-efﬁcient algorithms, where the central principle is to only query and ﬁt “infor-mative” labeled instances. It is, however, known that an active learning algorithm may incur unfairness due to such instance selection procedure. In this paper, we henceforth study metric-fair active learning of homogeneous halfspaces, and show that under the distribution-dependent PAC learning model, fairness and label efﬁciency can be achieved simultaneously. We further propose two extensions of our main results: 1) we show that it is possible to make the algorithm robust to the adversarial noise – one of the most challenging noise models in learning theory; and 2) it is possible to signiﬁcantly improve the label complexity when the underlying halfspace is sparse.