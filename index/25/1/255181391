Gesture classification and motion speed regression are always two major issues in myoelectrical prosthetic hand research. However, there is little research considering these two issues in conjunction. Some shared EMG feature information in these two processing tasks is promising to improve the performance of prosthetic hand control. In this study, a joint-loss (JL) neural network architecture is proposed to implement gesture classification and motion speed regression problems in parallel by sharing the hidden neural units in the training process and optimizing the joint loss function. We evaluated the proposed control system through motion experiments performed on six participants. The experiment result shows that the classification and regression models can successfully reproduce smooth movement based on EMG measurement with high accuracy. Furthermore, the possibility of clinical application is demonstrated through the online movement of the real prosthetic hand.