Machine learning (ML) models are often included in high-risk algorithmic decision-making software. Hence, ML is a particularly important facet of ethics education so that models are less biased and more fair to all users. Natural Language Processing (NLP) specifically functions on text, a human produced artifact, making it more prone to inheriting flawed biases. However, teaching about ethics in ML courses is lacking. To address this issue, we created 3 interventions in an NLP course to introduce students to biases in ML models. We employed a combination of hands-on programming activities, lecture, and a project that discusses ML fairness at different levels and for different populations including gender bias and disability bias. Each intervention included a reflection question about bias. We also interviewed 6 students to further understand the impact of the interventions. The answers to the reflection questions and the interviews were qualitatively analyzed using inductive coding. We found that integrating fairness topics throughout the NLP course with repeated discussions led to an overall positive shift in students' attitudes and awareness towards ML fairness.