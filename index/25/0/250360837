Stochastic high-order methods for ﬁnding ﬁrst-order stationary points in nonconvex ﬁnite-sum optimization have witnessed increasing interest in recent years, and various upper and lower bounds of the oracle complexity have been proved. However, under standard regularity assumptions, existing complexity bounds are all dimension-dependent (e.g., polylogarithmic dependence), which contrasts with the dimension-free complexity bounds for stochastic ﬁrst-order methods and deterministic high-order methods. In this paper, we show that the polylogarithmic dimen-sion dependence gap is not essential and can be closed. More speciﬁcally, we propose stochastic high-order algorithms with novel ﬁrst-order and high-order derivative estimators, which can achieve dimension-free complexity bounds. With the access to p -th order derivatives of the objec-tive function, we prove that our algorithm ﬁnds (cid:15) - stationary points with O ( n (2 p − 1) / (2 p ) /(cid:15) ( p +1) /p ) high-order oracle complexities, where n is the number of individual functions. Our result strictly improves the complexity bounds of existing high-order deterministic methods with respect to the dependence on n , and it is dimension-free compared with existing stochastic high-order methods.