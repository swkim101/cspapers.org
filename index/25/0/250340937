We develop a new approach, named Greedy when Sure and Conservative when Uncertain (GSCU), to competing online against unknown and non-stationary opponents. GSCU improves in four aspects: 1) introduces a novel way of learning opponent policy embeddings offline; 2) trains offline a single best response (conditional additionally on our opponent policy embedding) instead of a finite set of separate best responses against any opponent; 3) computes online a posterior of the current opponent policy embedding, without making the discrete and ineffective decision which type the current opponent belongs to; and 4) selects online between a real-time greedy policy and a fixed conservative policy via an adversarial bandit algorithm, gaining a theoretically better regret than adhering to either. Experimental studies on popular benchmarks demonstrate GSCUâ€™s superiority over the state-of-the-art meth-ods. The code is available online at https: //github.com/YeTianJHU/GSCU .