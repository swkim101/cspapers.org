Deep recommender systems (DRS) are intensively applied in modern web services. To deal with the massive web contents, DRS employs a two-stage workflow: retrieval and ranking, to generate its recommendation results. The retriever aims to select a small set of relevant candidates from the entire items with high efficiency; while the ranker, usually more precise but time-consuming, is supposed to further refine the best items from the retrieved candidates. Traditionally, the two components are trained either independently or within a simple cascading pipeline, which is prone to poor collaboration effect. Though some latest works suggested to train retriever and ranker jointly, there still exist many severe limitations: item distribution shift between training and inference, false negative, and misalignment of ranking order. As such, it remains to explore effective collaborations between retriever and ranker. In this work, we present a novel framework for the joint training of retriever and ranker, named CoRR (Cooperative Retriever and Ranker). With CoRR, the retriever is improved by deriving high-quality training signals from the ranker, while the ranker is improved by learning to discriminate hard negatives sampled by the retriever. We introduce two critical techniques. Firstly, we develop an adaptive and scalable sampler based on the retriever, to generate hard negative samples for the ranker’s training. Compared with the widely-used exact top-k sampling, our method effectively alleviates the issues of false negative and item distribution shift, and thus improves the ranker’s discriminability. Secondly, we propose a novel asymptotic-unbiased estimation of KL divergence, which serves as the objective for knowledge distillation. The new objective can be efficiently optimized with commonly-used optimizers. More importantly, it leads to better alignment of ranking order between retriever and ranker, which helps to improve the retrieval quality. We conduct comprehensive experiments over four large-scale datasets, where CoRR outperforms both conventional DRS and the existing joint training methods with notable advantages. Our code will be open-sourced to facilitate future research.