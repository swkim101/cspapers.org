Temporal knowledge graph (TKG) reasoning has attracted significant attention. Recent approaches for modeling historical information have led to great advances. However, the problems of time variability and unseen entities have become two major obstacles preventing further development. The time variability problem means that different historical timestamps play different roles in the inference process. Furthermore, in the context of time variability, the unseen entity problem means that a query cannot obtain a predicted entity that is unseen in the scale-varying history rather than in a fixed set, thus turning from static to dynamic. In this paper, we propose a novel method named DHU-NET for addressing the time variability challenge and the dynamic unseen entity challenge derived from it. With regard to the former concern, we propose a time-distributed representation learning method based on a graph convolutional network(GCN) and a self-attention mechanism, which learns the distributed representations of facts at different historical timestamps and comprehensively pays different levels of attention to the different timestamps. With regard to the latter issue, we extract the unseen entities from a global static KG based on a copy mechanism and bring them into consideration during the final prediction step. Experiments on six benchmark datasets demonstrate the substantial improvements achieved by DHUNET in terms of multiple evaluation metrics. Our released codes are available at https://github.com/CGCL-codes/DHUNET.