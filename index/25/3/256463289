We present a Bayesian deep structured semantic model (BDSSM) that is efficient in retrieval tasks with a large pool of candidates for real-time applications, e.g., in search engines and digital ads. Efficiency is achieved by indexing the items into groups based on sparse representation during offline pre-computation. In online retrieval, the algorithm only retrieves and ranks items from indices that are relevant to the query. We then explore optimization strategies in the algorithm to make sparse representations sparser. Finally, our algorithm is compared with other popular clustering-based, hashing-based, and tree-based retrieval methods. We measure the differences in multiple dimensions, including retrieval recall, storage of embeddings, and CPU time. We show that our approach outperforms other algorithms in both recall and CPU time with the same storage limit.