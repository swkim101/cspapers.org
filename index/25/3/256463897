Graph Neural Networks (GNNs) have attracted much research interest due to their successful applications on graph-structured data. Despite the effectiveness, due to the data dependency, GNNs are confronted with the neighborhood explosion and over-smoothing problems. Many sampling-based and level-down methods have been proposed to solve the neighborhood explosion problem to boost efficiency. However, they suffer from either poor accuracy or considerable runtime overheads. Moreover, the over-smoothing problem prevents GNNs from exploring more distant neighborhoods effectively. In this paper, we present a Community-and-Contraction-based Graph Neural Network (CC-GNN), which leverages community and contraction to boost the time and space efficiency of GNNs. Specifically, CC-GNN first performs contraction and retrieves the communities as super nodes, and connects them using a tailored similarity function to obtain an informative community contracted graph (CC-Graph). CC-GNN then learns the representations of the super nodes in the CC-Graph, which are used to reconstruct the representations of the original nodes. Finally, CC-GNN explores more distant neighborhoods without additional convolution layers, implicitly alleviating the over-smoothing problem. Since CC-GNN conducts the costly training on a much smaller contracted graph, the efficiency is boosted significantly. Most importantly, we have proved that the information loss of node representations caused by the CC-Graph is bounded. Extensive experimental studies verify the efficiency boost and the effectiveness.