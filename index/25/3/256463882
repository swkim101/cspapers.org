Knowledge Graph Question Answering (KGQA) models enable users to acquire entity-based answers from a Knowledge Graph by asking natural language questions (NLQs) without the need to learn a specialized graph query language or knowing the underlying schema of the knowledge graph. This work investigates hyperbolic graph representation learning methods to effectively and efficiently represent knowledge base items and natural questions. Our system, HyperKGQA, proposes a technique that embeds the knowledge graph in a hyperbolic manifold, then learns an adaptive transformation of pre-trained sentence representations into the space of entities and relations. Finally, a post-processing step refines the ranking of the candidate answers by computing the relevance score of the set of relations and the question. An extensive set of experiments conducted on two datasets shows that our method outperforms the current state-of-the-art models when reasoning over sparse graphs to answer multi-hop questions.