Graph neural network (GNN) is effective to model graphs for distributed representations of nodes and an entire graph. Recently, research on the expressive power of GNN attracted growing attention. A highly expressive GNN has the ability to generate discriminative graph representations. However, in the end-to-end training process for a certain graph learning task, an expressive GNN could generate graph representations overfitting the training data for the target task but losing information important for the model generalization, thus reducing the generalizability. In this paper, we propose Distribution Preserving GNN (DP-GNN), a GNN framework that can improve the generalizability of expressive GNN models by preserving several kinds of distribution information in graph representations and node representations. Besides the generalizability, by applying an expressive GNN backbone, DP-GNN can also have high expressive power. We evaluate the proposed DP-GNN framework on multiple benchmark datasets for graph classification tasks. The experimental results demonstrate that our model achieves state-of-the-art performances.