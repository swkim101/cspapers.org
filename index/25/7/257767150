Autonomous navigation is crucial for achieving the full automation of agricultural research and production management using agricultural robots. In this paper, we present a vision-based autonomous navigation approach for agriculture robots in trellised cropping systems, which stands out for its remarkable performance achieved entirely without human annotation. We propose a novel learning-based method that directly estimates the path traversibility heatmap from an RGB-D image and subsequently converts it into a preferred traversal path. One key advantage of our approach lies in its capability to predict the robot's preferred path directly, allowing us to obtain training labels without manual annotation. Specifically, we propose an automatic annotation pipeline that leverages the robot's path recorded during data collection. Furthermore, we develop a full navigation framework by integrating our path detection model with row switching modules, enabling the robot to smoothly transition between crop rows within the vineyard. We conduct extensive field trials in three different vineyards to validate the performance of our autonomous navigation framework. The results demonstrate that our approach provides a cost-effective, accurate, and robust solution for vineyard navigation.