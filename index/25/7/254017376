Recent research showed that the dual-pixel sensor has made great progress in defocus map estimation and image defocus deblurring.
However, extracting real-time dual-pixel views is troublesome and complex in algorithm deployment.
Moreover, the deblurred image generated by the defocus deblurring network lacks high-frequency details, which is unsatisfactory in human perception. To overcome this issue, we propose a novel defocus deblurring method that uses the guidance of the defocus map to implement image deblurring.
The proposed method consists of a learnable blur kernel to estimate the defocus map, which is an unsupervised method, and a single-image defocus deblurring generative adversarial network (DefocusGAN) for the first time.
The proposed network can learn the deblurring of different regions and recover realistic details. We propose a defocus adversarial loss to guide this training process.
Competitive experimental results confirm that with a learnable blur kernel, the generated defocus map can achieve results comparable to supervised methods.
In the single-image defocus deblurring task, the proposed method achieves state-of-the-art results, especially significant improvements in perceptual quality, where PSNR reaches 25.56 dB and LPIPS reaches 0.111.