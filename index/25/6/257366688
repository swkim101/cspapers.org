Evidence for the efficacy of exam wrappers has been varied, with some studies showing an improvement in grades and metacognition and others showing no evidence of improvement. The physical nature of wrappers makes implementation and study replication difficult. In this work, we develop a methodology for the deployment and evaluation of virtual exam wrappers. We then validate our model by replicating existing exam wrapper studies. The study followed 105 students in a CS2 course. Following each quiz and test in the course, students graded tests were returned to them online with a link to a virtual exam wrapper. Students were randomly assigned to one of three conditions. Students in the control condition were asked to complete an exam wrapper with questions about their perceptions of the course and the field of computer science. Students in the metacognition condition were asked questions regarding how they prepared for the test, where they lost marks, and what they planned to change in preparation for the next test. Students in the practice condition were asked to complete a question similar to those evaluated on the test. This initial pilot study validated our experimental design and the feasibility of the virtual wrapper model. No statistically significant differences were found between the groups in terms of grades or course outcomes. However, the ease of scaling the virtual exam wrapper model will allow for larger scale studies and cross institution replication.