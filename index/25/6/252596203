Bangladeshi Sign Language (BdSL)—like other sign languages— is tough to learn for general people, especially when it comes to expressing letters. In this poster, we propose PerSign, a system that can reproduce a person’s image by introducing sign gestures in it. We make this operation “personalized”, which means the generated image keeps the person’s initial image profile–face, skin tone, attire, background—unchanged while altering the hand, palm, and finger positions appropriately. We use an image-to-image translation technique and build a corresponding unique dataset to accomplish the task. We believe the translated image can reduce the communication gap between signers1 and non-signers without having prior knowledge of BdSL.