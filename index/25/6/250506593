Circular economy and agile manufacturing require a safe and efficient industrial robot system working in close human proximity. Although, close proximity local sensing enables safe collaboration with small cobots. However, they cannot ensure safety at high velocities with a heavy-duty industrial robot. Stereo-camera and 3D LiDAR-based touch-less global sensing methods exist, but they do not address the safety standards. This work proposes a novel method for estimating the safety parameters in speed and separation monitoring mode for 3D vision sensors. Accurate estimation of these parameters ensures compact sensing zones. Thus, enabling efficient human-robot collaboration for permanent operator presence. The method requires less effort in setup. The developed software with a graphical user interface enables workers from wide technical expertise to perform safety measurements at a precision of Â±15ms in reaction time estimation. The experiments are repeatable and capture the statistical data for low error in estimation. The estimated parameters for two exemplary 3D sensors enable a human to work in close proximity of 20 cm while enabling safety from a collision.