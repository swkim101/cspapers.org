Current Automatic Speech Recognition (ASR) systems, like Google Assistant, Apple's Siri, or Amazon's Alexa, continue to only support a small number of languages (English, Mandarin, Arabic, etc.), primarily those spoken in developed nations with abundant resources. While these languages have been able to reap the benefits of having such technology at their disposal, places like Ethiopia, and Vietnam are still far behind. This work represents a global collaboration to create a framework for customizing ASR systems for low resource languages (LRLs), or languages with limited human and financial resources. This paper describes the methodology for using an existing application (Kaldi) to implement an ASR system for two such languages, Amharic and Vietnamese, with the least amount of annotated speech. The languages are chosen to leverage available student expertise and create cross-cultural connections. The objective of the research is to create a procedure by which, given enough training records and annotation, any language can be added.