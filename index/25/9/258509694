Transformer-based object detectors have shown competitive performance recently. Compared with convolutional neural networks limited by the relatively small receptive ﬁelds, the advantage of transformer for visual tasks is the capacity to perceive long-range dependencies among all image patches, while the deﬁciency is that the local ﬁne-grained information is not fully excavated. In this paper, we introduce the C oarse-grained and F ine-grained crossing representations to build an efﬁcient D etection T ransformer (CFDT). Speciﬁcally, we propose a local-global cross fusion module to establish the connection between local ﬁne-grained features and global coarse-grained features. Besides, we propose a coarse-ﬁne aware neck which enables detection tokens to interact with both coarse-grained and ﬁne-grained features. Furthermore, an efﬁcient feature integration module is presented for fusing multi-scale representations from different stages. Experimental results on the COCO dataset demonstrate the effectiveness of the proposed method. For instance, our CFDT achieves 48.1 AP with 173G FLOPs, which possesses higher accuracy and less computation compared with the state-of-the-art transformer-based detector ViDT. Code will be available at https: //gitee.com/mindspore/models/tree/master/research/cv/CFDT .