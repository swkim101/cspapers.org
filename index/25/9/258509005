The collaborative inference systems are designed to speed up the prediction processes in edge-cloud scenarios, where the local devices and the cloud system work together to run a complex deep-learning model. However, those edge-cloud collaborative inference systems are vulnerable to emerging reconstruction attacks, where malicious cloud service providers are able to recover the edge-side users’ private data. To defend against such attacks, several defense countermeasures have been recently introduced. Unfortunately, little is known about the robustness of those defense countermeasures. In this paper, we take the ﬁrst step towards measuring the robustness of those state-of-the-art defenses with respect to reconstruction attacks. Speciﬁcally, we show that the latent privacy features are still retained in the obfus-cated representations. Motivated by such an observation, we design a technology called Sensitive Feature Distillation (SFD) to restore sensitive information from the protected feature representations. Our experiments show that SFD can break through defense mechanisms in model partitioning scenarios, demonstrating the in-adequacy of existing defense mechanisms as a privacy-preserving technique against reconstruction attacks. We hope our ﬁndings inspire further work in improving the robustness of defense mechanisms against reconstruction attacks for collaborative inference systems.