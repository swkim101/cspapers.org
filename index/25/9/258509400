This paper considers online convex optimization with hard constraints and analyzes achievable regret and cumulative hard constraint violation (violation for short). The problem distinguishes itself from online convex optimization with soft constraints, where a violation at one round can be compensated/cancelled by a conservative decision at a different round. We propose a RECtiﬁed Online Optimization al-gorithm (RECOO) and consider two settings: ﬁxed constraints and adversarial constraints. Both settings have been considered in the literature. Compared with existing results, RECOO achieves the best of two worlds and beyond. For the ﬁxed-constraints setting, RECOO achieves O ` ? T ˘ regret and O p 1 q violation, where T is the learning horizon. The best known results in this case are O p? T q regret and O ` T 1 { 4 ˘ violation. For the adversarial-constraints setting, it guarantees O p? T q regret and O p T 3 { 4 q violation, which match the best existing results. When the loss function is strongly convex, RECOO can guarantee O p log T q regret and O p 1 q violation for ﬁxed constraints, and O p log T q regret and O p? T log T q violation for adversarial constraints. Both these results are order-wise better than the existing bounds. The regret and violation bounds mentioned above use the best ﬁxed decision in hindsight as the baseline. This paper further considers a dynamic baseline where the comparator sequence is time-varying. This paper shows that RECOO not only improves the existing bounds for the ﬁxed-constraints setting but also for the ﬁrst time, establishes dynamic regret and violation bounds for the adversarial-constraints setting. Our experiment results conﬁrm that RECOO outperforms several existing algorithms for both ﬁxed and adversarial