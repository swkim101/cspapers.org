Recent years have witnessed a growing interest in investigating what Transformer-based language models (TLMs) actually learn from the training data. This is especially relevant for complex tasks such as the understanding of non-literal meaning. In this work, we probe the performance of three black-box TLMs and two intrinsically transparent white-box models on ﬁgurative language classiﬁcation of sar-casm , similes , idioms , and metaphors . We conduct two studies on the classiﬁcation results to provide insights into the inner workings of such models. With our ﬁrst analysis on feature importance, we identify crucial differences in model behavior. With our second analysis using an online experiment with human participants, we inspect different linguistic characteristics of the four ﬁgurative language types.