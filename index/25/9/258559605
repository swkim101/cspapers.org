Remote memory techniques are gaining traction in datacenters because they can signiﬁcantly improve memory utilization. A popular approach is to use kernel-level, page-based memory swapping to deliver remote memory as it is transparent, enabling existing applications to beneﬁt without modiﬁ-cations. Unfortunately, current implementations suffer from high software overheads, resulting in signiﬁcantly worse tail latency and throughput relative to local memory. Hermit is a redesigned swap system that overcomes this limitation through a novel technique called adaptive, feedback-directed asynchrony . It takes non-urgent but time-consuming operations ( e.g. , swap-out, cgroup charge, I/O deduplication, etc. ) off the fault-handling path and executes them asynchronously. Different from prior work such as Fastswap, Hermit collects runtime feedback and uses it to direct how asynchrony should be performed— i.e. , whether asynchronous operations should be enabled, the level of asynchrony, and how asynchronous operations should be scheduled. We implemented Hermit in Linux 5.14. An evaluation with a set of latency-critical applications shows that Hermit delivers low-latency remote memory. For example, it reduces the 99 th percentile latency of Memcached by 99.7% from 36 ms to 91 µ s . Running Hermit over batch applications improves their overall throughput by 1.24 × on average. These results are achieved without changing a single line of user code.