Distributional shifts in photometry and texture have been extensively studied for unsupervised domain adaptation, but their counterparts in optical distortion have been largely neglected. In this work, we tackle the task of unsupervised domain adaptation for semantic image segmentation where unknown optical distortion exists between source and target images. To this end, we propose a d istortion-a ware d omain a daptation (DaDA) framework that boosts the unsupervised segmentation performance. We ﬁrst present a r elative d istortion l earning (RDL) approach that is capable of modeling domain shifts in ﬁne-grained geometric deformation based on diffeomorphic transformation. Then, we demonstrate that applying additional global afﬁne transformations to the diffeomorphically transformed source images can further improve the segmentation adaptation. Besides, we ﬁnd that our distortion-aware adaptation method helps to enhance self-supervised learning by providing higher-quality initial models and pseudo labels. To evaluate, we propose new distortion adaptation benchmarks, where rectilinear source images and ﬁsheye target images are used for unsupervised domain adaptation. Extensive experimental results highlight the effectiveness of our approach over state-of-the-art methods under unknown relative distortion across domains. Datasets and more information are available at https://sait-fdd.github.io/ .