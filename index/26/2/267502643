Graph neural networks (GNNs) have demonstrated remarkable success in various real-world applications. However, they often inadvertently inherit and amplify existing societal bias. Most existing approaches for fair GNNs tackle this bias issue by assuming that discrimination solely arises from sensitive attributes such as race or gender, while disregarding the prevalent labeling bias that exists in real-world scenarios. Additionally, prior works attempting to address label bias through counterfactual fairness often fail to consider the veracity of counterfactual samples. This paper aims to bridge these gaps by investigating the identification of authentic counterfactual samples within complex graph structures and proposing strategies for mitigating labeling bias guided by causal analysis. Our proposed learning model, known as Real Fair Counterfactual GNNs (RFCGNN), also goes a step further by considering the learning disparity resulting from imbalanced data distribution across different demographic groups in the graph. Extensive experiments conducted on three real-world datasets and a synthetic dataset demonstrate the effectiveness and practicality of the proposed RFCGNN approach.