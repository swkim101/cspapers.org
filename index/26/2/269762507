Disinformation refers to the deliberate dissemination of fake or misleading information, which significantly threatens the modern social stability by undermining trust, intensifying polarization and manipulating public opinion. With the advances of generative AI, the landscape of modern disinformation is changing following the rise of Large Language Models. Recent studies has revealed the capability of generative language models to create convincing and misleading content against the truth and warned the availability of such models to be maliciously abused for deceptive generation. However, AI-driven disinformation is a human-centered societal issue in nature, the realization of which requires not only the in- depth discussion on the latest trends from both sides of generative AI and disinformation, but a critical analysis on the uncertainty of their potential interaction in practice as well. The paper introduces the new vision of AI-driven disinformation campaigns from the perspectives of human-centered AI, proposes a framework of core research questions based on the existing research gap, discusses the preliminary discovery in literature and initial experiments, and elaborates the main lines of research in the future work.