This paper investigates the logistic bandit problem, a variant of the generalized linear bandit model that utilizes a logistic model to depict the feedback from an action. While most existing research focuses on the binary logistic bandit problem, the multinomial case, which considers more than two possible feedback values, offers increased practical relevance and adaptability for use in complex decision-making problems such as reinforcement learning. In this paper, we provide an algorithm that enjoys both statistical and computational efficiency for the logistic bandit problem. In the binary case, our method improves the state-of-the-art binary logistic bandit method by reducing the per-round computation cost from O (log T ) to O (1) with respect to the time horizon T , while still preserving the minimax optimal guarantee up to logarithmic factors. In the multinomial case, with K + 1 potential feedback values, our algorithm achieves an (cid:101) O ( K √ T ) regret bound with O (1) computational cost per round. The result not only improves the (cid:101) O ( K √ κT ) bound for the best-known tractable algorithm—where the large constant κ increases exponentially with the diameter of the parameter domain—but also reduces the O ( T ) computational complexity demanded by the previous method.