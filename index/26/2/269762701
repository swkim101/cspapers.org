YouTube's recommendation system is integral to shaping user experiences by suggesting content based on past interactions using collaborative filtering techniques. Nonetheless, concerns about potential biases and homogeneity in these recommendations are prevalent, with the danger of leading users into filter bubbles and echo chambers that reinforce their pre-existing beliefs. Researchers have sought to understand and address these biases in recommendation systems. However, traditionally, such research has relied primarily on metadata, such as video titles, which does not always encapsulate the full content or context of the videos. This reliance on metadata can overlook the nuances and substantive content of videos, potentially perpetuating the very biases and echo chambers that the research aims to unravel. This study advances the examination of sentiment, toxicity, and emotion within YouTube content by conducting a comparative analysis across various depths of titles and narratives extracted by leveraging GPT-4. Our analysis reveals a clear trend in sentiment, emotion, and toxicity levels as the depth of content analysis increases. Notably, there is a general shift from neutral to positive sentiments in both YouTube video titles and narratives. Emotion analysis indicates an increase in positive emotions, particularly joy, with a corresponding decrease in negative emotions such as anger and disgust in narratives, while video titles show a steady decrease in anger. Additionally, toxicity analysis presents a contrasting pattern, with video titles displaying an upward trend in toxicity, peaking at the greatest depth analyzed, whereas narratives exhibit a high initial toxicity level that sharply decreases and stabilizes at lower depths. These findings suggest that the depth of engagement with video content significantly influences emotional and sentiment expressions.