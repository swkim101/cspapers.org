Multi-ﬁdelity fusion has become an important surrogate technique, which provides insights into expensive computer simulations and effectively improves decision-making, e.g., optimization, with less computational cost. Multi-ﬁdelity fusion is much more computationally efﬁcient compared to traditional single-ﬁdelity surrogates. Despite the fast advancement of multi-ﬁdelity fusion techniques, they lack a systematic framework to make use of the ﬁdelity indicator, deal with high-dimensional and arbitrary data structure, and scale well to inﬁnite-ﬁdelity problems. In this work, we ﬁrst generalize the popular autoregression (AR) to derive a novel linear ﬁdelity differential equation (FiDE), paving the way to tractable inﬁnite-ﬁdelity fusion. We generalize FiDE to a high-dimensional sys-tem, which also provides a unifying framework to seemly bridge the gap between many multi-and single-ﬁdelity GP-based models. We then propose ContinuAR, a rank-1 approximation solution to FiDEs, which is tractable to train, compatible with arbitrary multi-ﬁdelity data structure, linearly scalable to the output dimen-sion, and most importantly, delivers consistent SOTA performance with a significant margin over the baseline methods. Compared to the SOTA inﬁnite-ﬁdelity fusion, IFC, ContinuAR achieves up to 4x improvement in accuracy and 62,500x speedup in training time.