Classiﬁcation is a fundamental problem in machine learning, and considerable efforts have been recently devoted to the demanding long-tailed setting due to its prevalence in nature. Departure from the Bayesian framework, this paper rethinks classiﬁcation from a matching perspective by studying the matching probability between samples and labels with optimal transport (OT) formulation. Speciﬁcally, we ﬁrst propose a new variant of optimal transport, called Relative Entropic Optimal Transport (RE-OT), which guides the coupling solution to a known prior information matrix. We gives some theoretical results and their proof for RE-OT and surprisingly ﬁnd RE-OT can help to deblur for barycenter images. Then we adopt inverse RE-OT for training long-tailed data and ﬁnd that the loss derived from RE-OT has a similar form to Softmax-based cross-entropy loss, indicating a close connection between optimal transport and classiﬁcation and the potential for transferring concepts between these two academic ﬁelds, such as barycentric projection in OT, which can map the labels back to the feature space. We further derive an epoch-varying RE-OT loss, and do the experiments on unbalanced image classiﬁcation, molecule classiﬁcation, instance segmentation and representation learning. Experimental results show its effectiveness.