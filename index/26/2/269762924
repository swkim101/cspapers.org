Sequence recommendation tasks often have performance bottlenecks, mainly reflected in the following two aspects: previous research relied on a single item embedding distribution, resulting in a decrease in overall modeling ability. In addition, the implicit dynamic preferences reflected in user interaction sequences are not distinguished, and the feature representation ability is insufficient. To address these issues, we propose a novel model called Diffusion Recommendation with Implicit Sequence Influence (DiffRIS). Specifically, we establish an implicit feature extraction module, which includes multi-scale CNN and residual LSTM networks that learn local and global features of sequence information, respectively, to explore the length dependence of data features. Subsequently, we use the output of the module as a conditional input for the diffusion model, guiding the denoising process based on historical interactions. Through experiments on two open-source datasets, we find that implicit features of sequences have a positive impact on the diffusion process. The proposed DiffRIS framework performs well compared to multiple baseline models, effectively improving the accuracy of sequential recommendation models. We believe that the proposed DiffRIS can provide some research ideas for diffusion sequence recommendation.