
 Multiagent systems have evolved in both research and practice domains over the past decades. Application domains have also broadened into robotic and vehicular systems, among others. A self-organizing system comprises multiple agents and can adapt to changing operational environments. Early work on the self-organizing system has tackled the system design problem by introducing information fields and logical rules. As tasks become more complex, the difficulty of devising the fields and the rules has become harder. To overcome this limitation, a multiagent reinforcement learning based approach has been explored, aiming to let agents acquire the task knowledge by themselves. The research results thus far have verified the effectiveness of the learning-based approach. However, the training process of reinforcement learning takes a long time and a vast amount of computational resources. The question arises: can the previously trained team knowledge, embedded in neural networks, be reused so that the new training time can be significantly reduced? This paper addresses this overall question by investigating the effectiveness of transferring the knowledge of neural networks learned by a certain agent team to another team of the same domain but with different team sizes. Furthermore, the learning team has social abilities: they not only focus on the task states of the environment while learning but also observe the behavior of other agents. The results of this study have demonstrated the potential benefits as well as limitations of knowledge transfer between teams of the same domain but with different team sizes.