Many of today’s mobile robots are supposed to perform everyday manipulation tasks autonomously. However, in large-scale environments, a task-related object might be out of the robot’s reach, that is, the object is currently not perceivable by the robot. Hence, the robot first has to search for the object in its environment before it can perform the task. In this paper, we present an approach for object search in large-scale environments using different search strategies based on semantic environment models. We demonstrate the feasibility of our approach by integrating it into a robot system and by conducting experiments where the robot is supposed to search for objects within the context of fetch-and-delivery tasks within a multi-level building.