and a cosine learning rate schedule with a warm-up for the first 100 epochs. We start with an initial learning rate of 1 e − 4 and a decay of 1 e − 5 . The pre-training has been conducted on four NVIDIA A100 using multi-GPU (4) with distributed data parallel (DDP), implemented in MONAI 0.9.0., with a maximum of 800 epochs. We use the binary cross-entropy and Dice Similarity Coefficient (DSC) losses as the objective function for pre-training.