Driver distraction detection is an important function of driver monitoring systems and intelligent vehicles. Most previous research only focuses on the system development for daytime operations. In this paper, we propose a network model, V2IA-Net, which is able to use the daytime visible and nighttime infrared images for the driver distraction detection task. With the visible-infrared image translation, driver action recognition and head pose detection, the driver distraction behavior can be analyzed in real-time performance. To provide realistic driving scenes for network training and testing, a visible-infrared image dataset, VID, is created. The proposed V2IA-Net is trained on the unpaired images, and capable of common feature extraction for visible-infrared image conversion. In the experiments, our technique is compared with various driver distraction detection models. The results have demonstrated the effectiveness of the proposed method. Source code and datasets are available at https://github.com/kk2487/V2IA-Net.