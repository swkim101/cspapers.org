We consider information networks in the absence of interference and noise, and present an upper bound on the rate at which information can be transmitted using network coding. Our upper bound is based on combining properties of entropy with a strong information inequality derived from the structure of the network.The undirected k-pairs conjecture states that the information capacity of an undirected network supporting k point-to-point connections is achievable by multicommodity flows. Our techniques prove the conjecture for a non-trivial class of graphs, and also yield the first known proof of a gap between the sparsity of an undirected graph and its capacity. We believe that these techniques may be instrumental in resolving the conjecture completely. We demonstrate the importance of the undirected k-pairs conjecture by connecting it with a long-standing open question in Input/Output (I/O) complexity. We also show that proving the conjecture would provide the strongest known lower bound for computation in the oblivious cell-probe model and give a non-trivial lower bound for two-tape oblivious Turing machines.Finally, we conclude by considering the capacity of directed information networks. We construct a family of directed graphs whose capacity is much larger than the rate achievable using only multicommodity flows. The gap that we exhibit is linear in the number of vertices, edges, and commodities of the graph, which is asymptotically optimal.