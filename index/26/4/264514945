Collecting multimodal user data during physical tasks such as cooking, maintenance, or physical rehab is crucial to enable the design of better AI models, interfaces, and applications. However, this is a challenging task with external cameras and sensors due to user movement, self-occlusions and diversity of data streams during task performance. In this work, we present ModBand, a wearable sensor headband with an accompanying software pipeline to collect and visualize data such as facial images, pupillometry, egocentric video, and heart rate during physical task performance. ModBand can be modified, extended, and used both as a standalone device or integrated with existing head-mounted AR devices for AI-based task guidance. Our modular design incorporates cost-effective fabrication methods, such as 3D printing, and enables convenient integration or exclusion of sensors to support custom data collection needs.