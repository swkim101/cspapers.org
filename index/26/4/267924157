Although feature selection is a central problem in inductive learning as suggested by the growing amountof research in this area, most of the work hasbeen carried out underthe supervised learning paradigm, paying little attention to unsupervised learning tasks and, particularly, clustering tasks. In this paper, we analyze the particular bene(cid:12)ts that feature selection may provide in hierarchical clustering tasks and explore the power of feature selection methods applied as a preprocessing step under the proposed dimensions. Instead of only predicting class labels, the focus is on a more general inference tasks over all the features. Empirical results suggest that feature selection as preprocessing only provides limited improvements in the performance task. In addition, they raise the problem of the notion of irrelevance in unsupervised settings.