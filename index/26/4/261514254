This video first summarizes current research at the University of Massachusetts on mobile vehicle navigation using landmark recognition and a partial 3D world model. We then show how landmarks and world models might be automatically acquired and updated over time. 
 
A fundamental goal in robot navigation is to determine the "pose" of the robot - that is, the position and orientation of the robot with respect to a 3D world model, such as a hallway. In order to determine its pose, the robot identifies modeled 3D landmarks such as doors and baseboards in a 2D image of the hallway. Identifying landmarks involves determining correspondences of extracted image line segments with predicted landmark lines projected into the image. Model matching is achieved by a combinatorial optimization technique (local search) which minimizes the error in the model to data fit. From the model- data feature correspondences thus obtained, the 3D pose of the robot is computed via a non-linear optimization procedure. The best pose requires that lines in the 2D image lie on the planes formed by the corresponding 3D landmark lines and the camera center. Robust statistical methods are employed to detect outliers. Extension of the initial partial model (over time) is achieved by determining the camera pose over a sequence of images while simultaneously tracking new unmodeled features; triangulation is then used to determine the depth of these new features, allowing them to be incorporated into the 3D model.