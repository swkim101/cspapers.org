We study reinforcement learning in episodic inhomogeneous MDPs with adversarial full-information rewards and the unknown transition kernel. We consider the linear mixture MDPs whose transition kernel is a linear mixture model and choose the dynamic regret as the performance measure. Denote by d the dimen-sion of the feature mapping, H the length of each episode, K the number of episodes, P T the non-stationary measure, we propose a novel algorithm that enjoys an (cid:101) O (cid:0) √ d 2 H 3 K + (cid:112) H 4 ( K + P T )(1 + P T ) (cid:1) dynamic regret under the condition that P T is known, which improves previously best-known dynamic regret for adversarial linear mixture MDP and adversarial tabular MDPs. We also establish an Ω (cid:0) √ d 2 H 3 K + (cid:112) HK ( H + P T ) (cid:1) lower bound, indicating our algorithm is optimal in K and P T . Furthermore, when the non-stationary measure P T is unknown, we design an online ensemble algorithm with a meta-base structure, which is proved to achieve an (cid:101) O (cid:0) √ d 2 H 3 K + (cid:112) H 4 ( K + P T )(1 + P T ) + H 2 S 2 T (cid:1) dynamic regret and here S T is the expected switching number of the best base-learner. The result can be optimal under certain regimes.