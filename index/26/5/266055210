The Digital Services Act (DSA) represents a major legislative framework that mandates large social media providers to file Statements of Reasons (SoRs) to the DSA Transparency Database whenever they remove or restrict access to certain content on their platforms in the EU. In this work, we empirically analyze this unique data source and provide an early look at content moderation decisions of social media platforms in the EU. Our empirical analysis based on more than 156 million SoRs reveals significant differences in content moderation practices and how large social media platforms implement their obligations under the DSA. Our findings have important implications for regulators, suggesting the need to lay out more specific rules that ensure common standards on how social media providers handle rule-breaking content on their platforms.