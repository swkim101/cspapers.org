Autonomous vehicles at L2 and above are increasingly relying on stereo vision systems, where haze removal is critical to detect obstacles hidden in fog. Existing image dehazing techniques have low processing speed and high resource consumption, restricting their application scope in practice. In this work, we propose a hardware-software co-design solution for haze removal. It fully decouples calculation of the two main parameters, i.e., atmospheric light and transmittance, in the dehazing process. By eliminating the data dependency, parallelism in hardware acceleration is enhanced. Furthermore, in replacement of the conventional global homogeneous atmospheric light computation, we report a chunk-based heterogeneous method to reduce cache overhead. Our approach is implemented on FPGA, compared against five state-of-the-art (SOTA) works for image haze removal. Evaluation using test sets of real-world foggy driving scenarios shows that our object detection accuracy is over 88%, 9.5%-47.4% better than the SOTA works with neural networks (NN) on GPU, and 25.9%-52.2 % better than the SOTA works on FPGA. The processing speed varies with image resolution and our improvement is generally even more at higher resolution, which is 29.7% faster than the fastest SOTA. We have the lowest overall resource consumption, where the bottleneck BRAM usage is reduced by over 70%. The FPGA solution has circuit-level timing determinism at nanosecond, hence suitable for hard real-time applications.