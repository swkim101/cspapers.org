This paper presents a novel integration of a shared autonomous mobile humanoid robot for remote nursing assistance. The proposed nursing robot has a motorized versatile supporting structure to allow flexible integration of the system components, autonomously adjust its mobile manipulation workspace and improve its reachability and manipulability to operate in a cluttered environment. The robot also provides a novel integration of robot autonomy to reduce the human effort to coordinate the motorized chest and arm motion, control the precise manipulation of objects and camera viewpoint, and handle complex collision avoidance in human-guided gross manipulation. Moreover, we developed an open-source virtual testbed that integrates ROS- and Unity-based robot simulation and benchmark mobile manipulation nursing tasks and scenarios in a realistic simulation of a hospital environment. The virtual testbed supports various contemporary gaming and AR/VR interfaces to control the virtual human and robots, and provides autonomy for navigation, manipulation, and remote active perception assistance. We conducted a user study (N=9) to validate that the versatile supporting structure and shared autonomy of the physical testbed can effectively reduce the human effort to control unstructured manipulation, and improve the robot's reachability and manipulability. In addition, we conducted a pilot study (N=8) to test the usability of the virtual testbed and collect feedback from representative users.