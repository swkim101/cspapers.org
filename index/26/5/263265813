Privacy-preserving machine learning (PPML) techniques have allowed remote and private inference for resource-constrained internet-of-things (IoT) devices on the cloud. The main challenge in most of the existing PPML technologies is a severe slowdown in inference latency mainly due to the use of encryption during the computation. To combat this, an emerging method is to leverage encoding as an alternative. While this results in a significant speedup, it imposes the burden of encoding to the resource-constrained IoT/edge device. Despite being feasible for simple workloads where encoding is lightweight, devices with very limited computational capabilities face a tradeoff between latency and privacy when performing complex tasks. This work proposes an alternative strategy for privacy-preserving inference. Our main contribution is to propose a hybrid method that uses both encoding and encryption. Our key insight is to employ a cloud-side encoder achieved by leveraging homomorphic encryption. Since most computations are performed on plaintext, our method enjoys better latency than existing encryption-based methods. Additionally, the method eliminates the burden of encoding on the IoT device, resulting in improved latency AND privacy. We implement our system, Orient, on real-world setups and measure various important metrics including accuracy, privacy, and end-to-end latency. Further, we compare our system with state-of-the-art (SOTA) to highlight its advantages. We show that our method could improve SOTA inference latency by more than 400%, on average, and is an excellent candidate for PPML on low-end resource-constrained devices.