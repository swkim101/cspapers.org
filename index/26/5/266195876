Ocular mobility disorders such as strabismus af-fect millions of people. Patients' descriptions of their symptoms, such as what they see and how their vision has changed, are important for ophthalmologists to diagnose, monitor pro-gression, and evaluate treatment effectiveness. However, such verbal depiction may be vague and Subjective. A data-driven simulator that visualizes abnormal vision experienced by a strabismic patient can be helpful to objectively illustrate each individual's vision condition and thus to better understand and manage strabismus. To fulfill this technical void, this paper presents the first vision visualization robot that uses human eye movement data to simulate strabismic vision. We developed a robotic binocular eye platform, which is capable of displaying simulated visual scenes using its onboard cameras. Based on the hypothesis that a human's binocular vision fusion process can be mimicked as a homography transformation from one view to another view, we developed a pipeline to estimate the time-varying homography matrix, and generate the fused view of a human's binocular vision. The effectiveness of the proposed method is demonstrated through experiments with eye movement data from both healthy individuals and strabismic patients.