Flexible sensors are promising for ubiquitous sensing of human status due to their flexibility and easy integration as wearable systems. However, on-body displacement of sensors is inevitable since the device cannot be firmly worn at a fixed position across different sessions. This displacement issue causes complicated patterns and significant challenges to subsequent machine learning algorithms. Our work proposes a novel self-adaptive motion tracking network to address this challenge. Our network consists of three novel components: i) a light-weight learnable Affine Transformation layer whose parameters can be tuned to efficiently adapt to unknown displacements; ii) a Fourier-encoded LSTM network for better pattern identification; iii) a novel sequence discrepancy loss equipped with auxiliary regres-sors for unsupervised tuning of Affine Transformation parameters. Experimental results show that our method is robust across different on-body position configurations. Our dataset and code are available at: https://github.com/ZuoCX1996/Self-Adaptive-Motion-Tracking-against-On-body-Displacement-of-Flexible-Sensors.