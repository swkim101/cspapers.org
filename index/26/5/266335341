Customizing robotic behaviors to be aligned with di-verse human preferences is an underexplored challenge in the field of embodied AI. In this paper, we present Prompt-able Behaviors, a novel framework that facilitates efficient personalization of robotic agents to diverse human prefer-ences in complex environments. We use multi-objective re-inforcement learning to train a single policy adaptable to a broad spectrum of preferences. We introduce three distinct methods to infer human preferences by leveraging different types of interactions: (1) human demonstrations, (2) prefer-ence feedback on trajectory comparisons, and (3) language instructions. We evaluate the proposed method in person-alized object-goal navigation and flee navigation tasks in ProcTHOR [18] and RoboTHOR [17], demonstrating the ability to prompt agent behaviors to satisfy human prefer-ences in various scenarios. Project page: https://promptable-behaviors.github.io