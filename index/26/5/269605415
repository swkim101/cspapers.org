The tactile sensation of textiles is critical in determining the comfort of clothing. In remote scenarios such as online shopping, sensors need to distinguish different garments even with hand-held sensors, and current actuation devices can only present a limited number of known patterns and cannot transmit unknown tactile sensations. We propose Telextiles, an interface for remotely transmitting textile tactile sensations, which uses contrastive self-supervised learning to create a latent space that reflects the relative proximity of textiles. We convert the latent features into a scalar for the one-dimensional structure of the roller. We then select 16 equidistant samples from this line to represent different regions of the latent space. The roller rotates to select the textile with the closest feature. We also show visually the relationship between a textile touched by a remote user and a set of textiles previously registered in our system.