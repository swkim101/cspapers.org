In this paper, we present an event-based control framework for the efficient tracking of contour-based areas, such as road pavements, using a multirotor aerial vehicle equipped with a bio-inspired Dynamic Vision Sensor (DVS). Concerning the detection part, the DVS camera captures events, which are asynchronously fed into a Neuromorphic Hough Transform algorithm running on a SpiNN-3 board and implemented as a Spiking Neural Network (SNN). Next, the asynchronous output of the detection module is fed into an analytically formulated event-based Partitioned Visual Servoing (PVS) algorithm, running on conventional processing hardware, which allows the multirotor to autonomously track and navigate along the detected contour. The proposed architecture achieves efficient tracking of contour-based areas, while constantly maintaining the latter inside the DVS camera's field of view. A set of real-time experiments in various settings employing an octorotor equipped with a downward-looking DVS and a SpiNN-3 board demonstrate the effectiveness of the suggested framework.