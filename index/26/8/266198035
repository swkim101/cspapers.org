Many intelligent robots use a combination of radar and camera sensors to capture environmental information. Robust and accurate perception highly relies on the result of multi-sensor calibration. Most current spatial calibration methods require a calibration board or a special marker as the target. In this paper, we provide a novel calibration method for RGBD camera and millimeter-wave radar, which automatically estimates the extrinsic parameters. Our proposed method includes the following two stages: rough extrinsic parameters are estimated by using object contours as geometric constraints, and meanwhile, the optimum is reached via optimizing based on the difference of velocity obtained from camera and radar. It only needs an object moving past sensors, but does not require for a calibration board. We validate our method through simulation experiments and real-world experiments. We construct a simulation environment in CARLA to verify the performance of our proposed method against different angles. Furthermore, different levels of zero mean Gaussian noise are added to evaluate the stability of our method. In addition, real-world experiments with different hardware setups are taken to verify the feasibility of our method in real-world conditions.