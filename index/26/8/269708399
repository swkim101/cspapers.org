Advances in generative AI and the increasingly easy availability of tools for creating text, code, audio, and images have impacted almost all industry sectors, promising new efficiencies and changing work patterns. The darker side of this same technology is the problematic case of deepfakes created by AI and spread online to humiliate, manipulate, trick, or defraud ordinary individuals and public figures. Transparency, fairness, and beneficence are vital values of responsible and ethical AI. All of these values would preclude harmful uses of AI deep fakes. However, harmful deepfakes are usually the work of fraudsters with little regard for ethics and beyond the reach of the law. So, who should be responsible? Arguably, principles of responsible AI require tech companies and digital platforms to take responsibility for reducing harmful uses of deepfakes. These entities are gatekeepers to the creation and distribution of deepfakes. Therefore, they are ethically obligated to respond to the foreseeable consequential harms arising from generative AI. Increasingly, this is the response of lawmakers. Gatekeeper responsibility envisages that tech producers and platforms will proactively invest in technical solutions to harmful deepfakes, such as watermarking, finetuning, red teaming or automated content moderation, and proactive take-down responses. This response is compelling and might seem straightforward. As always, the details are more complex. The efficiency of the proposed technical responses is still emerging. They raise as yet unaddressed implications for smaller providers and the relations between tech companies and digital platforms. Moreover, even beginning to respond to online deepfakes requires social policy decisions that assess and weigh incommensurable considerations, including retaining trust on the Web, keeping vulnerable groups safe, preserving free speech and creativity, and not stifling the development of potentially beneficial technology. This presentation addresses these problematic choices in responding to the 'wicked' challenge of AI deepfakes on the Web. It proposes a networked response to the problem, embracing multiple relevant actors and influences.