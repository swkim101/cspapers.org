Radio Frequency (RF)-based gait recognition has emerged as a promising technology to authenticate individuals in a pervasive and unobtrusive way. However, a fundamental challenge remains in collecting extensive data of the same user in the same environment. To address this challenge, this paper introduces XGait, a cross-modal gait recognition framework that does not require the prior deployment of RF devices or explicit data collection. The key idea is to leverage the signals of the Inertial Measurement Unit (IMU), which is widely available in modern mobile devices, to simulate the RF signals that would be generated if the same person walked near RF devices. Despite the straightforward idea, several technical challenges need to be addressed due to the diversity of RF devices, the intrinsic difference between IMU signals and RF signals, and the complexity of gait. First, we propose an RF spectrogram generation method to consistently extract essential RF gait data features across different RF signals. Secondly, we propose a generative network-enabled IMU-to-RF translation approach that accurately converts IMU data to RF data. Finally, we design an RF gait spectrogram-specific transformer model to further improve the recognition performance. We conduct a comprehensive evaluation of XGait, involving thirty subjects in three different environments, utilizing three RF devices and seven mobile devices. Experimental results show that XGait consistently achieves over 99% Top-3 accuracy in various scenarios.