Existing Blind image Super-Resolution (BSR) methods focus on estimating either kernel or degradation infor-mation, but have long overlooked the essential content details. In this paper, we propose a novel BSR approach, Content-aware Degradation-driven Transformer (CDFormer), to capture both degradation and content rep-resentations. However, low-resolution images cannot pro-vide enough content details, and thus we introduce a diffusion-based module CD Former dif f to first learn Con-tent Degradation Prior (CDP) in both low- and high-resolution images, and then approximate the real distribution given only low-resolution information. Moreover, we apply an adaptive SR network CDFormersR that effectively utilizes CDP to refine features. Compared to previous diffusion-based SR methods, we treat the diffusion model as an estimator that can overcome the limitations of expensive sampling time and excessive diversity. Experiments show that CDFormer can outperform existing methods, establishing a new state-of-the-art performance on various bench-marks under blind settings. Codes and models will be avail-able at https://github.com/I2-Multimedia-Lab/CDFormer.