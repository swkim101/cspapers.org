Deploying humans in a high-risk environment to extract casualties in order to provide medical attention is an inherently dangerous endeavor. To minimize this risk, Robotics and Autonomous Systems can be deployed in hazardous areas in place of human personnel to limit the exposure of first responders to various life-threatening conditions. The success of robotic extraction of injured persons depends heavily on how safely the human subject is handled. Therefore, the integration of intelligent technologies for secure control and motion planning is crucial in overcoming the dynamic and complex challenges of robotic grasping and manipulation. In this regard, the measurement of the target human subject's weight is an essential factor for safe grasping and maneuvering during robotic interactions with humans. This paper presents a contactless vision-based approach for estimating the weight of the human body. This approach employs visual body perception, 3D body point cloud representation, and a deep learning network for body segmentation to measure specific body parameters. Next, the body parameters are fed into a neural network model to predict the total body weight. This prediction then enables an approximation of the weight of individual body segments to be obtained.