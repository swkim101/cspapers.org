Current approaches to learning cooperative multi-agent behaviors assume relatively restrictive settings. In fully cooperative multi-agent reinforcement learning, the learning algorithm controls all agents in the scenario, while in ad hoc teamwork, the learning algorithm usually assumes control over only a single agent in the scenario. However, many cooperative settings in the real world are much less restrictive. For example, in an autonomous driving scenario, a company might train its cars to cooperate with each other, yet once on the road, these cars must additionally cooperate with cars from other companies. Towards expanding the class of scenarios that cooperative learning methods may optimally address, this research agenda introduces and proposes to study N-agent ad hoc teamwork (NAHT), where a set of autonomous agents must interact and cooperate with dynamically varying numbers and types of teammates.