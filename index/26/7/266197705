Often in the field of haptic guidance, an important question is how the robotic device should assist some imperfect human movement. While many control strategies have been suggested to help improve human performance in particular tasks, structuring guidance in a generalizable way remains elusive. Many assistive controllers rely on predicting a user's goal movement or knowing some idealized trajectory a-priori but may fail to assist during an arbitrary task. In this study, we propose a ‘flipped’ approach to studying human-robot collaborative behavior - we ask humans to assist a robotic device whose movements are in some way imperfect. We conducted an experiment during which subjects assisted a haptic device performing a shape-following task autonomously but with different types of error-prone controllers. For each shape, we evaluated a simple trajectory-following controller as well as one with human-like motion constraints. We also evaluated the role of visual feedback on a user's ability to help the robot accomplish the unknown task. We found that the human was generally able to improve the robotic error in all trajectories when the robotic motion did not include gravity compensation; however, error reduction was primarily in the vertical direction. When the robotic controller included gravity compensation, the human user was not able to improve errors significantly, except for vertical errors when provided visual feedback. In the no visual feedback conditions, the human user contributed to significantly greater error for most paths compared to a robot with gravity compensation, indicating an inability to provide assistance in that case.