Online content moderation has become the subject of intense debate as policymakers and platform developers aim to balance values such as freedom of expression and community safety. Despite the impact of content moderation on public discourse and online experiences, the debate surrounding content moderation regulation rarely involves those impacted by these decisions. To explore how to engage individuals in learning opportunities that deepen understanding of social and technical aspects of online content moderation, we designed and tested an educational game: CONTENTR. The game gives participants experience debating and making decisions about platform governance. We used the Values at Play (VAP) game design framework to discover and translate social values into game elements, and then verified both values translation and learning outcomes using qualitative feedback from three phases of testing. We found that gameplay facilitated collaborative discussion and decision-making regarding the challenges of designing an online platform for mass appeal. Both tabletop and online versions of the game are available on our project website. Our findings highlight how gameplay can create a deeper understanding of the challenges involved in developing and enforcing online content policies, and challenge participants' pre-existing values and assumptions through both game elements and exposure to other participants' perspectives. We believe the game will be useful in courses ranging from civics and technology policy to information and computer science.