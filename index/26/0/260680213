Sparse general matrix-matrix multiplication (SpGEMM) is challenging especially on graphic accelerators. Existing solutions do not fully utilize the shared memory of the graphics accelerator. Our proposal could effectively utilize the graphics accelerator's on-chip shared memory and dynamically assign the device resources by grouping the rows based on a hybrid strategy for load balancing. Experiments show that our proposal achieves speedups of up to x7.43 in double precision compared to existing SpGEMM libraries. Our implementation is fully general and our optimization strategy adaptively processes the SpGEMM workload row-wise to substantially improve performance by decreasing the work complexity and utilizing the memory hierarchy more effectively.