Graph Neural Networks (GNNs) generalize conventional neural networks to graph-structured data and have received considerable attention owing to their impressive performance. In spite of the notable successes, the performance of Euclidean models is inherently bounded and limited by the representation ability of Euclidean geometry, especially when it comes to datasets with highly non-Euclidean latent anatomy. Recently, hyperbolic spaces have emerged as a promising alternative for processing graph data with tree-like structure or power-law distribution and a surge of works on either methods or novel applications have been seen. Unlike Euclidean space, which expands polynomially, hyperbolic space grows exponentially with its radius, making it more suitable for modeling complex real-world data. Hence, it gains natural advantages in abstracting tree-like graphs with a hierarchical organization or power-law distribution. To support the burgeoning interest in Hyperbolic Graph Neural Networks (HGNNs), the primary goal of this tutorial is to give a systematical review of the methods, applications, and challenges in this fast-growing and vibrant area, with the express purpose of being accessible to all audiences.More specifically, we will first give a brief introduction to graph neural networks as well as some preliminary of Riemannian manifold and hyperbolic geometry. We then will comprehensively revisit the technical details of the developed HGNNs, by unifying them into a general framework and summarizing the variants of each component. Besides, we will introduce applications deployed in a variety of fields. Finally, we will discuss several challenges and present the potential solutions to address them, including some initial attempts of our own, which potentially paves the path for the further flourishing of the research community.