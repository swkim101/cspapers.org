Synthesizing natural human motions that enable a 3D human avatar to walk and reach for arbitrary goals in 3D space remains an unsolved problem with many applications. Existing methods (data-driven or using reinforcement learning) are limited in terms of generalization and motion naturalness. A primary obstacle is the scarcity of training data that combines locomotion with goal reaching. To ad-dress this, we introduce WANDR, a data-driven model that takes an avatar's initial pose and a goal's 3D position and generates natural human motions that place the end effec-tor (wrist) on the goal location. To solve this, we intro-duce novel intention features that drive rich goal-oriented movement. Intention guides the agent to the goal, and in-teractively adapts the generation to novel situations without needing to define sub-goals or the entire motion path. Cru-cially, intention allows training on datasets that have goal-oriented motions as well as those that do not. WANDR is a conditional Variational Auto-Encoder (c- VAE), which we train using the AMASS and CIRCLE datasets. We evaluate our method extensively and demonstrate its ability to gener-ate natural and long-term motions that reach 3D goals and generalize to unseen goal locations. Our models and code are available for research purposes at wandr.is.tue.mpg.de.