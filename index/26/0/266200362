Trajectory prediction of neighboring agents is a critical task for high-speed robotics such as autonomous vehicles. In order to obtain fine-grained and robust scene representations, existing works attempt to consider abundant information that is deemed relevant. The cost, however, is the heavy computational burden and more importantly the inevitable interference brought by redundant information. In this paper, we exploit the explainable AI (XAI) techniques and propose a model in the framework of “Encoder-Decoder” named parallel explainable Transformer (PXT) to identify the contributive features for robust trajectory prediction. A two-branch encoder is designed to disentangle the roadway information and agents' historical trajectories for better feature explanation. Two stages of feature explanation are incorporated into the encoder. In the first stage, an explainable Transformer (XT) comprising a Layer-wise Relevance Propagation (LRP)-based interpretation module is designed and implemented in both branches to score and filter the contextual and motion features. In the second stage of interpretation, the ProbSparse attention mechanism is innovatively adopted to measure the level of interactivity with sparsity, so that the relationships among highly interactive agents are focused on. The results on the Argoverse Benchmark show that our proposal achieves state-of-the-art (SOTA) performance without delicate and tedious network design, demonstrating the effectiveness of tracing and retaining contributive features in enhancing the performance of trajectory prediction.