RPC-based Grid infrastructures emphasize on the composition of services on a large number of computing resources. The key issue to reach high performance is to enable exploitation of parallelism on services invocations and communications. Moreover, this process should be transparent to reuse legacy codes. In this paper we present Homa an IDL compiler and a run-time support for automatic detection of the parallelism of invocations and their data dependencies on a set of CORBA objects. On homogeneous computational grids, such as clusters, Homa is accompanied by a predictable cost model. For instance, in the case of a application with a small parallel time, among p processors the speed up of Homa versus CORBA is asymptotically O(p). Also we describe how Homa can efficiently use data parallel objects. The illustrations on a case study in computational chemistry validate the cost model on a computational grid. For service-based Metacomputing, Homa offers high automation and transparency to detect parallelism for scheduling algorithms.