This paper illustrates how a multi-agent system implements and governs a computational linguistic model of phonology for syllable recognition. We describe how the Time Map model can be recast as a multi-agent architecture and discuss how constraint relaxation, output extrapolation, parse-tree pruning, clever task allocation, and distributed processing are all achieved in this new architcture.