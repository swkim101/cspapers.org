Emerging data-driven scientific workflows are increasing leveraging distributed data sources to understand end-to-end phenomenon, drive experimentation, and facilitate important decision making. Despite the exponential growth of available digital data sources at the edge, and the ubiquity of non-trivial computational power for processing this data across the edge-HPC continuum, realizing such science workflows remain challenging. In this talk I will explore how the computing continuum, spanning resources at the edges, in the core and in-between, can be harnessed to support science. I will also describe recent research in programming abstractions that can express what data should be processed and when and where it should be processed, middleware services that automate the discovery of resources and the orchestration of computations across these resources.