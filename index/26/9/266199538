To personalize the robot guide experience, the robot needs to detect a person's indifference and adjust its explanation toward the person's interest in topics. However, detecting the person's indifference is challenging in a museum, as we cannot use a bulky wearable or facial expression recognition due to unexpected light condition or standing position. We propose to observe people's behaviors and movements on detecting people's indifference. To prove its feasibility, we invited 11 participants to our in-lab museum-like environment. Our robot explains exhibits while videorecording the interaction. Then, we asked participants to watch the recordings and report when they felt bored or indifferent to the explanation. We labelled their movement and matched them to their report so that we know which behaviors and movements hint the person's indifference. We used the decision tree and random forest methods to understand the common pattern when people are indifferent during the explanation in a museum scenario. From our observation experiment, we found that if the listener nods their heads many times or looks at the exhibit for a long time, they are likely interested in the topic, fewer overall movements or looking elsewhere hint that the listener may be indifferent, and if the explanation goes longer than three minutes, the listener would be likely bored.