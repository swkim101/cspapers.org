In this work, we propose a novel discriminative frame-work for dexterous grasp generation, named Dexterous Grasp TRansformer (DGTR), capable of predicting a di-verse set of feasible grasp poses by processing the object point cloud with only one forward pass. We formulate dex-terous grasp generation as a set prediction task and design a transformer-based grasping model for it. However, we identify that this set prediction paradigm encounters sev-eral optimization challenges in the field of dexterous grasping and results in restricted performance. To address these issues, we propose progressive strategies for both the training and testing phases. First, the dynamic-static matching training (DSMT) strategy is presented to enhance the opti-mization stability during the training phase. Second, we in-troduce the adversarial-balanced test-time adaptation (AB-TTA) with a pair of adversarial losses to improve grasping quality during the testing phase. Experimental results on the DexGraspNet dataset demonstrate the capability of DGTR to predict dexterous grasp poses with both high quality and diversity. Notably, while keeping high qual-ity, the diversity of grasp poses predicted by DGTR sig-nificantly outperforms previous works in multiple metrics without any data pre-processing. Codes are available at https://github.com/iSEE-Laboratory/DGTR.