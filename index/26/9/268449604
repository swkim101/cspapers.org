Artificial intelligence (AI) has become an increasingly critical component of not only the computing workforce but also society. It is essential for a diverse group of young people to contribute to this field. However, even within computing, AI is not taught to all post-secondary students. Students often must self-select into AI courses, meaning their reasons for choosing AI may be based on preconceptions of the discipline that may or may not be accurate. We extend the work of a small-n interview study of primarily Asian/Asian American undergraduate students, many of whom expressed perceptions of AI that paralleled identified computing stereotypes. Many of these stereotypes have the potential to discourage undergraduate computing students to take classes or specialize in AI, particularly those from underrepresented groups. Here we present a larger scale validation of those findings in the form of survey data conducted at a large public research institution in the USA. The survey largely confirmed the findings of the interview study at a larger scale, and we also found that gender did not significantly influence the results. Finally, we discuss strategies for AI integration into non-AI computing courses based on those previously used in responsible computing contexts, the goal being to counter harmful preconceptions before students specialize into computing subareas. AI has already made a great impact on a variety of computing and non-computing related disciplines, and is poised to play an increasing role across various areas in industry and society [1, 6, 7, 12, 13]. It is essential to educate young people to contribute to this field to ensure the development of a high-qualified workforce. This requires post-secondary computing students to sign on to learn about the discipline. However, within university computing departments AI is not always a part of the required undergraduate or graduate curriculum, meaning computing students must choose whether to take courses and further their education in AI based on their already existing opinions on the subject. One recent SIGCSE paper, ''Computing Specializations: Perceptions of AI and Cybersecurity among CS Students'' used interview methods to identify a variety of preconceptions related to AI: that AI is very difficult and time consuming ''intimidating'' ''rigorous''; AI requires advance meth skills ''I think all of AI/ML is essentially just math.''; AI is ''trending'' and ''cool''; AI requires an inherent brilliance ''they're really smart.''; AI will have a large societal impact (although not always for the better); and AI is a ''male-dominated'' discipline [11]. Many of these preconceptions were noted as matching preconceptions of computing disciplines more generally [9] and potentially having a discouraging impact on marginalized or historically excluded groups in computing environments, particularly women [8]. In this poster, we aim to validate the findings of Ojha et al. with quantitative data from a single institution survey of post-secondary computing students in the USA. To this end, we ask the following research questions. 1.) To what degree are the preconceptions of AI identified in Ojha et al. (2023) confirmed by a larger sample of post-secondary computing students at a large public US university? 2.) To what extent are there difference in preconceptions of AI based on gender?1