We present Condition-Aware Neural N etwork (CAN), a new method for adding control to image generative models. In parallel to prior conditional control methods, CAN controls the image generation process by dynamically manipulating the weight of the neural network. This is achieved by introducing a condition-aware weight generation module that generates conditional weight for convolution/linear layers based on the input condition. We test CAN on class-conditional image generation on ImageNet and text-to-image generation on COCO. CAN consistently delivers significant improvements for diffusion transformer models, including DiT and UViT. In particular, CA N combined with EfficientViT (CaT) achieves 2.78 FID on ImageNet $5l2\times 5l2$, surpassing DiT-XL/2 while requiring $52\times$ fewer MACs per sampling step.