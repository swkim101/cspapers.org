LiDAR-based 3D detection methods currently use bird’s-eye view (BEV) or range view (RV) as their primary basis. The former relies on voxelization and 3D convolutions, resulting in inefﬁcient training and inference processes. Conversely, RV-based methods demonstrate higher efﬁciency due to their compactness and compatibility with 2D convolutions, but their performance still trails behind that of BEV-based methods. To eliminate this performance gap while preserving the efﬁ-ciency of RV-based methods, this study presents an efﬁcient and accurate RV-based 3D object detection framework termed RangePerception . Through meticulous analysis, this study identiﬁes two critical challenges impeding the performance of existing RV-based methods: 1) there exists a natural domain gap between the 3D world coordinate used in output and 2D range image coordinate used in input, generating difﬁculty in information extraction from range images; 2) native range images suffer from vision corruption issue, affecting the detection accuracy of the objects located on the margins of the range images. To address the key challenges above, we propose two novel algorithms named Range Aware Kernel (RAK) and Vision Restoration Module (VRM), which facilitate information ﬂow from range image representation and world-coordinate 3D detection results. With the help of RAK and VRM, our RangePerception achieves 3.25/4.18 higher averaged L1/L2 AP compared to previous state-of-the-art RV-based method RangeDet, on Waymo Open Dataset. For the ﬁrst time as an RV-based 3D detection method, RangePer-ception achieves slightly