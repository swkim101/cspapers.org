Semantic segmentation of LiDAR point clouds can provide assistance for precise perception in autonomous driving, but traditional segmentation methods face challenges such as unbalanced class distribution and insufficient labeling. Generalized few-shot learning has been researched on image data, but these methods are difficult to apply directly to LiDAR point clouds. To tackle these challenges, we propose a generalized few-shot semantic segmentation method based on LiDAR point cloud data, enabling us to predict base and novel classes simultaneously. To improve the performance with limited novel class samples, we integrate semantic vectors and leverage the intrinsic relationship between base and novel class vectors to facilitate learning. We conduct comprehensive comparisons with other methods on the SemanticKITTI and constantly surpass them with higher mIoU, demonstrating the effectiveness of our method.