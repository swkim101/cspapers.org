Conversational Recommender System (CRS) aims to deliver personalized recommendations through interactive dialogues. Recent advances in prompt learning have shed light on this task. However, the performance of existing methods is conﬁned by the limited context within ongoing conversations. Moreover, these methods utilize training samples only for prompt parameter training. The constructed prompt lacks the ability to refer to the training data during inference, which exacerbates the problem of limited context. To solve this problem, we propose a novel D ynamic O pen-book P rompt approach, where the open book stores users’ experiences in historical data, and we dynamically construct the prompt to memorize the user’s current utterance and selectively retrieve relevant contexts from the open book. Speciﬁcally, we ﬁrst build an item-recommendation graph from the open book and convolute on the graph to form a base prompt which contains more information besides the ﬁnite dialogue. Then, we enhance the representation learning process of the prompt by tailoring similar contexts in the graph into the prompt to meet the user’s current need. This ensures the prompt provides targeted suggestions that are both informed and contex-tually relevant. Extensive experimental re-sults on the ReDial dataset demonstrate the signiﬁcant improvements achieved by our proposed model over the state-of-the-art meth-ods. Our code and data are available at https://