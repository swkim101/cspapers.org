We introduce Stochastic Integrated Explanations (SIX) - a general method for explaining predictions made by vision models. SIX employs stochastic integration on the internal representations across different network layers, producing explanation maps at various scales. The primary innovation of SIX is the introduction of randomness to the integration process by modeling the baseline representation as a random tensor. Through iterative sampling from the baseline distribution, SIX generates a diverse set of explanation maps, allowing the selection of the best-performing map based on a specific metric of interest. Extensive evaluations on various model architectures showcase the superior performance of SIX compared to state-of-the-art explanation methods, affirming its effectiveness across multiple metrics. Our code is available at: https://github.com/six-icdm/six