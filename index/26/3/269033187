Diffusion models have shown remarkable results for im-age generation, editing and inpainting. Recent works ex-plore diffusion models for 3D shape generation with neural implicit functions, i.e., signed distance function and occu-pancy function. However, they are limited to shapes with closed surfaces, which prevents them from generating di-verse 3D real-world contents containing open surfaces. In this work, we present UDiFF, a 3D diffusion model for unsigned distance fields (UDFs) which is capable to gener-ate textured 3D shapes with open surfaces from text conditions or unconditionally. Our key idea is to generate UDFs in spatial-frequency domain with an optimal wavelet trans-formation, which produces a compact representation space for UDF generation. Specifically, instead of selecting an appropriate wavelet transformation which requires expen-sive manual efforts and still leads to large information loss, we propose a data-driven approach to learn the optimal wavelet transformation for UDFs. We evaluate UDiFF to show our advantages by numerical and visual comparisons with the latest methods on widely used benchmarks. Page: https://weiqi-zhang.github.io/UDiFF.