
 Reinforcement Learning (RL) has created agents with superhuman performance in robotics and gaming. A central issue in using RL methods to automate engineering design is the inability to generalize and slow training. Even the most advanced curiosity-based RL algorithms require exploring millions of design states, which is infeasible with expensive physics models. Data from a human-subject design study shows that even novice human designers can solve design tasks in a few hundred actions. Behavioral cloning allows RL agents to imitate the policies of a human designer from their decision data. We evaluate the performance of a behavioral cloning agent trained on human design decision data collected in a controlled experiment. We compare three popular sequence learning architectures for behavioral cloning. Subsequently, we evaluate an AI design agent trained through behavioral cloning on human design decision data to automatically design an electric aircraft, starting from a baseline design. The results demonstrate that behavioral cloning effectively transfers human strategies to AI design agents with high sample efficiency.