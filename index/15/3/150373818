Human interaction involves very sophisticated non-verbal communication skills like understanding the goals and actions of others and coordinating our own actions accordingly. Neuroscience refers to this mechanism as motor resonance, in the sense that the perception of another persons actions and sensory experiences activates the observerâ€™s brain as if (s)he would be performing the same actions and having the same experiences.We analyze and model the non-verbal cues exchanged between two humans in handover actions. The contributions of this paper are the following: (i) computational models, using recorded motion data, describing the motor behaviour of each actor in action-in-interaction situations; (ii) a computational model that captures the behaviour of the "giver" and "receiver" during an object handover action, by coupling the wrist kinematic motion of the actors; and (iii) the transfer of these models to the iCub robot for both action execution and recognition.Our results show that: (i) the robot is able to interpret the human wrist motion and infer whether or not the observed action is an "handover"; and (ii) use the motor resonance model to coordinate its actions with the human partner, during handover actions.