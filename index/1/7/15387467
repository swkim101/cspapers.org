In this paper, we investigate the power of online learning in stochastic network optimization with unknown system statistics <i>a priori</i>. We are interested in understanding how information and learning can be efficiently incorporated into system control techniques, and what are the fundamental benefits of doing so. We propose two <i>Online Learning-Aided Control</i> techniques, <b>OLAC</b> and <b>OLAC2</b>, that explicitly utilize the past system information in current system control via a learning procedure called <i>dual learning</i>. We prove strong performance guarantees of the proposed algorithms: <b>OLAC</b> and <b>OLAC2</b> achieve the near-optimal [<i>O</i>(ε), <i>O</i>([log(1/ε)]<sup>2</sup>)] utility-delay tradeoff and <b>OLAC2</b> possesses an <i>O</i>(ε<sup>-2/3</sup>) convergence time. Simulation results also confirm the superior performance of the proposed algorithms in practice. To the best of our knowledge, <b>OLAC</b> and <b>OLAC2</b> are the first algorithms that simultaneously possess explicit near-optimal delay guarantee and sub-linear convergence time, and our attempt is the first to explicitly incorporate online learning into stochastic network optimization and to demonstrate its power in both theory and practice.