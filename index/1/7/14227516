In a previous paper, we proposed a special environment and techniques for the implementation of highly parallel processing. A new VLSI supercomputer architecture, DYPP (DYnamically Programmable multi-Processor), was introduced, with the unique property of being able to embed, and execute directly, program graphs both statically and dynamically. Either asynchronous (dataflow) or synchronous implementations of program graphs can be realized in DYPP. In the present paper, we provide further insight in its operation.
In the proposed ensemble architecture, we separate processing and communication into two distinct, though overlapping and interacting layers. Separate, simpler (and thus more reliable), processors are assigned to the connectivity layer, which becomes active and self-adaptive, thus being able to detect and compensate for malfunctions in the underlying layer of main processing elements.
There is no global control at either level. Rather in a first, static, version, the program graph (incorporating both connectivity information and operators, that is instructions), is “injected” in a preliminary, separate, phase via the connectivity-layer processors. In this phase, the connectivity graph is embedded between live (operational) main processing elements. In the second phase, processing takes place.
A more advanced option makes the connectivity layer fully dynamic. In this case, the program graph is continuously injected (embedded) in a flow fashion to interact with the flow of data and intermediate results, which flow is said to become leviating. This can greatly reduce the need for local program memory and large numbers of PEs, and correspondingly the required VLSI area. As well, it can dispel the need for (large) resident, localized, static programs characteristically present in von Neumann architectures. Based on data levitation, the generalization of systolic arrays becomes feasible.