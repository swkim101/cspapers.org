The problem of coordination in cooperative multiagent systems has been widely studied in the literature. In practical complex environments, the interactions among agents are usually regulated by their underlying network topology, which, however, has not been taken into consideration in previous work. To this end, we firstly investigate the multiagent coordination problems in cooperative environments under the networked social learning framework focusing on two representative topologies: the small-world and the scale-free network. We consider a population of agents where each agent interacts with another agent randomly chosen from its neighborhood in each round. Each agent learns its policy through repeated interactions with its neighbors via social learning. It is not clear a priori if all agents can learn a consistent optimal coordination policy and what kind of impact different topology parameters could have on the learning performance of agents. We distinguish two types of learners: individual action learner and joint action learner. The learning performances of both learners are evaluated extensively in different cooperative games, and the influence of different factors on the learning performance of agents is investigated and analyzed as well.