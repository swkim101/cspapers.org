This paper presents a computational model of verb acquisition which uses what we will call the principle of structured overcommitment to eliminate the need for negative evidence. The learner escapes from the need to be told that certain possibilities cannot occur (i.e., are "ungrammatical") by one simple expedient: It assumes that all properties it has observed are either obligatory or forbidden until it sees otherwise, at which point it decides that what it thought was either obligatory or forbidden is merely optional. This model is built upon a classification of verbs based upon a simple three-valued set of features which represents key aspects of a verb's syntactic structure, its predicate/argument structure, and the mapping between them.