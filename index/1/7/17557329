Concentric tube robots have shown promise for minimally invasive surgical (MIS) tasks that require navigation via tortuous anatomical paths. Despite extensive research on their kinematic and dynamic modelling, however, inaccuracies and deformations of their shape due to unknown loads and collisions with the anatomy make intraoperative shape sensing a requirement. This paper presents a vision-based shape-sensing algorithm for concentric tube robots. The proposed algorithm fuses information extracted from a standard imaging modality, monoplane X-ray fluoroscopy, with the kinematics model of the concentric tube robot, to achieve automatic, real-time, accurate and continuous robot-shape estimations despite kinematics' noise and unmodelled forces. Fusion is performed by a fast 2D/3D non-rigid registration, which combines kinematics and intraoperative tracking of the robot. Extensive simulations with a range of noise models and virtual loads acting on the robot, and experimental evaluation in air and in a skull phantom, demonstrate the clinical value of the proposed technique1.