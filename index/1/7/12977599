Although the ν-Support Vector Machine, ν-SVM, (Scholkopf et al., 2000) has the advantage of using a single parameter ν to control both the number of support vectors and the fraction of margin errors, there are two issues that prevent it from being used in many real world applications. First, unlike the C-SVM that allows asymmetric misclassification cost, ν-SVM uses a symmetric misclassification cost. While lower error rate is promoted by this symmetric misclassification cost, it is not always the preferred measure in many applications. Second, the additional constraint from ν-SVM makes its training more difficult. Sequential Minimal Optimization (SMO) algorithms that are very easy to implement and scalable to very large problems do not exist in a good form for ν-SVM. In this paper, we proposed two new ν-SVM formulations. These formulations introduce means to control the misclassification cost ratio between false positives and false negative, while preserving the intuitive parameter ν. We also propose a SMO algorithm for the ν-SVM classification problem. Experiments show that our new ν-SVM formulation is effective in incorporating asymmetric misclassification cost, and the SMO algorithm for ν-SVM is comparable in speed to that for C-SVM.