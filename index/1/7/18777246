A maximum likelihood approach to relevance feedback is introduced. This approach has the additional benefit of resolving document-query duality. The main idea is that in order to know whether and how much to modify a document and/or query in response to relevance feedback data, we need to have error models for documents, queries, and relevance feedback data. A maximum likelihood approach can then use these models to "decide" which document and/or query representations to modify. If this method is to be used for probabilistic models, then the probabilistic models must allow us to modify document and query representations in response to feedback data. Previously, the probabilistic models would never modify these representations, only give them low weights. Finally, we report preliminary results of an empirical test of this method using Cranfield data.