We are organizing a competition on gesture recognition. This challenge is part of a series of challenges on the theme of unsupervised and transfer learning. The goal is to push the state of the art in algorithms capable of learning data representations, which may be re-used from task to task, using unlabeled data and/or labeled data from similar domains. In this challenge, the competitors will obtain for training a large database of videos of gestures from various gesture lexicons (religious emblems, sports referee signals, marshalling signals to guide vehicles or machineries, diving signals to communicate under water, signs from sign languages for the deaf, and signs accompanying narratives of hearing people, etc.). They will then be tested on gestures from different domains and different gesture vocabularies, unknown in advance. The final test will be carried out in a live competition in which the systems will be demonstrated at the site of a conference during the summer 2012. We are holding a milestone event at the HCI workshop held in conjunction with ICCV 2011, where the organizers will demonstrate baseline systems and explain the competition protocol to encourage participation. Up to five competitors will demonstrate systems under development.