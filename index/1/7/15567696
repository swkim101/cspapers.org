Sequences found at the beginning of TV shows help the audience absorb the essence of previous episodes, and grab their attention with upcoming plots. In this paper, we pro-pose a novel task, text recap extraction. Compared with conventional summarization, text recap extraction captures the duality of summarization and plot contingency between adjacent episodes. We present a new dataset, TVRecap , for text recap extraction on TV shows. We propose an unsupervised model that identiÔ¨Åes text recaps based on plot descriptions. We introduce two contingency factors, concept coverage and sparse reconstruction , that encourage recaps to prompt the up-coming story development. We also propose a multi-view extension of our model which can incorporate dialogues and synopses. We conduct extensive experiments on TVRecap , and conclude that our model outperforms summarization approaches.