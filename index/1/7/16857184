Discriminative tasks, including object categorization and detection, are central components of high-level computer vision. However, sometimes we are interested in more refined aspects of the object in an image, such as pose or articulation. In this paper we develop a method (LOOPS) for learning a shape and image feature model that can be trained on a particular image class, and used to outline instances of the class in novel images. Furthermore, while the training data consists of uncorresponded outlines, the resulting LOOPS model contains semantically consistent landmark points that can be localized in an image. This localization facilitates a second round of classification along any descriptive axis, in which a small number of training instances are labeled. For example, we might distinguish between cheetahs that are running and those standing still. From this small number of labeled instances, we can use our localized outlines together with a simple nearest neighbor classifier to label novel test images with the label of interest. We show that across a range of classes with varying degrees of difficulty, the LOOPS approach can consistently and accurately localize the semantically consistent landmarks in test images. Furthermore, we show that the nearest neighbor classifier on the outlines localized by LOOPS allows for effective classification on several shape-based classification tasks.