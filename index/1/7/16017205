In this paper, we propose SakuraSensor, a participatory sensing system which automatically extracts scenic routes information from videos recorded by car-mounted smart-phones and shares the information among users in quasirealtime. As scenic routes information, we target flowering cherries along roads since the best period of flowering cherries is rather short and uncertain from year to year and from place to place. To realize SakuraSensor, we face two technical challenges: (1) how to accurately detect flowering cherries and its degree, and (2) how to efficiently find good places of flowering cherries (PoIs) using the participatory sensing technique. For the first challenge, we develop an image analysis method for detecting image pixels that belong to flowering cherries. To exclude artificial objects with similar color to flowering cherries, we also employ fractal dimension analysis to filter out unnecessary image areas. For the second challenge, we propose a method called k-stage sensing. In this method, the interval for sensing (taking a still image and applying the image analysis) by each car is dynamically shortened so that the roads near the already found PoIs are more densely sensed. We implemented SakuraSensor consisting of client-side software for iOS devices and server-side software for a cloud server and conducted experiments to travel cherry-lined roads and record videos by several cars. As a result, we confirmed that our method can identify flowering cherries at about 74 % precision and 84 % recall. We also confirmed that our k-stage sensing method could achieve the comparable PoI detection rate with half sensing times compared to a conventional method.