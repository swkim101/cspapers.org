Indexing and searching for digital information, especially images and video, are becoming important issues, because of the remarkable increase of digital documents. Content-based image retrieval technique is receiving widespread research interest, and many image retrieval systems, such as QBIC [1], Photobook [2] and VisualSEEK [4] have been developed So far, a lot of efforts have been put on image feature extraction in terms of colour, texture, shape and spatial relations (i.e., visual features). However, few approaches achieve a reasonable image content extraction and description at semantic level, that is a suitable description of the object content (i.e. objects in the images and the relationships between them) rather than the visual feature content extraction. This is mainly due to the fact that all objects have different visual appearances, which makes hardly possible to employ any exact mathematical formalisation for the same object. For instance, a table has various forms (shapes) in an image collection. In addition to the traditional extraction of' the wsual features, the alto of our work is also to extract and describe image contents at the semantic level, such as the extraction of concepts like tree, table, sky, beach, etc. This indexing enables the users to retrieve the deslred images which people usually want: "Please look for photos of my daughter playing m the garden". Usually, users group photos by semantic content rather than by low feature content [5]. As a consequence, the image segmentatmn and retrieval should be based on the results of understanding image contents. The approach described in [6] is a first step towards this direction. The approach shows how a system can be trained to recognize individual objects, handling therefore image retrieval at a semantic level. Object detection in an image is based on an object model. Due to the different appearances, multiple models are normally reqmred for each object defimt~on. For instance, when we talk about "sky", it may refer to blue clear sky, cloudy sky or sunset sky. In this case, the major role of the visual features (colour, texture, shapes, etc.) is to provide evidences for selecting the right object model. Despite the relative efficiency of the approach described in [6], because of the variant visual appearances of the objects in an image collection, it is not possible to avoid ambiguity and uncertainty in the indexing process. Obwously, for some cases the system is not able to give a precise semanuc label to an object. Also, some parts of the image may left unlabelled. For instance, a blue sky can be wrongly labelled as water m