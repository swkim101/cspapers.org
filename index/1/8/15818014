Recent developments in the design of human-machine interfaces have resulted in interfaces which make access to computer-based equipment more difficult for visually disabled people. The aim of this project was to explore whether it is possible to adapt such interfaces so as to make them usable by people who cannot see a screen. The approach adopted was based upon two principles: the replacement of visual interface entities by auditory analogues and appropriately constraining the resultant interface. Two forms of sound were used to embody the auditory interface: musical tones and synthetic speech. In order to test the principles a word processing program was implemented which demonstrated that a visual program might be adapted to be accessed through such an interface.