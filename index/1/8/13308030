Indexing text for accurate retrieval ZS a dificuli and in)portant problem.. On-ltne information services generally depend on “keyword” mdtces rather ihat~ other methods of retrieval, because of the pract~cal jealures of keywords for storage, dtssemtnatlonj and browsing m well as for retrveval. However, these methods OJ ~ndex~ng hove two major drawbacks: First, they m vst be laboriously asstgned by human indexers. Second, they are znaccuraie, because of mistakes made by these zndezers as well as the dtficulties users have tn choosing keywords jor their queries, and the ambzgulty a keyword may have. Carrent natural language text processing (AILP) lneihods help to overcome lhese problems. Such methods caa provzde auiomaiic ~ndezlng and keyword assign njeni capabilities that are at least as accuraie as human indezers in many applications. In adddlon, NLP syste?ns can merease the information conta~ned Ln keyword fields by separating keywords into segment~, or distinct fields that capture certain dtscrlminating content or relations among keywords. Th~s paper reports on a system that uses natural language text processing to derive keywords from free ted news siorles, separat,e these kegwords into segments, and awtomatica!iy butld a segmented database. The systenl M used as part of a conlmerctai news “cllpplng” altd relrieual prodwct. Preliminary rrsvlts show zn~provfd accuracy, as well as reduced cost. r[sulitng front fhesc oo tornated techniques.