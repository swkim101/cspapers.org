Vision-based robotic applications such as Simultaneous Localization and Mapping (SLAM), global localization, and autonomous navigation have suffered from problems related to dynamic environments involving moving objects and kidnapping. One of the possible solutions to these problems is to establish robust correspondences when obtaining images from static scenes. Therefore we propose an efficient technique for determining correspondences to recover the current camera pose; in the proposed method, the FAST corner detector and SIFT descriptors are combined because in many methods for vision-based robotic applications, corner features have been adopted since they enable fast computation and simplify the computation of the correspondences between consecutive images. However, to recover the pose of the camera after kidnapping or at an unknown initial position, a robust feature matching algorithm is required because the pose of a camera is unlikely to be the same as the poses in the database images. For this purpose, first, we determine some candidates for correspondences by combining corners with their multiple descriptors computed from previously defined scales, and then we select one of these candidates by optimizing the scale using a variant of the mean-shift algorithm. We apply the proposed matching algorithm to kidnapping and visual occlusion problems in autonomous navigation.