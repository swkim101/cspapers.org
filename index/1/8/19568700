A mobile robot with the task to detect objects of interest in its sensor patterns has to cope with ambiguous information. This paper defines the corresponding fusion process as a sequential decision problem with the objective to disambiguate initial object hypotheses. Reinforcement learning is proposed to develop efficient fusion strategies in terms of sensorimotor mappings. The presented system learns object models from visual appearance and uses a connectionist architecture for a probabilistic interpretation of the 2D views. The expected gain in the global classification accuracy provides a utility measure to reinforce actions leading to discriminative viewpoints. The system is verified in experiments with a sewer robot on the task of visually detecting house inlets in sewage pipes for navigation purposes. Crucial improvements in performance are gained using the learned fusion strategy in contrast to arbitrary action selections.