Prefetching and caching are widely-used approaches for improving the performance of file systems. A recent study shows that it is important to integrate the two, and proposed an algorithm that performs well both in theory and in practice [2, I]. That study waa restricted to the case of a single disk. Here, we study integrated prefetching and caching strategies for multiple disks. The interaction between caching and prefetching is further complicated when a system has multiple disks, not only because it is possible to do multiple prefetches in parallel, but also because appropriate cache replacement strategies can alleviate the load imbalance among the disks. We present two offline algorithms, one of which has provably near-optimal performance. Using tracedriven simulation, we evaluated these algorithms under a variety of data placement alternatives. Our results show that both algorithms can achieve near linear speedup when the load is distributed evenly on the disks, and our best algorithm performs well even when the placement of blocks on disks distributes the load unevenly. Our simulations also show that replicating data, even across all of the disks, offers little performance advantage over a striped layout if prefetching is done well. Finally, we evaluated online variations of the algorithms and show that the online algorithms perform well even with moderate advance knowledge of future file accesses.