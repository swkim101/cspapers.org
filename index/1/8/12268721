We study how an autonomous robot can attain a cognitive process that accounts for its symbolic manipulation of acquired knowledge without generating fatal gaps from the reality. The paper focuses on two essential problems; one is the symbol grounding problem and the other is how the internal symbolic processes can be situated with respect to the behavioral contexts. We investigate these problems by applying a dynamical system's approach to the robot navigation problem. Our formulation, based on a forward modeling scheme using recurrent neural learning, shows that the robot is capable of learning grammatical structure hidden in the geometry of the workspace from the local sensory inputs through its navigational experiences. Furthermore, the robot is capable of mentally simulating its own action plans using the acquired forward model. Our assertion is that the internal representation obtained is grounded, since it is self-organized solely through interaction with the physical world. We also show that structural stability arises in the interaction between the neural dynamics and the environmental dynamics, which accounts for the situatedness of the internal symbolic process.