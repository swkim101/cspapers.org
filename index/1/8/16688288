In multiprocessor architectures, it is frequently necessary to provide parallel communication among a potentially large number of processors and memories. Among the many interconnection schemes that have been proposed and analyzed, shuffle-exchange networks have received much attention due to their ability to allow a message to pass from any node to any other node in a number of steps that grows only logarithmically with the number of interconnected nodes (in the absence of contention) while keeping the number of hardware connections per node independent of the number of nodes.
Straight-forward use of shuffle-exchange networks to interconnect &Ngr; nodes involves having every packet pass through log2 &Ngr; stages enroute to its destination. By exploiting common structure in the addresses of the source and destination nodes, however, more sophisticated routing can reduce the average number of steps per message below log2 &Ngr;. In this paper, we describe and evaluate three levels of improvements to basic single-stage shuffle-exchange routing. Each one yields successively more benefit at the cost of more complexity. Using simulation, we show that the use of routing schemes that reduce the average distance can substantially reduce average message delay times and increase interconnection network capacity. We quantify the performance gains only in the case where messages from one node are destined with uniform probability over all nodes. However, it is clear that the advantage of the new schemes we propose would be still greater if there is some “locality” of communication that can be exploited by having the most frequent communication occur between pairs of nodes with shorter distances separating them.