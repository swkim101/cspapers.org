This paper presents an efficient approach to address the task of learning from large number of learning examples in structural domains. While in attribute-value representations only one mapping is possible between descriptions, in first order logic representations there are potentially many mappings. Classic approaches consider all mappings and then define a restricted hypothesis space to cope with the intractability of exploring all mappings. Our approach is to select one particular type of mapping at a time and use it as a basis to define a new hypothesis space. We show that such a hypothesis space, called a Matching Space, may be represented using attribute-value pairs. In a Matching Space, it is therefore possible to use propositional learners. The concept descriptions found may then be mapped back into the initial first order logic representation. It appears that characterizing a Matching Space is equivalent to shifting the representation of examples: the new learning examples represent only a "part" of the initial examples. Based on a taxonomy of elementary parts provided by the user, we consider a particular set of composite parts —called "morions"— that are used to automatically and iteratively change the representation of examples. Experimental results obtained with an implemented system, REMO, show the benefits of this approach. We have used REMO to learn characteristic descriptions of concepts related to the pronunciation of Chinese characters from a corpus of more than three thousands characters.