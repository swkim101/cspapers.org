Patrolling is an important task for autonomous mobile robots. In this paper, we focus on a single patrolling robot in indoor environments composed of rooms. For the robot, it is required to visit the rooms and detect unknown intruders as many as possible. However, the robot does not have correct information about intruders in the initiation step of patrolling. Therefore, the robot first acquires the information through the patrolling trials. As for the information, the robot focuses on intrusion probabilities into the rooms. Subsequently, target rooms are determined on the basis of the intrusion probabilities. This so-called explore/exploit tradeoff in reinforcement learning is a challenge for the intelligent patrolling. In this paper, we tackle the patrolling problem as a part of the learning issues. Thus a multi-armed bandit problem is introduced. For the challenge, we propose stochastic patrolling strategies based on Bayesian learning. Simulation experiments show that the robot is enabled to estimate the correct intrusion probabilities of the rooms. Through the discussion of the patrolling results, finally, we present the most effective patrolling strategy.