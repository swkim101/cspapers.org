The ability to track moving objects is a key part of autonomous robot operation in real-world environments. Whilst for many tasks knowing the positions of objects may be sufficient, tracking the identity of targets may also be desirable. When objects are well separated preserving identities is trivial, however, the identities of objects that pass close to one another may become confused. This paper considers methods to maintain the identities of tracked objects using a combination of LIDAR and video data. When objects are well separated, they are tracked using location information from the LIDAR. When objects move together and their identities cannot be resolved, interactions are recorded and later resolved using appearance models. A vision based approach is adapted for use with LIDAR data and a new method for identity reasoning is proposed. The methods are validated on a dataset comprising a total of 37906 manually labelled point cloud segments.