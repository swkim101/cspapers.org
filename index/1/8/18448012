Assessing student performance in cybersecurity labs and exercises is a difficult and time-consuming task. Simply recording the number of correct answers is inferior to in-depth assessment. Faculty are often best placed to offer expert feedback, advice, and guidance based on assessing student achievement and quality of performance for time-constrained exercises. Since this often takes place in the context of large classes and complex exercises, it can present obstacles to offering qualitative feedback. Yet, in some cases there is more information available that could simplify this task. This paper explores the use of command line history and visualization to add additional information and simplify the problem.