We consider the problem of maintaining aggregates and statistics over data streams, with respect to the last <i>N</i> data elements seen so far. We refer to this model as the <i>sliding window</i> model. We consider the following basic problem: Given a stream of bits, maintain a count of the number of 1's in the last <i>N</i> elements seen from the stream. We show that using <i>O</i>(1/<i>e</i> log<sup>2</sup><i>N</i>) bits of memory, we can estimate the number of 1's to within a factor of 1 + ε. We also give a matching lower bound of Ω(1/<i>e</i> log<sup>2</sup> <i>N</i>) memory bits for any deterministic or randomized algorithms. We extend our scheme to maintain the sum of the last <i>N</i> positive integers. We provide matching upper and lower bounds for this more general problem as well. We apply our techniques to obtain efficient algorithms for the <i>L<inf>p</inf></i> norms (for <i>p</i> ε [1, 2]) of vectors under the sliding window model. Using the algorithm for the basic counting problem, one can adapt many other techniques to work for the sliding window model, with a multiplicative overhead of <i>O</i>(1/εlog <i>N</i>) in memory and a 1 + ε factor loss in accuracy. These include maintaining approximate histograms, hash tables, and statistics or aggregates such as sum and averages.