This paper deals with sensor-based path planning and exploration for robots (with non-trivial geometry and kinematics, such as a manipulator arm) moving in unknown environments. The manipulator (with many degrees of freedom) is assumed to be equipped with two sensing modalities: (i) a large number of proximity sensors mounted on its body (the "skin" sensor) and (ii) a range sensor mounted on its wrist (an "eye" sensor). The task for the robot is to move around and explore its (initially) unknown environment while avoiding collisions with obstacles that are (initially) unknown to the robot. We present a sensor-based planning algorithm that utilizes information from these two drastically different sensing modalities, the "eye" and the "skin". Planar simulations show that combining use of eye and skin sensors leads to more efficient and more extensive exploration than with eye sensing modality alone.