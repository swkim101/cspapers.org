In present days, the number of application in which robots and users share the same workspace is increasing, as long as the need of cooperation between them. To achieve a smooth cooperation, in particular in surgical applications, the robot needs to timely change its behavior to adapt to the needs of the user. In this work, a simplified scenario for neurosurgery was defined in which the user interacts with the robot through a Graphical User Interface (GUI) and by touching the robot links and, based to those events and on the current status, different control modes are enabled in the high level controller we developed, such as autonomous, cooperative and teleoperation. Experiments were performed to measure the performances and safety of the developed high level controller in handling the transitions between two states by checking the continuity of data from the robot and from an external measurement system. Results proved that the trajectories of the end effector and links during the switching phase are continuous and thus the modular high level controller developed switches control safely without undesired deviation from desired course.