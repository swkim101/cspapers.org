Learning by demonstration methods have gained considerable interest in human-coupled robot control. It aims at modeling the goal motion trajectories through human demonstration. However, in lower exoskeleton control, the physical human-robot interaction is changing from pilot to pilot or even for one pilot in different walking patterns. This characteristic requires that the exoskeletons should have the ability to learn and adapt the motion trajectories as well as controllers online. This paper presents a novel Hierarchical Interactive Learning (HIL) strategy which reduces the complexity of the exoskeleton sensory system and is able to handle varying interaction dynamics. The proposed HIL strategy is composed of two learning hierarchies, namely, high-level motion learning and low-level controller learning. The Dynamic Movement Primitives (DMPs) combined with Locally Weighted Regression (LWR) are employed to model and learn the motion trajectories, while reinforcement learning (RL) is used to learn the model-based controller. We demonstrate the efficiency of proposed HIL strategy on a single degree-of-freedom (DOF) platform as well as a HUman-powered Augmentation Lower EXoskeleton (HUALEX) system. Experimental results indicate that the proposed HIL strategy is able to handle the varying interaction dynamics with less interaction force between the pilot and the exoskeleton when compared to traditional model-based control algorithms.