In order to recover camera motion and 3-d structure from a sequence of images we must rst relate points in the image plane to directions in space. This paper describes a least-squares algorithm for computing camera calibration from a series of motion sequences for which the translational direction of the camera is known. The method does not require special calibration objects or scene structure. It only requires the ability to move the camera in a given direction and to track features in the image as the camera moves. This method diiers from other recently developed approaches in at least two respects. First, since it is a linear least-squares method, it can include information from many sequences to produce a robust estimate of the calibration matrix, which can be updated dynamically as new measurements are taken. Second, it uses the most general possible linear model for calibration. Experimental results from applying the algorithm to a set of real motion sequences with noisy correspondence data are given and analyzed.