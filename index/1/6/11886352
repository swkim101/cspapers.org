Developmental robots require cognitive structures that can learn perception-action cycles via interactions with the environment. Here, we extend the efficient coding hypothesis, which has been used to model the development of sensory processing in isolation, to model the development of the perception-action cycle. Our extension combines sparse coding and reinforcement learning so that sensory processing and behavior co-develop to optimize a shared intrinsic motivational signal: the fidelity of the neural encoding of the sensory input under resource constraints. Applying this framework to a model of a robot actively observing a time-varying environment leads to the simultaneous development of visual smooth pursuit behavior and model neurons similar to cortical neurons selective to visual motion. We suggest that this general principle may form the basis for a unified and integrated approach to learning many other perception/action loops.