Synthesizing images of a real scene at novel viewpoints other than those of some given images is important for image-based rendering, hybrid reality, and other applications that involve real scenes. Novel view synthesis has been dealt with via explicit 3D reconstruction, image transfer, or plenoptic modeling. In this paper we present an interpolation-based solution that avoids the need of explicit 3D reconstruction. The key difficulty in the interpolation approach is, as viewpoint changes, not only could a scene feature's intensity profile in the image change, its image position could also shift. We show that a novel interpolation scheme, which we refer to as iEBI (indexed function example-based interpolation) mechanism, could tackle the difficulty and acquire quality novel views even from only a few example views. Experimental result on some benchmarking image data is shown to illustrate the solution's performance.