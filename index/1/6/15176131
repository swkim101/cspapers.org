We present a novel approach to deal with visual loop closure detection independently from the point of view in large scale environments. Loop closure detection is the process of recognizing when a robot comes back to a previously visited location and is a key issue for place recognition, topological localization and visual Simultaneous Localization And Mapping. Our solution relies on an ego-centred spherical representation of the environment and the exploitation of two kinds of information: local appearance and global feature density. Local appearance is provided by local features extracted from the spherical representation and processed using the bag of visual words approach. Global density information is computed from the distribution over the sphere of these features thus characterizing the environment structure. The approach is purely appearance-based and does not involve any geometric information such as epipolar constraints. An experiment on an 1.5kms trajectory in an environment containing buildings and vegetation validates our algorithm and shows a reduction of the false alarm rate by about 50% for the same probability of detection compared to the standard bag of visual words approach.