This position paper describes the IDIAP smart meeting room, the data streams it can capture, and some of the processing results that can be obtained from this data. It also describes a media browser whose aim is to enable interactive navigation within meeting recordings, and quickly find and play back segments of interest within these recordings. INTRODUCTION The Ambient Intelligence vision foresees rooms that record and observe human activity through multiple sensors such as video cameras and microphones. New benefits enabled by these types of rooms are varied and still in the process of being defined. One use for these systems is to recognize and assist with human communication. At IDIAP we have set up an experimental “smart meeting room” which records multi-party meetings with dozens of multimodal data streams and then processes these media streams to recognize events of potential interest. The aim is to enhance multi-party communication – both during the meetings, and outside the meetings afterwards. In this position paper, we describe how multimodal meeting recordings can be captured, structured and displayed for interactive browsing. Our approach makes use of processing techniques that recognize structure within these meetings, but combines automatic processing with manual interactive exploration of multimedia representations of the recordings. Our position is that effective browsing of recorded meetings requires the careful combination of both automatic recognition as well as interactive browsing. The combination of machine learning techniques with HCI may be a common requirement of ambient intelligence systems. The remainder of this paper is structured as follows: • A brief description of the IDIAP smart meeting room as a prototype example of an Ambient Intelligence environment • Discussion of some of the more important data streams captured and processed by the room. • Examples of some automatic processing results that we can obtain from these data streams • Description of a meeting browser that provides interactive manipulation to navigate and playback segments of interest from the meeting recording. The workshop presentation will also include a short demonstration of this browser to illustrate the issues addressed in this paper • Brief discussion of how to evaluate such a browser. THE IDIAP SMART MEETING ROOM The IDIAP smart meeting room is in many ways an ordinary conference room with a table, whiteboard, and computer projection screen. But the room it is also equipped with 24 microphones configured as lapel microphones, in the ears of a binaural manikin, and in two 8 channel tabletop microphone arrays (See Figure 1). Figure 1. IDIAP smart meeting room There are also three video cameras, and equipment for capturing time-stamped whiteboard strokes, pen strokes, and the computer projected images. All recorded data is precisely synchronized so that every microphone, penstroke, and video sample can be associated with simultaneously captured samples from other media streams. Figure 2 illustrates how timestamps are encoded in the upper two lines of each video frame. Further details about this room and its equipment are described in [2].