This paper proposes an interpretation system for recognizing human motion behaviors and constructing the behavior rules called Behavior Grammar. The system recognizes human motion behaviors based on the gestures, locations, directions, and distances by using a distributed omnidirectional vision system (DOVS). The DOVS consisting of multiple omnidirectional cameras is a prototype of a perceptual information infrastructure for monitoring and recognizing the real world. The sequences of interpreted behaviors are represented as a behavior graph to extract behavior rules. This paper shows how the system realizes robust and real-time visual recognition based on View and Motion based Aspect Models (VAMBAM) and the resultant behavior graph.