Vision sensors give mobile robots a relatively cheap means of obtaining rich 3D information of their environment, but lack the depth information that a laser range finder can provide. This paper describes a novel composite sensor approach that combines the information given by an omnidirectional camera and a laser range finder to efficiently solve the indoor Simultaneous Localization and Mapping problem and reconstruct a 3D representation of the environment. We report the results of validating our methodology using a mobile robot equipped with a 2D laser range finder and an omnidirectional came