The TOUR model is a computational model of human commonsense Knowledge of large-scale space. It shows how observations are assimilated into a description, from multiple perspectives, of the spatial environment. In this paper we propose a representation for sensory events at a level suited to this investigation, and an inference strategy by which these sensory events are assimilated into descriptions of spatial structure. We also discuss the states of partial Knowledge that occur during the learning process, and show that the representation exhibits graceful degradation of performance under resource limitations.