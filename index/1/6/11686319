We present a statistical method that exactly learns the class of constant depth µ-perceptron networks with weights taken from {-1,0 + 1} and arbitrary thresholds when the distribution that generates the input examples is member of the family of product distributions. These networks (also known as nonoverlapping perceptron networks or read-once formulas over a weighted threshold basis) are loop-free neural nets in which each node has only one outgoing weight. With arbitrary high probability, the learner is able to exactly identify the connectivity (or skeleton) of the target µ-perceptron network by using a new statistical test which exploits the strong unimodality property of sums of independent random variables.