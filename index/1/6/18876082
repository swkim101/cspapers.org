Brain-machine interfaces open a direct channel between a brain and a robot. This channel is commonly used to provide direct and active input to the robot, resulting in a tele-operation system. We argue in favor of a more passive brain-machine interface as a means for human-robot interaction. There, the brain signals of the human interaction partner are constantly monitored and decoded to detect particular states that correlate with events in the robot's behavior. Such a state can be surprise due to a strange or erroneous robot action. We review three studies that we conducted with our own EEG-based brain-robot interface framework. The interface is active, that is, we directly control humanoid robots in different application scenarios in a semi-autonomous manner. Our results show that automated and unconscious components in the EEG are the most robust and acceptable for the user. These are exactly the components that are useful for a passive interface. Finally, we present a pilot study where we extract correlates of human surprise from an interaction with a real humanoid robot. We show that, currently in offline analysis, we are able to extract similar components used in the structured, stimulus based active interfaces. We pinpoint the issues that need to be solved, such as a more reliable real-time decoding of brain signals from real-world interaction situations.