We analyze in detail the performance of a Hamming network classifying inputs that are distorted versions of one of its m stored memory patterns. The activation function of the memory neurons in the original Hamming network is replaced by a simple threshold function. The resulting Threshold Hamming Network (THN) correctly classifies the input pattern, with probability approaching 1, using only O(m ln m) connections, in a single iteration. The THN drastically reduces the time and space complexity of Hamming Network classifiers.