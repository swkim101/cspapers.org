This study presents an upward-looking camera-based global localization scheme using the position and orientation of ceiling features. If the robot pose is unknown, the region-based ceiling features from the current image are matched to a pre-built feature map from the RBPF-based SLAM process. Then, the candidate areas of the real robot pose are set around the matched features. The candidates are represented by two spots for the features having both position and orientation, while by a circle if they have only position. Finally, the real robot pose is determined at the intersection point. The candidate areas are realistically modeled by applying the observation error, and useless candidates are significantly reduced by considering the feature orientation. Several experiments in real environments validated the effectiveness of the proposed global localization scheme.