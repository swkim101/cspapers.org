Service robots are becoming increasingly available and it is expected that they will be part of many human activities in the near future. It is desirable for these robots to adapt themselves to the user’s needs, so non-expert users will have to teach them how to perform new tasks in a natural way. In this paper a new teaching by demonstration algorithm is described. It uses a Kinect R © sensor to track the movements of a user, it represents the tasks with a relational representation to facilitate the correspondence problem between the user and robot arm and to learn a more general policy, it uses reinforcement learning to improve over the initial sequences provided by the user, and it incorporates on-line feedback from the user during the learning process creating a novel dynamic reward shaping mechanism to converge faster to an optimal policy. We demonstrate the approach by learning simple manipulation tasks of a robot arm and show its superiority over more traditional reinforcement learning algorithms.