With the renaissance of neural network in recent years, relation classiﬁcation has again become a research hotspot in natural language processing, and leveraging parse trees is a common and effective method of tack-ling this problem. In this work, we offer a new perspective on utilizing syntactic information of dependency parse tree and present a position encoding convolutional neural network (PECNN) based on dependency parse tree for relation classiﬁcation. First, tree-based position features are proposed to encode the relative positions of words in dependency trees and help enhance the word representations. Then, based on a redeﬁnition of “context”, we design two kinds of tree-based convolution kernels for capturing the semantic and structural information provided by dependency trees. Finally, the features extracted by convolution module are fed to a classiﬁer for labelling the semantic relations. Experiments on the benchmark dataset show that PECNN outperforms state-of-the-art approaches. We also compare the effect of different position features and visualize the inﬂuence of tree-based position feature by tracing back the convolution process.