I. INTRODUCTION Telerobotic surgical systems involve a slave robot, which interacts with the patient, and a master console, operated by the human surgeon. The slave robot reproduces the hand movements of the surgeon, who in turn needs to observe the operative environment with which the robot is interacting. The latter can be achieved by a combination of visual and haptic cues that flow from the operating table to the surgeon. Visual feedback is already available in commercial robotic surgery systems (e.g., the Intuitive Surgical da Vinci Si), but current surgical robots have very limited haptic feedback, despite its expected clinical benefits [1]. This omission is mainly due to the negative effect that haptic feedback has on the stability of the teleoperation loop. Haptic force feedback can in fact lead to undesired oscillations of the system, which interfere with the surgery and may be dangerous for the patient [2], [3]. In this respect, cutaneous feedback has recently received great attention in the haptics and medical research fields; delivering ungrounded sensory cues to the surgeon's skin conveys rich information and does not affect the stability of the teleoperation system [2], [4], [5]; Prattichizzo et al. [2] call this approach sensory subtraction, in contrast to sensory substitution, as it subtracts the kinesthetic part of the interaction to leave only the cutaneous cues. This paper presents a novel cutaneous feedback system for the da Vinci surgical robot, as shown in Fig. 1. Designed to provide planar fingertip deformation and vibration cues to the surgeon, our system is composed of a BioTac tactile sensor mounted to one of the robot's slave tools and a cutaneous display device attached to the corresponding master controller. Contact deformations and vibrations sensed by the BioTac are directly mapped to input commands for the cutaneous device's motors using a model-free data-driven algorithm. A preliminary version of the deformation part of the algorithm was presented in [6].