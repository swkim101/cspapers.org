Our computational model is a random access machine with n read only input registers each containing c log n bits of information and a read and wile memory. We measure the time by the number of accesses to the input registers. We show thal for all k there is an E > 0 so that if n is sufficiently large then the elements distinctness problem cannot be solved in time kn with en bits of read and wile memory. that is. there is no machine with this values of the parameters which decides whether there are two different input registers whose contents are identical. Intmduction. One of the main goals of complexity theory is the separation of non-deterministic and deterministic computation. We solve the problem for random access machines with certain restrictions on the size of their working memory. Although the restrictions are strong, the working memory must be smaller than the input. still. under certain circumstances this computational model is realistic as we will explain later. Our seacrh problem. as described in the abstract is the element distinctness problem. that is. we have to decide whether there are different input registers with identical contents. We also show that there is a simple decision problem that can be solved in constant time (actually in IWO steps) using non-deterministic computation, while there is no deterministic linear time algorithm with enlogn bits read and write memory which solves the problem. More precisely if we allow kn time for some fixed constant k, then there is an 6 > 0 so that the problem cannot be solved with in log n bits of read and write memory if n is sufficiently large. The decision problem is the following: “Find two different input registers, so that the Hamming distance of their contents is at most i c log n”. i can be replaced by any fixed 0 < 7 < 4 if c is sufficiently loge with respect to 7. We actually show that the promise problem : “decide whether all occurring Hamming dist‘ances are greater than ($ r)c log n Copyright ACM 1999 I-58113.067.8199105...$5.00 or there is at least one which is smaller than ye log n” where 7 > 0 is an arbitmrily small constant, cannot be solved by a nonlinear algorithtn with the described limitations even if we know that we only get inputs where one of these conditions hold. (In this case E may depend on y loo). The proof of the theorem about the element distinctness problem is the main contribution of the present paper to the theory of lower bounds. We include the theorem about Hamming distances to give a more complete picture about the determinism versus non-determinism question and also because both in a motivational and technical sense the element distinctness result is built on it. (For a comparison to previously known lower hounds see the remarks about branching programs below.) The element distinctness problem is of great practical and theoretical interest, it has been studied in great detail in various computational models, particularly in the comparison model (see [BFKLT]. [BFW. [Kl, [Yl). A time space tradoff TS = n(n”) for the elements distinctness problem on comparison-based branching programs was conjectured by Borodin et al in [BFKLTI. A. Yao [Yl proved a tradeoff TS = R(na-‘(“)), where c(n) = O(l/(logn)+), which is very close IO optimal since Z’S = O(n’) is achievable even for sorting in the range c1 log n < S < czn/ log n (See [PR]). The best upper bounds for the element distinctness problem are given in the RAM model. We can solve the element distinctness problem with bucket sorting in our RAM in linear time with c’n log n bits of read and write memory, where c’ is a suitably choose” constant (see [AHlJl). This is a determinstic (non-probabilistic) algorithm. Our lower bounds are also about non-probabilistic algorithms. For the element distinctness problem we give a probabilistic algorithm which solves it in time kn with en hits of read and write memory provided that k > 0 is sufficicntly large with respect to e and n is sufficiently large with respect to k. Moreover our algorithm can be implemented in a random access machine defined in the usual sense. that is where 11x memory is organized into registers and we allow only arithmetic operations etc. (For the exact statement of this result see Theorem 5 in the last section.) This makes it very unlikely that our lower bound for the element distinclness problem can be improved since the ratio between the