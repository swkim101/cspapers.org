In this paper we derive and implement an algorithm for an indoor mobile robotics platform to estimate the manipulability of initially unknown obstacles while navigating through its environment to a pre-specified goal. The environment is represented by an evidence grid, where each cell contains a gamma-distributed cost as well as visual feature data in the form of a color histogram. While navigating, the robot associates visual features of objects occupying a given cell with manipulability cost estimates of that cell, learning whether an object or obstacle can be moved or not in the robot's attempt to reach the goal. We derive and utilize a lower confidence bound (LCB) estimate for the cost of each cell in order to incorporate an exploration (versus pure exploitation) element to the robot's search for the lowest-cost path. Combining the LCB cost estimates with the dynamic replanning search algorithm D*-Lite, we can quickly compute optimal navigation paths regardless of the numerous changes occurring in the robot's environmental belief state. We explain the probabilistic representation of cost in the evidence grid and provide simulation and real-world results for our algorithm in a navigation scenario with static and movable objects.