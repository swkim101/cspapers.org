In this paper we propose that two images are captured of every scene: a normal image and an image captured where a coloured filter is placed in front of the camera. This additional information is then used in solving for colour constancy. The novelty of our approach is not that we add a colour filter (this is an old idea) but in how we use the additional information. In contradistinction to previous work we propose that the dimensionality of the 6 measurements per image pixel remains at 3 (not 6): we do not add a filter to increase the number of degrees of freedom but rather as a way of estimating the illuminant. We say that a filter is chromagenic if the relationship between filtered and unfiltered RGBs varies with and depends strongly on illumination. The canonical chromagenic algorithm works by testing the applicability of pre-computed relations in situ in an image. We extend the chromagenic approach to incorporate knowledge of the gamut of colours we expect to see under a given light and so in effect we make a hybrid gamut mapping + chromagenic algorithm. Experiments validate our approach with chromagenic gamut mapping shown to deliver significantly better constancy than all other algorithms tested.