Java applications form an important class of applications running in the data center and in the cloud. They may perform better when more memory can be used in the heap, as the time spent in garbage collections is reduced. However, when ample CPU is available and memory is tight, such Java applications may do well with a smaller heap as it can absorb the cost of more garbage collections. In the cloud, the amount of resources available may vary from time to time. This paper investigates an approach based on the statistical design of experiments and performance data analytics to make resource trade-offs, between CPU and memory, to increase datacenter efficiency in the cloud.