We present a simple and practical algorithm for the <i>c</i>--approximate near neighbor problem (<i>c</i>--NN): given <i>n</i> points <i>P</i> ⊂ R<sup><i>d</i></sup> and radius <i>R</i>, build a data structure which, given <i>q</i> ∈ R<sup><i>d</i></sup>, can with probability 1 -- Δ return a point <i>p</i> ε <i>P</i> with dist(<i>p, q</i>) ≤ <i>cR</i> if there is any <i>p</i>* ε <i>P</i> with dist(<i>p</i>*, <i>q</i>) ≤ <i>R</i>. For <i>c</i> = <i>d</i> + 1, our algorithm deterministically (Δ = 0) preprocesses in time <i>O</i>(<i>nd</i> log <i>d</i>), space <i>O</i>(<i>dn</i>), and answers queries in expected time <i>O</i>(<i>d</i><sup>2</sup>); this is the first known algorithm to deterministically guarantee an <i>O</i>(<i>d</i>)---NN solution in constant time with respect to <i>n</i> for all <i>l</i><sub><i>p</i></sub> metrics. A probabilistic version empirically achieves useful <i>c</i> values (<i>c</i> < 2) where <i>c</i> appears to grow minimally as <i>d</i> → ∞. A query time of <i>O</i>(<i>d</i> log <i>d</i>) is available, providing slightly less accuracy. These techniques can also be used to approximately find (pointers between) all pairs <i>x, y</i> ε <i>P</i> with dist(<i>x, y</i>) ≤ <i>R</i> in time <i>O</i>(<i>nd</i> log <i>d</i>).
 The key to the algorithm is a locality-sensitive hash: a mapping <i>h</i>: R<sup><i>d</i></sup> → <i>U</i> with the property that <i>h</i>(<i>x</i>) = <i>h</i>(<i>y</i>) is much more likely for nearby <i>x, y</i>. We introduce a somewhat regular simplex which tessellates R<sup><i>d</i></sup>, and efficiently hash each point in any simplex of this tessellation to all <i>d</i> + 1 corners; any points in neighboring cells will be hashed to a shared corner and noticed as nearby points. This method is completely independent of dimension reduction, so that additional space and time savings are available by first reducing all input vectors.