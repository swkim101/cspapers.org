This paper examines a class of neuron based learning systems for dynamic control that rely on adaptive range coding of sensor inputs. Sensors are assumed to provide binary coded range vectors that coarsely describe the system state. These vectors are input to neuron-like processing elements. Output decisions generated by these "neurons" in turn affect the system state, subsequently producing new inputs. Reinforcement signals from the environment are received at various intervals and evaluated. The neural weights as well as the range boundaries determining the output decisions are then altered with the goal of maximizing future reinforcement from the environment. Preliminary experiments show the promise of adapting "neural receptive fields" when learning dynamical control. The observed performance with this method exceeds that of earlier approaches.