This paper presents a novel approach to textual question answering (QA) which identifies answers to natural language questions by leveraging large collections of question-answer pairs extracted from web sources or generated automatically from text.
 Instead of using the traditional retrieve-and-rerank approach common to most previous approaches to factoid question answering, we introduce a new model of answer authority which allows question-answering systems to estimate the quality of answers not just in isolation - but in the larger context of the information contained in the corpus as a whole.
 Our approach in this paper hinges on the creation of a new representation of the information stored in a document collection, known as a Question-Answer Database (QUAB).We assume that a QUAB represents a weighted directed graph consisting of the set of factoid question-answer pairs (QAP) that can be asked - and answered - given the content of a corpus. Once a set of QAP have been generated, we use inferential relationships identified by a system for recognizing textual entailment in order to construct the link structure necessary to compute the authority of each interconnected question or answer.
 We have found access to the QUAB graph not only improves the accuracy of current answer retrieval techniques, but also allows for the determination of when no valid answer can be found for a question in a text corpus. Experimental results show that the authority derived from a graph of question-answer pairs can increase the performance of a factoid QA system by nearly 30%.