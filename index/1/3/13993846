The Difference of Gaussian (DoG) saliency maps originally proposed by Koch and Ullman had information channels for intensity, opponent colors, and edge orientations, but from the beginning it was suggested that additional channels could and should be added. This paper addresses selective attention in video sequences, and adds motion channels to the saliency maps. The resulting attention windows display better-than-random correlation to the eye fixations of human subjects. This paper is not the first to add motion data to saliency maps. It is, however, the first paper we know of to explicitly compare the performance of saliency maps with and without a motion channel. The surprising negative result is that adding motion channels does not improve the performance of saliency-based selective attention, as measured by correspondence with human eye fixations. We draw two conclusions from this experiment: (1) although motion is clearly a critical attentional cue, the saliency map model may not extend as easily to motion data as some people (ourselves included) thought; and (2) the standard evaluation metric for selective attention algorithms - better than random correlation to human eye fixations - is outdated. Our community needs to focus on comparative studies between algorithms instead.