This video demonstrates a mixed reality (MR) environment which is constructed for development of autonomous behaviors of robots. Many kinds of functions are required to be integrated for realizing an autonomous behavior. For example, autonomous navigation of humanoid robots needs functions, such as, recognition of environment, localization and mapping, path planning, gait planning, dynamically stable biped walking pattern generation, and sensor feedback stabilization of walking. Technologies to realize each function are well investigated by many research works. However, another effort is required for constructing an autonomous behavior by integrating those functions. We demonstrate a MR environment in which internal status of a robot, such as, sensor status, recognition results, planning results, and motion control parameters, can be projected to the environment and its body. We can understand intuitively how each function works as a part of total system in the real environment by using the proposed system, and it helps solving the integration problems. The overview of the system, projection of each internal status, and the application to an autonomous locomotion experiment are presented in the video clip.