This paper presents a semantic spatial language grammar and a novel chunking method that allows nested structures to be encoded as a single label. The proposed semantic grammar, when used with a cognitive architecture described elsewhere, makes it possible for a mobile robot to follow complex, human-generated spatial descriptions for a fetch task. The semantic grammar is based on an interdisciplinary analysis of a corpus of human generated indoor spatial language. The "deep" chunking method facilitates encoding deep grammatical structures into a single-level label. The proposed method has been successfully used by an autonomous agent in a virtual environment as well as by a physical mobile robot. The deep chunking approach allows fast, feature-based machine learning methods usually used for shallow chunking to be used for deep nested parsing which better supports real-time interaction with a robot. Preliminary accuracy results are presented along with planned improvements and additional applications.