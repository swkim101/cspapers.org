This paper uncovers the axiomatic basis for the probabilistic relation "x is independent of y, given z" and offers it as a formal definition of informational dependency. Given an initial set of such independence relationships, the axioms established permits us to infer new independencies by non-numeric, logical manipulations. Additionally, the paper legitimizes the use of inference networks to represent probabilistic dependencies by establishing a clear correspondence between the two relational structures. Given an arbitrary probabilistic model, P, we demonstrate a construction of a unique edge-minimum graph G such that each time we observe a vertex x separated from y by a subset S of vertices, we can be guaranteed that variables x and y are independent in P, given the values of the variables in S.