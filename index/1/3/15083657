The digital segmentation algorithm described in this paper subdivides speech signals into discrete sections which permit to localize most of the spoken phonemes in natural speech. Two pre-segmenta-tion steps separate pauses and voiceless parts from the (voiced) rest of the signal. The subsequent main segmentati on step tries to describe the speed of articulation in the vocal tract according to some global speech parameters. Since, during an utterance, the vocal tract does not move at constant speed, but attempts to realize the articula-tor y target position associated with each phoneme, sections with relatively low changes of vocal tract position ("stationary" segments) and sections with greater changes ("dynamic" segments) can be separated. The dynamic segments can be further characterized when the direction of change in the course of the parameters is regarded. 1. Introduction This paper describes a segmentation algorithm which forms part of a recognition system for natural speech on the basis of phonemes and phoneme-like elements (Fig. I). The topic of this paper will be confined to the segmentation steps; the remaining steps of the system have been described elsewhere The extreme difference between the information content of the acoustic speech signal and its written counterpart forms one principal problem of any automatic speech recognition system. The classifier itself which classifies the signal into the desired output classes (such as words, phonemes etc.) usually cannot cope with an information content too large. Therefore,it needs a preprocessor which reduces the great redundancy of the signal. For this, one has to extract a series of significant parameters which, whatever they are, maintain most of the (phonetic) information significant for the classi-fier, but throw off a great part of the signal redundancy. Another problem in recognition of continuous speech is given by the fact that the output of the recognizer has to be discrete in time, and that the classifier can process a limited number of output classes only. Thus, it is obvious that the output of the classifier in a recognition system for continuous speech cannot be words and even not be syllables /Olson, 1967/. Recognition on the basis of phonemes or similar elementary units, however, requires time localization of these units in the speech signal. That means, it poses the problem of segmentation. It is left to the processing strategy whether segmentation is done together with classification (recognition) or during the preprocessing step /Paulus 1974/. In the system described here, â€¦