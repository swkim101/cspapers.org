Deformations are an essential aspect of our interaction with real bodies, prompting the development of many modelling and simulation methods for virtual environments. Some of the methods address specific classes of interaction, e.g. pushing, grabbing, cutting or needle insertion, whereas hybrid approaches have been proposed to deal with more complex scenarios. However, a general strategy to combine different simulation methods is still not available. This paper presents a unified approach to combine different methods, each optimised for a specific interaction and object type. Our approach is tailored to the needs of simulating haptic Human-Robot Interactions and allows abstracting from the implementation details of different methods for modelling deformable objects. It has been integrated with collision detection and friction models, ported to a graphic processing unit (GPU), and demonstrated with realistic simulations and experiments.