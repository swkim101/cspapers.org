In this paper authors have presented a method to localize and detect human being from Kinect captured sequence of images. The proposed method takes a sequence of gray (G) scale image and the corresponding depth (D) image as input. The gray scale image and the depth information are captured using two different sensors within the same device, Kinect and the processing are executed in the processor attached with Kinect. The proposed method localizes the human by using their motion along x, y direction and then considers all pixels connected with those pixels and over a 3D plane to accomplish the segmentation with an accuracy of 77%. Experimental results demonstrate that our method is robust against existing method for human localization.