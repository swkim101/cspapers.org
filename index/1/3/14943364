We propose a music recommendation prototype named Pictune. Pictune utilizes location-based image retrieval and other Web services to recommend music for users virtually located at any position where such services are available. Our study is theoretically supported by two psychological findings. First, the need for music is driven by diverse motives, such as the leisure, informative, self-educational or experiential motives [2]. Interestingly, such motives are also spotted in photography. Second, the perception of the environment can significantly influence the expectation of music [4]. For example, when a person sees a landmark, its concept may be stimulated, evoking the expectation of other connection related to it, such as music and pictures. On the other hand, the melody of a song can facilitate learning and recall of the situation. The main objective of this work is to develop a mobile Web application which acquires the userâ€™s ambience and retrieves music by it. The ambience of a user, as she accesses the application, is defined by her location, time-of-day (TOD), day-of-year (DOY), and the weather. These elements can be easily acquired from either the terminal or the Web. The main challenge is to explore the correlation between user ambience and the online rich photos, which are associated with numerous tags describing not only the facts (such as the ambience and the object being shot) but also subjective feelings, sensings, perceptions, and intuitions. Pictune contains the following components: (1) A music database where each music is associated with a set of tags. (2) An image database indexed by ambience vector. Each ambience is associated with a set of tagged images. These data are retrieved from Flickr API and an online weather service. The components of the ambience vector are represented in discretized form for ease of computation. (3) A tag-by-ambience matrix Mta (precomputed from the image database) where each element indicates the weight of a tag for a particular ambience. Given the current ambience of a new query, we first compute a vector of relevant tags (denoted by T ) with weights. Then we perform an emotion enhancement process on T , which uses an emotional Word-