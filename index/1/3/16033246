Standard but ad hoc measures such as sum-of-squared pixel differences (SSD) are often used when comparing and registering two images that have not been previously observed before. In this paper, we propose a framework to address the problem of learning a parametric feature distance measure to measure the dissimilarity between pairs of images. The method is based on optimizing the parameters of the distance measure in order to minimize correspondence classification errors on training data. Because the learning process involves relative (rather than absolute) visual content between image pairs, the learned distance measure may also be applied to other images with very different visual content. Results on matching classification with a wide variety of image content show that the learned feature distance measure clearly outperforms the standard measures of SSD, chamfer and Bhattacharyya histogram distances.