Online 3D point cloud classification and scene understanding are crucial tasks for Unmanned Ground Vehicles (UGVs) equipped with multiple laser scanners. Due to the poor performance of traditional 2D image representation model for 3D point clouds, a novel Optimal Bearing Angle (OBA) model is therefore proposed to overcome the limitations of texture information losing and image blurring caused by the UGV's on-the-fly navigation. With the result of 3DSLIC based super-pixel segmentation in OBA images, the center of points belonging to each segmented OBA image patch is assigned as CRF graph node, so that a simplified CRF graph structure is constructed for online contextual classification of 3D laser points in urban environments. Moreover, total 29-dimensional features are extracted from both the raw 3D laser points and the corresponding OBA images. A large number of urban scenes selected from both DUT2 dataset and KAIST dataset are used as testing data in our experiments, and the results show the validity and performance of the proposed method.