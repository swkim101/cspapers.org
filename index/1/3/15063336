In this article we introduce the problem of finding an optimal path in order to find a stationary object placed in the environment whose map is not a-priory known. At first sight the problem seems to be similar to exploration which has been thoroughly studied by the robotic community. We show that a general framework for search can be derived from frontier-based exploration, but exploration strategies for selection of a next goal to which navigate a robot cannot be simply reused. We present three goal selection strategies (greedy, traveling salesmen based, and traveling deliveryman based) and statistically evaluate and discuss their performance for search in comparison to exploration.