This work tackles the problem of recovering the structure of a scene from a single image. The goal is to interpret automatically the image to obtain the spatial layout of the scene. In essence, the method proposed classifies the environment as floor or walls and their relative positions. Instead of using standard cameras for solving this particular task, our work is novel in using omnidirectional vision, which is advantageous as it captures in a single image the whole surrounding structure. We also consider man-made indoor scenes, where geometric relationships like parallelism and orthogonality are common. Our contribution is a new method for recovering the scene layout by using extracted line segments from a single omnidirectional image. Collection of lines and geometric constraints provide sufficient information to generate a set of possible scene structures. We also create a map of orientations in the image to test these hypotheses and select the one with the best fitting as the resultant structure.