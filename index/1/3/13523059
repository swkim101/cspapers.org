This paper deals with the perception subsystem of an autonomous mobile robot which must navigate in structured or semistructured environments. For intervention in high risk zones, mismatches between an a priori known model of the environment and the perceived scenes must be considered, as well as the possibility that the ground is not necessarily horizontal. The incremental building of a model used for localization tasks only is addressed. It contains the representations of particular 3-D features extracted from depth images acquired by a laser range finder. Perceiving the same features again allows reestimation of the positions of the robot and the localization features in the environment. The problem of using simultaneously both previous kind of localization models is particularly considered.