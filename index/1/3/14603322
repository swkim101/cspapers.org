Three questions motivate much work in AI. How should an agent's state of belief be represented? How should an agent change its state of belief upon recording an observation? And what is a practical way for domain experts to convey their states of belief to agents? 
Probability calculus provides answers to these questions: A state of belief should be (1) represented by a probability function over some language, (2) changed using probabilistic conditionalization, and (3) conveyed using a probabilistic causal network. Despite the popularity of these answers, domain experts have often complained about their commitment to numeric degrees of belief. In this thesis, I attempt to address this complaint by suggesting an abstract belief calculus that is not committed to numbers (nor to any specific set of degrees of belief) and yet has the key features of probability calculus. The abstract calculus has three major components: (1) Abstract states of belief, (2) abstract conditionalization, and (3) abstract causal networks. The calculus is also equipped with an algorithm for computing degrees of belief, which corresponds to a popular algorithm in the probabilistic literature. 
I present many concrete instances of the proposed abstract belief calculus. Some of these instances are well known, such as proposition, possibility, and probability calculi. But other instances are novel, such as objection calculus. I also show that objection calculus is closely related to clause management and diagnosis systems--which are influential in AI--and study the ramifications of this relation.