This research is investigating a new interaction paradigm for Interactive Information Retrieval (IIR), where all input and output is mediated via speech. While such information systems have been important for the visually impaired for many years, a renewed focus on speech is driven by the growing sales of internet enabled mobile devices. Presenting search results over a speech-only communication channel involves a number of challenges for users due to cognitive limitations and the serial nature of the audio channel [2]. Other research has shown that one cannot just ‘bolt on’ speech recognizers and screen readers to an existing system [5]. Therefore the aim of this research is to develop a new framework for effective and efficient IIR over a speech-only channel: a Spoken Conversational Search System (SCSS) which provides a conversational approach to determining user information needs, presenting results and enabling search reformulations. This research will go beyond current Voice Search approaches by aiming for a greater integration between document search and conversational dialogue processes in order to provide a more efficient and effective search experience when using a SCSS. We will also investigate an information seeking model for audio and language models. Presenting a Search Engine Result Page (SERP) over a speechonly communication channel presents a number of challenges, e.g., the textual component of a standard search results list has been shown to be ineffectual [4]. The transient nature of speech poses problems due to memory constraints, and makes the possibility of “skimming” back and forth over a list of results (a standard process in browsing a visual list) difficult. These issues are greatly exacerbated when the result being sought is further down the list. This research will advance the knowledge base by: Providing an understanding of which strategies and IIR techniques for SCSS are best for users. Defining novel technologies for contextual conversational interaction with a large collection of unstructured documents that supports effective search over a speech-only communication channel (audio). Determining new methods for providing summary-based resultpresentation for unstructured documents.