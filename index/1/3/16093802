There are two major clifficnlties in implement ing prefet thing: avoicling stalling the cache because of prefetch operations, and maintaining coherence between prefet cl] recluests ancl the cache content.. The first constraint is critical because stalling the cache is likely to mean stalling the processor since superscalar processors can issue up to a cache request, every cycle. This problem is often solvecl by using a prefe tch bufler, so that. the cache neecl not be st allecl to reloacl incoming prefet ch requests. Surprisircgly enough, the second constraint,, coherence, is then simply solvecl b.y Using a pre fetch buffer of one cache line six. In this paper, it is shown that a single-line prefetch buffer can only exploit a fraction of’ prefet clling pot ent ial performance. A multiple-line prefetcll buffer implementation that still maintains coherence is proposed. Simulations indicate that a simple prefet clling t eclmique like taggcci prcfctclc can remove nearly twice as much cache misses in the SPflC~ cocles if an 8-line rather than a l-line buffer is usecl. Also, with usual implementations of prefetcll buffers, a buffer hit can still cost up to tlmee cycles (against one cycle upon a cache hit) because of’ cache check, buffer check and buffer-to-cache reloacl operations. In this paper, it is shown that most of these prefet ch clelay cycles can be hiclden by aclcling a specific stage in the instruction pipeline. ~ocle reordering t eclmiques are nsecl to carefully investigate t lle performance tracleoff raised by this new pipeline stage.