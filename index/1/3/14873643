This paper is concerned with the interpretation of visual information for robot localization. It presents a probabilistic localization system that generates an appropriate observation model online, unlike existing systems which require pre-determined belief models. This paper proposes that probabilistic visual localization requires two major operating modes - one to match locations under similar conditions and the other to match locations under different conditions. We develop dual observation likelihood models to suit these two different states, along with a similarity measure-based method that identifies the current conditions and switches between the models. The system is experimentally tested against different types of ongoing appearance change. The results demonstrate that the system is compatible with a wide range of visual front-ends, and the dual-model system outperforms a single-model or pre-trained approach and state-of-the-art localization techniques.