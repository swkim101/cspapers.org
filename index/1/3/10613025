This paper presents a method for catadioptric line matching across multiple images. While most of previous works deals with vertical lines and planar motion, our approach is able to match any kind of lines between two views separated by a rigid transformation without any prior knowledge of the epipolar geometry. Catadioptric lines are represented by their normals in sphere space and we use only these normals and their relative positions in order to perform the matching. A geometric hashing approach allows in the first image to construct hashing tables based on bases defined by every possible couples of normals. In the second image, a voting scheme permits to select the best corresponding bases and subsequently to match catadioptric lines.We show that the proposed representation is invariant in the case of a pure rotation and quasi-invariant for a combination of rotation and translation. We also propose different experimental results obtained in real time on real outdoor sequences.