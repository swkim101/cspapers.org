Modern processors have included hardware accelerators to provide high computation capability and low energy consumption. With specific hardware implementation, accelerators can improve performance and reduce energy consumption by orders of magnitude compared to general purpose cores. However, hardware accelerators cannot tolerate memory and communication latency through extensive multi-threading; this increases the demand for efficient memory interface and network-on-chip (NoC) designs. In this paper we explore the global management of NoCs in accelerator-rich architectures to provide predictable performance and energy efficiency. Accelerator memory accesses exhibit predictable patterns, creating highly utilized network paths. Leveraging these observations we propose reserving NoC paths based on the timing information from the global manager. We further maximize the benefit of paths reservation by regularizing the communication traffic through TLB buffering and hybrid-switching. The combined effect of these optimizations reduces the total execution time by 11.3% over a packet-switched mesh NoC and 8.5% over the EVC [18] and a previous hybrid-switched NoC [29].