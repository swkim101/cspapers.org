We present a real-time framework for planning natural and smooth grasping motions in an online manner based on the interaction with human. The proposed framework is able to change its grasp strategies agilely according to the interaction with human. Given human demonstrations, we develop a motion field graph consisting of nodes and edges where the nodes contains reference finger poses and their time derivatives, and the edges indicates the similarity between a pair of nodes. Based on the graph, a new grasping motion can be planned that adapts to the changes of the environment and the interaction. The motion field guarantees smooth motions by integrating the velocities obtained from the demonstrations. To validate the framework, we build a demo system where a human can hand a cup over to a tele-operated robot or a virtual humanoid avatar which are controlled by an another person at a remote location. Also, the virtual avatar can grasp and manipulate a cola can.