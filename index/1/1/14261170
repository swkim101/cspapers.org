This paper describes recent results from the robotics community that develop a theory, similar in spirit to the theory of computation, for analyzing sensor-based agent systems. The central element to this work is a notion of dominance of one such system over another. This relation is formally based on the agents' progression through a derived information space, but may informally be understood as describing one agent's ability to "simulate" another. We present some basic properties of this dominance relation and demonstrate its usefulness by applying it to a basic problem in robotics. We argue that this work is of interest to a broad audience of artificial intelligence researchers for two main reasons. First, it calls attention to the possibility of studying belief spaces in way that generalizes both probabilistic and nondeterministic uncertainty models. Second, it provides a means for evaluating the information that an agent is able to acquire (via its sensors and via conformant actions), independent of any optimality criterion and of the task to be completed.