We introduce a new collaborative machine learning paradigm in which the user directs a learning algorithm by manually editing the automatically induced model. We identify a generic architecture that supports seamless interweaving of automated learning from training samples and manual edits of the model, and we discuss the main difficulties that the framework addresses. We describe Augmentation-Based Learning (ABL), the first learning algorithm that supports interweaving of edits and learning from training samples. We use examples based on ABL to outline selected advantages of the approach--dealing with bad data by manually removing their effects from the model, and learning a model with fewer training samples.