for nearest 2~1.~ 1[rntroducfio~ In this chapter we examine a probabilistic approach to information retrieval. We assume that documents and queries are represented as binary vectors. The value in a particular position of a vector indicates the presence (1) or absence (0) of the concept associated with that position. For a given query q, documents are ranked for retrieval on the basis of a similarity or distance measure calculated from the document and query vectors ~. This retrieval model is really just a special case of the nearest-neighbour problem. That is, given a set of N points in n space, and a distinguished point q, find the m points that lie nearest q according to some distance measure. In our retrieval model the documents are the points, the query is q, n is the total number of concepts in the system and 'nearest' is synonymous with 'greatest similarity'. In the discussion that follows we shall concentrate on the case where rn = 1. Cases where m > 1 are straightforward generalisations. The standard way of doing a nearest-neighbour search is to examine all the documents, calculate the similarity measure for each and then select the m best. This requires O(N) time for a collection of N documents, which may be prohibitively expensive and time-consuming for large N, especially when interactive response is required. The optimal nearest-neighbour algorithm (Friedman, Bentley and Finkel, 1977) requires only O(logN) time but is unusable if the dimensionality of the space is high. Specifically, the optimal algorithm has a multiplicative constant of approximately 1.6 n, where n is the dimension of the space. Information retrieval systems typically have hundreds or even thousands of concepts, and in such situations 1.6 n log N is much larger than N, even when N is very large. In this chapter we begin by presenting briefly a deterministic nearest-neighbour search algorithm that is faster than the O(N) search and achieves the same results as a full search, but is not crippled in high-dimensional spaces. We then present a modification to the basic algorithm that allows the user to specify a maximum tolerable level of error (which may be zero). This tolerance * We shall assume throughout this chapter that the similarity measure used has range [0,1], where 1 indicates maximal similarity and 0 indicates minimal similarity.