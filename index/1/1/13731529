Automated Personalized Audio is a relatively new concept, currently making its debut on the Web. Personalized audio relies on the existence of information about the music (music metadata) and information about the users (listener profiles). By gathering profile information, personalized audio systems attempt to select appropriate content for each user. This paper introduces the PERSONALDJ architecture for personalized audio. An evaluation of the concept is presented on the basis of data gathered from user tests. These tests were performed with a prototype developed from this architecture using simple mood based music metadata.