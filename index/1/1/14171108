A computational time of numerical linear algebra (NLA) programs on recent scientific computers depends not only on amount of floating-point arithmetic operations but also on the amount of data transfer and the richness of parallelisms contained in the algorithm. The matrix-matrix operations have a property that the amount of data-transfer between cache and memory can be supressed by changing the computational order. However the ways to exploit the machine capability for each system are related to the computers and systems. It seems complicated for the users and the software vendors to tailor their complicated subprograms to factorize large scale FEM matrix to the various types of computers. A standardization is most valuable to those applications that are numerically intensive, long-running, developed to work on many different platforms, widely used in the public, and hopeless of the automated tuning by the compiler. We propose two types of matrix-matrix operation routines to be included in BLAS standard. One of them is functional extension to the current -GEMM and _SYRK routines to manipulate pentagonal matrix, which can be used as tools of various band matrix factorizations. The second is the new subroutines named -SKAB and _SKBB, which can be used as tools of various skyline matrix factorizations including out-of-core solvers.