Intelligent agents who are situated in nuiltiagent domains must reason about one anothers' actions and plans. Following the tradition of earlier work in AI, we present a model of plan recognition as belief and intention ascription, an inherently defeasible reasoning process. However, we encode this process using a direct argumentation system. Within this system, we can make explicit statements about why one candidate ascription should be preferred over another. And we can avoid the overly strong assumption that the actor's plan is correct from the perspective of the observer--an assumption that was necessary in previous formalizations of plan recognition.