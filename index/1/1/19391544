Bone milling is widely used in many hard tissue surgical procedures, and the main concern is the mechanical damage to some important tissues induced by the high-speed rotating tool. In this study, the behavior of the human auditory system is analyzed. Following this, a commercially available microphone is mounted on the robot arm and then measures the sound generated from bone milling. Inspired by the bandpass filtering in the cochlea, the recorded sound pressure signal is decomposed into a set of subband signals by wavelet packet transform. Inspired by encoding and perception mechanisms in human auditory system, the average amplitude of the wavelet coefficients in each subband is calculated and inputted to a self-organizing feature map so as to classify different milling states. In order to increase the robustness to noise, the sum of the Manhattan distances between all winning neurons is calculated to select the optimum dimension of the map. The experimental results in milling in vitro porcine spines prove that the proposed method can determine which type of tissue is being cut when the suction noise exists, and the success classification rate is no less than 85%. Therefore, the safety of the robot-assisted milling surgery is improved.