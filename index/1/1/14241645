The method of <i>stable random projections</i> is a useful tool for efficiently computing the <i>l</i>α (0 < α ≤ 2) norms and distances in massive data in one pass. Consider a data matrix <b>A</b> ∈R<sup><i>nxD</i></sup>. If we multiply <b>A</b> with a projection matrix <b>R</b> ΕR <sup><i>Dxk</i></sup> (<i>k</i>« <i>D</i>),whose entries are i.i.d. samples of an α-stable distribution,then the projected matrix <b>B</b> = <b>A</b>x <b>R</b> Ε <b>R</b> <sup><i>nxk</i></sup>x containsenough information to approximately recover the <i>l</i> α properties in <b>A</b>.
 We propose <i>very sparse stable random projections</i>, by replacing the α stable distribution with a (much simpler) mixture of a symmetric α Pareto distribution (with probability Β, 0 β Β 1) and a point mass at the origin(with probability 1-Β). This leads to a significant 1 over Β fold speedup for small Β when computing <b>B</b> = <b>A</b>x<b>R</b> and a 1 over Β-fold cost reduction in storing <b>R}</b>. By analyzing the convergence, we show that in"reasonable" datasets Β often can be very small (e.g.,<i>D</i><sup>1/2</sup> without hurting the estimation accuracy. Some numerical evaluations are conducted, on synthetic data, Web crawldata, and gene expression microarray data.