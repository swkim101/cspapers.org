We present a novel approach to introduce visual information in the walking pattern generator for humanoid robots in a more direct way than the current existing methods. We make use of a model predictive control (MPC) visual servoing strategy, which is combined to the walking motion generator. We define two schemes based on that principle: a position-based and an image-based scheme, with a Quadratic Program (QP) formulation in both cases. Finally, we present some simulation results validating our approach.