We outline the retrieval of images from a network of security cameras by means of an attribute-based query. Our approach is based on detectors for several object classes which enable combined queries to retrieve people based on characteristic pieces of luggage. The approach works independently of camera recording frame rates since it does not rely on tracking or background assumptions, and it requires neither real training images nor manual annotations since it is entirely trained on synthetic data. By performing an approximate 3D auto-calibration for each camera from a few detected humans and exploiting object-level context in a 3D coordinate system, we can significantly improve the precision of otherwise weakly performing detectors for inconspicuous object classes. We evaluate our approach on data from an airport security camera network and demonstrate the system's ability to respond to combined appearance and 3D metric contextual attribute queries over multiple cameras.