We present a novel gesture recognizer suitable for fast prototyping of gesture-based applications. The recognizer uses a nearest neighbor approach, and requires a small number of samples for each class. The similarity between two gestures is calculated through a three steps procedure: firstly, each gesture is approximated to a polyline, in order to extract its main movements; then, the two polylines are aligned to obtain an equal number of segments from both of them; lastly, the distance is found by summing the contribution of each pair of segments. We tested the recognizer on two different datasets and found that it performs more accurately than a state-of-art method.