We propose a discriminative compact scene descriptor for single-view cross-season place recognition. Unlike previous bag-of-words approaches which rely on a library of vector quantized visual features, the proposed scene descriptor is based on a library of raw image data (such as available visual experience, images shared by other colleague robots, and publicly available image data on the web) that is directly mined to find nearest neighbor (NN) visual features (i.e., landmarks) for effectively explaining the input image. Our scene matcher adopts naive Bayes nearest neighbor (NBNN) techniques, where (1) raw visual features are used without vector quantization, and (2) image-to-class (rather than image-to-image) distance is used for scene comparison. Finally, we acquire a challenging cross-season place recognition dataset and validate the effectiveness of the proposed scene descriptor.