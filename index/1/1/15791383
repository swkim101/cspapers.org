To analyze auditory scenes of robots' surrounding environments, not only speeches but also non-speech sounds are important, which are spatially distributed and have different spectral and temporal characteristics. Thus, this paper investigates Acoustic Event Identification (AEI) which includes problems of localization, detection, and identification of sound sources. To achieve AEI by a robot in a real environment, we first propose to use a robot audition framework including sound source localization and separation to localize, detect, and separate acoustic events. For the identification, we propose two Bayesian models, iterative Latent Dirichlet Allocation (it-LDA) and Nested Pitman-Yor process with Uncertainty Compensation (NPY-UC). it-LDA and NPY-UC extract noise-robust sound-units and sound-words, respectively, and they consider probabilistic spectral and temporal uncertainties to robustify AEI against harsh environments such as noise and reverberation, etc. We have implemented these proposed methods using a robot-embedded microphone array. The preliminary results showed 5-18 pts improvement compared to a conventional GMM method in noisy environments thanks to the Bayesian framework in consideration of uncertainties.