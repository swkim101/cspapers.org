This paper evaluates our attempt to solve the large network analysis problems in the time domain by use of a simulation method with computation efficiency and program simplicity. We present a Quasi-general Symbolic FET Macromodel (QGSM) which can represent many different logic function gates; hence, the simulation program needs only one macromodel QGSM. We also discuss the Functional Latency Concept (FLC). With FLC we can avoid analyzing more inactive subnetworks to realize savings in CPU time. Finally, we describe a triple-iteration loop method which can be readily incorporated into the time-domain analysis. The experimental program exhibits topological flexibility, computational accuracy, and programming simplicity.