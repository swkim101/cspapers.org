We present a general and systematic method for neural network design based on the genetic algorithm. The technique works in conjunction with network learning rules, addressing aspects of the network's gross architecture, connectivity, and learning rule parameters. Networks can be optimized for various application-specific criteria, such as learning speed, generalilation, robustness and connectivity. The approach is model-independent. We describe a prototype system, NeuroGENESYS, that employs the backpropagation learning rule. Experiments on several small problems have been conducted. In each case, NeuroGENESYS has produced networks that perform significantly better than the randomly generated networks of its initial population. The computational feasibility of our approach is discussed.