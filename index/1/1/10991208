By source-level IP packet burst, we mean several IP packets sent back-to-back from the source of a flow. We first identify several causes of source-level bursts, including TCP's slow start, idle restart, window advancement after loss recovery, and segmentation of application messages into multiple UDP packets. We then show that the presence of packet bursts in individual flows can have a major impact on aggregate traffic. In particular, such bursts create scaling in a range of timescales which corresponds to the burst duration. Uniform "spreading" of bursts in the time axis reduces the scaling exponent in short timescales (up to 100-200ms) to almost zero, meaning that the aggregate traffic becomes practically uncorrelated in that range. This result provides a plausible explanation for the scaling behavior of Internet traffic in short timescales. We also show that removing packet bursts from individual flows reduces significantly the tail of the aggregate marginal distribution, and it improves queueing performance, especially in moderate utilizations (50-85%).