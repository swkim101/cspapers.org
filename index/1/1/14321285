Localization in multi-robot systems is a key problem in multi agent systems. In many cases, specially involving legged robots, like the Robocup soccer competition, it relies on predefined landmarks at known locations. However, when several objects are in motion, vision occlusions due to agents in the field of view make this kind of localization unfeasible for mild time periods. This also happens if landmarks are not within the field of view. This paper presents a technique to let a robot estimate its position with respect to objects or robots by sharing whatever visual data it has with its teammates. Shared data is used to estimate the relative positions of robots watching the same object via stereoscopy. The rest of the robots can be localized via triangulation and acquire information on the position of hidden or unknown objects that other members of the team can see. The system has been tested with two Aibo ERS 7 robots from Sony and an Aiball.