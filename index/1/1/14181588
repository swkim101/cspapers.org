The application of Markov chains and queueing theory to real performance evaluation problems often raises the question on how to best integrate in the model the observed characteristics of a workload. For example, what if job inter-arrival times to the system are statistically correlated? How can this be described compactly in a Markov model? What if the service time distribution is heavytailed? What if arrivals are periodic? Markovian arrival processes (MAPs) offer an elegant solution to these questions using the familiar framework of Markov theory [6]. MAPs have been developed with the aim of fitting in a compact Markov model workloads with statistical correlations and non-exponential distributions. This compact model can be then embedded in the infinitesimal generator of a performance model for a real system to represent events that occur with non-exponential inter-arrival times. For example, using matrix-geometric methods, one can easily study MAP/MAP/1 queues, where both inter-arrival times and service times are MAPs that describe temporal dependent processes [6]. MAPs also provide greater flexibility and realism compared to independent and identically distributed (i.i.d.) workload models such as Erlang, Coxian, or hyper-exponential; i.i.d. models describe the statistical distribution of inter-arrival times between events, but not their temporal order. Thus they cannot represent features such as burstiness, periodicities, or variability at multiple time scales that are frequent in computer workloads and network traffic [4, 7, 5]. MAPs have been explicitly developed to overcome this limitation of i.i.d. models. Considered as a time-series modeling technique, MAPs may be seen as a class of hidden Markov models where observations depend on the state of an underlying continuous-time Markov chain (CTMC). Observations are continuous values that follow a phasetype distribution [6], which is the class of distributions describing