Visual attention helps identify the salient parts of a scene and enables efficient object recognition by allocating visual resources to more relevant regions of the scene. In this paper, we present an object recognition framework that combines top-down volitional recognition with attention processes using a swarm of cooperating intelligent agents. Each agent in the swarm is a selfcontained independent classifier that can, given any location in the image, predict the presence of a particular object of interest. Our framework combines bottom-up attention and top-down object classification using Particle Swarm Optimization (PSO) dynamics in a novel architecture that utilizes spatially-modulated evolutionary search to rapidly detect objects of interest in a scene. We use bottom-up maps that are automatically built from saliency, past swarm experience, and constraints on possible object positions to modify the swarmâ€™s behavior and help guide the swarm in locating objects. We present fast object detection/recognition results for a variety of video sequences. Our results show that our framework allows objects to be quickly and accurately located and classified using very sparse sampling of the scene.