This paper demonstrates a proof of concept for a platform independent vision based localisation system that can be mounted on any mobile platform and operates in real-time. The system is able to globally localise given a pre-scanned 3D model of the environment. This is a deliberate deviation from the SLAM (Simultaneous Localisation and Mapping) approach because we are interested in global localisation, which assumes a map is readily available. A panoramic mirror and a webcam is used as the vision sensor. A particle filter is used for localisation. Typically, the particle filter requires odometry feedback from the mobile platform to know where to move the particles. This dependency is relocated to visual odometry from the camera, which provides rotation and translation feedback, reinforcing the concept of a portable and platform independent localisation system. Currently, our visual odometry does not provide metric values for translation, but instead derives it by assuming the platform moves at a some average speed. We suggest some solutions to this problem in the discussion. Our system is analogous to a GPS device but can operate in conditions where a GPS signal is not available and can provides greater accuracy than current consumer GPS.