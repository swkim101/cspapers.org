Replicating the human hand capabilities is a great challenge in telemanipulation as well as in autonomous grasping and manipulation. One of the main issues is the difference between human and robotic hands in terms of kinematic structure, which does not allow a direct correlation of the joints. We recently proposed an object-based mapping algorithm able to replicate on several robotic hand models the human hand synergies. In such approach the virtual object shapes were a-priori defined (e.g. a sphere or an ellipsoid) and the transformation was represented as the composition of a rigid body motion and a scale variation. In this work, we introduce a generalization of the object-based mapping that overcomes the definition of a shape for the virtual object. We consider only a set of reference points on the hands. We estimate a homogeneous transformation matrix that represents how the human hand motion changes its reference point positions. The same transformation is then imposed to the reference points on the robotic hand and the joints values obtained through a kinematic inversion technique. The mapping approach is suitable also for telemanipulation scenarios where the hand joint motions are combined with a wrist displacement.