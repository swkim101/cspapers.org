Neural machine translation (NMT) with recurrent neural networks, has proven to be an effective technique for end-to-end machine translation. However, in spite of its promising advances over traditional translation meth-ods, it typically suffers from an issue of unbalanced outputs, that arise from both the nature of recurrent neural networks themselves, and the challenges inherent in machine translation. To overcome this issue, we propose an agreement model for neural machine translation and show its effectiveness on large-scale Japanese-to-English and Chinese-to-English translation tasks. Our results show the model can achieve improvements of up to 1.4 B LEU over the strongest baseline NMT system. With the help of an ensemble technique, this new end-to-end NMT approach Ô¨Ånally outperformed phrase-based and hierarchical phrase-based Moses baselines by up to 5.6 B LEU points.