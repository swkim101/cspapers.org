The paper begins by defining a class of distributed memory machines which have useful properties as retrieval and filtering devices. These memory mechanisms store large numbers of associations on a single composite vector. They provide a natural format for encoding the syntactic and semantic constraints associated with linguistic elements. A computational architecture for parsing natural language is proposed which utilises the retrieval and associative features of these devices. The parsing mechanism is based on the principles of Lexical Functional Grammar and the paper demonstrates how these principles can be derived from the properties of the memory mechanisms.