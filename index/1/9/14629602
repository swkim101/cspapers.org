In this paper, we address the pursuit/evasion problem of capturing an omnidirectional evader using a Differential Drive Robot (DDR) in an obstacle-free environment. The goal of the evader is to keep the pursuer farther than the capture distance for as long as possible and for the pursuer the goal is to capture the evader as soon as possible. In [1] an open-loop time-optimal strategy is proposed for this pursuit/evasion problem. In [2] a state feedback-based time-optimal motion policy for the DDR is provided. The time-optimal strategies obtained in [1] are in Nash equilibrium, meaning that any unilateral deviation of a player from the optimal strategies does not provide it a benefit in its payoff. However, Nash equilibrium does not tell if one player deviates from its optimal policy then, does there exist a new strategy for the other player that can take advantage of such deviation? If so, which is the required information to improve the payoff compared with the worst case scenario? In this paper we address those questions, analysing the scenario in which the players deviate from their optimal controls. We show that when the evader deviates from its optimal speed there are cases where there exists a new pursuer motion strategy that reduces the time to capture the evader. The shown cases where the time to capture the evader is reduced require more information about the evader's state. Nevertheless, there are also cases in which despite the availability of new information, the pursuer must stick to the worst case strategy, otherwise it cannot capture the evader.