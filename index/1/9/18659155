However difficult the fundamental problems of theoretical computer science may seem, there is very little to suggest that they are anything more than knotty combinatorial problems. So, when we look for reasons for our inability to resolve P = NP and related questions, we most likely find them dealing with a lack of understanding of particular computational problems and their lower bounds. This is the sense of Hopcroft's prediction: “...within the next five years, nobody will prove that any of these problems takes more than let's say n2 time. I think that's a reasonably safe conjecture and it also illustrates how little we know about lower bounds.” [MT]. Hopcroft's guess is uncanny in its accuracy—after six years and considerable effort by many researchers, his conjecture remains unchallenged. The results in this paper offer a possible explanation for our failure to resolve these problems. Roughly, the main result of the sequel links lower bounds and a branch of mathematical logic known as model theory. In particular, we prove that the existence of nonpolynomial lower bounds is equivalent to the existence of nonstandard models of a sizable fragment of arithmetic. Since these are deep logical issues and there are very few techniques for handling them, and since the nonstandard models in question are non-effective, it seems plausible that this linking of complexity theory and logic explains our failure to obtain nontrivial lower bounds. One of the aims of mathematical logic is to clarify the relation between mathematical theories and their interpretations—or models.