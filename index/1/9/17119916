The nearest-neighbour search (NNS) problem is to store a set of points and return the point of shortest distance to any given query point. In the fully-dynamic NNS problem, the data structure is maintained under insertions and deletions of points. This paper proves lower bounds for the dynamic NNS problem in two dimensions with respect to the Euclidean norm in finite precision models. The lower bound holds in the cell probe model, so it "can be trusted to apply to virtually any conceivable sequential algorithm" [8]. We consider the following setting: The dimension is 2, and the points S C U 2 are integral with U = {1 , . . . ,2w}. The word size of our model is w, so every point from U 2 fits into two words. The update operations are insert(p), which adds p E U to S, and delete(p), which removes a point. The query is nearest(p), which returns a point q E S minimising [[p-q[], their Euclidean (or, L2) distance. We show that any data structure that supports these operations needs f~(log [U[/log log [U[) amortised time per operation. For the semi-dynamic variants of the NNS problem, i.e., where the updates are only insertions or only deletions, we show the same bound for the worst-case time per operation.