Previous studies on human-pose estimation rely on the design of factors to represent underlying probability distributions. However, designing factors is laborious and yet, the designed factors may not represent the underlying probability distributions. In this paper, we propose to use a neural network to automatically design factors in one of the existing models called the action-mixture model (AMM). Factors that are designed automatically by neural networks can be adapted to different situations. The semantic meaning of random variables in AMM can be transferred to a neural network, rendering the semantic meaning of hidden neurons transparent to users. The design process consists of two stages: structure identification and parameter learning. In the structure identification, we propose a bottom-up approach to build a neural network while preserving the structure of AMM. In the parameter learning, we propose a part-based approach to learn synaptic weights by decomposing a neural network into parts. Synaptic weights that have been learnt in one part can be used as initial weights for learning synaptic weights in another part. Based on the concept of distributed representation, the proposed two-stage, neural-network-based design process is used to design a scalable neural network to realize an AMM. Experimental results showed that the scalable neural network outperformed AMM and some existing works.