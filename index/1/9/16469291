We discuss the problem of automatically discovering different acoustic regions in the world, and then labeling the trajectory of a robot using these region labels. We use quantized Mel Frequency Cepstral Coefficients (MFCC) as low level features, and a temporally smoothed variant of Latent Dirichlet Allocation (LDA) to compute both the region models, and most likely region labels associated with each time step in the robot's trajectory. We validate our technique by showing results from two datasets containing sound recorded from 51 and 43 minute long trajectories through downtown Montreal and the McGill University campus. Our preliminary experiments indicate that the regions discovered by the proposed technique correlate well with ground truth, labeled by a human expert.