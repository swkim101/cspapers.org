We address domain adaptation (DA) for binary classification in the challenging case where no target label is available. We propose an original approach that stands in a recent framework of Balcan et al. allowing to learn linear classifiers in an explicit projection space based on good similarity functions that may be not symmetric and not positive semi-definite (PSD). Following the DA frame- work of Ben-David et al., our method looks for a relevant projection space where the source and target distributions tend to be close. This objective is achieved by the use of an additional regularizer motivated by the notion of algorithmic robustness proposed by Xu and Mannor. Our approach is formulated as a linear program with a 1-norm regularization leading to sparse models. We provide a theoretical analysis of this sparsity and a generalization bound. From a practical standpoint, to improve the efficiency of the method we propose an iterative version based on a reweighting scheme of the similarities to move closer the distributions in a new projection space. Hyperparameters and reweighting quality are controlled by a reverse validation process. The evaluation of our approach on a synthetic problem and real image annotation tasks shows good adaptation performances.