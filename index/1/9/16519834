We consider the costs of access to data stored in search trees assuming that those memory accesses are managed with a cache. Our cache memory model is two-level, has a small degree of set-associativity, and uses LRU replacement, and we consider the number of cache misses that a set of accesses incurs. For standard tree access--searches and traversals---changing the degree of set-associativity has no effect on performance.To explain this, we develop general stochastic access models, an adaptation of the independent reference model (IRM), and analyze the expected number of cache hits and misses incurred by these types of access. The models and analyses are accurate: we are able to exactly predict the cache performance of tree data structures. In addition, we prove why set-associativity is of little or no benefit for these types of memory access and give examples where direct-mapping performs better than set-associativity.