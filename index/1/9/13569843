We demonstrate a problem with the standard technique for learning probabilistic decision lists. We describe a simple, incremental algorithm that avoids this problem, and show how to implement it efficiently. We also show a variation that adds thresholding to the standard sorting algorithm for decision lists, leading to similar improvements. Experimental results show that the new algorithm produces substantially lower error rates and entropy, while simultaneously learning lists that are over an order of magnitude smaller than those produced by the standard algorithm.