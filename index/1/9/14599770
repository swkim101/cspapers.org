視覚を持つ移動ロボットが,複雑な環境内を自律的に走 行するためには,環境に適応して行動を決定することが重要 である.そのためには,ロボット自身が環境に関する何らか のモデルを持っている必要がある. 従来からの研究においては,ロボット上の視覚センサか らの2次元画像情報を処理して詳細な3次元幾何情報を再構 成し,この3次元情報を用いてロボットの取り巻く環境を表 現している研究例が多い.この様な手法は,コンピュータ ビジョンの分野において,Ullman1)によって”shape from motion”の問題が定式化されて以来,多くの研究がなされて いる.最近の研究では,2次元画像系列から2, 3),アフィン または投影不変量から4, 5, 6, 7),カメラキャリブレーショ ンから8),それぞれ3次元情報を求める研究がある.これら の研究では,3次元情報やその不変量をできるだけ正確に求 めることを目的としている.しかしながら,どれくらいの再 構成の精度が必要であるかを決めることは難しい.3次元情 報は一般的な形式をしておりその情報を使用する際に簡単に 変換が可能であるとして,3次元情報をもとにした環境の表 現が,ロボットのナビゲーション等に有効であると一般的に 言われている.しかしながら,ロボットを使用する際には, センサ情報やモーター制御に対して実時間処理しなければ ならない.さらに,目的とするタスクに依存してロボットを 取り巻く環境全体を表現する必要はなく,また見え方の異な る環境を必ずしも区別する必要もない.例えば, たとえば, 障害物発見や回避をタスクとした場合,机や椅子が乱雑に配 置された屋内環境も,岩などを含む屋外環境も識別する必要 がない.これまでの3次元幾何情報の再構成を主眼として来 たアプローチでは,これらを同一視することは困難であると 考えられる. そこで,視覚情報を用いて与えられたタスクを達成する 自律エージェントにとって,どのような環境表現が適当であ るかについて考えなければならない.この問題に対して,ロ ボット学習の研究者は,ロボットに対して,外界から知覚さ れたデータに対して行動すること,すなわち,環境状態とロ ボット自身の行動の最適な関係を学習させようとしてきた 9).この状態と行動の最適な関係が,タスクもしくはロボッ トの行動に基づく環境表現と考えられる.これによって,タ スクを達成するために詳細な3次元情報を再構成する必要が なくなる.しかしながら,これまでのロボット学習の研究に おいては,特定のタスクの行動学習を行なうために,環境を 記述する記述子に対する候補は,知覚された莫大なデータの 中から前もって選択されている.またこれらの記述子の候補 は,環境シーンの構成要素や特定の状況やタスクに依存して 決定されている. そこで,この報告では,環境シーンの構成要素に独立で, モータコマンドと密接に関連したロバストな記述子である画 像運動情報を利用して,実ロボットに,目的のタスクを達成 させるための行動に基づく環境表現を獲得させる手法につい て述べる.ここでは,目的のタスクを達成するための行動に 基づく環境表現を運動スケッチと呼んでいる.ロボットのタ スクとしては,動的環境内で障害物を回避しながら対象物体 を追跡するというタスクを想定している.