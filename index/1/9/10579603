Like oral communication, gestures are a natural way to carry out human machine interface. In the early days of robotic systems, human gesture was used to control robot movements by means of a master-slave structure. In spite of the use if robot programming languages, manual control is the most reliable way to carry out complex tasks in unstructured environments. In these situations, a non-contact, passive and remote system can be helpful to control a teleoperated robot by means of human gestures. In this paper, a vision system able to detect, locate and track the head and hands of a human body is presented. The system uses several calibrated cameras placed around the operator scenario to locate the body parts of a person in 3D. The system combines different computer vision techniques to increase the reliability of the body parts detection: image movement detection, user skin colour segmentation and stereo. The data provided by these modules are focused looking for coherence according to the human body dimensions. With the scheme proposed it is possible to obtain a low-cost real-time system for human computer interfacing based in a natural way of communication (gestures). Civil area such as big robots in shipyards, mines, public works or cranes is some possible applications.