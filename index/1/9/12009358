We analyze problems confronted by computer agents that synthesize plans that take into account (and employ) the plans of other, similar, cooperative agents. From the point of view of each of these agents, the others are dynamic entities that possess information about the world, have goals, make plans to achieve these goals, and execute these plans. Thus, each agent must represent not only the usual information about objects in the world and the preconditions and effects of its own actions, but it must also represent and reason about what other agents believe and what they may do. We describe a planning system that addresses these issues and show how it solves a sample problem.