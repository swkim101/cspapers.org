Programs that make extensive use of widely shared variables are expected to achieve modest speedups for non-bus-based cache coherence protocoLr, pam’cularly as the number ofprocessors sharing the data grows large. Protocols such as the IEEE Scalable Coherent Interjhce (SCI) are optimized for data that is not widely shared; the GLOW protocol extensions are specljically &signed to address this limitation. The GLO w extensions take advantage of physical locality by mapping K-a~ logical sharing trees to the network topology. This results in protocol messages that travel shorter distances, expen”encing lower latency and consuming less bandwidth. To build the sharing trees, GLO w caches directory information at strategic points in the network, allowing concurrency, and therefore, scalability, of read requests. Scalability in writes is achieved by exploiting the shan-ng tree to invaliahte or update nodes in the sharing tree concurrently. We have dey%ted the GLO w extensions with respect to SCI and we have implemented them in the Wisconsin Wind Tunnel (WWT) parallel discrete event simulator We studied them on an example topology, the K-ary Ncube, and explored their scalability with four programs for large systems (up to 256processors).