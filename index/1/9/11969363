We present an algorithm, Shared-State Sampling (S3), for the problem of detecting large flows in high-speed networks. While devised with different principles in mind, (S3) turns out to be a generalization of two existing algorithms tackling the same problem: Sample-and-Hold and Multistage Filters. S3 is found to outperform its predecessors, with the advantage of smoothly adapting to the memory technology available, to the extent of allowing a partial implementation in DRAM. (S3) exhibits mild tradeoffs between the different metrics of interest, which greatly benefits the scalability of the approach. The problem of detecting frequent items in streams appears in other areas. We also compare our algorithm with proposals appearing in the context of databases and regarded superior to the aforementioned. Our analysis and experimental results show that, among those evaluated, (S3) is the most attractive and scalable solution to the problem in the context of high-speed network measurements.