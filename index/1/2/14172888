Recent research in appearance-based mapping has introduced a diverse range of techniques to deal with environments under varying conditions. Common to almost all the existing methods is that they expect a supervised or offline training. Furthermore, some approaches match sequences, assuming constant velocity over the routes. This work addresses the challenges of appearance-based mapping in an online setup without making assumptions or acquiring prior knowledge of the environment. For this purpose, we exploit the topology preserving capability of self-organizing neural networks and learn the perceptual representation of environments using GIST features. Due to the fact that real-world environments are complex and large-scale, we let the network grow while accounting for the amount of error in the network due to perceptual differences among the places. Given the current state of the network and a query image at any time instant, it is possible to identify whether a place comes from the visited location by computing maximum a posteriori estimate over the network. The extensive experiments on three standard datasets, St. Lucia (4 videos), KITTI (2 sequences), and the Oxford City Center dataset, demonstrate the strength of our approach for real-time place recognition while concurrently learning the spatial representation of scenes.