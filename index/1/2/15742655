An adaptive synergy controller is presented which allows a dexterous artificial hand to unscrew and screw an object using facial expressions derived from electromyogram (EMG) signals. In preliminary experiments, the finger joint motions of nine human test subjects were recorded as they unscrewed a bottle cap in multiple orientations of their hands with respect to the object. These data were used to develop a set of adaptive sinusoidal joint synergies to approximate the orientation-dependent human motions, which were then implemented on a dexterous robotic manipulator via the proposed adaptive synergy controller. The controller is driven through a noninvasive interface which allows a single input to drive the bioinspired human motions using facial expressions. The adaptive synergy controller was evaluated by four able-bodied subjects who were able to unscrew and screw an instrumented object using the artificial hand in two orientations with a 100% success rate.