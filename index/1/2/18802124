This paper deals with the automation of dextrous grasping in a partly known environment using a stereo vision system and a multifingered hand mounted on a robot arm. Effective grasping requires a combination of sensing and planning capabilities. We propose an integrated approach that combines computer vision, path planning, and manipulator control in three complementary activities: the reconstruction of task-oriented models of the workspace, the determination of appropriate grasping configurations from computed 'preshapes' of the hand, and the automatic generation and execution of hand/arm motions using a hybrid geometric path planner and a hybrid control system. This paper outlines the architecture of our system, discusses the techniques we have developed on grasp planning, and finishes with a brief description of work-in-progress on the implementation and some preliminary experimental results.<<ETX>>