This paper studies the effect of limited precision data representation and computation on word embeddings. We present a systematic evaluation of word embeddings with limited memory and discuss method-s that directly train the limited precision representation with limited memory. Our results show that it is possible to use and train an 8 -bit Ô¨Åxed-point value for word embedding without loss of performance in word/phrase similarity and dependency parsing tasks.