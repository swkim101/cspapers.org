Plans provide an explicit expectation of future observed behavior based upon the domain knowledge and a set of action models available to a planner. Incorrect or missing models lead to faulty plans usually characterized by catastrophic goal failure. Non-critical anomalies occur, however, when actual behavior during plan execution differs only slightly from expectations, and plans still achieve the given goal conjunct. Such anomalies provide the basis for model adjustments that represent small adaptations to the planner's background knowledge. In a multi-agent environment where 1000 or more individual plans can be executing at any one time, automation is required to support model anomaly detection, evaluation and revision. We provide an agent-based algorithm that generates hypotheses about the cause of plan anomalies. This algorithm leverages historical plan data and a hierarchy of models in a novel integration of hypothesis generation and verification. Because many hypotheses can be generated by the software agents, we provide a mechanism where only the most important hypotheses are presented to a user as suggestions for model repair.