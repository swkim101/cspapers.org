Continual Flow Pipelines (CFP) allows a processor core to process instruction windows of hundreds of instructions without increasing cycle-critical pipeline resources. When a load misses the data cache, CFP checkpoints the processor register state and then moves all miss dependent instructions into a low complexity non-critical waiting buffer to unblock the pipeline. Meanwhile, miss independent instructions execute normally and update the processor state. When the miss data returns, CFP replays the miss dependent instructions from the waiting buffer and then merges the miss dependent and the miss independent execution results.
 CFP was initially proposed for cache misses to DRAM. Later work focused on reducing the execution overhead of CFP by avoiding flushing the pipeline before replaying miss dependent instructions, and on allowing these instructions to execute concurrently with miss independent instructions. The goal of these improvements was to gain performance by applying CFP to L1 data cache misses that hit the last level on chip cache. However, many applications or execution phases of applications incur excessive amount of replay and/or rollbacks to the checkpoint. This frequently cancels any benefits from CFP or even causes performance degradation.
 In this paper, we improve the CFP architecture by using a novel virtual register renaming substrate, and by tuning the replay policies to mitigate excessive replays and rollbacks to the checkpoint. We describe these new design optimizations and show, using Spec 2006 benchmarks and microarchitecture performance and power models of our design, that our Tuned CFP architecture improves performance and power consumption over previous CFP architectures by ~15% and 9%, respectively.