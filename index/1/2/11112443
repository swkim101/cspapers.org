In conventional task-space control problem of robots, a single task-space information is used for the entire task. When the task-space control problem is formulated in image space, this implies that visual feedback is used throughout the movement. While visual feedback is important to improve the endpoint accuracy in presence of uncertainty, the initial movement is primarily ballistic and hence visual feedback is not necessary. The relatively large delay in visual information would also make the visual feedback ineffective for fast initial movements. Due to limited field of view of the camera, it is also difficult to easure that visual feedback can be used for the entire task. Therefore, the task may fail if any of the features is out of view. In this paper, we present a new task-space control strategy that allows the use of dual task-space information in a single controller. We shall show that the proposed task-space controller can transit smoothly from Cartesian-space feedback at the initial stage to vision-space feedback at the end stage when the target is near.