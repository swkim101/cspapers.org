We are interested in projecting emotions as a tool for approximating computationally intensive sequential decisionmaking models of single-agent systems. Specifically, we believe that affect can be used to tradeoff computational complexity with quality of the solution, thereby producing approximations that compare favorably with other approximation techniques. Our research is predicated on the thesis that cognitive appraisal of the environment induces internal emotions that in turn affect the agentâ€™s decision-making process. In order to validate our thesis, we require a computational model for capturing the dynamics of emotions and generating behaviors characteristic of several emotional states. We are especially interested in modeling affective agent planning in stochastic domains where the agent is unaware of its current state (e.g. its physical location), but receives a series of percepts that may guide it. In this context we propose utilizing a decision-theoretic framework called Partially ObservableMarkov DecisionProcess (POMDP). Solution of a problem modeled as a POMDP, produces a policy that controls agent planning. Exact solutions of POMDPs are intractable spurring interest into approximation techniques that compute near-optimal solutions using less running time. Towards this end, we propose employing affect as a justification for reducing the size of the input POMDP model, and therefore the computational complexity of its solution. In doing so, we not only demonstrate the feasibility of employing affect as a potential approximation technique, but also present a computational model that can generate behaviors characteristic of several emotions. The primary contributions of this paper are twofold: We explore the feasibility of employing affect to produce nearoptimal approximations to optimal plans in less time. Secondly, we propose a hybrid agent architecture that employs a reactive finite state machine based metareasoner and a deliberative POMDP based planner, to model different affective behaviors. We validate our claims through experimentation on an example toy problem domain. The remainder of this paper is structured in the following manner. In the next section we discuss some related work and put our model in the proper context. Thereafter we in-