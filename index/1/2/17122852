With recent advances in AI technology, there has been increased interest in improving AI computational throughput and reducing cost, as evidenced by a number of current projects. To obtain maximum benefit from these efforts, it is necessary to scrutinize possible efficiency improvements at every level, both hardware and software. Custom AI machines, better AI language compilers, and massively parallel machines can all contribute to efficient AI computations. However, little information is available concerning how to achieve these efficiences. A systematic study was undertaken to fill this gap. This paper describes the main results of that study, and points out specific improvements that can be made. The areas covered include: AI language semantics, AI language compilers, machine instruction set design, parallelism, and important functional candidates for VLSI implementation such as matching, associative memories, and signal to symbol processing for vision and speech.