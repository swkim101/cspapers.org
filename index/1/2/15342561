In this paper, we raise and investigate the question of (storage) space- (retrieval) time tradeoff for a static database, in the general framework of Fredman's. As will be seen, such tradeoff results also lead to lower bounds on the complexity of processing a sequence of m INSERT and QUERY instructions. The latter results are incomparable to Fredman's, since the presence of DELETE instructions was crucial for his proof technique. We will present our results in detail in the next few sections. Here we will only mention three main conclusions. Firstly, circular query is shown to be intrinsically hard in the sense that, for some static database with n records, there is a space-time tradeoff TS -&-gt; n1 + -&-egr; where -&-egr;-&-gt;0; in contrast, orthogonal query can always be implemented with space S-&-equil;0(n(log n)k) and time T-&-equil;0((log n)k) for fixed k. Furthermore, any algorithm for processing 0(n) INSERT and QUERY instructions must use time -&-Ohgr;(n1+-&-egr;) in the worst case. Secondly, for the -&-ldquo;interval-&-rdquo; query, we have determined the space-time tradeoff quite precisely to be T @@@@ -&-agr;(S,n), where -&-agr; is the inverse to an Ackermann's function first defined by Tarjan [9]. This is a rare case where the function -&-agr; arises outside the context of path compression, and is obtained through a totally independent derivation. Thirdly, we prove that, for the interval query, any algorithm to process a sequence of 0(n) INSERT and QUERY must take time -&-Ohgr;((n log n)/(log log n)) in the worst case. This means that one cannot hope to maintain the most efficient static data structure (with retrieval time -&-agr;(S,n)) in the dynamic case.