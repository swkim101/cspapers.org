Similarity measure is one of the keys of a high- performance content-based image retrieval (CBIR) system. Given a pair of images, existing similarity measures usually produce a static and constant similarity score. However, an image can usually be perceived with different meanings and therefore, the similarity between the same pair of images may change when the concept being queried changes. This paper proposes a query-sensitive similarity measure, Qsim, which takes the concept being queried into account in measuring image similarities, by exploiting the query image as well as the images labeled by user in the relevance feedback process. Experimental comparisons to state-of-the-art techniques show that Qsim has superior performance.