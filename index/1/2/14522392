A homogeneous paradigm for evidence integration is presented, and a vision system to recognize 3D objects is demonstrated using this paradigm. A new concept called generalizedfeatures supports a highly modular architecture, and allows a uniform treatment of features at all levels of recognition - from simple partial features to complex feature assemblies and 3D objects. Layered, concurrent parameter transforms vote for feature hypotheses on the basis of image data and previously reconstructed features. Additional transforms identify supporting or conflicting relationships between hypotheses. The entire reconstruction and indexing process occurs within recognition networks, which collect votes, fuse evidence from various sources and insure global consistency. The overall approach allows the system to completely avoid the common weak point of explicit, low-level scene segmentation. Features reconstructed by the vision system include surface regions and 3D surface intersection curves. Experimental results, including noise sensitivity, for real data from a laser range finder are presented.