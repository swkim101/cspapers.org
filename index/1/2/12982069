This paper presents an average-case analysis of the fc-nearest neighbor classifier (k-NN). Our analysis deals with m-of-n// concepts, and handles three types of noise: relevant attribute noise, irrelevant attribute noise, and class noise. We formally compute the expected classification accuracy of fc-NN after a certain fixed number of training instances. This accuracy is represented as a function of the domain characteristics. Then, the predicted behavior of fc-NN for each type of noise is explored by using the accuracy function. We examine the classification accuracy of fc-NN at various noise levels, and show how noise affects the accuracy of fc-NN. We also show the relationship between the optimal value of k and the number of training instances in noisy domains. Our analysis is supported with Monte Carlo simulations.