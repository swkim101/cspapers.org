In todayâ€™s market, different systems (e.g., camera, microwave etc.) exist that can perform specialized tasks. However, users find it frustrating to learn how to operate these task-oriented systems (TOSs) in a manner that suits their needs. If a single agent can interface users with different TOSs, then the users need not learn how to interact with each TOS separately; instead, they just need to learn how to interact with one agent. In addition, if the agent is rational, users can flexibly adapt the operation of the TOSs by interacting with the agent. For example, consider a pool controller that can accept commands to heat a pool, stop heating, and provide the temperature. A user interacting directly with such a system will have to issue the appropriate commands when required. By integrating a rational interfacing agent with such a system, the user could tell the agent to heat the pool every Saturday at 10:00 am and maintain the temperature around 35oC until 1:00 pm. The agent will then issue appropriate commands to the pool controller at the required times. For such an interfacing agent to effectively control different TOSs it should have the capability not only to translate a user request into a TOS instruction, and to issue that instruction to the TOS at the appropriate time(s), but also to track the effect of those commands and to detect any perturbations, such as contradictory information, or a difference between expected and actual outcomes. We are developing such a perturbation tolerant, domainindependent interfacing agent (Anderson, Josyula, & Perlis 2003; Josyula, Anderson, & Perlis 2003) by modeling the beliefs, desires, intentions, expectations and achievements of the agent. The current version of the agent has been successfully integrated with and tested on six different TOSs. Our agent is built on a logical engine (ALFA Active Logic For Agents) based on Active Logic (Elgot-Drapkin & Perlis 1990; Purang et al. 1999; Purang 2001). ALFA can keep track of the evolving time, handle contradictory information and distinguish between desires, intentions and expectations that are achievable and those that are not. Therefore, our agent based on ALFA can rationally deliberate despite having deadlines and contradictory beliefs, desires or other mental attitudes. In addition, it can allocate its resources to satisfy achievable goals, resist attempting un-