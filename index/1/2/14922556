Robot localization is one of the most common tasks in autonomous systems. Unlike most vision-based methods which perform localization from cameras mounted on the robot, we propose a system which uses an off-board camera to achieve localization. For this purpose, we use a similarity measure between a camera image and a synthetic image generated using a 3D object model. In contrast to other methods, a previous training period is not necessary as we use a model of shading appearance based on the surface curvature of the 3D model. Assuming a reasonably planar area which is observed by an off-board camera, an initial position estimation in the camera image (based on 2D blob tracking) makes it possible for the 3D model to be rendered near the object in the image. From this initial guess, the model is then compared against the real image, such that it can converge to the true vehicle pose. Experiments are performed with a forklift-like robot in an outdoor industrial environment, considering different illumination conditions. The results are compared against a laser-based ground-truth, and illustrate the applicability of the method with a low average error.