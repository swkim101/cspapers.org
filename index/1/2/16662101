This paper describes a "bootstrapping" approach to the engineering of appropriate training-data representations for inductive learning. The central idea is to begin with an initial set of human-created features and then generate additional features that have syntactic forms that are similar to the human-engineered features. More specifically, we describe a two-stage process for the engineering of good representations for learning: first, generating by hand (usually in consultation with domain experts) an initial set of features that seem to help learning, and second, "bootstrapping" off of these features by developing and applying operators that generate new features that look syntactically like the expert-based features. Our experiments in the domain of DNA sequence identification show that an initial successful human-engineered representation for data can be expanded in this fashion to yield dramatically improved results for learning.