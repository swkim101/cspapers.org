A necessary function of ILP systems is to test whether rulesets intensionally cover examples. In general, when R contains recursive clauses, the above test may not terminate. In order that ILP techniques can serve end users directly in applications such as knowledge discovery in databases, general methods must be provided to ensure that the learned rulesets are executable and, in particular, that they do not lead to infinite recursion. To the best of our knowledge, all current methods are based on some kind of “Literal Order” or analog. Among them, the method “Ordering a Set of Constants and then Ordering Recursive Literals” that FOIL used (Cameron-Jones & Quinlan 1993) is one of the most advanced. However, this method suffers in at least three ways. ❶It can not be extended to Multiple Predicate Learning (MPL) (Raedt et cl. 1993) that involves more than one relation, e.g. when relation R invokes S and S invokes R. ❷It may not order constants correctly so as to have to rely on users to define constant orders for many recursive learning tasks. Sometimes this is necessary but not easy for users. ❸It needs to define theory constants that are strong hints of ground clauses. In our opinion, in order to overcome the above shortcomings, FOIL should memory more of previous learning to help further search in rule space. If we can efficiently record and update the effects that are made to the instance space every time when a new (recursive) clause is added to the rule, we can design more powerful heuristics to help search the rule space. Based on this idea, we invented instance graph H(R,E), where R is a ruleset and E is an instance space.