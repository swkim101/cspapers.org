This is a massively parallel ATPG that explores device-level, block-level and word-level parallelism in GPU. Eight-detect transition fault ATPG experiments on large benchmark circuits show that our technique achieved 5.6 and 1.6 times speedup compared with a single-core and 8-core CPU commercial tool, respectively. Test patterns selected from our test set are about the same length and quality as those selected from commercial N-detect ATPG. To the best of our knowledge, this is the first proposed GPU-based ATPG algorithm.