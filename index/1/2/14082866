Depth cameras, like the Microsoft Kinect system, are valuable sensors for mobile robotics since their data enables a highly detailed perception of the environmental structure. Certainly, their amount of data is often too high to be processed in real-time by the limited resources of mobile robots. One way of using these sensors is to reduce the amount of data by extracting features like planes from the raw depth images. In this work we present a method to extract planes from depth images based on the Randomized Hough Transformation, which is specially adapted to the properties of the Kinect sensor. Therefore we use a noise model of the sensor to solve the task of finding proper parameter metrics for the Randomized Hough Transform. As a result, our approach extracts the planes from a depth image in less than one millisecond on the platform of a mobile robot and is therefore real-time capable.