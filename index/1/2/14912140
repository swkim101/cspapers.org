Visual prosthesis simulators aim to provide a means of demonstrating, evaluating and improving the results of artificial vision devices. They transform the normal view of a camera scene into a form that represents the visual perceptions that would be caused by applying electrical stimulation to a part of the human visual pathway. These perceptions are called phosphenes and, in a cortical visual prosthesis, can be elicited through stimulation of the neurons in the visual cortex. This paper presents an FPGA implementation of a real-time vision system that simulates this phenomenon. The system is low-cost, mobile and consists of a CMOS camera, FPGA development board, and a head-mounted display. The methods of implementation discussed in this paper are applicable to other intelligent mobile sensor and machine vision applications where speed, low latency and low power consumption are important factors.