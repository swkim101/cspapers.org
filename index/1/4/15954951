The endoscopic guidance system for minimally invasive surgery presented here autonomously aligns the laparoscopic camera with the end-effectors of the surgeon's instruments. It collects information on the movements of the instruments from former interventions and can therefore predict them for autonomous guidance of the endoscopic camera. Knowledge is extracted by trajectory clustering, maximum likelihood classification and a Markov model to predict states. Alternative movements in an ongoing intervention are modeled. A first prototype of a robotic platform for minimally invasive surgery is described, which has two instrument arms, an autonomous robotic camera assistant and two haptic devices to control the instrument arms. The approach of long-term prediction and optimal camera positioning was tested in a phantom experiment with a hit rate of over 89% for predicting the movement of the end-effectors. Including this prediction for computing the camera position, leads to 29.2% less movements and to an improved visibility of the instruments.