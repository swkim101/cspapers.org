It is an important ability for any mobile robot to be able to estimate its posture and to gauge the distance it travelled. The information can be obtained from various sources. In this work, we have addressed this problem in a dynamic quadruped robot. We have designed and implemented a navigation algorithm for full body state (position, velocity, and attitude) estimation that does not use any external reference (such as GPS, or visual landmarks). Extended Kalman Filter was used to provide error estimation and data fusion from two independent sources of information: Inertial Navigation System mechanization algorithm processing raw inertial data, and legged odometry, which provided velocity aiding. We present a novel data-driven architecture for legged odometry that relies on a combination of joint sensor signals and pressure sensors. Our navigation system ensures precise tracking of a running robot's posture (roll and pitch), and satisfactory tracking of its position over medium time intervals. We have shown our method to work for two different dynamic turning gaits and on two terrains with significantly different friction. We have also successfully demonstrated how our method generalizes to different velocities.