We propose an autonomous mental development model that can voluntarily decide where and what it wants to see based on a bottom-up and top-down visual selective attention model in conjunction with human interaction. The proposed bottom-up saliency map model was developed by mimicking the functions of the visual pathway from the retina to the visual cortex through LGN. A low level topdown attention model implemented by a modified hierarchical Fuzzy ART network can incrementally inhibit uninteresting areas and reinforce interesting areas through human interaction. And a high level top-down attention model with human interaction for object non-specific representation and detection is proposed, which consists of a Gaussian mixture model and a maximum likelihood method for object representation and detection, respectively. The proposed model can generate a plausible attention map and give control signals to the effectors in robots to increase the machine intelligence through human interaction, autonomously.