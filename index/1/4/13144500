The development of the anthropomorphic flutist robot was started since 1990. The aim of this research has been to reproduce the functionality of human organs to interact musically with humans and to clarify the mechanism involved in human flute playing from an engineering view point. The newest version of the flutist robot (WF-4) has improved considerably the functionality and human-like shape of the organs involved in the flute playing. Up to now, the flutist robot has been used to reproduce as best as possible the human performance, although it is desirable to be also useful to improve some of the required skills that beginner flutists must acquire; in this case, the sound quality. The robot could demonstrate several times the correct way of playing and provide useful feedback based on the analysis of the harmonic structure of the student's performance. Therefore, it becomes necessary to find performance indexes that enable the robot to classify and evaluate quantitatively learners' performances to provide feedback (verbal and/or visual) to correct their executions. In this paper, we briefly describe some of the improvements done on the newest version of the flutist robot and we present different ways how the robot can evaluate the human performance by an experimental setup.