Mobile manipulators, which consist of a mobile base and a robot manipulator equipped with a vision system, are appropriate for transferring small quantities of a range of different materials in production lines. Position and orientation errors of the mobile base relative to the station are inevitably caused by the non-horizontality of the ground and positioning errors of the mobile base. Hence, this study utilises an uncalibrated eye-in-hand vision system to provide visual information for controlling the manipulator mounted on the mobile base, to pick up a workpiece located on the station. A vision-guided control strategy is proposed. It is based on selected image features and an image-based look-and-move control structure. The control law employed in the control structure is based mainly on the off-line estimate of the transformation from feature space to Cartesian space using the least squares estimation algorithm. Finally, the positioning performance of the eye-in-hand manipulator is experimentally evaluated by controlling the end-effector of the manipulator to approach and grasp the workpiece in various locations on a station.