We tackle the task of extracting tweets that mention a speciﬁc event from all tweets that contain relevant keywords, for which the main challenges include unbalanced positive and negative cases, and the unavailability of manually labeled training data. Existing meth-ods leverage a few manually given seed events and large unlabeled tweets to train a classi-ﬁer, by using expectation regularization training with discrete ngram features. We pro-pose a LSTM-based neural model that learns tweet-level features automatically. Compared with discrete ngram features, the neural model can potentially capture non-local dependencies and deep semantic information, which are more effective for disambiguating subtle semantic differences between true event mentions and false cases that use similar wording patterns. Results on both tweets and forum posts show that our neural model is more effective compared with a state-of-the-art discrete baseline.