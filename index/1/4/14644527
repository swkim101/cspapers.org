A comprehensive evaluation of the Software Requirements Engineering Methodology (SREM) was performed to assess its capabilities for specifying the software requirements of large, embedded computer systems and to recommend improvements which would enhance its effectiveness. Specific evaluation criteria were developed to judge the effectiveness of the methodology, its support tools and user training. The approach included attending a SREM training course and using SREM to specify the software requirements for two Air Force systems. The relatively small number of errors uncovered indicates the effectiveness of disciplined requirements analysis techniques and the capabilities of SREM for exposing subtle problems.
 In general, it was found that the SREM was an effective vehicle for specifying and analyzing the software requirements of large embedded computer systems, especially descriptions of real world objects, data requirements and message processing. However, deficiencies were noted in the specification language, in the “friendlinéss” of the user interfaces to the analysis and simulation tools, in the performance of these tools and in the effectiveness of the training. Appropriate improvements to all of the functional deficiencies are recommended.