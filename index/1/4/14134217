User traits disclosed through written text, such as age and gender, can be used to per-sonalize applications such as recommender systems or conversational agents. However, human perception of these traits is not perfectly aligned with reality. In this paper, we conduct a large-scale crowdsourcing ex-periment on guessing age and gender from tweets. We systematically analyze the quality and possible biases of these predictions. We identify the textual cues which lead to miss-assessments of traits or make annotators more or less conÔ¨Ådent in their choice. Our study demonstrates that differences be-tween real and perceived traits are noteworthy and elucidates inaccurately used stereotypes in human perception.