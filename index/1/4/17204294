In this paper, we discuss a coordinated haptic training architecture useful for transferring expertise in teleoperation-based manipulation between two human users. The objective is to construct a reality-based haptic interaction system for knowledge transfer by linking an expert's skill with robotic movement in real time. The benefits from this approach include 1) a representation of an expert's knowledge into a more compact and general form by learning from a minimized set of training samples, and 2) an increase in the capability of a novice user by coupling learned skills absorbed by a robotic system with haptic feedback. In order to evaluate our ideas and present the effectiveness of our paradigm, human handwriting is selected as our experiment of interest. For the learning algorithms, artificial neural network (ANN) and support vector machine (SVM) are utilized and their performances are compared. For the evaluation of the performance of the output of the learning modules, a modified Longest Common Subsequence (LCSS) algorithm is implemented. Results show that one or two experts' samples are sufficient for the generation of haptic training knowledge, which can successfully recreate manipulation motion with a robotic system and transfer haptic forces to an untrained user with a haptic device. Also in the case of handwriting comparison, the similarity measures result in up to an 88% match even with a minimized set of training samples.