We propose a dimension reduction technique named Resilient Subclass Discriminant Analysis (RSDA) for high dimensional classification problems. The technique iteratively estimates the subclass division by embedding the Fisher Discriminant Analysis (FDA) with Expectation-Maximization (EM) in Gaussian Mixture Models (GMM). The new method maintains the adaptability of SDA to a wide range of data distributions by approximating the distribution of each class as a mixture of Gaussians, and provides superior feature selection performance to SDA with modified EM clustering that estimates a posteriori probability of latent variables in lower-dimensional Fisher's discriminant space, which also improves the robustness in problems of small training datasets compared with conventional EM algorithm. Extensive experiments and comparison results against other well-known Discriminant Analysis (DA) methods are presented using synthetic data, benchmark datasets as well as a real computational vision problem.