While the design of social robots, has engaged researchers for some time, only recently have the human implications of interaction with such robots been considered. In this paper, we address how children and adults behave toward and think about the social robot AIBO. Our work is informed by a conceptual framework that draws on constructs within cognitive psychology: the essentialist theory of cognitive development and scripts. At the same time, our research challenges assumptions of both the essentialist theory of cognitive development and scripts and argues for a more dynamic and complex formulation of these constructs. Four studies of children and adults interacting with AIBO conducted by our research team serve to illustrate aspects of this framework. We close by suggesting further questions raised by this work. Reeves and Nass (2002) have proposed that “individuals’ interactions with computers, television, and new media are fundamentally social and natural, just like interactions in real life” (p. 5 authors’ emphasis). The new media of social robots are of special interest in this regard, since they particularly evoke social and affective human responses (Breazeal, 2003; Fong, Nourbakhsh, & Dautenhahn, 2003; Lee, Park, and Song 2005). In this paper, we suggest a conceptual framework for understanding human responses to social robots in general, and to the social robot AIBO, in particular. This conceptual framework draws on the constructs of the essentialist theory of cognitive development, particularly as elaborated by Susan Gelman (2004) and her colleagues, as well as the construct of cognitive script (Shank and Abelson 2002). However, it places these ideas within a dynamic constructivist systems perspective (Melson, forthcoming) in which individuals construct the meaning of human-robot interactions over time as they experience these interactions. The resulting ‘constructions,’ evident in behavior, cognitions, and emotions related to the social robot, are the product of individual human and robot characteristics and history as well as the context and history of interaction. Hence, like all dynamic systems, HRI properties are emergent and not fully determined a priori. A Framework for Understanding Human Responses to Social Robots Essentialist Theory of Cognition In the essentialist theory of cognition (Gelman 2004), once an object is identified as belonging to a particular domain, essentialist beliefs lead one to infer ‘essences,’ i.e., distinct unseen properties that reflect the underlying nature that imparts category identity. For example, five year olds will infer bones as internal parts of an unfamiliar object labeled as an “animal” but batteries as internal parts of an unfamiliar object labeled as a “machine” (Gottfried and Gelman 2005). Thus, a key feature of the essentialist view of cognitive development is category assignment. When encountering an unfamiliar social robot, individuals ask themselves (usually unconsciously): “What type of object is this?” The answer to this question allows one to infer unseen category attributes (e.g., if a computer like machine, it probably has batteries or power source, microchips, and sensors). However, essentialist theory assumes ontologically a limited and presumably fixed number of broad essences—biological, psychological, or artifactual—into which one slots unfamiliar objects. In this sense, essentialist theory divides its ontology into predetermined Platonic categories. To forecast our argument, encounters with social robots may challenge such an ontological accounting, showing evidence of category boundaries that shift, blur, and overlap. Sociable robots may prompt humans to construct new ontological categories to make sense of their interactions with them.