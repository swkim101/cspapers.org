We present a navigation guidance system that guides a human to a goal point with a tactile belt interface and a stationary laser scanner. We make use of ROS local navigation planner to find an obstacle-free path by modeling the human as a non-holonomic robot. Linear and angular velocities to keep the `robot' on the path are dynamically calculated, which are then converted to vibrations and applied by the tactile belt. We define directional and rotational vibration patterns and evaluate which ones are suitable for guiding humans. Continuous patterns for representing directions had the least average angular error with 8.4°, whereas rotational patterns were recognized with near-perfect accuracy. All patterns had a reaction time slightly more than 1 seconds. The person is tracked in laser scans by fitting an ellipse to the torso. Average tracking error is found to be 5cm in position and 14° in orientation in our experiments with 23 people. Best tracking results was achieved when the person is 2.5m away and is facing the sensor or the opposite way. The human control system as a whole is successfully demonstrated in a navigation guidance scenario.