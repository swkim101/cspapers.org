Crowdsourcing provides new ways of cheaply and quickly gathering large amounts of information contributed by volunteers online. This method has revolutionised the collection of labelled data, in computational linguistics and elsewhere. However, to create annotated linguistic resources from crowdsourced data we face the challenge of having to combine the judgements of a potentially large group of annotators. Here we put forward the idea of using principles of social choice theory to design new methods for aggregating linguistic annotations provided by individuals into a single collective annotation.