In general, the problems of objects' and rooms' categorizations for robotic applications have been addressed separately. The current trend is, however, towards a joint modelling of both issues in order to leverage their mutual contextual relations: object → room (e.g. the detection of a microwave indicates that the room is likely to be a kitchen), and room → object (e.g. if the robot is in a bathroom, it is probable to find a toilet). Probabilistic Graphical Models (PGMs) are typically employed to conveniently cope with such relations, relying on inference processes to hypothesize about objects' and rooms' categories. In this work we present a Conditional Random Field (CRF) model, a particular type of PGM, to jointly categorize objects and rooms from RGBD images exploiting object-object and object-room relations. The learning phase of the proposed CRF uses Human Knowledge (HK) to eliminate the necessity of gathering real training data. Concretely, HK is acquired through elicitation and codified into an ontology, which is exploited to effortless generate an arbitrary number of representative synthetic samples for training. The performance of the proposed CRF model has been assessed using the NYU2 dataset, achieving a success of ~ 70% categorizing both, objects and rooms.