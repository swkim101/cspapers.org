Hand-eye coordination involves four tasks: i) identification of the object to be manipulated, ii) ballistic arm motion to the vicinity of the object, iii) preshaping and alignment of the hand, and finally iv) manipulation or grasping of the object. Motivated by the operation of biological systems and utilizing some constraints for each of the above mentioned tasks, we are aiming at design of a robust, robotic hand-eye coordination system. Hand-eye coordination tasks we consider here are of the basic fetch-and-carry type useful for service robots operating in everyday environments. Objects to be manipulated are, for example, food items that are simple in shape (polyhedral, cylindrical) but with complex surface texture. To achieve the required robustness and flexibility, we integrate both geometric and appearance based information to solve the task at hand. We show how the research in human visuo-motor system can be facilitated to design a fully operational, visually guided object manipulation system.