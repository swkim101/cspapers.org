Traditional collaborative filtering, and content-based approaches attempt to learn a static recommendation model in a batch fashion. These approaches are not suitable in highly dynamic recommendation scenarios, like news recommendation and computational advertisement. Due to this well-known limitation, in the last decade a lot of efforts have been spent over the study of online learning techniques. Currently, a lot of attention has been devoted to improvements on the theoretical guarantees, without caring too much about computational cost and memory footprint. However, in the era of big-data content features tend to be high-dimensional, which leads to a direct challenge for traditional on-line learning algorithms (e.g., multi-armed bandits) since these are mostly designed for low-dimensional feature spaces. In this work we face the aforementioned problem, investigating an approximated context-aware bandit learner. Our model takes into account the problem of finding the actual low-dimensional manifold spanned by data content-features. In particular, we propose to store the covariance matrix of the previously seen contexts in a compressed space, without losing too much in terms of recommendation quality. With this work we provide an overview over the main properties, describe the adopted techniques, and report on preliminary experimental results on a synthetic dataset. We also discuss a drawback of the proposed method that may appear in typical scenarios and suggest future research avenues.