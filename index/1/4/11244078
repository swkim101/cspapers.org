We propose a probabilistic method for tracking articulated objects, such as the human figure, across multiple layers in monocular image sequence. In this method, each link of a probabilistic articulated object is assigned to one individual image layer. The layered representation allows us to robustly model the pose and occlusion of object parts during its motion. Appearance of links is described in terms of learned statistics of basic image features, such as color, and geometric models of robust spatial kernels. This results in a highly efficient computational method for inference of the objectâ€™s pose. We apply this approach to tracking of the human figure in monocular video sequences. We show that the proposed method, coupled with a learned dynamic model, can lead to a robust articulated object tracker.