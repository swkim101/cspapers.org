The initial CRAY X-MP multitasking implementation supported multitasking of infrequently synchronizing jobs running in a dedicated environment. Running in a shared environment or using too small a granularity often had adverse effects on performance. The original mechanisms were not designed for general use and hence were neither flexible nor efficient. Additionally, multitasking as an integrated feature (user libraries and operating system) needed to vary the number of processors working on a problem quickly. We subsequently implemented simpler mechanisms in the user libraries and operating system. The new mechanisms exploit the speed of a set of hardware registers which are shared among cooperating CPUs to achieve the needed performance. In retrospect, we saw how neatly a data-flow paradigm fit our design. presented in Section 6. Performance data (Section 7) and conclusions (Section 8) finish the presentation. 1 .1 . Defin i t ions We define multitasking as creating asynchronously executing processes within one address space. When running on a multiple CPU machine, several processes may be simultaneously executing in physical CPU(s). Granularity is the execution time between synchronizations among cooperating tasks. We ignore the task size or the amount of code between synchronization points and concentrate on execution time. Large granularity is on the order of 107 or more clock periods on a CRAY X-MP, or about 100 milliseconds. Macrotasking is defined as large-granularity multitasking. Small granularity is on the order of l04 clock periods or about 100 microseconds. Microtasking is small-granularity multitasking with operating system support. Dedicated use of a machine means that one program runs standalone. Shared use of a machine means users compete for machine resources. 'i 1. I n t r o d u c t i o n This paper describes how multitasking on CRAY X-MP computers can be usefully viewed as a data-flow problem. We begin with an overview of approaches to multitasking (Section 2). Next we describe our initial implementation of multitasking (Section 3) and motivation for requirements for a new approach (Section 4). Section 5 describes the new implementation and explains how it satisfies the perceived needs. Application code using the new scheme is Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. Â© 1985 A C M 0 8 9 7 9 1 1 7 4 I 12 /85-0107 $ 0 0 . 7 5 2. Su rvey Multiple processor computers are receiving great attention as a solution to the growth in demand for high-performance computing resources. It is important to be able to use all the processors on one probh,m, or multitask that problem. Two conventional approaches to multitasking exist. The first is our macrotasking approach. It is the obvious approach for the "expensive" CPU situation. A job runs until it has "lots of work" to do and then requests additional CPUs from the operating system. When a non-parallel portion of the program is reached, the extra CPUs can be released to the operating system. Leaving idle CPUs available to other processes is important when they are an expensive resource. This scheme has the disadvantage of high startup time but is efficient if the execution time is long