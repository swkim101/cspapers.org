Robots are added to human teams to increase the team's skills or capabilities but in order to get the full benefit the teams must trust the robots. We present an approach that allows a robot to estimate its trustworthiness and adapt its behavior accordingly. Additionally, the robot uses case-based reasoning to store previous behavior adaptations and uses this information to perform future adaptations. In a simulated robotics domain, we compare case-based behavior adaption to behavior adaptation that does not learn and show it significantly reduces the number of behaviors that need to be evaluated before a trustworthy behavior is found.