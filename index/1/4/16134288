Indoor aerial robots are useful in many applications due to their size, agility and ability to hover. However, tweaking a state-feedback controller to fly stably takes either intensive human supervision, or extensive modeling and identification, hence has never been trivial. In this paper, we give a successful flight controller design that can learn from a single demonstration performed by human and hover indoor aerial robots autonomously on maiden flight1.