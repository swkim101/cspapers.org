K-nearest neighbor (KNN) is a popular classification algorithm with good scalability, which has been widely used in many fields. When dealing with imbalanced data, minority examples are given the same weight as majority examples in the existing KNN algorithm. In this paper, we pay more attention to the minority class than the majority class, and we increase the weight of minority class according to the local characteristic of minority class distribution. In addition, we compare the proposed algorithm with the existing Weighted Distance K-nearest neighbor (WDKNN). Experimental results show that our algorithm performs better than WDKNN in imbalanced data sets.