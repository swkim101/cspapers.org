This paper introduces S TEM and L AMB , embeddings trained for stems and lemmata instead of for surface forms. For morphologically rich languages, they perform significantly better than standard embeddings on word similarity and polarity evaluations. On a new WordNet-based evaluation, S TEM and L AMB are up to 50% better than standard embeddings. We show that both embeddings have high quality even for small dimensionality and training corpora.