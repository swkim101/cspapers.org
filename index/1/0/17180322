In this paper an object-based visual attention model extending Duncan's integrated competition hypothesis is presented for robots. Based on Gestalt rules the model segments the visual field into primitive groupings by evaluating both edge continuity and color similarity. An object representation is also built in long-term memory by using contour and color features. Dependent on the task and object representation, top-down modulation performs on pre-attentive features, followed by bottom-up competition. The object-based salience is evaluated by combination of pixel-wise salience within each pre-attentive grouping. The attended object is finally refined to reach an accurate representation in working memory. This model has been applied into two tasks of mobile robots: task-specific still and moving object detection. Experimental results in cluttered scenes are shown to validate this model.