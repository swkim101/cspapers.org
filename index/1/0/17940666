Many neurorobotic experiments require central pattern generators (CPGs) and motion primitives for the target robot, which have to be given prior to an experiment as building blocks. The creation of artificial neural networks, that produce the desired motions, is a tedious and time-consuming task. Also, rapidly varying motion patterns to test alternative motions is difficult due to the rigid nature of the usually hardwired networks. To overcome this problem, a novel network architecture is introduced that allows to capture motions directly from demonstrated movements on the robot hardware. The demonstrated motion patterns are stored in the activation dynamics of the network, instead of in the synaptic weights. This allows the rapid creation and modification of neural CPGs for various - even complex - motions directly on the robot. With a simple adaptation method, the activation dynamics representing the captured motions can also be used to determine synaptic weights to create fixed, reusable neural building blocks. The applicability of the proposed neural network architecture is demonstrated by generating two arm motions for a humanoid robot by demonstration. The successful applications show that the neural motion capturing approach is a useful method to generate CPGs for neurorobotic experiments.