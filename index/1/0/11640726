In previous work (Bennett 1993 DeJong and Bennetl 1993) we proposed a machine learning approach called permissive planning to extend classical planning into the realm of real world plan execution. Our prior results have been favorable but empirical (Bennett and DeJong 1991). Here we examine the analytic foundations of our empirical success. We advance a formal account of realworld planning adequacy. We prove that permissive planning does what it claims to do it probabilistically achieves adequate real-world performance or guarantees that no adequate real-world planning behavior is possible within the flexibility allowed. We prove that the approach scales tractably We prove that restrictions are necessary without them permissive planning is impossible. We also show how these restrictions can be quite naturally met through schema based planning and explanation-based learning.