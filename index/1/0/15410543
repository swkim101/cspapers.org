We study the problem of computing and learning non-anonymous reserve prices to maximize revenue. We first define the {\sc Maximizing Multiple Reserves (MMR)} problem in single-parameter matroid environments, where the input is $m$ valuation profiles v^1,...,v^m, indexed by the same n bidders, and the goal is to compute the vector r of (non-anonymous) reserve prices that maximizes the total revenue obtained on these profiles by the VCG mechanism with reserves r. We prove that the problem is APX-hard, even in the special case of single-item environments, and give a polynomial-time 1/2-approximation algorithm for it in arbitrary matroid environments. We then consider the online no-regret learning problem, and show how to exploit the special structure of the MMR problem to translate our offline approximation algorithm into an online learning algorithm that achieves asympototically time-averaged revenue at least 1/2 times that of the best fixed reserve prices in hindsight. On the negative side, we show that, quite generally, computational hardness for the offline optimization problem translates to computational hardness for obtaining vanishing time-averaged regret. Thus our hardness result for the MMR problem implies that computationally efficient online learning requires approximation, even in the special case of single-item auction environments.