1. I n t r o d u c t i o n Randomness have been playing an ever increasing role in computer science. The demand for cheap random bits and repeatabil i ty of random experiments have resulted in the need for pseudorandom generators. Clearly one has to be careful in the design of a pseudorandom generator to make sure that the output behaves "randomly". Classically this meant that the sequence produced by the generator passed certain statistical tests (see Knuth [K]). This point of view was dramatically changed in 1982 by the papers by Blum and Micali IBM] and Yao [Y]. One important change was a new definition of what should be required of a pseudorandom generator, namely its output should be indistinguishable from truly random bits by all probabilistic polynomial t ime algorithms. The second important contribution was the construction of pseudorandom generators satisfying this new stringent definition (under some specific assumption). Blum and Micali's generator IBM] was proved secure under the assumption that the discrete logar i thm problem was hard and Yao generalized this to show how to construct a secure generator from any oneway permutat ion. Of course it would be very nice to prove that a given generator is secure without any assumptions, Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. but to unconditionally prove that a generator is secure is at least as difficult as proving that N P ~ P and thus this seems too much to ask for. The next best thing is to investigate exactly what assumptions are required. In 1985, Levin [L] proved that necessary and sufficient conditions for the existence of a secure generator is the existence of a function which is oneway on its iterates. This condition is not, however, completely natural and thus the search for more natural conditions continued. Goldreich, Krawczyk and Luby [GKL] gave a construction for a secure generator given the existence of a regular oneway function. Then recently, Impagliazzo, Levin and Luby JILL] proved that the existence of a oneway function in the nonuniform model (i.e. cannot be inverted by polynomial size circuits) implies the existence of nonuniformly secure generators (i.e. cannot be distinguished from random bits by polynomial size circuits). Their teclmique did not extend to show that the existence of a oneway function in the uniform model guarantees the existence of generators which are uniformly secure, and the main open question in the area was to prove that this is the case. The main result of this paper is to indeed prove that oneway functions in the uniform model imply uniformly secure generators. Since it is easy to see that secure generators imply oneway functions we have hence obtained natural necessary and sufficient conditions for the existence of secure generators. Our construction uses mostly the same ideas as [ILL]. A key concept of JILL] is that of a false entropy generator (FEG). A function g is a FEG if the distribution G generated by picking a random x and computing g(x) is indistinguishable from a distribution D, where D has higher entropy than G. In the uniform case we also want D to be polynomial time samplable i.e. that there is a probabilistic polynomial t ime algorithm that outputs a random element from D: JILL] proved that the existence of a FEG implies the existence of a secure pseudorandom generator (this has been strengthened by Oded Go, tireÂ© 1990 ACM 089791-361-2/90/0005/0395 $1.50 395 ich [G] to show that if there are two distributions that computationally indistinguishable but statistically different then there exists secure generators). Let f be a oneway permutat ion and b a predicate that is hard to approximate given the information f (x) . Consider g(x) = (f(~:), b(x)) and let G be the distribution generated by g on a random input. Since b is hard to approximate, G is indistinguishable from D = (f(x), r) where r is a random bit and D has higher entropy than G since if f is a permutation, then f (x) determines z and hence b(z) uniquely. Thus g is a FEG. It seems like this construction on top of a oneway function f needs a predicate b which is hard given f . However by the elegant result by Goldreich and Levin [GL] we know that we can always take b to be a random xor. Let us now turn to the case where f is not a permutation. In this case ( f (x ) ,b (z ) ) is still indistinguishable from (f(x), r) but g might still not be a FEG. The reason is that f ( x ) does not any more determine b(x) and hence it is not clear that changing b(x) to a random bit increases the entropy, fILL] solved this problem by output t ing also a hashfunction h(x) in order to determine x uniquely, and letting g'(x) = (f(z) , h(z), b(x)). The corresponding distribution G ~ now has lower entropy then the distribution given by ( f (x) , h(z), r) where r is a random bit. However, releasing extra information about x might help an algorithm that tries to invert f and if h(x) outputs too many bits, the mapping x (f(z), h(x)) might not be oneway and thus the output of g' could be distinguishable from (f(x), h(z), r). It turns out that it is both profitable and safe to change b(x) to a random bit when h outputs approximately log i f -1 ( f(z)) I bits. However this creates a nonuniform competing distribution (since cannot compute this number) and this is the source of the nonuniformity of fILL]. We get around this problem by generating many xi and computing f(xi), b(xi) and h(xi) for hash functions of random sizes. We then output all f(xi), h(xi), 11~[1~ and M where M is random matrix and B is the vector of the b(xi) values. If the size of M is chosen correctly this is indistinguishable from the distribution where everything is identical except that B is chosen randomly and this latter distribution has a higher entropy. The main difficulty in the proof is to prove that MB is indistinguishable from M Y where Y is picked randomly. The proof of this is similar to the proof of Levin [L] of the sharp version of Yao's XOR-lemma. The present lemma proves more than is needed for the present application. Namely, we prove that if B consists of bits that each can be guessed with probability at most (1 + p)/2 (over the input and the coinflips of the algorithm) then the conclusion follows (for suitable choice for the size of M). However, in our application, with probability 1 p (over the input), no probabilistic polynomial time algorithm can gain any significant advantage over guessing, and with probability p (over the input) the bit might be totally predictable. Using this stronger property it is possible to give a simpler proof. This simpler proof will appear in a forthcoming journal paper, which will be a combination of the present paper and fILL]. In this paper we prove the stronger lemma by the more complicated proof since we believe that the stronger version of the lemma is interesting on its