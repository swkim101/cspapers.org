Spoken dialog managers have benefited from stochastic planners such as MDPs. However, so far, MDPs do not handle well noisy and ambiguous utterances from the user. We address this problem by inverting the notion of dialog state; the state represents the us râ€™s intentions, rather than the system state. This approach allows for simple and intuitive dialog description at the sacrifice of state observability. We use a POMDP-style approach to generate dialog policies; however, the intractability of POMDP solutions requires an approximate solution. We instead augment the state representation of the MDP by providing the system with the maximum likelihood state and a compressed representation of the belief state. In this way, the system can approximate the optimal POMDP solution, but at MDP-like speeds.