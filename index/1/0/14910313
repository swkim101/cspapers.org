Appearance-based batch nonlinear optimization techniques for simultaneous localization and mapping (SLAM) have been highly successful in assisting robot motion estimation. Traditionally, these techniques are applied in a single privileged coordinate frame, which can become computationally expensive over long distances, particularly when a loop closure requires the adjustment of many pose variables. Recent approaches to the problem have shown that a completely relative coordinate framework can be used to incrementally find a close approximation of the full maximum likelihood solution in constant time. However, due to the nature of these discrete-time techniques, the state size becomes intractable when challenged with high-rate sensors. We propose moving the relative coordinate formulation of SLAM into continuous time by estimating the velocity profile of the robot. We derive the relative formulation of the continuous-time robot trajectory and formulate an estimator for the SLAM problem using temporal basis functions. Although we do not yet take advantage of large-scale loop closures, we intentionally use a relative formulation to set the stage for future work that will close loops in constant time. We show how the estimator can be used in a window-style filter to incrementally find the batch solution in constant time. The estimator is validated on a set of appearance-based feature measurements acquired using a two-axis scanning laser rangefinder over a 1.1km trajectory.