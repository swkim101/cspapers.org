This study aims to realize lip synchronized speech with less actuators installed for robotic mouth motion. Asynchronous lip postures in a robot speech gives most human listeners strongly negative impressions of fakeness, horror and awkwardness. Some misperception might happen while the speech listeners are hearing one voice but seeing another different mouth pattern. A 2-DOF oral mechanism is developed to perform lip synchronization for an android robot with speaking capabilities in this study. Its functional specification is determined through some preliminary investigations. After merging two types of classical mechanism designs, it can generate 6 essential lip postures for speech matching. The realistic effect on lip synchronized speech of this 2-DOF system is close to that of the Multi-DOF ones. The effectiveness of the lip-synchronization of the new simplified oral mechanism has been demonstrated in verification experiments.