Ordering search results collected from multiple sources is a challenge to metasearch engines. We present an “autonomous” ranking method, meaning one that does not depend on the individual rankings returned by the engines participating in the search. Instead, it applies our TOPIC method for evaluating the reputation of a web page on a topic [7, 6] to the problem of ranking the results to a query. (TOPIC is available at www.cs.toronto.edu/db/topic). Methods for ranking query result pages based on some notion of relatedness or authoritativeness have been studied in the literature [5, 1] and implemented in commercial systems [3]. There is also work on incorporating user intentions (eg. ‘current events’, ‘research papers’ or ‘individual home pages’) to a metasearch engine [4]. TOPIC computes, given a page, those topics on which the page has highest reputation, by a combination of link and content analysis. In this paper, the topics are derived from the user’s query; the reputation of each result page on the query topic is computed, and the value used to rank the result pages across all participating search engines, without biasing the ranking towards any of the sources. A comparative study of link analysis algorithms has been published by Borodin et al. [2]. Our work differs from Kleinberg’s approach [5] in that there is no concept of a base set that can affect the final ranking. It also differs from Page Rank [3], the ranking function used in Google, since it does not require storing a large collection of pages.