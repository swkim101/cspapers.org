Load balancing mechanisms and scheduling algorithms play a critical role in achieving efficient server utilization and providing robust delay performance in a wide range of networked systems. We will review some celebrated schemes and optimality results which typically assume that detailed state information, e.g. exact knowledge of queue lengths, is available in assigning jobs to queues or allocating a shared resource among competing users. In practice, however, obtaining such state information is non-trivial, and usually involves a significant communication overhead or delay, which is particularly a concern in large-scale networked systems with massive numbers of queues. These scalability issues have prompted increasing attention for the implementation complexity of load balancing and scheduling algorithms as a crucial design criterion, besides the traditional performance metrics. In this talk we examine the delay performance in such networks for various load balancing and scheduling algorithms, in conjunction with the associated implementation overhead. In the first part of the talk we focus on a scenario with a single dispatcher where jobs arrive that need to be assigned to one of several parallel queues. In the second part of the talk we turn to a system with a single resource, e.g. a shared wireless transmission medium, which is to be allocated among several nodes. We will specifically explore the delay scaling properties in a mean-field framework where the total load and service capacity grow large in proportion. The mean-field regime not only offers analytical tractability, but is also highly relevant given the immense numbers of servers in data centers and cloud networks, and dense populations of wireless devices and sensors in Internet-of-Things (IoT) applications. Time permitting, we will also discuss the impact of the underlying network structure and a few open research challenges.