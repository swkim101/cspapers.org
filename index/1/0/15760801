Highly nonlinear and ill-conditioned numerical optimization problems take their toll on the convergence of existing res- olution methods. Stochastic methods such as Evolutionary Algorithms carry out an efficient exploration of the search- space at low cost, but get often trapped in local minima and do not prove the optimality of the solution. Deterministic meth- ods such as Interval Branch and Bound algorithms guaran- tee bounds on the solution, yet struggle to converge within a reasonable time on high-dimensional problems. The contri- bution of this paper is a hybrid algorithm in which a Differen- tial Evolution algorithm and an Interval Branch and Contract algorithm cooperate. Bounds and solutions are exchanged through shared memory to accelerate the proof of optimal- ity. It prevents premature convergence toward local optima and outperforms both deterministic and stochastic existing approaches. We demonstrate the efficiency of this algorithm on two currently unsolved problems: first by presenting new certified optimal results for the Michalewicz function for up to 75 dimensions and then by proving that the putative mini- mum of Lennard-Jones clusters of 5 atoms is optimal.