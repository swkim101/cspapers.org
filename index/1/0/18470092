This paper reports on our work and re sults framing signal processing algorithm op timization as a machine learning task A sin gle signal processing algorithm can be repre sented by many di erent but mathematically equivalent formulas When these formulas are implemented in actual code they have very di erent running times Signal process ing optimization is concerned with nding a formula that implements the algorithm as ef ciently as possible Unfortunately a correct mapping between a mathematical formula and its running time is unknown However empirical performance data can be gathered for a variety of formulas This data o ers an interesting opportunity to learn to predict running time performance In this paper we present two major results along this direc tion Di erent sets of features are iden ti ed for mathematical formulas that distin guish them into partitions with signi cantly di erent running times and A function approximator can learn to accurately predict the running time of a formula given a limited set of training data Showing the impact of selecting di erent features to describe the in put this work contributes an extensive study on the role of learning for this novel task