In this paper, we argue that a mobile robot's environment can be determined by computing local maps surrounding feature points, called fixation points. These fixation points are obtained by searching the scene for points which present some interesting cue for robot navigation. This 3-D computation is based on a monocular active vision system composed of a camera, mounted on a rotating table accurately controlled by a computer, which gazes the fixation point as the robot moves. The system then computes the local map and updates it with each new observation in order to increase its accuracy and robustness. Real experimentation in a complex indoor scene illustrates that the 3-D scene coordinates can be obtained with a good accuracy by integrating several observations.