This paper presents a biologically-inspired model of self-organization for robotic intermediary vision. Two mechanisms are under concern. First, the development of low-level local feature detectors that perform a piecewise categorization of the sensory signal. Second, the hierarchical grouping of these local features in a holistic perception. While the grouping mechanism is expressed as a classical agglomerative clustering, underlying similarity measures are not pre-given but developed from the signal statistics.