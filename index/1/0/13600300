This paper describes an online place discovery and recognition engine that fuses information over time to create topologically distinct places. A key motivation is the recognition that a single image may be a poor exemplar of what constitutes a place. Images are not `places' nor are they `documents'. Instead, by treating image-sequences as a multimodal distribution over topics - and by discovering topics incrementally and online - it is possible to both reduce the memory footprint of place recognition systems, and to improve precision and recall. Distinctive key-places are represented by a cluster topics found from the covisibility graph of a relative simultaneous localization and mapping engine - key-places inherently span many images. A dynamic vocabulary of visual words and density based clustering is used to continually estimate a set of visual topics, changes in which drive the place-recognition process. The system is evaluated using an indoor robot sequence, a standard outdoor robot sequence and a long-term sequence from a static camera. Experiments demonstrate qualitatively distinct themes associated with discovered places - from common place types such as `hallway', or `desk-area', to temporal concepts such as `dusk', `dawn' or `mid-day'. Compared to traditional image-based place-recognition, this reduces the information that must be stored without reducing place-recognition performance.