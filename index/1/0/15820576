Uncertainty estimates related to the position of image features are seeing increasing use in several computer vision problems. Many of these have been recast from standard least squares model fitting to techniques that minimize the Mahalanobis distance, which weighs each error vector by covariance of the observations. These include structure from motion and traditional geometric camera calibration. Uncertainty estimates previously derived for the case of corner localization are based on implicit assumptions that preclude sophisticated image noise models. Uncertainties associated with these features tend to be over estimated. In this work, we introduce a new formulation for feature location uncertainty that supports arbitrary pixel covariance to derive a more accurate positional uncertainty estimate. The method is developed and evaluated in the case of a traditional interest operator that is in widespread use. Results show that uncertainty estimates based on this new formulation better reflect the error distribution in feature location.