This paper presents a distributed algorithm for performing joint localisation of a team of robots. The mobile robots have heterogeneous sensing capabilities, with some having high quality inertial and exteroceptive sensing, while others have only low quality sensing or none at all. By sharing information, a combined estimate of all robot poses is obtained. Inter-robot range-bearing measurements provide the mechanism for transferring pose information from well-localised vehicles to those less capable. In our proposed formulation, high frequency egocentric data (e.g., odometry, IMU, GPS) is fused locally on each platform. This is the distributed part of the algorithm. Inter-robot measurements, and accompanying state estimates, are communicated to a central server, which generates an optimal minimum mean-squared estimate of all robot poses. This server is easily duplicated for full redundant decentralisation. Communication and computation are efficient due to the sparseness properties of the information-form Gaussian representation. A team of three indoor mobile robots equipped with lasers, odometry and inertial sensing provides experimental verification of the algorithms effectiveness in combining location information.