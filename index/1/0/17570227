Despite the availability in the literature of several constraint-based motion generation algorithms, modest attention has been paid to their robustness with respect to noise, and more in general, to unstructured uncertainties. Especially in the case of sensor-related constraints, the envisaged robustness properties are clearly crucial to enforce the correct and expected behaviour of these algorithms. This paper contributes with a method to explicitly account for different sources of uncertainty. We also suggest a computational efficient way to consistently modify the constraint specification in order to obtain such robustness. An experimental verification on a visual aided grasping task, where visibility of the object is to be maintained, enlightens the benefits of the proposed approach in terms of achieving the desired robustness.