A rational agent in a multi agent world must decide on its actions based on the decisions it expects others to make, but it might believe that they in turn might be basing decisions on what they believe the initial agent will decide. Such reciprocal rationality leads to a nesting of models that can potentially become intractable. To solve such problems, game theory has developed techniques for discovering rational, equilibrium solutions, and AI has developed computational, recursive methods. These different approaches can involve different solution concepts. For example, the Recursive Modeling Method (RMM) finds different solutions than game-theoretic methods when solving problems that require mixed-strategy equilibrium solutions. In this paper, we show that a crucial difference between the approaches is that RMM employs a solution concept that is overeager. This eagerness can be reduced by introducing into RMM second-order knowledge about what it knows, in the form of a flexible function for mapping relative expected utility of an option into the probability that the agent will pursue that option. This modified solution concept can allow RMM to derive the same mixed equilibrium solutions as game-theory, and thus helps us delineate the types of knowledge that lead to alternative solution concepts.