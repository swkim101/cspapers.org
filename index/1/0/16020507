The "Talking Robots" experiment, inspried by the "Talking Heads" experiment from Sony, explores possibilities on how to ground symbols into perception using language, with two autonomous Aibo robots in an unconstained environment. We present here the first results of this experiment and outline in the conclusion a planned extension to social behaviors grounding.