We present an analysis of the error growth in inertial tracking due to sensor noise. This analysis focuses on a problem arising in tracking systems with both optical and inertial sensors. Optical sensors always need a line-of-sight, and a natural idea is to continue tracking using only inertial sensors during an occlusion when the line-of-sight is lost. Several error sources are present in inertial tracking; here we consider the error due to sensor noise which cannot be compensated and is present even if the setup is perfectly calibrated and initialized. The result of this analysis is a mathematical expression for the expected error as a function of time and provides an answer to the following two questions: Depending on the precision needed and the inertial sensors employed, for how long is purely inertial tracking possible? Which sensor characteristics have to be improved to decrease the tracking error?