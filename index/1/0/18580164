Genetic programming (GP) can learn complex concepts by searching for the target concept through evolution of population of candidate hypothesis programs. However, unlike some learning techniques, such as Artiicial neural networks (ANNs), GP does not have a principled procedure for changing parts of a learned structure based on that structure's performance on the training data. GP is missing a clear, locally optimal update procedure , an equivalent of gradient-descent back-propagation for ANNs. This article introduces a new mechanism, \internal reinforcement ," for deening and using performance feedback on program evolution. A new con-nectionist representation for evolving param-eterized programs, \neural programming" is also introduced. We present the algorithms for the generation of credit and blame assignment in the process of learning programs using neural programming and internal reinforcement. The article includes some of our extensive experiments that demonstrate the increased learning rate obtained by using our principled program evolution approach.