This paper specifies and evaluates the accuracy of the Smart Tissue Anastomosis Robot (STAR). The STAR is a proof of concept vision-guided robotic system equipped with an actuated laparoscopic suturing tool and a multispectral vision system. The STAR supports image-based suturing commands and is capable of detecting near-infrared fluorescent (NIRF) markers that provide reliable visual segmentation and tracking. The paper reports the best case scenario accuracy specifications of the STAR as derived from its configuration and calibration parameters. We also evaluate experimentally the effects of overlaying NIRF markers on the accuracy of the STAR when these markers are used as the source of image-based commands and we compare these results to the accuracy of the STAR with image-based commands generated from plain color images. Our results demonstrate that the STAR is able to place sutures on a planar phantom with an average accuracy of 0.5 mm with a standard deviation of 0.2 mm and that NIRF markers have no statistically significant adverse effect on the accuracy.