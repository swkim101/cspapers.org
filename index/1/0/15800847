We present a new mapping and navigation system based on human-recognizable landmarks with highly compact representations. Road segments, intersections and salient structures such as houses and trees are detected using vision and LiDAR data. The landmarks are entered in a sparse metric-topological map that is used for navigation. In contrast to traditional SLAM approaches, however, we only store the information required to navigate along the path of the robot that built the map. Due to the sparseness of the data, it can easily be transmitted to other robots via a low-bandwidth radio connection (9600 bit/s), allowing the receivers to reconstruct the map, localize themselves in it and follow the path recorded by the sender. All of this is done without the help of global navigation satellite systems such as GPS. The algorithms were tested and evaluated in practical experiments with our autonomous cars MuCAR-3 and MuCAR-4.