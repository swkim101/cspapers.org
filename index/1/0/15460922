As computational agents become more sophisticated, it will frequently be necessary for the agents to disagree with users. In these cases, it might be useful for the agent to use politeness strategies that defuse the person's frustrations and preserve the human-computer relationship. One such strategy is distancing, which we implemented by spatially distancing an agent's voice from its body. In a 2 (agent disagreement: none vs. some) x 2 (agent voice location: on robotic body vs. in control box) between-participants experiment, we studied the effects of agent disagreement and agent voice location in a collaborative human-agent desert survival task (N=40). People changed their answers more often when agents disagreed with them and felt more similar to agents that always agreed with them, even when substantive content was identical. Strikingly, people felt more positively toward the disagreeing agent whose voice came from a separate control box rather than from its body; for agreement, the body-attached voice was preferred.