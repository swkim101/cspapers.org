This paper focuses on learning to select behavioral primitives and generate sub-goals from practicing a task. We present a novel algorithm that combines Q-learning and a locally weighted learning method to improve primitive selection and sub-goal generation. We demonstrate this approach applied to the tilt maze task. Our robot initially learns to perform this task using learning from observation, and then learns from practice.