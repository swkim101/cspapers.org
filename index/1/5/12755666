Research at the intersection of language and other modalities, most notably vision, is becoming increasingly important in nat-ural language processing. We introduce a toolkit that can be used to obtain feature representations for visual and auditory information. MMF EAT is an easy-to-use Python toolkit, which has been developed with the purpose of making non-linguistic modalities more accessible to natural language processing researchers.