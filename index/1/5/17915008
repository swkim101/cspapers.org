Research and development of recommender systems has been a vibrant field for over a decade, having produced proven methods for “preference-aware” computing. Recommenders use community opinion histories to help users identify interesting items from a considerably large search space (e.g., inventory from Amazon [7], movies from Netflix [9]). Personalization, recommendation, and the “human side" of data-centric applications are even becoming important topics in the data management community [3]. A popular recommendation method used heavily in practice is collaborative filtering, consisting of two phases: (1) An offline model-building phase that uses community opinions of items (e.g., movie ratings, “Diggs” [6]) to build a model storing meaningful correlations between users and items. (2) An on-demand recommendation phase that uses the model to produce a set of recommended items when requested from a user or application. To be effective, recommender systems must evolve with their content. In current update-intensive systems (e.g., social networks, online news sites), the restriction that a model be generated offline is a significant drawback, as it hinders the system’s ability to evolve quickly. For instance, new users enter the system changing the collective opinions over items, or the system adds new items quickly (e.g., news posts, Facebook postings), which widens the recommendation pool. These updates affect the recommender model, that in turn affect the system’s recommendation quality in terms of providing accurate answers to recommender queries. In such systems, a completely real-time recommendation process is paramount. Unfortunately, most traditional state-of-the-art recommenders are “hand-built", implemented as custom software not built for a real-time recommendation process [1]. Further, for some