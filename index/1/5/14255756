This paper describes an EEG-based human brain-actuated robotic system, which allows performing navigation and visual exploration tasks between remote places via internet, using only brain activity. In operation, two teleoperation modes can be combined: robot navigation and camera exploration. In both modes, the user faces a real-time video captured by the robot camera merged with augmented reality items. In this representation, the user concentrates on a target area to navigate to or visually explore; then, a visual stimulation process elicits the neurological phenomenon that enables the brain-computer system to decode the intentions of the user. In the navigation mode, the target destination is transferred to the autonomous navigation system, which drives the robot to the desired place while avoiding collisions with the obstacles detected by the laser scanner. In the camera mode, the camera is aligned with the target area to perform an active visual exploration of the remote scenario. In June 2008, within the framework of the experimental methodology, five healthy subjects performed pre-established navigation and visual exploration tasks for one week between two cities separated by 260km. On the basis of the results, a technical evaluation of the device and its main functionalities is reported. The overall result is that all the subjects were able to successfully solve all the tasks reporting no failures, showing a high robustness of the system.