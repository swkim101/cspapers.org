The goal of this research is to develop systems that support human activities through environmental intelligence. These systems may include agents that interact with people in a sensor-rich setting. As a first step, we have developed a distributed vision system with 12 omnidirectional cameras to recognize what is happening at a subway station. Conventional recognition systems require intermediate models of human behavior, such as geometrical models. However, it is hard to calibrate many cameras with enough accuracy to use this framework. Therefore, we propose a memory-based method that does not require any calibration or a priori models. The developed system recognizes "people are walking toward a ticket gate," "people are going down the stairs," and so on. In addition, we have developed a method to select what information is necessary to make these discriminations. This method, which is analogous to an aspect of attention, reduces the computation involved in learning support vector machines to about 0.5% of its original value and increases classification accuracy by 2 to 23%.