1 Background Our previous research focused on the issues of representation for situated embodied agents using behavior{based control architectures. We worked on incorporating representation and learning into such adaptive, behavior{based systems implemented both in simulation and on physical robots. In particular, we developed and demonstrated on a physical robot a distributed representation that allowed for continuous exploration of the environment, learning of its structure, and using it to nd paths to various goal locations (Matari c 1991, Matari c 1992b). Besides providing a novel approach to representing information within a situated, behavior{based system, the model was also shown to have potential biological relevance (Matari c 1990). Our more recent research has been inspired by ethology, and addresses the issues in synthesizing and analyzing group behaviors in a multi{agent system. Speciically, we worked on generating complex, adaptive, and goal{driven group behaviors from simple local interactions between individuals in a society (Matari c 1992a). We developed a methodology for deriving basic behaviors for a given domain and using those to construct higher{level group behaviors (Matari c 1993). We applied the methodology developed in this work to a variety of domains of group interaction including graphical agents, a collection of up to twenty mobile robots, the stock market, and animal and insect colonies. We have recently extended the interaction paradigm described above to include learning to coordinate individualist and social behaviors in a group context. We have developed a strategy for accelerated individual learning by taking advantage of multiple goals and multiple reward functions. We have also worked on principally building in knowledge into the reward functions (Matari c 1994b). Finally, we applied this reinforcement strategy to social learning in a domain where multiple physical agents learn to optimize individual and collective beneet (Matari c 1994a).