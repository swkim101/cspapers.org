Let lf be the transition matrix, and a the initial state distribution. for a discrete-time finite-state irreducible Markov chain. A stopping rule for M is an algorithm which observes the progress of the chain and then stops it at some random time r; the distribution of the final state is denoted by ar. We give a useful characterization for stopping rules which are optimal for given target distribution r, in the sense that ~' = ~ and the expected stopping time Er is minimal. Four classes of optimal stopping rules are described, including a unique " threshold " rule which also minimizes max(r). The minimum value of E17, which we denote by H(a, r), is easily computable from the hitting times of M, For applications in computing, the most important, case is when u is concentrated on a single starting state s and r is the stationary distribution T. We describe a simple, practical stopping rule which achieves target distribution close to T in expected time of order Z&.. = max, Lf(s, m). Finally, we give a stopping rule that runs in time polynomial in the maximum hitting time of Al and achieves the stationary distribution exactly, even though the transition probabilities of the chain are unknown. Some of the work described herein is joint with David Aldous.