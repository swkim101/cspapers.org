A GOMS analysis was used to predict the behavior of an expert in a graphic, machine-paced, highly interactive task. The analysis was implemented in a computational model using the Soar cognitive architecture. Using only the information available in an instruction booklet and some simple heuristics for selecting between operators, the functional-level behavior of the expert proved to be virtually dictated by the objects visible on the display. At the keystroke-level, the analysis predicted about 60% of the behavior, in keeping with similar results in previous GOMS research. We conclude that GOMS is capable of predicting expert behavior in a broader range of tasks than previously demonstrated.