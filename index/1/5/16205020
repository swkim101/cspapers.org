The aim of this work is to demonstrate that it is possible to use a single camera to solve the problem of Simultaneous Localization And Mapping in dynamic environments obtaining, at the same time, the estimation of the moving objects trajectories. Specifically, we show that it is possible to segment the features belonging to independently moving objects from a moving camera using a MonoSLAM algorithm together with a Bearing-Only Tracker. The idea is to exchange between two parallel working systems, i.e. the SLAM filter and the bearingonly tracker, information about the pose of the camera and the motion of the feature to improve the robustness of the SLAM algorithm and maintain a consistent estimation of both the pose, the map, and the features trajectories. Experiments in simulated and real environments substantiate that the proposed technique is able to maintain consistent estimations in a fast and robust way suitable for a real-time application, even in situations where classical MonoSLAM algorithms are deemed to fail.