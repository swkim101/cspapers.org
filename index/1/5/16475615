Knowledge of the human grasp pose is crucial in common control schemes for human-robot object manipulation tasks. Biased estimates of the grasp pose cause undesired interaction wrenches on the human partner, which disturbs the interaction and the recognition of motion intention. A use of wearable motion sensors for tracking the human motion facilitates the grasp pose estimation without a global sensing system. This paper presents an approach for estimating an unknown grasp pose of the human using wearable motion sensors while minimizing undesired interaction wrenches applied to the human. A condition necessary for convergence of the estimator together with appropriate robot motion strategies are provided. Estimation of relative orientation and displacement is performed online and based on minimizing the error in the least-square sense. The estimation process does not rely on a global sensing system and it considers only the measurements of the velocity and acceleration of the cooperating partners in their respective local frames. The approach is experimentally evaluated in a physical human-robot interaction scenario.