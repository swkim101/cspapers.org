This paper presents an active object recognition and pose estimation system for household objects in a highly cluttered environment. A sparse feature model, augmented with the characteristics of features when observed from different viewpoints is used for recognition and pose estimation while a dense point cloud model is used for storing geometry. This strategy makes it possible to accurately predict the expected information available during the Next-Best-View planning process as both the visibility as well as the likelihood of feature matching can be considered simultaneously. Experimental evaluations of the active object recognition and pose estimation with an RGB-D sensor mounted on a Turtlebot are presented.