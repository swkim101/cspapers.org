We present a visual based approach for reactive autonomous navigation of an underwater vehicle. In particular, we are interested in the exploration and continuous monitoring of coral reefs in order to diagnose disease or physical damage. An autonomous underwater vehicle needs to decide in real time the best route while avoiding collisions with fragile marine life and structure. We have opted to use only visual information as input. We have improved the Simple Linear Iterative Cluster algorithm which, together with a simple nearest neighbor classifier, robustly segment and classify objects from water in a fast and efficient way, even in poor visibility conditions. From the resulting classification and the current robot's direction and orientation, the next possible free-collision route can be estimated. This is achieved by grouping together neighboring water superpixels (considered as “regions of interest”). Finally, we use a model-free robust control scheme that allows the robot to autonomously navigate through the free-collision routes obtained in the first step. The experimental results, both in simulations and in practice, show the effectiveness of the proposed navigation system.