In recent years, continuum robots have gained significant momentum in terms of technological maturity and clinical application. Their flexibility allows complex treatment sites to be reached with minimal trauma to the patient. However the reliable control of continuum robots is still an ongoing research issue in the robotics community because their deformable structure makes the modeling of these devices difficult. This motivates the use of external sensors or vision to achieve accurate control. In this paper, a motion control framework based on a vision sensor is proposed in order to perform accurate and controlled movements of a flexible robot that is mounted to an anthropomorphic robotic arm. The vision sensor, which relies on a single camera, provides accurate 3D shape reconstruction and spatial localisation of the flexible robot. This information is used to provide feedback for the real-time control of the flexible robot. The vision sensor detects the robot first in an image stream by modeling its appearance using compressed visual features in an online learning framework. This is combined with the kinematics information from the anthropomorphic robotic arm in order to accurately reconstruct and localise the 3D shape of the flexible robot by minimizing an energy function. Detailed analysis of the framework and a validation are presented in order to demonstrate the practical value of the proposed method.