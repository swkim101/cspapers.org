Recently, there has been increasing interest in using unlabeled data for classi(cid:12)cation. However, whether these unlabeled data are truly useful is still under debate. In order to have a better understanding of relevant issues, it is worthwhile to precisely formulate the problem and carefully analyze the value of unlabeled data under certain learning models. In this paper, we approach this problem from the statistical point of view, where we assume that a correct model of the underlying distribution is given. We demonstrate that Fisher information matrices can be used to judge the asymptotic value of unlabeled data. We apply this methodology to both \passive partially supervised learning" and \active learning", and draw conclusions from this analysis. Experiments will be provided to support our claims.