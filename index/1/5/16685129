We provide a methodology for characterizing the dataflow behavior of dynamic instruction streams through the use of a tool that simplifies the process of analysis by examining instructionlevel traces in reverse order of execution. Many properties of instruction streams are more amenable to processing in this direction, and the combined two-pass (creation and post-processing) analysis renders most measurements straightforward. Using this approach, we characterize the streams of the SPEC2000 integer benchmarks compiled for the Alpha ISA on the OSF operating system. We separate dynamic instructions into essential and non-essential categories. Non-essential instructions contribute neither to program output nor to control flow, and can thus be removed by an optimizer to improve performance, reduce power, etc. For essential instructions, we touch on redundancy through an examination of silent stores (those that write values identical to those already in memory) and their associated dataflow. We separate the remaining essential instructions into those that affect program output and those that affect only control flow. Finally, we employ the approach to examine the amount of live data in memory over the lifetime of a program. Further characterizations and additional details about the reverse trace tool appear in a technical report. Processing consists of two phases, one in which the trace is generated, and one in which the trace is analyzed backwards, i.e., from the last dynamic instruction to the first. To produce the traces, we used an extension of the Alpha instruction-level simulator in the SimpleScalar 3.0 tool set to execute versions of the SPEC2000 integer benchmarks compiled using the Compaq Alpha C compiler, âˆ—This work was funded in part by NSF CAREER grants NSF-CCR00-92740 and NSF-ACI-99-84492, and gracious support from AMD, Intel, and Sun. The content of the information does not necessarily reflect the position or the policy of these organizations.