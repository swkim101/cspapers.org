Novice computer users have many incorrect beliefs about the commands on their system. This paper considers the problem of providing explanatory responses that correct these mistaken user beliefs. Current approaches correct mistaken beliefs by trying to infer the reasons why the user holds them. In contrast, our advisor corrects these beliefs simply by explaining why he doesn't share them. This allows the advisor to provide reasonable advice even when no robust user model is available. Our advisor constructs this explanation from scratch, using a set of domain-independent strategies for justifying plan-oriented beliefs. This differs from existing systems, such as explanationbased story understanders, that provide explanations by modifying existing explanations and fail to address the underlying problem of forming the initial explanation. This approach gives our advisor the ability to explain novel misconceptions.