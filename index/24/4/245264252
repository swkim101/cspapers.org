Automated guided vehicles operation in human populated factory environments is a challenging task, especially when there is a demand to operate without following fixed paths defined by guide wires, magnetic tape, magnets, or transponders embedded in the floor. The paper at hand introduces a vision-based method enabling safe and autonomous operation of pallet moving vehicles that accommodate pallet detection, pose estimation, docking control and pallet pick up in such industrial environments. A dedicated perception topology relying on monocular vision and laser-based measurements has been applied and installed on-board a novel robotic pallet truck. Pallet detection and pose estimation are performed in two steps. Firstly, a deep neural network is used for the fast isolation of pallets' regions of interest and, secondly, model-based geometrical pattern matching on point cloud data is applied to extract the pallet pose. Robot alignment with candidate pallet is performed with a dedicated visual servoing controller. The developed method has been extensively evaluated both in simulated and real industrial environments with the pallet truck and proved to have real-time performance achieving increased accuracy in navigation, pallet detection and pick-up.