Truncated linear regression is a classical challenge in statistics, wherein a label, ğ‘¦ = ğ‘¤ ğ‘‡ ğ‘¥ + ğœ€ , and its corresponding feature vector, ğ‘¥ âˆˆ R ğ‘˜ , are only observed if the label falls in some subset ğ‘† âŠ† R ; otherwise the existence of the pair ( ğ‘¥, ğ‘¦ ) is hidden from observation. Linear regression with truncated observations has remained a challenge, in its general form, since the early works of Tobin (1958); Amemiya (1973). When the distribution of the error is normal with known variance, recent work of Daskalakis et al. (2019) provides computationally and statistically efï¬cient estimators of the linear model, ğ‘¤ . In this paper, we provide the ï¬rst computationally and statistically efï¬cient estimators for truncated linear regression when the noise variance is unknown, estimating both the linear model and the variance of the noise. Our estimator is based on an efï¬cient implementation of Projected Stochastic Gradient Descent on the negative log-likelihood of the truncated sample. Importantly, we show that the error of our estimates is asymptotically normal, and we use this to provide explicit conï¬dence regions for our estimates.