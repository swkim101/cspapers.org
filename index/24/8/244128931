Heterogeneous graph neural network (HGNN) has shown superior performance and attracted considerable research interest. However, HGNN inherits the limitation of representational power from GNN via learning individual node embeddings based on their neighbors, largely ignoring the potential correlations between nodes. In fact, the complex correlation between nodes (e.g., distance) is crucial for many graph mining tasks. How to establish correlations between multiple node embeddings and improve the representational power of HGNN is still an open problem. To solve it, we propose a heterogeneous distance encoding (HDE) technique to fundamentally improve the representational power of HGNN. Specifically, we define heterogeneous shortest path distance to describe the relative distance between nodes, and then jointly encode such distances for multiple nodes of interest to establish their correlation. By simply injecting the encoded correlation into the neighbor aggregating process, we propose a novel distance encoding based heterogeneous graph neural network (called DHN), which is able to learn more expressive heterogeneous graph representations for downstream tasks. More importantly, the proposed DHN relies only on the graph structure and ensures the inductive ability of HGNN. Significant improvements over four real-world graphs demonstrate the representational power of HDE.