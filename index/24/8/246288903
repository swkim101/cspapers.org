Alzheimer’s Disease (AD) is an irreversible neurodegenerative disease that commonly occurs in the elderly. With the current accelerated aging process, the accurate diagnosis of early AD is essential for patient care and disease delay. In recent years, Magnetic Resonance Imaging (MRI) has become increasingly important in diagnosing AD due to advances in deep learning and neuroimaging technology. This paper proposes a model framework for multi-classification prediction of Alzheimer’s disease based on fusing multi-modal features. Firstly, the sMRI data are pre-processed based on ROI templates with different segmentation accuracy levels to extract morphological features including gray matter volume, surface area and cortical thickness, and then these features are combined with the corresponding Clinical Data to produce the Indicators dataset. Secondly, a 3DCNN-SE module is proposed to extract the primary features from the 3D MRI data. In order to reduce the dimensionality of the Indicators, an Indicator Selection Strategy is designed to select the most relevant features from the Indicators. Finally, a Multi-Attention-Fusion Module (MAFM) is developed to perform multi-modal data fusion on the results of feature extraction and selection, followed by a SoftMax classifier for AD disease diagnosis. We evaluated 596 patients from the Alzheimer’s Disease Neuroimaging Initiative(ADNI), including 198 patients with Alzheimer’s disease (AD), 200 patients with mild cognitive impairment (MCI), and 198 patients cognitively normal(CN). As a result, 88% accuracy is achieved on the three classifications, which is better than the related methods mentioned in literature.