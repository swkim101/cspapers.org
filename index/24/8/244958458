This work concerns self-supervised video representation learning (SSVRL), one topic that has received much attention recently. Since videos are storage-intensive and contain a rich source of visual content, models designed for SSVRL are expected to be storage-and computation-efﬁcient, as well as effective. However, most existing methods only focus on one of the two objectives, failing to consider both at the same time. In this work, for the ﬁrst time, the seemingly contradictory goals are simultaneously achieved by exploiting compressed videos and capturing mutual information between two input streams. Speciﬁcally, a novel Motion Vector based Cross Guidance Contrastive learning approach (MVCGC) is proposed. For storage and computation efﬁciency, we choose to directly decode RGB frames and motion vectors (that resemble low-resolution optical ﬂows) from compressed videos on-the-ﬂy. To enhance the representation ability of the motion vectors, hence the effectiveness of our method, we design a cross guidance contrastive learning algorithm based on multi-instance InfoNCE loss, where motion vectors can take supervision signals from RGB frames and vice versa. Comprehensive experiments on two downstream tasks show that our MVCGC yields new state-of-the-art while being signiﬁcantly more efﬁcient than its competitors.