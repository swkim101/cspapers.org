We propose a multi-camera simultaneous localization and mapping (SLAM) system using the Manhattan constraint to support automated valet parking. The proposed method uses multiple cameras to expand the system field of view, to improve the robustness of the SLAM system in textureless regions, where point features from different cameras are jointly optimized by a uniform cost function. To improve global map scale consistency, we utilize wheel odometer in the system initialization and the multi-camera cost function. In addition, we introduce the Manhattan world assumption, an abstraction of a man-made environment, into the proposed algorithm, to improve its estimation processes and make it suitable for the multi-camera SLAM system. The Manhattan world assumption is used to estimate the camera rotation by line features in the image and provide a global orientation constraint that increases the mapping accuracy. The proposed algorithm demonstrates stability in low-texture regions and achieves superior accuracy in experiments conducted in multistory parking lots, compared with other algorithms including monocular and multi-camera versions. Regarding efficiency, the proposed algorithm processes twice the number of measurements with 50% additional computation time while maintaining SLAM stability under a textureless environment.