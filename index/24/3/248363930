Social media platforms such as Facebook and Twitter benefited from massive adoption in the last decade, and in turn facilitated the possibility of spreading harmful content, including false and misleading information. Some of these contents get massive distribution through user actions such as sharing, to a point that content removal or distribution reduction does not always stop its viral spread. At the same time, social media platforms efforts to implement solutions to preserve its integrity are typically not transparent, causing that users are not aware of any integrity intervention happening on the site. In this paper we present the rationale for adding what are now visible friction mechanisms to content share actions in the Facebook News Feed, its design and implementation challenges, and results obtained when applying them in the platform. We discuss effectiveness metrics for such interventions, and show their effects in terms of positive integrity outcomes, as well as in terms of bringing awareness to users about potentially making harmful content viral.