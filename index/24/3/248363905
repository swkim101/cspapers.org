Hoaxes and hidden agendas make for compelling conspiracy theories. While many of these theories are ultimately innocuous, others have the potential to do real harm, instigating real-world support or disapproval of the theories. This is further fueled by social media which provides a platform for conspiracy theories to spread at unprecedented rates. Thus, there is a need for the development of automated models to detect conspiracy theories from the social media space in order to quickly and effectively identify the topics of the season and the prevailing stance. To support this development, we create ground truth data through human annotation. In this work, we collect and manually annotate a dataset from Twitter, comprising of four conspiracy theories. Each Tweet is annotated with one of the four topics {climate change, COVID-19 origin, COVID-19 vaccine, Epstein-Maxwell trial}, and its stance towards the conspiracy theory {support, neutral, against}. We perform experiments on this multi-topic dataset to demonstrate its usage in conspiracy-detection, stance-detection and topic-detection.