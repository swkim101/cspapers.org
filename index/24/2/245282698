Semantic segmentation serves as a cornerstone for safety autonomous driving and has been achieved remarkable progress at the price of dense annotations. Unsupervised domain adaptation was widely utilized to addresses this labor-intensive problem, which transfers the knowledge learned from labeled synthetic datset to real-world without any annotations. However, most existing adaptation works predict the segmentation results and domain identification results separately only with the last-layer feature, and ignore the intrinsic relationship among these two tasks. To address this issue, we present a CO-Interactive Network (COINet) for unsupervised adaptive segmentation. In particular, we propose a scale-aware distilled decoder to integrate multi-scale features dynamically through the designed inter-distilled module (IDM) and obtain fine-grained feature representations. A dual-task classifier is advanced with this decoder, to jointly predict the segmentation results and pixel-wise domain prediction results, which extracts shared complementary information for accurate segmentation. We further devise a co-interactive loss to explicitly model the intrinsic relationship among the segmentation and domain prediction, enabling the feature distribution alignment in pixel-level and an optimal segmentation decision boundary. We demonstrate the effectiveness of the proposed COINet on benchmark adaptation settings with extensive experimental and ablation results, and our model shows favorable performance against existing algorithms.