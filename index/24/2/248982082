We describe a method to separate abuse from legitimate trafﬁc when we have categorical features and no labels are available. Our approach hinges on the observation that, if we could locate them, unattacked bins of a categorical feature x would allow us to estimate the benign distribution of any feature that is independent of x . We give an algorithm that ﬁnds these unattacked bins (if they exist) and show how to build an overall classiﬁer that is suitable for very large data volumes and high levels of abuse. The approach is one-sided: our only signiﬁcant assumptions about abuse are the existence of unattacked bins, and that distributions of abuse trafﬁc do not precisely match those of benign. We evaluate on two datasets: 3 million requests from a web-server dataset and a collection of 5.1 million Twitter accounts crawled using the public API. The results conﬁrm that the approach is successful at identifying clusters of automated behaviors. On both problems we easily outperform unsupervised methods such as Isolation Forests, and have comparable performance to Botometer on the Twitter dataset.