Low-cost sensors are extensively used in numerous Internet of Things (IoT) applications to measure relevant physical processes. Today, processing context data is increasingly done by proprietary algorithms tuned to a specific use-case, e.g., a sensor measuring activity intensity of a cow. Readings from these sensors may be subject to data distribution shifts, which challenge robustness of models using these sensor readings. In this paper, we propose a new sensor data processing framework, which leverages a co-dependency between data quality and model robustness to detect performance issues of data-driven predictive models in the field. We show how distribution shifts in the input data impact the quality of the model, which relies on application-specific sensors, and present indicators capable of detecting such shifts in the wild. The proposed framework used in the context of precision cattle farming allows improving the quality of cow lameness predictive models on the field data by up to 62%.