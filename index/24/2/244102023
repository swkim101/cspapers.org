Deep state-space models (DSSMs) enable temporal predictions by learning the underlying dynamics of observed sequence data. They are often trained by max-imising the evidence lower bound. However, as we show, this does not ensure the model actually learns the underlying dynamics. We therefore propose a constrained optimisation framework as a general approach for training DSSMs. Building upon this, we introduce the extended Kalman VAE (EKVAE), which combines amortised variational inference with classic Bayesian ﬁltering/smoothing to model dynamics more accurately than RNN-based DSSMs. Our results show that the constrained optimisation framework signiﬁcantly improves system identiﬁcation and prediction accuracy on the example of established state-of-the-art DSSMs. The EKVAE out-performs previous models w.r.t. prediction accuracy, achieves remarkable results in identifying dynamical systems, and can furthermore successfully learn state-space representations where static and dynamic features are disentangled.