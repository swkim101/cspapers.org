Most of the state-of-the-art visual-inertial SLAM methods pay less attention to the scene structure of man-made environments. In this paper, based on the assumption of multiple local Manhattan worlds (MWs), we propose a Manhattan frame (MF) re-identification method to build relative rotation constraints between MF matching pairs and tightly couple these constraints into global bundle adjust module. Specifically, a coarse-to-fine vanishing point (VP) estimation method and pose guided MF temporal consistency verification method are firstly proposed to improve the accuracy and robustness of MF estimation. Then unreliable MF matching pairs are filtered out by a spatial temporal consistency check. Finally, the relative rotation constraints of the remaining MF matching pairs are combined into global bundle adjustment energy function for further optimization. We have validated our proposed method on both synthetic and real-world datasets. When comparing with the baseline method [1], the real-time absolute trajectory error (ATE) of our proposed method has decreased by 29.1%, 19.8% on TartanAir hospital and EuRoC datasets respectively. Our method also exceeds existing state-of-the-art algorithms on both synthetic and real-world datasets.