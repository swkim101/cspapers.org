Memristor based crossbars are a promising platform for neural network acceleration. To deploy a trained network model on a memristor crossbar, memristors need to be programmed to realize the trained weights of the network. However, due to process and dynamic variations, deviation of weights from the trained value is inevitable and inference accuracy thus degrades. In this paper, we propose a unified Bayesian inference based framework which connects hardware variations and algorithmic training together for robust computing on memristor crossbars. The framework incorporates different levels of variations into priori weight distribution, and transforms robustness optimization to Bayesian neural network training, where weights of neural networks are optimized to accommodate variations and minimize inference degradation. Simulation results with the proposed framework confirm stable inference accuracy under process and dynamic variations.