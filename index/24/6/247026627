This work explores the exam data for a second-year course, Introduction to Computer Systems. Specifically, we are analyzing and releasing anonymized versions of the autosave logs for the exams. We can see what question a student was working on at any time, and using the autograding capabilities of the server, what their score is when they switch to a different question. In our initial analysis, we observe that the question the student starts solving is sufficient to distinguish between exam performance. The data also shows there is little correlation between the time students take on an exam and their performance. Finally, our data will be released publicly.