As Computer Science Professors, we strive to construct courses that maximally support and contribute to student learning through carefully crafted in-class and out-of-class activities. There is evidence that homework enhances student learning, and that students are more likely to do their homework when it affects their grade. Thus, faculty often find themselves seeking the right balance between the increase in student understanding that additional graded homework might offer and the burden of grading that homework if automated grading software is not available. Peer grading may seem like the obvious solution, since it results in only a limited increase in student workload while still incentivizing homework completion. Unfortunately, students tend to distrust their peers' abilities to evaluate their work, and consequently previous approaches to summative peer assessment risk increasing both student frustration and faculty grading load. This experience report describes SPARK, our unique approach to summative peer assessment that we have successfully used over several semesters for weekly problem sets in a theoretical computer science course as well as on a more limited basis in both undergraduate and graduate robotics courses. Surveys indicate that a majority of students find it easy to use the SPARK approach to grade their peers, believe that the homework assignments helped their learning, acknowledge that they would not have put the same time and effort into their homework had it not been graded, and believe that SPARK's method of computing their final grade for an assignment is fair.