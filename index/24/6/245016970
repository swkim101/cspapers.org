Traditional methods for kernel selection rely on parametric kernel functions or a combination thereof and although the kernel hyperparameters are tuned, these methods often provide sub-optimal results due to the limitations induced by the parametric forms. In this paper, we propose a novel formulation for kernel selection using efﬁcient Bayesian optimisation to ﬁnd the best ﬁtting non-parametric kernel. The kernel is expressed using a linear combination of functions sampled from a prior Gaussian Process (GP) deﬁned by a hyperkernel. We also provide a mechanism to ensure the positive deﬁniteness of the Gram matrix constructed using the resultant kernels. Our experimental results on GP regression and Support Vector Machine (SVM) classiﬁcation tasks involving both synthetic functions and several real-world datasets show the superiority of our approach over the state-of-the-art.