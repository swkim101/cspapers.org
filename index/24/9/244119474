Executing natural language instructions in a physically grounded domain requires a model that understands both spatial concepts such as left_of and above , and the compositional language used to identify landmarks and articu-late instructions relative to them. In this paper, we study instruction understanding in the blocks world domain. Given an initial arrange-ment of blocks and a natural language instruction, the system executes the instruction by manipulating selected blocks. The highly compositional instructions are composed of atomic components and understanding these components is a necessary step to executing the instruction. We show that while end-to-end training (supervised only by the correct block location) fails to address the challenges of this task and performs poorly on instructions involving a single atomic component, knowledge-free auxiliary signals can be used to signiﬁcantly improve performance by providing supervision for the instruction’s components. Speciﬁ-cally, we generate signals that aim at helping the model gradually understand components of the compositional instructions, as well as those that help it better understand spatial concepts, and show their beneﬁt to the overall task for two datasets and two state-of-the-art (SOTA) models, especially when the training data is limited—which is usual in such tasks.