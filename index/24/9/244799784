Advances in generative modeling based on GANs has motivated the community to find their use beyond image generation and editing tasks. In particular, several re-cent works have shown that GAN representations can be re-purposed for discriminative tasks such as part segmen-tation, especially when training data is limited. But how do these improvements stack-up against recent advances in self-supervised learning? Motivated by this we present an alternative approach based on contrastive learning and compare their performance on standard few-shot part seg-mentation benchmarks. Our experiments reveal that not only do the GAN-based approach offer no significant per-formance advantage, their multi-step training is complex, nearly an order-of-magnitude slower, and can introduce ad-ditional bias. These experiments suggest that the inductive biases of generative models, such as their ability to dis-entangle shape and texture, are well captured by standard feed-forward networks trained using contrastive learning.