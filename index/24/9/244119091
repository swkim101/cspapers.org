In this paper, we present a new method for training a writing improvement model adapted to the writer’s ﬁrst language (L1) that goes beyond grammatical error correction (GEC). Without using annotated training data, we rely solely on pre-trained language models ﬁne-tuned with parallel corpora of reference translation aligned with machine translation. We evaluate our model with corpora of academic papers written in English by L1 Portuguese and L1 Spanish scholars and a reference corpus of expert academic English. We show that our model is able to address speciﬁc L1-inﬂuenced writing and more complex linguistic phenomena than existing methods, outper-forming what a state-of-the-art GEC system can achieve in this regard. Our code and data are open to other researchers 1 .