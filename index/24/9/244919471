Distributional shifts between training and target domains may degrade the prediction accuracy of learned models, mainly because these models often learn features that possess only correlation rather than causal relation with the output. Such a correlation, which is known as “spurious correlation” statistically, is domain-dependent hence may fail to generalize to unseen domains. To avoid such a spurious correlation, we propose La tent C ausal I nvariance M odels (LaCIM) that speciﬁes the underlying causal structure of the data and the source of distributional shifts, guiding us to pursue only causal factor for prediction. Speciﬁcally, the LaCIM introduces a pair of correlated latent factors: (a) causal factor and (b) others, while the extent of this correlation is governed by a domain variable that characterizes the distributional shifts. On the basis of this, we prove that the distribution of observed variables conditioning on latent variables is shift-invariant. Equipped with such an invariance, we prove that the causal factor can be recovered without mixing information from others, which induces the ground-truth predicting mechanism. We propose a Variational-Bayesian-based method to learn this invariance for prediction. The utility of our approach is veriﬁed by improved generalization to distributional shifts on various real-world data. Our code is freely available at https://github.com/wubotong/LaCIM .