We study offline recommender learning from explicit rating feedback in the presence of selection bias. A current promising solution for dealing with the bias is the inverse propensity score (IPS) estimation. However, the existing propensity-based methods can suffer significantly from the propensity estimation bias. In fact, most of the previous IPS-based methods require some amount of missing-completely-at-random (MCAR) data to accurately estimate the propensity. This leads to a critical self-contradiction; IPS is ineffective without MCAR data, even though it originally aims to learn recommenders from only missing-not-at-random feedback. To resolve this propensity contradiction, we derive a propensity-independent generalization error bound and propose a novel algorithm to minimize the theoretical bound via adversarial learning. Our theory and algorithm do not require a propensity estimation procedure, thereby leading to a well-performing rating predictor without the true propensity information. Extensive experiments demonstrate that the proposed algorithm is superior to a range of existing methods both in rating prediction and ranking metrics in practical settings without MCAR data. Full version of the paper (including the appendix) is available at: https://arxiv.org/abs/1910.07295.