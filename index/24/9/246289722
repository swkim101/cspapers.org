Graph representation learning aims at preserving structural and attributed information in latent representations. It has been studied mostly in the setting of static graph. In this work, we propose a novel approach for representation learning over dynamic attributed graph using the tool of normalizing flows for exact density estimation. Our approach has three components: (1) a time-aware graph neural component for aggregating graph information at each time step, (2) an adapted graph recurrent component for updating graph temporal contexts, and (3) a conditional normalizing flows component for capturing the evolution of node representations in latent space along time. Particularly, the third component has two sub-models of normalizing flows. One is used to capture the distribution of node representations of arbitrary complexity by considering graph temporal contexts as conditions. It learns invertible transformations to map node representations into simple priors conditioning on temporal contexts. The other one is dedicated to capture the evolutionary patterns of prior distributions. Extensive experiments demonstrate the proposed approach can outperform competitive baselines by a significant margin for dynamic link prediction on future graphs.