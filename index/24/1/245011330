We study the problem of training certiﬁably robust models against adversarial examples. Certiﬁable training minimizes an upper bound on the worst-case loss over the allowed perturbation, and thus the tightness of the upper bound is an important factor in building certiﬁably robust models. However, many studies have shown that Interval Bound Propagation (IBP) training uses much looser bounds but outperforms other models that use tighter bounds. We identify another key factor that inﬂuences the performance of certiﬁable training: smoothness of the loss landscape . We ﬁnd signiﬁcant differences in the loss landscapes across many linear relaxation-based methods, and that the current state-of-the-arts method often has a landscape with favorable optimization properties. Moreover, to test the claim, we design a new certiﬁable training method with the desired properties. With the tightness and the smoothness, the proposed method achieves a decent performance under a wide range of perturbations, while others with only one of the two factors can perform well only for a speciﬁc range of perturbations. Our code is available at https://github.com/sungyoon-lee/LossLandscapeMatters .