First-level (L1) caches have been traditionally implemented with Static Random-Access Memory (SRAM) technology, since it is the fastest memory technology, and L1 caches call for tight timing constraints in the processor pipeline. However, one of the main downsides of SRAM is its low density, which prevents L1 caches to improve their storage capacity beyond a few tens of KB. On the other hand, the recent Domain Wall Memory (DWM) technology overcomes such a constraint by arranging multiple bits in a magnetic racetrack, and sharing a header to access those bits. Accessing a bit requires a shift operation to align the target bit under the header. Such shifts increase the final access latency, which is the main reason why DWM has been mostly used to implement slow last-level caches. This paper proposes a novel DWM-based L1 cache data array design, namely Fast-Track Cache (FTC), that allows L1 caches with bigger storage capacities while reducing the shift overhead thanks to an enhanced exploitation of spatial and temporal localities. Experimental results show that most FTC accesses do not require shifts. As a consequence, and due to its larger capacity, FTC improves the processor performance on average by 15% over a conventional SRAM memory subsystem and the state-of-the-art TapeCache architecture based on DWM. At the same time, energy savings are improved on average by 34% over the conventional design.