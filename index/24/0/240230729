The predominance of biased articles and its consumption by the readers is becoming a considerable issue. Researchers across domains have made efforts to mitigate biases in language. However, due to the subjective nature of the problem, it is not trivial to detect bias embedded in a text. In this paper, we propose a deep linguistically informed multi-task transformer-based model to automatically detect bias in written text. The model is fine-tuned with a domain-specific corpus and further trained for learning the objectives. We evaluate the performance of the proposed model with respect to baseline systems across multiple datasets. We observed that augmenting linguistic features along with contextual embedding improves the performance of the neural network model to automatically detect bias in text.