Convolutional neural networks (CNNs) for biomedical image segmentation are often of very large size, resulting in high memory costs and high latency of operations. To ensure CNNs’ accommodation of key computing resource constraints in specific applications, network compression is commonly used. However, time-consuming training/validation experiments are often involved when searching for a compressed CNN for a specific imaging application, in order to achieve a desired compromise between the network size and network accuracy. Recognizing that biomedical images tend to have relatively uniform target objects, we present kCC-Net, a framework to reduce the cost of compressing CNNs for biomedical image segmentation. kCC-Net first uses training data complexity and target network architecture to estimate the network accuracy degradation caused by compression and compute a layer-wise multiplier for generating a compressed network, referred to as CC-Net. To enhance kCC-Net’s ability to extract rich hierarchical features, we incorporate a multi-scale approach by utilizing multiple submodules of CC-Net to generate a new network which is capable of extracting finer features. Verified using three public biomedical image segmentation datasets, our proposed kCC-Net framework is shown to be effective, retaining up to $\sim 95$% of the full-sized networks’ segmentation accuracy, while utilizing $\sim 51 x$ fewer network trainable weights (average reduction) of the full-sized networks.