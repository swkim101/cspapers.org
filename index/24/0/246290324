Traditional online learning for vertex classification adapts graph Laplacian regularization into ridge regression, which hardly resolve robustness issue against adversarial examples. To tackle the problem, we propose a more general min-max optimization framework for adversarial online kernel learning (OKL). The derived online algorithm can achieve a min-max regret compared with the optimal model found offline. Nonetheless, optimizing in the reproducing kernel Hilbert space suffers from expensive computational costs. While first-order methods accumulate an optimal $\mathcal{O}(\sqrt{T})$ regret, they only require $\mathcal{O}(t)$ time and space per trial. Second-order methods converge to an optimum much faster with $\mathcal{O}(\log T)$, but suffer an expensive $\mathcal{O}(t^{2})$ per-trial cost. This paper adopts selective sampling to make the OKL scaling to large datasets through constructing a small and accurate embedded space for vertex representation, so that OKL could be performed more efficiently on this sketched kernel space. To achieve this goal, we introduce a novel confidence-aware dictionary selection strategy and a model-based update routine, where for an expected sampling probability p, the computational cost can be reduced by a factor of $p^{2}$ to $\mathcal{O}(p^{2}t^{2})$ space and time per trial, while the regret remains comparable. Numerical experiments are conducted on real-world benchmark datasets to illustrate the efficacy of our method.