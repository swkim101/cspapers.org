Graph Neural Networks (GNNs) have achieved significant success in handling graph-structured data, such as knowledge graphs, citation networks, molecular structures, etc. However, most of them are usually shallow structures because of the over-smoothing problem that the representations of nodes are indistinguishable when stacking many layers. Several recent studies have tried to design deep GNNs for powerful expression ability by enlarging the receptive fields to aggregate information from high-order neighbors. But deep models may give rise to overfitting problem. In this paper, we propose a novel insight to aggregate more useful information based on multi-view which does not require deep structures. Specifically, we first design two complementary views to describe global topology and feature similarity of nodes. Then we devise an attention strategy to fuse node representations, named M ulti-V iew G raph C onvolutional N etowrk(MV-GCN). Further, we introduce a self-supervised technique to learn node representations by contrastive learning on different views, which can learn distinctive node embeddings from a large number of unlabeled data, named M ulti-V iew C ontrastive G raph C onvolutional Network(MV-CGC). Finally, we conduct extensive experiments on six public datasets for node classification, which prove the superiority of two proposed models compared with state-of-the-art methods.