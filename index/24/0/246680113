Type inference for dynamic programming languages such as Python is an important yet challenging task. Static type inference techniques can precisely infer variables with enough static constraints but are unable to handle variables with dynamic features. Deep learning (DL) based approaches are feature-agnostic, but they can-not guarantee the correctness of the predicted types. Their per-formance significantly depends on the quality of the training data (i.e., DL models perform poorly on some common types that rarely appear in the training dataset). It is interesting to note that the static and DL-based approaches offer complementary benefits. Un-fortunately, to our knowledge, precise type inference based on both static inference and neural predictions has not been exploited and remains an open challenge. In particular, it is hard to integrate DL models into the framework of rule-based static approaches. This paper fills the gap and proposes a hybrid type inference approach named Hityper based on both static inference and deep learning. Specifically, our key insight is to record type dependen-cies among variables in each function and encode the dependency information in type dependency graphs (TDGs). Based on TDGs, we can easily integrate type inference rules in the nodes to conduct static inference and type rejection rules to inspect the correctness of neural predictions. Hityper iteratively conducts static inference and DL-based prediction until the TDG is fully inferred. Experi-ments on two benchmark datasets show that Hityper outperforms state-of-the-art DL models by exactly matching 10% more human annotations. Hityper also achieves an increase of more than 30% on inferring rare types. Considering only the static part of Hityper, it infers 2× ~3× more types than existing static type inference tools. Moreover, Hityper successfully corrected seven wrong human an-notations in six GitHub projects, and two of them have already been approved by the repository owners.