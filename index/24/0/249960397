The core of the HPDC research and the main scientific contributions push forward the state of the art in how to program and execute parallel and distributed applications and analysis faster, more efficiently, more reliably, and in a more secure way. Researchers in our domain are facing two important challenges when transforming an idea into an innovative algorithm and an innovative algorithm into a successful software: evaluation methodology and software engineering. These challenges arise, in particular, every time a new branch of HPDC research topic emerges. In this talk, I will discuss the relation between methodology, algorithms, and software for HPDC. I will specifically focus on three domains: experimental platforms for HPDC research, fault tolerance at extreme scale, and lossy compression for scientific data. For these three domains, I will review the motivations behind the research, the current situation, and what I see as the potential next directions.