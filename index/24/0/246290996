Graph Neural Networks (GNNs), combining node features and structure information flexibly, have been widely studied and applied in many fields. The growth of graph size and rich features generates a considerable demand for achieving scalability while maintaining good classification performance in the research of GNNs. Graph partition technique, as used in a recent work ClusterGCN, which divides the graph into several sub-graphs, has become an important strategy to achieve the scalability, but the loss of information still affects the results. In this paper, AdClusterGCN is proposed to establish the interaction between graph partition and node classification, in which they can promote each other, and the effectiveness and efficiency of the model can be ensured at the same time. AdClusterGCN combines GNN models trained on a sequence of graph partitions to capture different features, where the current partition is affected using adjusted node/edge weights computed from the results of GNN models on previous partitions. The PageRank and resampling techniques are adopted to keep sufficient attention on important nodes in different models. We implement our method with TensorFlow and experimental studies show that AdClusterGCN achieves state-of-the-art performance on several public benchmarks.