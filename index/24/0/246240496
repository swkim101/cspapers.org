The quality of learning generally improves with the scale and diversity of data. Companies and institutions can therefore benefit from building models over shared data. Many cloud and blockchain platforms, as well as government initiatives, are interested in providing this type of service. These cooperative efforts face a challenge, which we call "exclusivity attacks". A firm can share distorted data, so that it learns the best model fit, but is also able to mislead others. We study protocols for long-term interactions and their vulnerability to these attacks, in particular for regression and clustering tasks. We find that the choice of communication protocol is essential for vulnerability: The protocol is much more vulnerable if firms can continuously initiate communication, instead of periodically asked for their inputs. Vulnerability may also depend on the number of Sybil identities a firm can control.