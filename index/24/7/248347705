Due to the widespread availability of smartphones and digital cameras with GPS functionality, the number of photos associated with geographic coordinates or geoinformation on the internet is continuously increasing. Besides the obvious benefits of geotagged images for the users, geodata can enable a better understanding of the image content and thus facilitate their classification. This work shows the added value of integrating auxiliary geodata during a multi class single label image classification task. Various ways of encoding and extracting auxiliary features from raw coordinates are compared, followed by an investigation of approaches to integrate these features into a convolutional neural network (CNN) by fusion models. We show the classification improvements of adding the raw coordinates and derived auxiliary features such as satellite photos and location-related texts (address information and tags). The results show that the best performance is achieved by a fusion model, which is incorporating textual features based on address information. It is improving the performance the most while reducing the training time: The accuracy of the considered 25 concepts was increased to 85%, compared to 71% in the baseline, while the training time was reduced by 21%. Adding the satellite photos into the neural network shows significant performance improvements as well, but increases the training time. In contrast, numerical features derived directly from raw coordinates do not yield a convincing improvement in classification performance.