Studies on the production of emotions have been conducted to create robotic facial expressions. The reported methodologies for generating emotions for a robot have focused on recognizing a user’s emotions using devices, such as cameras and microphones, and then generating the reactive emotions of a robot according to the user’s emotions. However, these methodologies may have some limitations in delivering emotions in the robot that match the robot’s utterances to users. In this paper, we propose a methodology for producing robotic emotions suitable for a robot’s utterances based on texts so that it can be applied to various fields such as robotic dialogue and reading services. To produce human-like emotions in a robot, our methodology applied patterns of human emotional changes as well as the resilience theory that humans have an ability to recover their emotional states considering their own personality over time. We measured the performance of the model for analyzing texts and observed that there is a linear correlation between the predicted emotions and the annotated ones from humans. Furthermore, when we carried out the experiments based on scenarios, our methodology could produce human-like patterns of emotional changes and the robot could recover its emotional state on its own.