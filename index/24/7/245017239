In this paper, we model the subspace of convolutional ﬁlters with a neural ordinary differential equation (ODE) to enable gradual changes in generated images. Decom-posing convolutional ﬁlters over a set of ﬁlter atoms allows efﬁciently modeling and sampling from a subspace of high-dimensional ﬁlters. By further modeling ﬁlters atoms with a neural ODE, we show both empirically and theoretically that such introduced continuity can be propagated to the generated images, and thus achieves gradually evolved image generation. We support the proposed framework of image generation with continuous ﬁlter atoms using various experiments, including image-to-image translation and image generation conditioned on continuous labels. Without auxiliary network components and heavy supervision, the proposed continuous ﬁlter atoms allow us to easily manipulate the gradual change of generated images by controlling integration intervals of neural ordinary differential equation. This research sheds the light on using the subspace of network parameters to navigate the diverse appearance of image generation.