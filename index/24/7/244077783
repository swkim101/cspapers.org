The last decade has witnessed the emergence of algorithmic fairness as a new frontier in the application of theoretical computer science to problems of societal concern. The delay between academic investigation and industrial rhetoric acknowledging the concern has been surprisingly brief. This alacrity has positive and negative consequences, to wit, opportunity for quick adoption of technology and pressure for quick fixes. An early dichotomy in the literature differentiates between group notions of fairness - based on comparing prediction/classification statistics for (typically disjoint) demographic groups - and individual fairness, i.e., requiring that similar individuals be treated similarly [2]. Both face challenges. Group fairness criteria are appealing but can be meaningless [2, 8] or mutually incompatible [1, 7]; individual fairness requires a task-specific metric specifying the degree to which pairs of individuals are (dis)similar for the purposes of the task at hand. Considerable progress toward learning such a metric from an expert was made only recently [6]; see also [4]. Focus on similarity metrics has thrown into relief foundational questions about randomness and uncertainty. Some questions are specific to the philosophy of fairness, for example, questions about the value of an ex ante guarantee of fairness offered by a roll of the dice. Others involve the choice of metric, exposing the role of context. For example, should the likelihood that a job candidate will succeed in the advertised position be evaluated in the context of the work culture of the specific company that listed the position, or in an ideal, or even just a more egalitarian company with stronger culture of inclusivity?