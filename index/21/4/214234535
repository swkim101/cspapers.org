
 This paper focuses on the idea of energy efficient cooperative collision avoidance between two quadcopters. Two strategies for reciprocal online collision-avoiding actions (i.e., coherent maneuvers without requiring any real-time consensus) are proposed. In the first strategy, UAVs change their speed, while in the second strategy they change their heading to avoid a collision. The avoidance actions are parameterized in terms of the time difference between detecting the collision and starting the maneuver and the amount of speed/heading change. These action parameters are used to generate intermediate way-points, subsequently translated into a minimum snap trajectory, to be executed by a PD controller. For realism, the relative pose of the other UAV, estimated by each UAV (at the point of detection), is considered to be uncertain â€” thereby presenting substantial challenges to undertaking reciprocal actions. Performing supervised learning based on optimization derived labels (as done in prior work) becomes computationally burden-some under these uncertainties. Instead, an (unsupervised) neuroevolution algorithm, called AGENT, is employed to learn a neural network (NN) model that takes the initial (uncertain) pose as state inputs and maps it to a robust optimal action. In neuroevolution, the NN topology and weights are simultaneously optimized using a special evolutionary process, where the fitness of candidate NNs are evaluated over a set of sample (in this case, various collision) scenarios. For further computational tractability, a surrogate model is used to estimate the energy consumption and a classifier is used to identify trajectories where the controller fails. The trained neural network shows encouraging performance for collision avoidance over a large variety of unseen scenarios.