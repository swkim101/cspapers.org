Peer-to-peer (P2P) lending marketplaces on the Web have been growing over the last decade. By providing online platforms, P2P lending enables individuals to borrow and lend money directly from and to one another. Since the applicants on P2P lending platforms may lack sufficient financial history for assessment, quite a few P2P lending service providers have been utilizing the applicants’ social relationships to improve the risk prediction accuracy of loan applications. However, utilizing the information of applicants’ social relationships may introduce discrimination in prediction. In this paper, we analyze and evaluate the impact of the applicants’ social relationships on the fairness of risk prediction for P2P lending. We investigate over a million loan records collected from Prosper.com, one of the leading P2P lending companies in the world. We construct the Prosper social network of loan borrowers and lenders, and generate the social features of applicants by adapting a state-of-the-art social credit scoring scheme to the Prosper social network. We consider two types of fairness notions in the literature, namely individual fairness and counterfactual fairness. Our results demonstrate that the social score harms both individual and counterfactual fairness of classification. To address this issue, we design two new algorithms that mitigate bias by generalizing social features. Our experimental results show that our mitigation algorithms can reduce bias while utilizing social scores effectively.