Sparse representation has been applied successfully in many image analysis applications, including abnormal event detection, in which a baseline is to learn a dictionary from the training data and detect anomalies from its sparse codes. During this procedure, sparse codes which can be achieved through finding the L0-norm solution of the problem: min ‖Y −Dα‖2 +‖α‖0, is crucial. Note that D refers to the dictionary and α refers to the sparse codes. This L0-norm solution, however, is known as a NP-hard problem. Despite of the research achievements in some classification fields, such as face and action recognition, a comparative study of codes in abnormal event detection is less studied and hence no conclusion is gained on the effect of codes in detecting abnormalities. We constrict our comparison in two types of the above L0-norm solutions: greedy algorithms and convex L1-norm solutions. Considering the property of abnormal event detection, i.e., only normal videos are used as training data due to practical reasons, effective codes in classification application may not perform well in abnormality detection. Therefore, we compare the sparse codes and comprehensively evaluate their performance from various aspects to better understand their applicability, including computation time, reconstruction error, sparsity, detection Proceedings of the 31 st International Conference on Machine Learning, Lille, France, 2015. JMLR: W&CP volume 37. Copyright 2015 by the author(s). accuracy on the UCSD Anomaly Dataset. Experiments show that greedy algorithms, especially MP and StOMP algorithm could achieve better abnormality detection with relatively less computations.