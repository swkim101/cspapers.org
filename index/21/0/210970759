In this work we propose an unsupervised training method that finetunes a single image depth estimation CNN towards a new environment. The network, which has been pretrained on stereo data, only requires monocular input for finetuning. Unlike other unsupervised methods, it produces depth estimations with absolute scale â€“ a feature that is essential for most practical applications, yet has mostly been overlooked in the literature. First, we show how our method allows adapting a network trained on one dataset (Cityscapes) to another (KITTI). Next, by splitting KITTI in subsets, we show the sensitivity of pretrained models to a domain shift. We then demonstrate that, by finetuning the model using our method, it is possible to improve the performance on the target subset, without using stereo or any form of groundtruth depth and with preservation of the correct absolute scale.