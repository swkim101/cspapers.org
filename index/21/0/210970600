The need for robots autonomously navigating in more and more complex environments has motivated intense R& D efforts in making robot pose estimation more accurate and reliable. This paper presents a multi-sensor multi-hypothesis method for robust 6-DoF localization in complex environments. Robustness and accuracy requirements are addressed as follows. First, camera and LIDAR features are seamlessly integrated in the same statistical framework, benefiting from their synergies and providing robustness in scenarios with low or varying densities of LIDAR and visual features. Second, a multi-hypothesis approach is adopted to cope with scenario symmetries. The method has been carefully designed to operate in real time using feature and hypothesis filtering and efficient hypothesis refinement, and has been coded in a multi-core implementation. The proposed method has been extensively validated for closed-loop aerial robot navigation in different urban and industrial scenarios and has shown advantages over well-known single-sensor techniques.