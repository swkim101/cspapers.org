This paper brings together machine learning and investigative journalism to examine sockpuppets accounts, a historical breed of fake accounts that are non-automated and human-controlled. Due to their flexible and human-centered nature, sockpuppets pose a complication for purely technological approaches to detecting and studying fake accounts. We find that as machine learning-based detection methods of bots slowly grow stronger, adversaries engaging in disinformation are turning to such sockpuppets accounts, and in particular a subset of sockpuppets that we call “infiltrators” — those that aim to integrate into a community in order spread disinformation. This represents a new stage in the evolution of the sockpuppet concept: where bots seek to simulate audiences and drown online social media platforms with a particular point of view, infiltrators seek to persuade and assimilate genuine audiences from within. In addition to these insights into infiltrator sockpuppets, combining machine learning and investigative journalism enables learning something more than detection and important patterns of activity: it can also gain a sense of the motivations and reasoning of adversaries who engage in disinformation.