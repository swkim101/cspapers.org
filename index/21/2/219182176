We demonstrate that projecting data points into hyperplanes is good strategy for general-purpose kernel design. We used three different hyperplanes generation schemes, random, convex hull and Î±-shape, and evaluated the results on two synthetic and three well known image-based datasets. The results showed considerable improvement in the classification performance in almost all scenarios, corroborating the claim that such an approach can be used as a general-purpose kernel transformation. Also, we discuss some connection with Convolutional Neural Networks and how such an approach could be used to understand such networks better.