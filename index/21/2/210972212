Performance of current 3D point based detectors is limited by the number of points they can process, consequently limiting their accuracy. In this paper we propose a novel architecture coined as Edge-Aware PointNet, that incorporates geometric shape priors as binary maps, integrated in parallel with the PointNet++ framework, through convolutional neural networks (CNNs). The proposed architecture takes individual object instances as input and learns the task of object recognition for 3D shapes. To train the network, we present a dataset of 31k 2.5D synthetic point clouds rendered from ModelNet40. Through 2.5D representation, the network learns object recognition despite occlusion that enables improved performance on objects from real world, while 2D binary maps enable feature learning that is independent of number of points in the point cloud. Comprehensive experimentation shows that the proposed network is able to improve performance by 2.5% on ModelNet40 and 2.6% on ModelNet10 datasets, as compared to the baseline PointNet++. We also show improved performance as compared to state-of-the-art methods, on a real world RGBD dataset where our network improves results by 8%. Our code and dataset is publicly available at github.com/Merium88/Edge-Aware-PointNet.