Although online content continues to grow, the prevalence of dark side content such as hate, misinformation, disinformation, conflicting, fake, and so on continues to grow and has become a problem for online and offline society. Consequently, work into automated analytical and detection methods has gained much attention. The scarcity of the labeled dataset has, however, become one of the major challenges in both machine and deep learning to develop an effective supervised learning model. As a result, most State-of-the-Art (SOTA) approaches focus on English languages for the detection of such content. The identification task of such content has become a problem due to the diversity of languages used on social media platforms. We propose transfer learning since it needs only access to a large unlabeled text available on social media platforms. Since we use data from Amharic Language, which is in the low-resource language family for machine leaarning, transfer learning is found effective. First, we prepare a topic and word embedding models using Facebook data as a task-specific and a general corpus from different web domains respectively. Second, we combine topic embedding and word embedding and then send the features to a fully-connected Recurrent Neural Networks (RNNs). Our preliminary experimental results from the newly proposed attention-based topic model combined with word embedding outperform the baselines.