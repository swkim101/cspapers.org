Many Internet of Things (IoT) applications would ben-eﬁt if streams of data could be analyzed rapidly at the Edge, near the data source. However, existing Stream Processing Engines (SPEs) are unsuited for the Edge because their designs assume Cloud-class resources and relatively generous throughput and latency constraints. This paper presents E DGE W ISE , a new Edge-friendly SPE, and shows analytically and empirically that E DGE W ISE improves both throughput and latency. The key idea of E DGE W ISE is to incorporate a congestion-aware scheduler and a ﬁxed-size worker pool into an SPE. Though this idea has been explored in the past, we are the ﬁrst to apply it to modern SPEs and we provide a new queue-theoretic analysis to support it. In our single-node and distributed experiments we compare E DGE W ISE to the state-of-the-art Storm system. We report up to a 3x improvement in throughput while keeping latency low.