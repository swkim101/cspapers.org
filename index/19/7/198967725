
 Multi-fidelity Gaussian process (GP) modeling is a common approach to employ in resource-expensive computationally demanding algorithms such as optimization, calibration and uncertainty quantification where multiple datasets of varying fidelities are encountered. Briefly, in its simplest form, a multi-fidelity GP is trained on two separate sources of datasets each with its own fidelity level, e.g., a software code/simulator for the low-fidelity source and real-world experiments for the high-fidelity source. Adaptive sampling for multi-fidelity Gaussian processes is a challenging task since we not only seek to estimate the next sampling location of the design variable, but also account for the data fidelities. This issue is often addressed by including the cost of the data sources as an another element in the search criterion in conjunction with an uncertainty reduction metric. In this work, we extent the traditional design of experiment framework for multi-fidelity GPs by partitioning the prediction uncertainty based on the fidelity level and the associated cost of execution. In addition, we utilize the concept of a meta-model believer which quantifies the effect of adding an exploratory design point on the GP uncertainty prediction. We demonstrate the framework using academic examples as well as an industrial application of a steady-state thermodynamic operation point of a fluidized bed process.