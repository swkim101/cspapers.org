In this paper we study a model of information consumption where consumers sequentially interact with a platform that offers a menu of signals (posts) about an underlying state of the world (fact). At each time, incapable of consuming all posts, consumers screen the posts and only select (and consume) one from the offered menu. We show that in the presence of uncertainty about the accuracy of these posts, and as the number of posts increases, adverse effects such as slow learning and polarization arise. Specifically, we establish that, in this setting, bias emerges as a consequence of the consumer's screening process. Namely, consumers, in their quest to choose the post that reduces their uncertainty about the state of the world, choose to consume the post that is closest to their own beliefs. We study the evolution of beliefs and we show that such a screening bias slows down the learning process, and the speed of learning decreases with the menu size. Further, we show that the society becomes polarized during the prolonged learning process even in situations where the society's belief distribution was not a priori polarized.