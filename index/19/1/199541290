In this paper, we propose the reinforcement learning based multi-robot collision avoidance approach by learning collision. Dynamical path re-planning, which is massively used in classical collision avoidance methods, needs overall information of the environment. Also, training agent robots to avoid the collision and pursue a goal point simultaneously is inefficient since the agent should learn two tasks. As the number of tasks that the agent should learn increases, it is difficult to make the performance of an algorithm consistent, which is known as reproducibility issue. To overcome these limitations, Collision Avoidance by Learning Collision (CALC), which learns collision instead of avoiding an obstacle robot is suggested. To solve the collision avoidance problem efficiently, the proposed method divides the problem into training and planning. In the training algorithm, an agent robot learns how to collide with a single obstacle robot and then generates a trained policy. With the trained policy, the agent can pursue a goal point since the policy leads the agent to ‘collide’ with the goal. Furthermore, by taking action in a reverse way from the trained policy, the agent can avoid multiple obstacle robots in the planning algorithm at once. The proposed method is validated both in the robot simulation and real robot experiment, and compared with the existing collision avoidance method.