The interplay between human biases and the underlying data collection and algorithmic methods to present users with relevant information in information retrieval (IR) systems have undesirable side effects, such as filter bubbles, censorship and developing beliefs in false information. Previous work in the areas of interactive information retrieval, document classification, behavioral economics and user profiling provide the foundation for our research. Using existing knowledge about human bias and profile data, we propose leveraging this information to raise awareness to users about their behavior in the frame of IR systems and inferences made. It is our goal to understand to what extent user behavior is changed. Our position is that education and awareness are much better approaches to address the ethical and human rights concerns when compared to regulatory measures and non-transparent changes to IR algorithms. It is believed the approach outlined below has the potential to dampen the effects of filter bubbles, reduce consumption of misleading and potentially hateful content, to broaden perspectives and protect the fundamental human right to freedom of expression.