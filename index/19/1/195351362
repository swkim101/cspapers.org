Complex machine learning models are now an integral part of modern, large scale retrieval systems. However, collection size growth continues to outpace advances in efficiency improvements in the learning models which achieve the highest effectiveness. The current literature on cascade ranking does not address the issue of how state-of-the-art learning-to-rank (LTR) models can be adapted to a cascaded architecture. Secondly, complex neural networks for retrieval tasks are now in their infancy similar to LTR 15 years earlier and are attaining effective results. New research challenges arise with these models that require vast amounts of training data. Most of the current research is focused on constructing new models that improve effectiveness, leaving the questions of explainability and efficiency as open problems. This research proposes to focus on improving the efficiency-effectiveness trade-offs within machine learned models for late stage re-ranking and aims to: i) devise a cascade ranking architecture that can be used with current state-ofthe-art LTR algorithms; ii) study the robustness of current ad-hoc neural ranking models; iii) propose solutions for current efficiency challenges in neural ranking models and investigate how featuredriven machine learning and neural methods may be combined for ranking tasks. Cascade ranking has recently become an important point of emphasis within Information Retrieval. Growing collection sizes continue to curb the advancements of more sophisticated learning methods where effectiveness continues to improve. Wang et al. [4] provide one of the earliest works for cascade ranking designed specifically for IR. The key advantage of such an architecture is flexibility â€“ an allowance for more fine grained control over the trade-off between efficiency and effectiveness. However, existing methods for cascade ranking focus on retrofitting the cascade approach into an existing algorithm and are not generalizable across