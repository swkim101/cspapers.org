In this paper, we propose an approach to learn compact representations from salient landmarks detected by a visual attention algorithm to recognize previously visited places in underwater environments. Instead of using hand-crafted local descriptors as it has been typically done in visual place recognition, we use a convolutional autoencoder to obtain an ad hoc descriptor generator from salient landmarks. The main advantage of using an autoencoder is that it can learn in an unsupervised manner directly from the salient landmarks. In addition, we show that it is possible to do the training with less than 100,000 examples instead of several hundreds of thousands or even millions of labeled examples as in other convolutional architectures. The trained convolutional autoencoder is used to obtain descriptors for salient landmarks that are later utilized in a voting scheme to calculate similarity between images with the objective of finding if a place has already been visited. The proposed method has obtained good results compared to SeqSLAM and FAB-MAP in different datasets obtained from robotic explorations of coral reefs in real life conditions. Moreover, when the visual attention algorithm is used, fewer features are required to get a good performance in terms of precision and recall compared when using the SURF method to extract visual features.