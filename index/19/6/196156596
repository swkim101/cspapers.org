Distributions of input variables of a limit-state function are required for reliability analysis. The distribution parameters are commonly estimated using samples. If some of the samples are in the form of intervals, the estimated distribution parameters may also be given in intervals. Traditional reliability methodologies assume that interval distribution parameters are independent, but as shown in this study, the parameters are actually dependent since they are estimated from the same set of samples. This study investigates the effect of the dependence of distribution parameters on the accuracy of reliability analysis results. The major approach is numerical simulation and optimization. This study indicates that the independent distribution parameter assumption makes the estimated reliability bounds wider than the true bounds due to interval samples. The reason is that the actual combination of the distribution parameters may not include the entire box-type domain assumed by the independent interval parameter assumption. The results of this study not only reveal the cause of the inaccuracy of the independent distribution parameter assumption, but also demonstrate a need of developing new reliability methods to accommodate dependent distribution parameters.