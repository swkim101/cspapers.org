Although expanding the scale of Convolutional Neural Network (CNN) improves image recognition accuracy, it raises computational complexity and power consumption. Increasing the number of hidden layers improves the accuracy of identification, but also increases the amount of calculation. ResNet, which recorded the best accuracy in image recognition in 2015, consists of 152 layers, 230 MB of memory for storing weights, and 11.3 billion multiply-accumulate operations are required. Currently, high-performance computer that processes a large amount of computation at high speed performs Deep Learning and it consumes a lot of power. In order to execute Deep Learning on a device such as a smartphone, it is necessary to execute a large amount of computation with low power consumption and low latency. As impact of the end of CMOS miniaturizing, development of software algorithms and hardware accelerators for program is significant to shorten the execution time. The switching time tends to become larger due to an increase in parasitic capacitance between circuits. Latency becomes a serious problem as the clock rate of the processor increases. Figure 1: Value is represented by time difference between two signals. ImageNetCompetition in 2015.