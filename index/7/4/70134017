In this study, we characterize machine learning regression techniques for their ability to predict storm-related transmission outages based on local weather and transmission outage data. To test the machine learning regression techniques, we use data from the central Oregon Coast — which is particularly vulnerable to storm-related transmission outages — for a case study. We test multiple regression methods (linear and polynomial models with varying degrees) as well as support vector regression methods using linear, polynomial, and Radial-Basis-Function kernels. Results indicate relatively poor prediction capability by these methods, but this is attributed to the lack of outage data (characteristic of low-probability, high-risk events), and a cluster of data points representing momentary (<0 seconds) outages. More long-term outage data could lead to better characterization of the models, enabling others to quantify the frequency of storm-related transmission outages based on local weather data. Only by understanding the frequency of these occurrences can a cost-benefit analysis for potential transmission upgrades or generation sources be completed.