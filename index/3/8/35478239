Research has focused on developing control strategies that allow to work with imprecisely calibrated or even uncalibrated robot systems. A popular approach is to close the control loop with visual feedback (visual servoing), even though this requires continuous, high rate image processing. In contrast, we developed a strategy that can compensate calibration errors by integrating sparse visual feedback asynchronously. This strategy was motivated by neuroscientific studies which show that human grasping definitely requires only sparse asynchronous visual feedback, even with disturbed visual input. We analyze the performance of our control strategy on a robotic hand-eye system consisting of a 6 d.o.f. manipulator and a pan-tilt head with a stereo camera system. To analyze thoroughly which calibration errors can be compensated by sparse feedback, we furthermore built a complete simulation model of the real hand-eye system, including the vision modules. Taken together, experimental and simulation results show that calibration errors can be compensated with a very moderate amount of (asynchronous) visual feedback. Thus, the proposed control strategy can indeed be seen as a serious alternative to visual servoing for real robotics applications. This shows that robotics can profit from taking a closer look at the results of neuroscience.