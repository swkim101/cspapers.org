A Q-Learning based back-off algorithm was proposed in this paper because the traditional DCF approach used for IEEE 802.11p MAC protocol to access the channel has some problems of the low packet delivery rate, high delay and the poor scalability in VANETs. The proposed algorithm which is quite different from the traditional BEB algorithm was adopted by the nodes(agents) to interact with surroundings continuously and learn from each other. The vehicle nodes adjust the size of CW(Contention Window) dynamically according to the results learned from the surroundings so that the nodes can access the channel with the optimal CW eventually minimizing the packet collisions and end-to-end delay. The simulation results show that the communication nodes using the proposed algorithm can adapt to the unknown vehicular environment rapidly, and simultaneously the high packet delivery ratio, low end-to-end delay and high fairness can be achieved for vehicular network with various load.