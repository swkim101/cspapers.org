This paper describes processes of transforming michi-annai-bun, literally street-guide-sentence into a map on a display device: we first show how such transformation is performed, and then we discuss what it means in terms of understanding natural language expressions. INTRODUCTION In Artificial Intelligence and Cognitive Science there have been a number of studies concerned with maps and directions. Notably, KuipersÂ£l3 presented a model of representation of large scale environments and used it in constructing routes with street descriptions. Riesbeck[2] observed that much of spatial reasoning was unnecessary when one reads a written set of directions. He claimed that, without detailed information on all the turns, distances, and locales, the set of directions was clear and sensible if it is satisfied certain conditions. He then wrote a program that judged the clarity and crucial ity of the sentence in the text giving directions. Here we present another program that is concerned with michi-annal-bun, literally street-guide-sentence. QJLT program computes a picture (map) from michi-annai-bun or texts giving directions. The effort is made with a similar ideas in mind that Simmons described when he computed pictures from natural language for the clown's microworld[3].