A method to determine the position and pose of an active camera-head by aligning a 3D model of its surrounding environment with an observed 2D image is proposed. The camera-head is mounted on a mobile robot and freely moves in a 3D space. We aim at visual feedback to correct the estimation error of its position and pose obtained from dead reckoning. Since the nuclear power plant where the robot moves about consists of many pipes without particular marks, most of features in the observed images are occluding edges of the pipes. For robustly finding 3D-2D point correspondences on the occluding edges, two-type predicted images which are calculated from the 3D environmental model by a view simulator are used as follows: 1) 3D model points which correspond to the observed occluding edges are quickly obtained from the predicted depth image; 2) The predicted intensity image is used to select only the 3D model points which are expected to appear clearly in the observed image. As a result, point correspondences between the observed image and the 3D model can be robustly found even in complicated scenes. Preliminary experiments using an actual plant mock-up have shown that the method is promising.