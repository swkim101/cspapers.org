This paper introduces a general-purpose communication package built on top of MPI which is aimed at improving inter-processor communications for parallel computations characterized by large numbers of messages. The current library provides a utility for such applications based on two key attributes that are: (i) explicit consideration of the neighborhood communication pattern to avoid many-to-many calls and to reduce the number of collective calls and (ii) use of non-blocking MPI functions along with message packing to reduce actual communications in number and time. The introduction of the neighborhood communications leads to substantial reductions in the data exchange cost.