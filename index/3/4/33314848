The world of supercomputing is rightfully caught up in the notion of exascale computing, and the number of cores being touted keeps growing. As a result, there there is less and less attention being paid to what the individual core can or can not provide. The argument goes: The core is but a brick; we are constructing buildings. I submit that the two vectors are orthogonal, and we throw away a lot of potential if we don’t also address what the individual core can provide. I do not argue for one ox to pull the plow rather than a thousand chickens. I ask for yokes of oxen. To address the inherent capabilities of the individual core, I find the transformation hierarchy enlightening. I identified the concept 30 years ago, reflecting that although (a) problems are described in natural language, it is really (b) the electrons that solve these problems as they move from one voltage potential to another. To get from (a) to (b) requires working through several layers, requiring several transformations. That was 1981, long before the era of multi-core. In those days, the layers provided safe abstractions – people worked within their own layer, not paying much attention to the other layers. In my view, part of the solution to the exascale computing requirement requires expanding the awareness at each layer to what goes on beneath that layer. In this talk, I hope to suggest several steps for improving performance if every layer of the transformation hierarchy is allowed to help. They include: multiple interfaces to the “bare metal”, the importance of ILP (which is not dead, incidentally), directives from the compiler, and run-time systems that are intrinsically coupled to the microarchitecture. Although I address these issues from the standpoint of the single core, there is nothing to preclude them from being considered at a higher level of abstraction where they can be applied with thousands of cores at our disposal. If time permits, I may have a few words to add about that.