Unsup ervisedLearningUsingMMLJonathan J. OliverComputer Science Dept.Monash University, Clayton,Victoria, 3168, Australiajono@cs.monash.edu.auRohan A. Baxterrohan@cs.monash.edu.auChris S. Wallacecsw@cs.monash.edu.auAbstractThis pap er discusses the unsup ervised learn-ing problem. An imp ortant part of the unsu-p ervised learning problem is determining thenumb er of constituent groups (comp onents orclasses) which b est describ essome data.Weapply the Minimum Message Length (MML)criteriontotheunsup ervisedlearning prob-lem,mo difying anearliersuchMMLappli-cation.We give an empirical comparison ofcriteriaprominentintheliteratureforesti-mating the numb er of comp onents in a dataset.WeconcludethattheMinimum Mes-sageLengthcriterionp erformsb etterthanthe alternatives on thedata consideredherefor unsup ervised learning tasks.1INTRODUCTIONWe discuss the unsup ervised learning problem.Therearemanyapproachestounsup ervisedlearning.Within AI there have b een systems such as (a) CLUS-TER{MichalskiandStepp[16],(b)COBWEBFisher[13], (c) AQ17 { Wnek and Michalski29, (d)AUTOCLASS { Cheeseman et al.[7]and (e) Snob {Wallaceetal.[25;26]whichusesMML.Spath23,Page 7]de nes unsup ervised learning (or cluster anal-ysis) in the following way:\The ob jective of cluster analysis is to sepa-ratea setof ob jectsinto constituentgroups(classes,clumps, clusters)so thatthemem-b ers of one group di er from one another aslittle as p ossible, according to a chosen crite-rion".An imp ortant part of the unsup ervised learning prob-lem is determining thenumb er of constituentgroups(which we shall call comp onents for the remainder ofthis pap er) which b est describ es some data.SnobandAUTOCLASSareinthecategoryofmix-ture model lers[12; 24; 15].They assume that the dataunder consideration was generated from a distributionwhich is the sum of simpler distributions.That is, oursample,x1;2: : : ;nisassumedtoarisefromadistribution taking the formf(x)=kXj=1pj;wherefj(x) is a distribution (with a simple form), andpjis the relative weight off(x).We b egin with the univariate case and concentrate onmo dels wherethecomp onent distributions are Gaus-sian,i.e.,fj(x)N;2j).Whenwegeneraliseto the multidimensional case, we replace the variance,2j,byacovariancematrix.Themathematics fordiagonal covariance matrix is discussed in Section 5.Toformsuchamo del,weestimatek,thenumb erof comp onents, and the following parameters for eachcomp onent from 1 tok:j| the mean of comp onentj,j| the standard deviation of comp onentj, andpj| the relative weight of comp onentj.Avarietyofapproacheshasb eenusedtoestimatetheseparameters.Wolfe[30]and Day11give max-imum likeliho o d estimates forj;andpgivenk.Thestandardmaximum likeliho o d approachhasdif- cultyifwealloeachcomp onenttohavdistinct