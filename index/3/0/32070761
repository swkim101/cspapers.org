Traditional Beowulf clusters have been homogeneous platforms for distributed-memory MIMD parallelism. However, the shift to multicore architectures has made shared-memory MIMD parallelism increasingly important, and inexpensive manycore GPGPUs have revived SIMD parallelism. This paper presents a case study in designing and building a heterogeneous cluster as a learning platform for tera-scale distributed- and shared-memory MIMD parallelism, and GPGPU parallelism.