In data cleaning, data quality rules provide a valuable tool for enforcing the correct application of semantics on a dataset. Traditional rule discovery techniques assume a reasonably clean dataset, and fail when faced with a dirty one. Enforcement of these rules for error detection is much less effective when mined on dirty data. In the databases literature, a popular and expressive type of logic-based data quality rule (or Integrity Constraint) is the constant Conditional Functional Dependency (cCFD) [Fan et al., 2011], which can be easily understood by a data analyst. We introduce a probabilistic model that combines error detection and rule induction (cCFDs), we show that this methodology performs better than just traditional logic-based error detection. Moreover, after inference is performed, we provide a set of rules which is statistically sound and with low redundancy. To the best of our knowledge this is the first work to combine statistical anomaly detection with logic-based approaches to data cleaning.