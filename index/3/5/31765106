This paper describes an approach which integrates several conflicting and corroborating shape-from-texture methods in a single system. The system uses a new data structure, the augmented texel, which combines multiple constraints on orientation in a compact notation for a single surface patch. The augmented texels initially store weighted orientation constraints that are generated by the system's several independent shape-from-texture components. These texture components, which run autonomously and may run in parallel, derive constraints by any of the currently existing shape-from-texture approaches e.g. shape-from-uniform-texel-spacing. For each surface patch the augmented texel then combines the potentially inconsistent orientation data, using a Hough transform-like method on a tesselated gaussian spheres, resulting in an estimate of the most likely orientation for the patch. The system then defines which patches are part of the same surface, simplifing surface reconstruction. 
 
This knowledge fusion approach is illustrated by a system that integrates information from two different shape-from-texture methods, shape-from-uniform-texel-spacing and shape-from-uniform-texel-size. The system is demonstrated on camera images of artificial and natural textures.