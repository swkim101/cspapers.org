In order to determine both location and orientation of a mobile robot, we use omni-directional view images from a camera mounted on top of the robot. Images are sampled circularly on rings at various radii. Correlation values between rings of different images are regarded as the similarity of the image, therefore the similarity of locations. Using real images taken at different times in navigation experiments, we computed correlation values normalized by brightness, and confirmed the robot can be localized in 50 cm to 100 cm range with 3-10 degree orientation accuracy. The idea of using aggregated sum of circular samples for representing landmarks at multiple levels is also presented.