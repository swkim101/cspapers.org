Game-theoretic equilibria are usually steady-state properties; that is, given that all the players' actions correspond to an equilibrium point, it would be irrational for any of them to deviate from this behavior, given that the others stick to their strategy. A major weakness of this type of concept is that it falls to predict how players arrive at this equilibrium in the first place, or how they "choose" one such equilibrium, if several such points exist. A theory of equilibrium selection has been proposed by Hars~inyi and Selten [HS88]; however, it usually assumes some form of prior coordination between players, in the form of a tracing procedure. This is a strong prerequisite, often unrealistic. A different attempt is provided by the theory of learning in games [FL99], that aims to explain the emergence of such equilibria as the result of an evolutive "learning" process. Such models assume one (or several) populations of agents, that interact by playing a certain game, and updating their behavior based on the outcome of this interaction. In order for evolutionary results of this sort to offer convincing insights on equilibrium selection in real-life applications, they have to display "robustness" with respect to the various idealizations inherent in any mathematical model. Several types of bias have been previously considered [FYg0, HG93, NS00] in the game-theoretic literature. In this work we address a different source of potential bias: uniform matching; that is, choosing the players to interact uniformly at random from those available. Instead we advocate a re-examination off the results of the theory of learning in games under adversarial models. Not surprisingly, our framework is strongly related to the theory of self-stabilization of distributed systems IDol001. Our proofs highlight some principles for proving convergence (the existence of a winning strategy for scheduler-luck games [Dol00], monotonicity and composition o/winning strategies), that can conceivably be applied in general settings.