This paper presents a methodology for mapping and localization of Unmanned Aerial Vehicles (UAVs) based on the integration of sensors from different modalities. Particularly, we integrate distance estimations to Ultra-Wideband (UWB) sensors and 3D point-clouds from RGB-D sensors. First, a novel approach for environment mapping is introduced, exploiting the synergies between UWB sensors and point-clouds to produce a multi-modal 3D map that integrates the estimated UWB sensors position. This map is further integrated into a Monte Carlo Localization method to robustly estimate the UAV pose. Finally, the full approach is tested with real indoor flights and validated with a motion tracking system.