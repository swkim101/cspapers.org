In this work, we propose a novel model that focuses on object features by combining object detection with CNN and LSTM networks. In recent years, a multitude of deep learning-based methods for Visual Localization, have been extensively researched. However, conventional methods do not adequately account for object-level features. Therefore, it is difficult to use indoors where similar objects appear frequently. Our method applies CNN for feature extraction on detected objects cropped by YOLOv8, an object detection algorithm, and then integrates these features into a single feature vector using LSTM, enabling location estimation that takes into account multiple object features. Experiments using the new indoor dataset of our laboratory room have revealed that our proposed method achieves a 19.0% higher accuracy compared to CNN models that input the whole image with the same number of layers. These results demonstrate the promising potential of exploring methods focused on object features for indoor localization. The codes are available at https://github.com/sakusaku3939/YoloLSTM.