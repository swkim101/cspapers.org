. Object reconstruction from 3D point clouds has achieved impressive progress in the computer vision and computer graphics research field. However, reconstruction from time-varying point clouds (a.k.a. 4D point clouds) is generally overlooked. In this paper, we propose a new network architecture, namely RFNet-4D, that jointly reconstruct objects and their motion flows from 4D point clouds. The key insight is that simultaneously performing both tasks via learning spatial and temporal features from a sequence of point clouds can leverage individual tasks, leading to improved overall performance. To prove this ability, we design a temporal vector field learning module using unsupervised learning approach for flow estimation, leveraged by supervised learning of spatial structures for object reconstruction. Extensive experiments and analyses on benchmark dataset validated the effectiveness and efficiency of our method. As shown in experimental results, our method achieves state-of-the-art performance on both flow estimation and object reconstruction while performing much faster than existing methods in both training and inference. Our code and data are available at https://github.com/ hkust-vgd/RFNet-4D . jointly reconstruction of objects and estimation of temporal flows from dynamic point clouds. The proposed network is built upon a compositional encoder effectively capturing informative spatio-temporal representations for 4D point clouds, and a joint learning paradigm leveraging sub-tasks to improve overall performance. We extensively evaluated our proposed RFNet-4D and compared it with existing works on benchmark dataset. Experimental results demonstrated the effectiveness and efficiency of our method in comparison with current state-of-the-art.