The proliferation of Conversational AI agents 001 (CAAs) has emphasised the need to distinguish 002 between human and machine-generated texts, 003 with implications spanning digital forensics 004 and cybersecurity. While prior research pri-005 marily focussed on distinguishing human from 006 machine-generated text, our study takes a more 007 refined approach by analysing different CAAs. 008 We construct linguistic profiles for five CAAs, 009 aiming to identify Uniquely Identifiable Lin-010 guistic Patterns (UILPs) for each model us-011 ing authorship attribution techniques. Author-012 ship attribution (AA) is the task of identify-013 ing the author of an unknown text from a pool 014 of known authors (Juola, 2008). Our research 015 seeks to answer crucial questions about the ex-016 istence of UILPs in CAAs, the linguistic over-017 lap between various text types generated by 018 these models, and the feasibility of Authorship 019 Attribution (AA) for CAAs based on UILPs. 020 Promisingly, we are able to attribute CAAs 021 based on their original texts with a weighted 022 F1-score of 96.94%. Further, we are able to 023 attribute CAAs according to their writing style 024 (as specified by prompts), yielding a weighted 025 F1-score of 95.84%, which sets the baseline for 026 this task. By employing principal component 027 analysis (PCA), we identify the top 100 most 028 informative linguistic features for each CAA, 029 achieving a weighted F1-score ranging from 030 86.04% to 97.93%, and an overall weighted 031 F1-score of 93.86%. 032