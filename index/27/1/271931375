A quote tweet allows users to share oth-001 ers’ content and add their comments. To 002 help users write a quote tweet with bet-003 ter public engagement, we study the pop-004 ular quote tweet generation task. It aims 005 to generate quote tweets with higher popu-006 larity reflected by more likes, replies, and 007 retweets. Despite the exceptional language 008 generation capabilities of large language mod-009 els (LLMs), limited work has examined how 010 LLMs can learn the popularity of text to en-011 gage the public better. Consequently, we pro-012 pose a novel Re sponse-augmented P opularity-013 A ligned L anguage M odel (RePALM) to align 014 language generation to popularity by leverag-015 ing readers’ insights from augmented auto-016 responses. Here, we employ the Proximal 017 Policy Optimization framework with a dual-018 reward mechanism to jointly explore the quote 019 tweet’s popularity and consistency with the 020 auto-responses. For experiments, we gathered 021 two datasets of quote tweets with external links 022 and others’ tweets. Extensive results show 023 the superiority of RePALM over advanced lan-024 guage models without response augmentation. 1 025