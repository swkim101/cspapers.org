Spoken Named Entity Recognition (NER) aims 001 to extract entities from speech. The extracted 002 entities can help voice assistants better under-003 stand userâ€™s questions and instructions. How-004 ever, current Chinese Spoken NER datasets 005 are laboratory-controlled data that collected 006 by reading existing texts in quiet environ-007 ments, rather than natural spoken data, and 008 the texts used for reading are also limited in 009 topics. These limitations obstruct the devel-010 opment of Spoken NER in more natural and 011 common real-world scenarios. To address 012 this gap, we introduce a real-world Chinese 013 Spoken NER dataset (RWCS-NER), encom-014 passing open-domain daily conversations and 015 task-oriented intelligent cockpit instructions. 016 We compare several mainstream pipeline ap-017 proaches on RWCS-NER. The results indicate 018 that the current methods, affected by Automatic 019 Speech Recognition (ASR) errors, do not per-020 form satisfactorily in real settings. Aiming 021 to enhance Spoken NER in real-world scenar-022 ios, we propose two approaches: self-training-023 asr and mapping then distilling (MDistilling). 024 Experiments show that both approaches can 025 achieve significant improvements, particularly 026 MDistilling. Even compared with GPT4.0, 027 MDistilling still reaches better results. We be-028 lieve that our work will advance the field of 029 Spoken NER in real-world settings. 030