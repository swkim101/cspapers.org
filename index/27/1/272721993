Layout planning, spanning from architecture to inte- rior design, is a slow, iterative exploration of ill-defined problems, adopting a “I'll know it when I see it” approach to potential solutions. Recent advances in gener- ative models promise automating layout generation, yet of- ten overlook the crucial role of user-guided iteration, can- not generate full solutions from incomplete design ideas, and do not learn for the inter-dependency of layout at- tributes. To address these limitations, we propose Mask- PLAN, a novel generative model based on Graph-structured Dynamic Masked Autoencoders (GDMAE) featuring five transformers generating a blend of graph-based and image- based layout attributes. MaskPLAN lets users generate and adjust layouts with partial attribute definitions, create al- ternatives for preferences, and practice new composition- driven or functionality-driven workflows. Through cross- attribute learning and the user input as a global conditional prior we ensure that design synthesis is calibrated at every intermediate stage, maintaining its feasibility and practi- cality. Extensive evaluations show MaskPLAN's superior performance over existing methods across multiple metrics.