
 Predicting material responses like strain and energy under various loading conditions is crucial for understanding structure-property relationships and guiding material design. However, this task can be computationally expensive and complex, especially for diverse materials with vast design spaces. Traditional methods like physics-based simulations can be time-consuming and costly, while experimental exploration across large spaces is impractical. Convolutional neural networks (CNNs) and fully connected neural networks (FNNs) offer promising alternative, enabling efficient and accurate material response predictions based on simulations or experimental data. This is particularly beneficial for materials with intricate microstructures that are difficult to characterize with conventional methods. However, CNNs and FNNs often face challenges due to limited training data, leading to poor generalization and low robustness. Additionally, material prediction tasks often encounter unbalanced data where acquiring different responses comes at varying costs. This unbalance can bias model predictions and hinder generalization to unseen material structures. To address these limitations, we propose employing multi-task learning (MTL) to enhance the understanding of material behavior in those deep learning models, specifically targeting the problem of unbalanced data. MTL leverages shared information between multiple interconnected learning tasks, allowing the model to learn from complementary information. In the context of material prediction, MTL can be employed to jointly train CNNs on predicting multiple responses, like displacement and strain energy. This shared learning approach enhances the modelâ€™s ability to identify underlying patterns and relationships, leading to more accurate and robust predictions.