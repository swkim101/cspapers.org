Upper limb dysfunction has become a significant challenge in healthcare, affecting individuals suffering from neurological conditions such as strokes and spinal cord injuries. To address this issue, wearable exoskeletons have emerged as promising solutions. Effective human-robot interaction (HRI) is crucial for seamlessly integrating these technologies into rehabilitation and assistive care settings. Electromyography (EMG) signals offer valuable insights into human muscular control and have been utilized to control robotic systems, enhancing user acceptance and interaction. This paper proposes a novel technique for continuously predicting joint movements from raw single-channel EMG signals using a Deep Neural Network (DNN) architecture. First, single-channel EMG signals from the biceps are acquired simultaneously with the elbow angular position, and the acquired data are then converted into a dataset for supervised learning. Second, a neural architecture based on Gated Recurrent Units (GRU) is proposed and implemented for the training phase. Finally, the proposed model is tested on real data, and the results are thoroughly evaluated using three evaluation metrics. We achieved RMSE=3.84~12.72°, MAE=2.92~10.24°, and R-squared=0.96~0.99. Comparison of our results with existing literature demonstrates the superiority and robustness of the proposed method, especially in handling different muscular efforts