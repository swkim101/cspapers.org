Time series anomaly detection is a critical task with applications in various domains. Due to annotation challenges, self-supervised methods have become the mainstream approach

for time series anomaly detection in recent years. However,

current contrastive methods categorize data perturbations into

binary classes, normal or anomaly, which lack clarity on the specific impact of different perturbation methods. Inspired by the hypothesis that "the higher the probability of misclassifying perturbation types, the higher the probability of anomalies", we propose PCRTA, our

approach firstly devises a perturbation classifier to learn the

pseudo-labels of data perturbations. Furthermore, for addressing "class collapse issue" in contrastive learning, we propose a perturbation guiding positive and negative samples

selection strategy by introducing learnable perturbation classification networks. Extensive experiments on six realworld datasets demonstrate the significant superiority of our

model over thirteen state-of-the-art competitors, and obtains average

5.14%, 8.24% improvement in F1 score and AUC-PR, respectively.