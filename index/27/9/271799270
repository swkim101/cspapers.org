In this work, a tube-based nearly optimal solution to motion planning in unknown workspaces is presented. The advantages of reactive motion planning are combined with a Policy Iteration Reinforcement Learning scheme to yield a novel solution for unknown workspaces that inherits provable safety, convergence and optimality. Moreover, in simply-connected workspaces, our method is proven to asymptotically provide the globally optimal path. Our method is compared against a provably asymptotically optimal RRTâ‹† method, as well as a relevant reactive method and provides satisfactory performance, closely matching or outperforming the former.