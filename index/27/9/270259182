We present a secure decentralized learning framework suitable for resource-constrained devices within a cluster environment. Our approach focuses on enhancing privacy preservation during model aggregation by utilizing Differential Privacy. This technique adds random noise to gradients obtained from local training on edge devices before sending them for aggregation. This noise addition ensures that sensitive information within the gradients remains distorted, thus safeguarding user privacy. We showcase the implementation of our system on a cluster system employing Raspberry Pi 4 Model B devices, illustrating its feasibility and effectiveness in real-world scenarios. Through this demonstration, we highlight the practical applicability of our system in enabling secure decentralized learning within resource-constrained environments.