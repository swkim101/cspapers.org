Locating and replacing lost items can be a time-consuming and demanding task, requiring a significant amount of resources. While tag-based object tracking systems like Apple's AirTags are suggested, attaching tags on objects can compromise their usability and become costly as the number of objects increases. To mitigate this challenge, we propose AcousTrack, a novel object-tracking system that eliminates the need for additional tags. AcousTrack instead leverages smartwatches to capture acoustic signals emitted when objects come into contact with surfaces. These acoustic signals contain unique physical characteristics of both objects and surfaces, facilitating the identification of object types and their respective locations. In our preliminary evaluation, we analyze the sounds emitted by three different objects positioned across three varying locations, achieving an accuracy of 92.2% in object classification and 98.3% in location classification.