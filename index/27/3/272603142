Despite recent improvements, the processing of long sequences with Transformers models remains a subject in its own right, including automatic summary. In this work, we present experiments on the automatic summarization of scientific articles using BART models, considering textual information coming from distinct passages from long texts for summarization. We demonstrate that considering document structure improves the performance of state-of-the-art models and approaches the performance of LongFormer in English.