Despite the signiﬁcant success of large vision-language models (LVLMs), some studies have revealed that LVLMs suffer from the hal-lucination problem, where the LVLMs’ response contains descriptions of non-existent objects. Although various benchmarks have been proposed to investigate this problem, they mostly focus on single-turn evaluation and overlook the hallucination raised by textual inputs. To investigate the hallucination problem of LVLMs when given long-term misleading textual history, we propose a novel visual dialogue hallucination evaluation benchmark VisDiaHalBench. The benchmark consists of samples with ﬁve-turn questions about an edited image and its original version. Vis-DiaHalBench differs from previous hallucination benchmarks in the following three points: