Pairwise Ranking Prompting (PRP) demon-001 strates impressive effectiveness in zero-shot 002 document re-ranking tasks with large language 003 models (LLMs). However, in the existing meth-004 ods, PRP only outputs the same label for the 005 comparison results of different confidence in-006 tervals without considering the uncertainty of 007 pairwise comparison, which implies an under-008 utilization of the generation probability infor-009 mation of LLMs. To bridge this gap, we pro-010 pose PRP-Graph, a novel pairwise re-ranking 011 approach, based on a refined scoring PRP unit 012 that exploits the output probabilities of target 013 labels to capture the degree of certainty of 014 the comparison results. Specifically, the PRP-015 Graph consists of two stages, namely ranking 016 graph construction and ranking graph aggre-017 gation. Extensive experiments conducted on 018 the BEIR benchmark demonstrate the superi-019 ority of our approach over existing PRP-based 020 methods. Comprehensive analysis reveals that 021 the PRP-Graph displays strong robustness to-022 wards the initial ranking order and delivers ex-023 ceptional re-ranking results with acceptable ef-024 ficiency. Our code and data will be available. 025