Data drift, which denotes a misalignment be-tween the distribution of reference (i.e., training) and production data, constitutes a significant challenge for AI applications, as it under-mines the generalisation capacity of machine learning (ML) models. Therefore, it is imperative to proactively identify data drift before users meet with performance degradation. Moreover, to ensure the successful execution of AI services, endeavours should be directed not only toward detecting the occurrence of drift but also toward effectively addressing this challenge. In this work, we introduce a tool designed to detect data drift in text data. In addition, we propose an unsupervised sampling technique for extracting representative examples from drifted instances. This approach be-stows a practical advantage by significantly reducing expenses associated with annotating the labels for drifted instances, an essential pre-requisite for retraining the model to sustain its performance on production data.