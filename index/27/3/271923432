To better analyze informal arguments on public forums, we propose the task of argument ex-plication , which makes explicit an argument’s structure and implicit reasoning by outputting triples of propositions 〈 claim , reason , warrant 〉 . The three slots, or argument components, are derived from the widely known Toulmin (1958) model of argumentation. While prior research applies Toulmin or related theories to anno-tate datasets and train supervised models, we develop an effective method to prompt generative large language models (LMs) to output explicitly named argument components proposed by Toulmin. In particular, we prompt a language model with the theory name (e.g., ‘According to Toulmin model’ ). We evaluate the outputs’ validity through a human study and automatic evaluation based on prior argumentation datasets, and perform robustness checks over alternative LMs, prompts, and argumentation theories. Finally, we conduct a proof-of-concept case study to extract an interpretable argumentation (hyper)graph from a large corpus of critical public comments on whether to allow the COVID-19 vaccine for children, suggesting future directions for corpus analysis and argument visualization. 1