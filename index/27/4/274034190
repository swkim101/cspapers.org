
 This paper investigates leveraging transfer learning to improve the performance of reinforcement learning based generative agents for multi-objective design optimization. First, a transformer-based generative agent is developed and its training procedure is outlined. Then, the generative agent is pre-trained on a metamaterial design problem in two different multitask settings. One setting is defined by different parameterizations of the metamaterial design problem. The objective of this setting is to determine the agent’s ability to transfer to problems with new parameterizations and new physics models. The second setting is defined by the same parameterizations, but each problem in the training set has unique constraints. The objective of this setting is to determine the agent’s ability to transfer to unseen constraints. For each multitask setting, the pre-trained agent is fine-tuned on different validation metamaterial design problems to assess its ability to transfer to new problem parameterizations, new stiffness models, and new stiffness ratio constraints. Finally, the agent’s performance on the validation problems is baselined against a genetic algorithm (GA) designed to handle constrained problems. Results show that pre-training greatly improves the performance of the generative agent on the validation problems. Furthermore, the pre-trained agent is able to achieve the same or better hypervolume of the GA while only requiring a fraction (10–20%) the number of function evaluations.