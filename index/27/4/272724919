LiDAR localization is a fundamental task in robotics and computer vision, which estimates the pose of a Li- DAR point cloud within a global map. Scene Coordinate Regression (SCR) has demonstrated state-of-the-art performance in this task. In SCR, a scene is represented as a neural network, which outputs the world coordinates for each point in the input point cloud. However, SCR treats all points equally during localization, ignoring the fact that not all objects are beneficial for localization. For exam-ple, dynamic objects and repeating structures often negatively impact SCR. To address this problem, we introduce LiSA, the first method that incorporates semantic aware-ness into SCR to boost the localization robustness and accuracy. To avoid extra computation or network parame-ters during inference, we distill the knowledge from a seg-mentation model to the original SCR network. Experi-ments show the superior performance of LiSA on standard LiDAR localization benchmarks compared to state-of-the- art methods. Applying knowledge distillation not only pre-serves high efficiency but also achieves higher localization accuracy than introducing extra semantic segmentation modules. We also analyze the benefit of semantic in-formation for LiDAR localization. Our code is released at https://github.com/Ybchun/LiSA.