Parkinson's disease (PD) is a devastating movement disorder accelerating in global prevalence, but a lack of precision symptom measurement has made the development of effective therapies challenging. The Unified Parkinson's Disease Rating Scale (UPDRS) is the gold standard for assessing motor symptom severity, yet its manual scoring criteria are vague and subjective, resulting in coarse and noisy clinical assessments. Machine learning approaches have the potential to modernize PD symptom assessments by making them more quantitative, objective, and scalable. How-ever, the lack of benchmark video datasets for PD motor exams hinders model development. Here, we introduce the TULIP dataset to bridge this gap. TULIP emphasizes pre-cision and comprehensiveness, comprising multi-view video recordings (6 cameras) of 25 UPDRS motor exam activities, together with ratings by 3 clinical experts, in a cohort of Parkinson's patients and healthy controls. The multi-view recordings enable 3D reconstructions of body movement that better capture disease signatures than more conventional 2D methods. Using the dataset, we establish a base-line model for predicting UPDRS scores from 3D poses, illustrating how existing diagnostics could be automated. Looking ahead, TULIP could aid the development of new precision diagnostics that transcend UPDRS scores, providing a deeper understanding of PD and its potential treatments.