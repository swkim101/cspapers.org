A machine learning task can be viewed as a sequential pipeline of different algorithmic choices, including

data preprocessing, model selection, and

hyper-parameter tuning. Automated machine learning selects this sequence in an

automated manner. While such approaches are natural in supervised settings,

 they remain challenging for unsupervised tasks such as outlier detection because of the lack of availability of label-centric feedback. In this paper, we present an instance-level metalearning approach for outlier detection. This approach learns how outlier instances are related to normal points in many labeled data sets to create a supervised meta-model. This

meta-model is then used on a new (unlabeled) data set to predict outliers. We show the robustness of our approach on several benchmarks from the OpenML repository.