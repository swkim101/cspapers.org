The evolution of machine learning (ML) as an enabling technology has opened a new era of possibilities and applications. Among these advancements, distributed learning, specifically federated learning (FL), emerges as a significant shift in collaborative intelligence. FL's unique ability to leverage decentralized data sources promises innovation and privacy protection for local datasets across diverse domains, including healthcare, finance, object recognition, and beyond. However, despite its potential benefits, FL has shown to be vulnerable to various threats. From poisoning attacks to adversarial perturbations and information inference, malicious actors pose significant challenges to the integrity of FL systems. Effectively addressing these vulnerabilities requires the implementation of security-by-design principles within FL frameworks. In this talk, we steer through the complex landscape of FL attacks and defenses, shedding light on the ongoing arms race between adversaries and defenders. We examine their advantages and drawbacks, gaining valuable insights into the evolving nature of these threats. We conclude by outlining research challenges and directions to enhance the resilience and security of FL systems.