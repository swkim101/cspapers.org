Machine learning-based binary function similarity detection (ML-BFSD) has witnessed significant progress recently. They often choose control flow graph (CFG) as an important feature to learn out of functions, as CFGs characterize the control dependencies between basic code blocks. However, the exact role of CFGs in model decisions is not explored, and the extent to which CFGs might lead to model errors is unknown. This work takes a first step towards assessing the role of CFGs in ML-BFSD solutions both theoretically and practically, and promotes their performance accordingly. First, we adapt existing explanation methods to interpreting ML-BFSD solutions, and theoretically reveal that existing models heavily rely on CFG features . Then, we design a solution δ CFG to manipulate CFGs and practically demonstrate the lack of robustness of existing models. We have extensively evaluated δ CFG on 11 state-of-the-art (SOTA) ML-BFSD solutions, and find that the models’ results would flip if we manipulate the query functions’ CFGs but keep semantics, showing that most models have bias on CFG features . Our theoretic and practical assessment solutions can also serve as a robustness validator for the development of future ML-BFSD solutions. Lastly, we present a solution to utilize δ CFG to augment training data, which helps deprioritize CFG features