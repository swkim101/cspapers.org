Machine learning-based intelligent systems have experienced a massive growth over the past few years, and are close to becoming ubiquitous in the technology surrounding our daily lives. However, a critical challenge in machine learning-based systems is their vulnerability to security attacks from malicious adversaries. The vulnerability of these systems is further aggravated as it is non-trivial to establish the authenticity of data used to train the system, and even innocuous perturbations to the training data can be used to manipulate the systems behavior in unintended ways. Recent reports about malicious manipulation of social media feeds masquerading as authentic news items provide compelling evidence towards developing stronger and more resilient measures for combating adversarial attacks on machine learning-based systems. The ALECâ€™18 symposium was organized to address the overarching need towards making automated, machine learning-based systems more robust and resilient against adversarial attacks, so that humans can use them in a safe and sustained manner. The areas of interest of the symposium included the following topics: