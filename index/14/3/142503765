—Machine learning empowers trafﬁc-analysis attacks that breach users’ privacy from their encrypted trafﬁc. Recent advances in deep learning drastically escalate such threats. One prominent example demonstrated recently is a trafﬁc-analysis attack against video streaming by using convolutional neural networks. In this paper, we explore the adaption of techniques previously used in the domains of adversarial machine learning and differential privacy to mitigate the machine-learning-powered analysis of streaming trafﬁc. Our ﬁndings are twofold. First, constructing adversarial samples effectively confounds an adversary with a predetermined classiﬁer but is less effective when the adversary can adapt to the defense by using alternative classiﬁers or training the classiﬁer with adversarial samples. Second, differential-privacy guarantees are very effective against such statistical-inference-based trafﬁc analysis, while remaining agnostic to the machine learning clas-siﬁers used by the adversary. We propose two mechanisms for enforcing differential privacy for encrypted streaming trafﬁc, and evaluate their security and utility. Our empirical implementation and evaluation suggest that the proposed statistical privacy approaches are promising solutions in the underlying scenarios.