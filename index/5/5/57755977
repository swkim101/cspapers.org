In many robotics tasks successful execution requires high precision pose estimates of the objects in the workcell. When the object pose is provided by a computer vision system it is therefore crucial that the vision system is configured such that the required precision is achieved. An important part of the configuration is the sensor placement, however, most work in the field of sensor placement does not take the random, semi-constrained nature of the initial object pose into account. This paper presents a framework which uses an analysis of object stable poses together with dynamic simulation to predict the probability distribution of initial object poses. The framework is highly modular and uses precomputed pose uncertainties and a mixture model to make the integration over all possible stable poses feasible. This makes the framework applicable to a wide range of sensors and uncertainty models. The framework is evaluated in simulation for a concrete example: A single PrimeSense Carmine to be placed at an optimal elevation angle in a table picking scenario where pose uncertainties are modeled using Gaussians.