This paper proposes a distributed deep reinforcement learning (RL) based strategy for a team of Unmanned Aerial Vehicles (UAVs) to autonomously fight forest fires. We first model the forest fire as a Markov decision process (MDP) with a factored structure. We consider optimally controlling the forest fire without agents using dynamic programming, and show any exact solution and many approximate solutions are computationally intractable. Given the problem complexity, we consider a deep RL approach in which each agent learns a policy requiring only local information. We show with Monte Carlo simulations that the deep RL policy outperforms a hand-tuned heuristic, and scales well for various forest sizes and different numbers of UAVs as well as variations in model parameters. Experimental demonstrations with mobile robots fighting a simulated forest fire in the Robotarium at the Georgia Institute of Technology are also presented.