There is continually growing interest to accelerate DNNs using FPGAs, e.g., Microsoft Catapult [3], thanks to FPGAs inherently power-efficient architecture and their capability for streaming-fashion data marshalling and computation on the massively parallel FPGA structure. However, in comparison to ASIC-based accelerators, e.g. Google TPU [2] and IBM TrueNorth [1], their energy efficiency is still a key concern. In order to bridge this gap, we propose UnderVolt FNN, a novel FPGA-based accelerator that leverages aggressive undervolting for improving the energy efficiency of DNNs in the inference phase, without compromising the inference accuracy and performance. Toward this goal, we first extensively characterize the behavior of undervolting faults on real FPGAs, and accordingly, propose a fault mitigation technique to prevent the DNNs accuracy loss. In consequence, UnderVolt FNN achieves 25.2% of the total power savings gain without compromising the DNNs accuracy and performance. We believe that the proposed technique has potential to improve the energy-efficiency of enterprise systems such as Microsoft Catapult.