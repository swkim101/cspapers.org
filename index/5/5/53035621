Brain-Computer Interface (BCI) enables human to communicate with and intuitively control an external device through brain signals. Movement intention recognition paves the path for developing BCI applications. The current state-of-the-art in EEG based BCI usually involves subject-specific adaptation before ready to use. However, the subject-independent scenario, in which a well-trained model is directly applied to new subjects without any pre-calibration, is particularly desired yet rarely explored. In order to fill the gap, we present a Convolutional Attention Model (CAM) for EEG-based human movement intention recognition in the subject-independent scenario. The convolutional network is designed to capture the spatio-temporal features of EEG signals, while the integrated attention mechanism is utilized to focus on the most discriminative information of EEG signals during the period of movement imagination while omitting other less relative parts. Experiments conducted on a real-world EEG dataset containing 55 subjects show that our model is capable of mining the underlying invariant EEG patterns across different subjects and generalizing to unseen subjects. Our model achieves better performance than a series of state-of-the-art and baseline approaches.