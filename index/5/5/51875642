p We present theory connecting three major generative modeling frameworks: divergence-, IPMand kernel-based approaches. p A novel, conceptually simple procedure is introduced, termed Ï‡2GAN, that is stable at training and generates diverse samples. p Our formulation naturally generalizes to problems requiring simultaneous matching of multiple distributions. p To fully exploit the learned critic function, we repurpose it as a weighting mechanism in a resampling procedure.