This paper explores a neural network-based approach to computing similarity of two texts written in different languages. Such similarity can be useful for a variety of applications including cross-lingual information retrieval and cross-lingual text classification. To compute similarity, we focus on neural machine translation models and examine the utility of their intermediate states. Through experiments on an English-Japanese translation corpus, it is demonstrated that the intermediate states of input texts are indeed beneficial for computing cross-lingual text similarity, outperforming other approaches including a strong machine translation-based baseline.