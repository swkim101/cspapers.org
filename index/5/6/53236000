Large scale data centers are enabling the new era of Internet cloud computing. The computing platform in such data centers consists of low-cost commodity servers that, in large numbers and with software support, match the performance and reliability of expensive enterprise-class servers of yesterday, at a fraction of the cost. The network interconnect within the data center, however, has not seen the same scale of commoditization or dropping price points. Today's data centers use expensive enterprise-class networking equipment and associated best-practices that were not designed for the requirements of Internet-scale data center services -- they severely limit server-to-server network capacity, create fragmented pools of servers that do not allow any service to run on any server, and have poor reliability and utilization. The commoditization and redesign of data center networks to meet cloud computing requirements is the next frontier of innovation in the data center.
 Recent research in data center networks addresses many of these aspects involving both scale and commoditization. By creating large flat Layer 2 networks, data centers can provide the view of a flat unfragmented pool of servers to hosted services. By using traffic engineering methods (based on both oblivious and adaptive routing techniques) on specialized network topologies, the data center network can handle arbitrary and rapidly changing communication patterns between servers. By making data centers modular for incremental growth, the up-front investment in infrastructure can be reduced, thus increasing their economic feasibility. This is an exciting time to work in the data center networking area, as the industry is on the cusp of big changes, driven by the need to run Internet-scale services, enabled by the availability of low-cost commodity switches/routers, and fostered by creative and novel architectural innovations.
 What the Tutorial will cover: We will begin with an introduction to data centers for Internet/cloud services. We will survey several next-generation data center network designs that meet the criteria of allowing any service to run on any server in a flat unfragmented pool of servers and providing bandwidth guarantees for arbitrary communication patterns among servers (limited only by server line card rates). These span efforts from academia and industry research labs, including VL2, Portland, SEATTLE, Hedera, and BCube, and ongoing standardization activities like IEEE Data Center Ethernet (DCE) and IEEE TRILL. We will also cover other emerging aspects of data center networking like energy proportionality for greener data center networks.