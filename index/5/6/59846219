The Broadcast News Navigator (BNN) is a fully implemented system that incorporates image, speech, and language processing together with visualization and user preference modeling to support intelligent, personalized access to broadcast news video. The demonstration will illustrate the use of the system's underlying machine learning enabled story segmentation and processing, called the Broadcast News Editor (BNE). A live, scenario-based demonstration will illustrate the use of named entity search, temporal visualization of entities, story clustering and geospatial story visualization, discovery of entity relations, and personalized multimedia summary generation. By transforming access from sequential to direct search and providing hierarchical hyperlinked summaries, we will demonstrate how users can access topics and entity specific news clusters nearly three times as fast as direct search of digital video. In short, we will demonstrate intelligent news on demand enabled by a suite of AI technologies.