An open question in artificial intelligence is how to learn useful representations of the real world. One approach is to learn symbols, which represent the world and its contents, as well as models describing the effects on these symbols when interacting with the world. To date, however, research has investigated learning such representations for a single specific task. Our research focuses on approaches to learning these models in a domain-independent manner. We intend to use these symbolic models to build even higher levels of abstraction, creating a hierarchical representation which could be used to solve complex tasks. This would allow an agent to gather knowledge over the course of its lifetime, which could then be leveraged when faced with a new task, obviating the need to relearn a model every time a new unseen problem is encountered.