I. MOTIVATION Deploying convolutional neural networks (CNNs) effectively in real-time applications often requires both high throughput and low power consumption. However, a state-of-the-art CNN typically performs about 10 FLOPs per evaluation [1]. Reducing this computational cost has become an essential challenge. Several prior studies have proposed pruning ineffectual features and weights statically, thus reducing the FLOPs [2]. Dedicated hardware accelerators have also been shown to improve performance by exploiting the sparsity in a CNN [3], [4], [5]. However, the aforementioned proposals suffer from increasing the irregularity of the computation at the finest granularity. We propose a novel approach to reduce CNN computation, called channel gating, which dynamically prunes the unnecessary computation specific to a particular image, while minimizing the accuracy loss and hardware modification. Intuitively, channel gating leverages the spatial information inside the input features to identify ineffective receptive fields and skip the corresponding computation by gating a fraction of the input channels. The paper makes the following major contributions: • We introduce the channel gating scheme, which dynamically prunes computation on input channels at receptive field level. • We propose an efficient single-pass training scheme to train the channel gating CNN from scratch, allowing the network to automatically learn an effective gating policy. • We demonstrate the benefits of introducing channel gating in CNNs empirically and get 66% and 60% reduction in FLOPs with 0.22% and 0.29% accuracy loss on the CIFAR-10/100 datasets respectively using a state-of-theart ResNet model. • We propose a specialized accelerator architecture, which improves the performance and energy efficiency of the channel gating CNN inference (Ongoing).