Replication is essential for fault-tolerance, but it is also a source of high overhead. Some recent in-memory systems use remote direct memory accesses (RDMA) to create redundant copies of data in remote memory. RDMA is attractive, since it is low-latency, high-throughput, and has no CPU overhead at the target. However, even with RDMA, no existing replication protocol avoids redundant data copying and target-side work. Backup servers may receive updates via RDMA, but they must actively incorporate the updates into replicas to update backup data structures and to ensure that only fully received messages are applied. In this paper, we present Tailwind, a zero-copy recovery log replication protocol for scale-out in-memory databases. Tailwind is the first replication protocol that eliminates all CPU-driven data copying and fully bypasses target server CPUs for data replication. In Tailwind , all data movement is done via device DMA; one-sided RDMA writes place data directly in remote I/O buffers in its final form for stable storage. Tailwind substantially improves replication throughput and response latency compared with conventional RPC-based replica-tion. In symmetric systems where servers both serve requests and act as replicas, Tailwind also improves normal-case throughput by freeing server CPU resources for request processing. We implemented and evaluated Tailwind on RAMCloud, a low-latency in-memory storage system. Experiments show Tailwind improves RAMCloud's normal-case request processing through-put by 1.7⇥. It also decreases writes median and 99 th percentile latencies by 2⇥ and 3⇥ respectively.