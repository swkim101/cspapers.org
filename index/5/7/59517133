Meta-learning has proven to be a successful strategy in attacking problems in supervised learning and reinforcement learning that involve small amounts of data. State-of-the-art solutions involve learning an initialization and/or learning algorithm using a set of training episodes so that the meta-learner can generalize to an evaluation episode quickly. These methods perform well but often lack good quantiﬁcation of uncertainty, which can be vital to real-world applications when data is lacking. We propose a meta-learning method which efﬁciently amortizes hierarchical variational inference across tasks, learning a prior distribution over neural network weights so that a few steps of Bayes by Backprop will produce a good task-speciﬁc approximate posterior. We show that our method produces good uncertainty estimates on contextual bandit and few-shot learning benchmarks