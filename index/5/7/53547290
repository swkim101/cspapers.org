Social robots are designed to interact and communicate with humans. We have conducted a pilot study to explore how an artificial empathy module can affect Human-Robot Interactions. For that pilot study, we chose to evaluate the effects of a module we developed called "attention-based empathic module" and we set up an experiment within two conditions, "Empathy" (i.e., with this module), and "No-Empathy" (i.e., without this module). In order to define what aspects of HRI are affected, we used several metrics found in HRI literature including self-reported questionnaires-e.g., perceived empathy test-physiological measures-e.g., number of attentional disengagements-and objective measures-e.g., time of interaction, and performance. Dividing 36 participants into two groups and controlling the main biases inherent in subjects selection, we found that the "attention-based empathic module" seems to have affected 9 metrics: the interaction duration, how trustworthy the robot was perceived, the number of disengagements , how empathic the robot was perceived, how much participants felt they knew the robot, how the robot's intelligence was perceived, how comfortable the interaction was perceived, how much the robot was perceived as knowledgeable, and how engaging the interaction was perceived. Due to the exploratory approach of this study, these results have to be confirmed.