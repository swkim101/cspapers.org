Learning complex physical tasks via trial-and-error is still challenging for highdegree-of-freedom robots. The greatest challenge is optimally selecting the next trials to evaluate while improving sample efficiency. We propose a novel learning framework consisting of the task modelling and exploration components. The task model maps the parameter space defining a trial, to the task outcome space. The exploration model enables efficient search in the trial parameter space to generate the subsequent most informative trials, by simultaneously exploiting all the information gained from previous trials and reducing the task modelâ€™s overall uncertainty. We validate our framework on a challenging bimanual-robot puckpassing task. Results show that the robot successfully acquires the necessary skills after only 100 trials without any prior information about the task or target positions. Our approach also enables efficient skill transfer to new environments which was validated experimentally.