Topic models have been used extensively as a tool for corpus exploration, and a cottage industry has developed to tweak topic models to better encode human intuitions or to better model data. However, creating such extensions requires expertise in machine learning unavail-able to potential end-users of topic modeling software. In this work, we develop a frame-work for allowing users to iteratively reÔ¨Åne the topics discovered by models such as latent Dirichlet allocation (LDA) by adding constraints that enforce that sets of words must ap-pear together in the same topic. We incorporate these constraints interactively by selectively removing elements in the state of a Markov Chain used for inference; we investigate a va-riety of methods for incorporating this information and demonstrate that these interactively added constraints improve topic usefulness for simulated and actual user sessions.