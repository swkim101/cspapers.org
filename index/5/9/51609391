In practice, the circumstance that training and test data are clean is

not always satisfied. The performance of existing methods in the learning using

privileged information (LUPI) paradigm may be seriously challenged, due to the

lack of clear strategies to address potential noises in the data. This paper

proposes a novel Robust SVM+ (RSVM+) algorithm based on a rigorous theoretical analysis.

Under the SVM+ framework in the LUPI paradigm, we study the lower bound of

perturbations of both example feature data and privileged feature data, which

will mislead the model to make wrong decisions. By maximizing the lower bound, tolerance

of the learned model over perturbations will be increased. Accordingly, a novel

regularization function is introduced to upgrade a variant form of SVM+. The

objective function of RSVM+ is transformed into a quadratic programming

problem, which can be efficiently optimized using off-the-shelf solvers.

Experiments on real-world datasets demonstrate the necessity of studying robust

SVM+ and the effectiveness of the proposed algorithm.