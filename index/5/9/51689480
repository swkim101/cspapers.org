Can we classify species of very similar looking organisms quickly and accurately using only out of the box feature transfer? What if we only have small number of images? This experimental paper is part of on-going project on species recognition research and evaluates transfer learning and fine-tuning approaches on two highly specialized fine-grained datasets. The two fine-grained datasets were specifically assembled for the purpose of this research. These datasets consist of images of New Zealand native species of moths and ”cryptic” plants of Genus Corposma found also in New Zealand. We compare results from finetuning experiments with performance of transfer learning without fine-tuning. The latter results are based on features extracted from various levels of depth in the InceptionV3 network, including fully connected layers. The extracted features serve as inputs to a number of classification algorithms. We observe contrasting results for the two datasets. For the dataset of moths, the method based on features extracted from deep levels of the InceptionV3 network outperforms fine-tuning in accuracy (90.09% versus 87.18%). This is not the case for the dataset of cryptic plants (60.46% versus 74.37%). Despite both datasets being fine-grained in nature, these experimental differences could be attributed to intrinsically different morphology of organisms and warrant further investigation.