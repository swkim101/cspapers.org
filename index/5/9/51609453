This paper introduces a new approach for machine teaching that

partly addresses the (unavoidable) mismatch between what the

teacher assumes about the learning process of the student and the

actual process. We analyze several situations in which such mismatch

takes place, including when the student?s learning algorithm

is known but the corresponding parameters are not, and when the

learning algorithm itself is not known. Our analysis is focused on

the case of a Bayesian Gaussian learner, and we show that, even

in this simple case, the lack of knowledge regarding the student?s

learning process significantly deteriorates the performance of machine

teaching: while perfect knowledge of the student ensures that

the target is learned after a finite number of samples, lack of knowledge

thereof implies that the student will only learn asymptotically

(i.e., after an infinite number of samples). We introduce interactivity

as a means to mitigate the impact of imperfect knowledge

and show that, by using interactivity, we are able to recover finite

learning time, in the best case, or significantly faster convergence,

in the worst case. Finally, we discuss the extension of our analysis

to a classification problem using linear discriminant analysis, and

discuss the implications of our results in single- and multi-student

settings.