The modern data center drives the digital revolution. Only by utilizing buildings packed with computers are we able to process the gigantic amount of digital information produced every day. Internet companies like Google and Facebook have successfully demonstrated how web-scale infrastructures are built without the need for specialized high-end hardware. By utilizing cheap, readily available off-the-shelve components, hardware costs are kept at a minimum, in turn reducing total cost of ownership (TCO). Today, however, energy is responsible for an increasing fraction of the TCO. Energy efficiency is a driving factor for innovation in data center (DC) design. In a typical data center, servers consume 59% of the total energy [4], representing the single largest potential for savings. Approaches to save energy in servers can be categorized in two ways [3, 2]: (a) making individual components energy-proportional, and (b) utilizing (deep-)sleep states with near-zero energy consumption. Because deep-sleep states have the largest potential for energy savings, we want to power down servers whenever possible. Powering down machines, however, discourages the use of inexpensive, direct attached storage (DAS). Data stored on local disks becomes unavailable as soon as the machine goes offline. [5] observed that cluster size “is determined primarily based on data set size instead of incoming request throughput”,i.e., it is important to keep all data accessible at all times. Centrally consolidating storage using a dedicated storage interconnect is an expensive solution to this problem. Popular choices include Fiber Channel, SAS, or iSCSI technologies. We propose to deploy additional COTS hardware to keep all disks accessible, even if servers are switched off.