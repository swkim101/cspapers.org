Existing multi-label learning (MLL) approaches mainly assume all the labels are observed and construct classification models with a fixed set of target labels (known labels). However, in some real applications, multiple latent labels may exist outside this set and hide in the data, especially for large-scale data sets.

Discovering and exploring the latent labels hidden in the data may not only 

find interesting knowledge but also help us to build a more robust learning model.

In this paper, a novel approach named DLCL (i.e., Discovering Latent Class Labels for MLL) is proposed which can not only discover the latent labels in the training data but also predict new instances with the latent and known labels simultaneously.

Extensive experiments show a competitive performance of DLCL against other 

state-of-the-art MLL approaches.