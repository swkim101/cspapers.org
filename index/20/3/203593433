Generative Adversarial Networks training is not easy due to the minimax nature of the optimization objective. In this paper, we propose a novel end-to-end algorithm for training generative models which uses a non-minimax objective simplifying model training. The proposed algorithm uses the approximation of Wasserstein-2 distance by Input Convex Neural Networks. From the theoretical side, we estimate the properties of the generative mapping fitted by the algorithm. From the practical side, we conduct computational experiments which confirm the efficiency of our algorithm in various applied problems: image-to-image color transfer, latent space optimal transport, image-to-image style transfer, and domain adaptation.