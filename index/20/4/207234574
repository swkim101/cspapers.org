Algorithmic processes that convert data into narrative news texts allow news rooms to publish stories with limited to no human intervention (Carlson, 2015, p. 416). The new trend creates many opportunities, but also raises significant legal questions. Aside from financial benefits, further refinement could make the smart algorithms capable of writing less standard, maybe even opinion, pieces. The responsible human merely needs to define clear questions about what the algorithm needs to discuss in the article and in what manner. But how does it square with the traditional rules of publishing, editorial control and the privacy and data protection framework? This paper analyses the legal implications when employing robot journalists. More specifically, the question of authorship for algorithmic output and the liability issues that could arise when the algorithmic output includes unlawful personal data processing as well as inaccurate, harmful or even illegal content will be assessed. The analysis is performed analyzing European legislation on copyright and data protection and applying Belgian legislation on press liability as a consistent country example to support certain legal considerations and conclusions. Furthermore, the paper answers the question as to how publishers could prevent the creation of inaccurate content by the algorithms they use.