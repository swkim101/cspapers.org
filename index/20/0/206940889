This paper describes the implementation of a system for integrating ground-level images with data from a Geographical Information System (GIS). The images are captured using a video camera on a moving platform. Amalgamation of data takes the form of both transforming GIS data into the image space, and transforming the image data into the 3-D world space for comparison with existing GIS data. In current implementations, e.g. inverse perspective transformation, a flat scene is initially assumed and image-based knowledge is used to compensate for errors. The method used here improves on this assumption by using a readily-available source of elevation data (the GIS) for the image scene. It is shown that typical functions available in a GIS are very suitable for this ground-based scene analysis; this rich source of data significantly reduces the image processing required in order to carry out a task. Calibration of a camera and combination of the images with GIS and other sensor data is demonstrated. The effectiveness of the use of the GIS to ease planning and locate orientation features for an autonomous robot task is shown. The results of application of the technique to outdoor scenes are given and discussed.