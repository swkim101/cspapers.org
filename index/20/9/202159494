Syn(es)thetic Reality explores a new way of sensing the world by understanding sounds through colors. It looks to simulate projective chromesthesia, an experience of seeing colors involuntarily as a result of sound input. The project achieves this through an augmented reality web application to be run on mobile phones via a wearable device. By displaying audio based color content composited over the camera feed, the user's visual perception is altered to reflect their auditory perception. The basic principle is to correlate sound frequencies to hue and amplitude to saturation and visualise these colors creatively.