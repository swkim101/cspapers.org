As described in the main paper, our intermediate image synthesis network H is based on the SPADE 2 generator [2]. The SPADE generator contains two main components where one is a set of SPADE 3 branches1 and the other is the main image synthesis branch. A SPADE branch converts an input 4 semantic image to a scalar map γ and a bias map ξ, which are fed into a layer in the main image 5 synthesis branch. Typically, multiple SPADE branches are used in the SPADE generator. In our 6 adaptive video-to-video synthesis framework, we use the network weight generation module E to 7 dynamically generate the learnable weights in all the SPADE branches in the SPADE generator, as 8 visualized in Figure 1. 9