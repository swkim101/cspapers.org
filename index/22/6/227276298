Multi-agent Imitation learning (MAIL) refers to the problem that agents learn to perform a task interactively in a multi-agent system through observing and mimicking expert demonstrations, without any knowledge of a reward function from the environment. MAIL has received a lot of attention due to promising results achieved on synthesized tasks, with the potential to be applied to complex real-world multi-agent tasks. Key challenges for MAIL include sample efﬁciency and scalability. In this paper, we proposed Bayesian multi-type mean ﬁeld multi-agent imitation learning (BM3IL). Our method improves sample efﬁciency through establishing a Bayesian formulation for MAIL, and enhances scalability through introducing a new multi-type mean ﬁeld approximation. We demonstrate the performance of our algorithm through benchmarking with three state-of-the-art multi-agent imitation learning algorithms on several tasks, including solving a multi-agent trafﬁc optimization problem in a real-world transportation network. Experimental results indicate that our algorithm signiﬁcantly outperforms all other algorithms in all scenarios.