Network quantization is essential for deploying deep models to IoT devices due to its high efﬁciency. Most existing quantization approaches rely on the full training datasets and the time-consuming ﬁne-tuning to retain accuracy. Post-training quantization does not have these problems, however, it has mainly been shown effective for 8-bit quantization due to the simple optimization strategy. In this paper, we propose a Bit-Split and Stitching framework (Bit-split) for lower-bit post-training quantization with minimal accuracy degradation. The proposed framework is validated on a variety of computer vision tasks, including image classiﬁcation, object detection, instance segmentation, with various network architectures. Speciﬁcally, Bit-split can achieve near-original model performance even when quantizing FP32 models to INT3 without ﬁne-tuning.