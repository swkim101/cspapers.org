We introduce a framework for inference in general state-space hidden Markov 1 models (HMMs) under likelihood misspeciﬁcation. In particular, we leverage 2 the loss-theoretic perspective of Generalized Bayesian Inference (GBI) to deﬁne 3 generalised ﬁltering recursions in HMMs, that can tackle the problem of inference 4 under model misspeciﬁcation. In doing so, we arrive at principled procedures for 5 robust inference against observation contamination by utilising the β -divergence. 6 Operationalising the proposed framework is made possible via sequential Monte 7 Carlo methods (SMC), where most standard particle methods, and their associated 8 convergence results, are readily adapted to the new setting. We apply our approach 9 to object tracking and Gaussian process regression problems, and observe improved 10 performance over both standard ﬁltering algorithms and other robust ﬁlters