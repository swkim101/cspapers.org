Kernel selection for kernel-based methods is pro-hibitively expensive due to the NP-hard nature of discrete optimization. Since gradient-based optimizers are not applicable due to the lack of a differentiable objective function, many state-of-the-art solutions resort to heuristic search or gradient-free optimization. These approaches, however, require imposing restrictive assumptions on the explorable space of structures such as limiting the active candidate pool, thus depending heavily on the intuition of domain experts. This paper instead proposes DTERGENS , a novel generative search framework that constructs and optimizes a high-performance composite kernel expressions generator. DTERGENS does not restrict the space of candidate kernels and is capable of obtaining ï¬‚exi-ble length expressions by jointly optimizing a generative termination criterion. We demonstrate that our framework explores more diverse kernels and obtains better performance than state-of-the-art approaches on many real-world predictive tasks.