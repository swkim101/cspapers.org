The development of Internet of Things calls for ubiquitous and low-cost localization and posture estimation. We present LiTag, a visible light based localization and posture estimation solution with COTS cameras. The core of LiTag is based on the design of a chip-less and battery-less optical tag which can show different color patterns from different observation directions. After capturing a photo containing the tag, LiTag can calculate the tag position and posture by combining the color pattern and the geometry relation between the camera image plane and the real world. Unlike existing marker-based visible localization and posture estimation approaches, LiTag can work with a single camera without calibration, which significantly reduces the calibration overhead and deployment costs. We implement LiTag and evaluate its performance extensively. Results show that LiTag can provide the tag position with a median error of 1.6 cm in the 2D plane, a median error of 12 cm in the 3D space, and posture estimation with a median error of 1Â°. We believe that LiTag has a high potential to provide a low-cost and easy-to-use solution for ubiquitous localization and posture estimation with existing widely deployed cameras.