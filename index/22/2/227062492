Versatile Video Coding (VVC) is the most recent video coding standard, released in July 2020 with two major purposes: (1) providing a similar perceptual quality as the current state-of-the-art High Efficiency Video Coding (HEVC) solution at around half the bitrate and (2) offering native flexible, high-level syntax mechanisms for resolution adaptivity, scalability, and multi-view. However, despite of the compression efficiency, the decoded video obtained with VVC compression still contains distortions and quality degradation due to the nature of the hybrid block and transform based coding approach. To overcome this problem, this paper proposes a novel quality enhancement method for VVC compressed videos where the most advanced deep learning-based multi-frame quality enhancement model (MFQE) is employed. In the proposed QE method, the VVC decoded video is firstly segmented into the peak quality and non-peak quality pictures. After that, a Long-short term memory and two sub-networks are created to achieve better quality video pictures. Experimental results show that, the proposed MFQE based VVC quality enhancement method is able to achieve important quality improvement when compared to the original VVC decoded video.