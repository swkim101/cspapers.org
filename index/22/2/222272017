Post-processing immunity is a fundamental property of differential
privacy: it enables the application of arbitrary data-independent 
transformations to the results of differentially private outputs 
without affecting their privacy guarantees. 
When query outputs must satisfy domain constraints, post-processing 
can be used to project them back onto the feasibility region. 
Moreover, when the feasible region is convex, a widely adopted class of post-processing steps is also guaranteed to improve accuracy. Post-processing has 
been applied successfully in many applications including census 
data, energy systems, and mobility. However, its effects on the 
noise distribution is poorly understood: It is often argued that 
post-processing may introduce bias and increase variance. This paper 
takes a first step towards understanding the properties of 
post-processing. It considers the release of census data and 
examines, both empirically and theoretically, the behavior of a 
widely adopted class of post-processing functions.