The search for good outcomes-be it government policies, technological breakthroughs, or a lasting purchase-takes time and effort. In this paper, we consider a continuous-time search setting. Discoveries beget discoveries and their observations are correlated over time, which we model using a Brownian motion. A searching agent makes two critical decisions: how ambitiously or broadly to search at any point, and when to cease search. Once search stops, the agent is rewarded for the best outcome observed throughout her search. We call this search process retrospective search. We fully characterize the optimal search policy. The stopping boundary takes a simple form: the agent terminates search as soon as search outcomes fall a certain fixed distance below the best-observed outcome; that fixed distance is termed the drawdown size. Search scope is chosen to minimize the expected discounted costs before either a new best-outcome is observed or search is terminated. The optimal search scope is a U- shaped function of the difference between the best outcome and the current outcome; the scope is the smallest when the difference is half of the optimal drawdown size. Both the expected best outcome and expected discounted costs are increasing in drawdown size, and the optimal drawdown size is chosen to strike a balance between the two, given the U-shaped optimal scopes. The optimal policy exhibits natural comparative statics that we explore. We also show the special features that emerge from contracting with a retrospective searcher.