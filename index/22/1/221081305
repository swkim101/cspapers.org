Optimally solving decentralized partially observable Markov decision processes (Dec-POMDPs) under either full or no information sharing received signiﬁcant attention in recent years. However, little is known about how partial information sharing affects existing theory and algorithms. This paper addresses this question for a team of two agents, with one-sided information sharing, i.e. both agents have imperfect information about the state of the world, but only one has access to what the other sees and does. From the perspective of a central planner, we show that the original problem can be reformulated into an equivalent information-state Markov decision process and solved as such. Besides, we prove that the optimal value function exhibits a speciﬁc form of uniform continuity. We also present heuristic search algorithms utilizing this property and providing the ﬁrst results for this family of problems.