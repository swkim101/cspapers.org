The problem of learning fair classiﬁers has mainly been addressed in three ways. First, pre-processing approaches alter We address the problem of classiﬁcation under the labels of the examples or their representation to increase fairness constraints. Given a notion of fairness, the intrinsic fairness of a dataset. A classiﬁer learned on the goal is to learn a classiﬁer that is not discrimi-this modiﬁed data is then more likely to be fair (Feldman natory against a group of individuals. In the liter-et al., 2015; Calmon et al., 2017; Kamiran & Calders, 2012; ature, this problem is often formulated as a con-Dwork et al., 2012; Zemel et al., 2013). Second, post-hoc strained optimization problem and solved using procedures transform existing accurate but unfair classiﬁers relaxations of the fairness constraints. We show into fair classiﬁers (Chzhen et al., 2019; Hardt et al., 2016; that many existing relaxations are unsatisfactory: Woodworth et al., 2017; Kamiran et al., 2010). Finally, di-even if a model satisﬁes the relaxed constraint, it rect methods learn a fair and accurate classiﬁer in a single can be surprisingly unfair. We propose a princi-step (Kamishima et al., 2012; Zafar et al., 2017b;a; Calders pled framework to solve this problem. This new & Verwer, 2010; Wu et al., 2019; Donini et al., 2018; Cotter approach uses a strongly convex formulation and et al., 2019; Agarwal et al., 2018; Goh et al., 2016). In this comes with theoretical guarantees on the fairness paper, we focus on the latter kind of approaches. of its solution. In practice, we show that this method gives promising results on real data.