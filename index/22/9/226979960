Advances in markerless and un-instrumented hand tracking allow us to make full use of the hands' dexterity for interaction with computers. However, the biomechanics of hand movements remain to be thoroughly studied in HCI. The large number of degrees of freedom of the hand (25) presents us with a huge design space of possible gestures, which is hard to fully explore with traditional methods like elicitation studies or design heuristics. We propose an approach to develop a model of fatigue and stress of manual mid-air input, inspired by prior work on the ergonomics of arm movements and on the performance of multi-finger gestures. Along with our vision of the incoming challenges in mid-air interaction, we describe a design framework for mid-air input that, given such models, can be used to automatically evaluate any given gesture set, or propose an optimal gesture vocabulary for a given set of tasks.