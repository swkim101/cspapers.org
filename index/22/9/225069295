Lidar odometry (LO) is a key technology in numerous reliable and accurate localization and mapping systems of autonomous driving. The state-of-the-art LO methods generally leverage geometric information to perform point cloud registration. Furthermore, obtaining the point cloud semantic information describing the environment more abundantly will facilitate the registration. We present a novel semantic lidar odometry method based on self-designed parameterized seman-tic features (PSFs) to achieve low-drift ego-motion estimation for autonomous vehicle in real time. We first use a convolutional neural network-based algorithm to obtain point-wise semantics from the input laser point cloud, and then use semantic labels to separate road, building, traffic sign and pole-like point cloud and fit them separately to obtain corresponding PSFs. A fast PSF-based matching enables us to refine geometric features (GeFs) registration, thereby reducing the impact of blurred submap surface on the accuracy of GeFs matching. Besides, we design an efficient instance-level method to accurately recognize and remove the dynamic objects while retaining static ones in the semantic point cloud, which are beneficial to further improve the accuracy of LO. We evaluate our method, namely PSF-LO, on the public dataset KITTI Odometry Benchmark and rank #1 among semantic lidar methods with an average translational error of 0.82% in the test dataset.