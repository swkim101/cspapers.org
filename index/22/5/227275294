This paper develops a novel and uniﬁed framework to analyze the convergence of a large family of Q-learning algorithms from the switching system perspective. We show that the nonlinear ODE models associated with Q-learning and many of its variants can be naturally formulated as afﬁne switching systems . Building on their asymptotic stability, we obtain a number of interesting results: (i) we provide a simple ODE analysis for the convergence of asynchronous Q-learning under relatively weak assumptions; (ii) we establish the ﬁrst convergence analysis of the averaging Q-learning algorithm, and (iii) we derive a new sufﬁcient condition for the convergence of Q-learning with linear function approximation