Partial label learning assumes inaccurate supervision where each training example is associated with a set of candidate labels, among which only one is valid. In many real-world scenarios, however, it is costly and time-consuming to assign candidate label sets to all the training examples. To circumvent this difﬁculty, the problem of semi-supervised partial label learning is investigated in this paper, where unlabeled data is utilized to facilitate model induction along with partial label training examples. Speciﬁcally, label propagation is adopted to instantiate the labeling conﬁdence of partial label examples. After that, maximum margin formulation is introduced to jointly enable the induction of predictive model and the estimation of labeling conﬁdence over unlabeled data. The derived formulation enforces conﬁdence-rated margin maximization and conﬁdence manifold preservation over partial label examples and unlabeled data. We show that the predictive model and labeling conﬁdence can be solved via alternating optimization which admits QP solutions in either alternating step. Extensive experiments on synthetic as well as real-world data sets clearly validate the effectiveness of the proposed semi-supervised partial label learning approach.