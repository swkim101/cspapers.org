Graph Convolutional Networks (GCNs) have shown promising results in modeling graph-structured data. However, they have difﬁculty with processing digraphs because of two reasons: 1) transforming directed to undirected graph to guarantee the symmetry of graph Laplacian is not reasonable since it not only misleads message passing scheme to aggregate incorrect weights but also deprives the unique characteristics of digraph structure; 2) due to the ﬁxed receptive ﬁeld in each layer, GCNs fail to obtain multi-scale features that can boost their performance. In this paper, we theoretically extend spectral-based graph convolution to digraphs and derive a simpliﬁed form using personalized PageRank. Speciﬁcally, we present the Digraph Inception Convolutional Networks (DiGCN) which utilizes digraph convolution and k th -order proximity to achieve larger receptive ﬁelds and learn multi-scale features in digraphs. We empirically show that DiGCN can encode more structural information from digraphs than GCNs and help achieve better performance when generalized to other models. Moreover, experiments on various benchmarks demonstrate its superiority against the state-of-the-art methods.