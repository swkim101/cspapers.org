This paper explores the idea that skillful assembly is best represented as dynamic sequences of Manipulation Primitives, and that such sequences can be automatically discovered by Reinforcement Learning. Manipulation Primitives, such as "Move down until contact", "Slide along x while maintaining contact with the surface", have enough complexity to keep the search tree shallow, yet are generic enough to generalize across a wide range of assembly tasks. Moreover, the additional "semantics" of the Manipulation Primitives make them more robust in sim2real and against model/environment variations and uncertainties, as compared to more elementary actions. Policies are learned in simulation, and then transferred onto a physical platform. Direct sim2real transfer (without retraining in real) achieves excellent success rates on challenging assembly tasks, such as round peg insertion with 0.04mm clearance or square peg insertion with large hole position/orientation estimation errors.