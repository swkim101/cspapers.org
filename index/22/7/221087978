Sparse principal component analysis (PCA) is a widely-used dimensionality reduction tool in statistics and machine learning. Most meth-ods mentioned in literature are either heuristics for good primal feasible solutions under statistical assumptions or ADMM-type algorithms with stationary/critical points convergence property for the regularized reformulation of sparse PCA. However, none of these methods can efﬁciently verify the quality of the solutions via comparing current objective values with their dual bounds, especially in model-free case. We propose a new framework that ﬁnds upper (dual) bounds for the sparse PCA within polynomial time via solving a convex integer program (IP). We show that, in the worst-case, the dual bounds provided by the convex IP is within an afﬁne function of the global optimal value. Moreover, in contrast to the semi-deﬁnition relaxation, this framework is much easier to scale for large instances. Numerical results on both artiﬁcial and real cases are reported to demonstrate the advantages of our method.