Most existing recommender systems leverage users' complete original behavioral logs, which are collected from mobile devices and stored by the service provider and further fed into recommendation models. This may lead to a high risk of privacy leakage since the recommendation service provider may be trustless. Despite many research efforts on privacy-aware recommendation, the problem of building an effective recommender system completely preserving user privacy is still open. In this work, we propose a general framework named differentially private local collaborative filtering for recommendation. The designed workflow consists of three steps. First, for accumulated behavioral logs saved on users' devices, a differentially private protection mechanism is adopted to help obfuscate the real interactions before reporting them to the server. Second, after collecting all obfuscated records from all users, the server runs an estimation model to calculate similarities between each pair of items. This step requires no user-relevant data, and thus it does not introduce any auxiliary privacy risk. Last, the server sends the estimated user-irrelevant item-similarity matrix to each user device, and the recommendation results are inferred locally based on item similarities with each user's locally stored original behavioral data. To verify our method's efficacy, we conduct extensive experiments on three real-world datasets, demonstrating that our proposed method achieves the best performance compared with the state-of-the-art baselines. We further demonstrate that our method still works well under various privacy budgets and different data sparsity level.