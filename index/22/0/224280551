Asking a clarifying question can be a key element improving the performance of information seeking systems, particularly conversational search systems due to their limited bandwidth interfaces. While generating and asking clarifying questions is important; get-ting an answer for the clarifying question is also essential as a clarifying question without an answer is useless. Therefore, as the first step in current research, we analysed human-generated clarifying questions in a Community Question Answering website as a sample of conversation. This helped us to gain a better insight into how users interact with clarification. We investigated the clarifying questions in terms of whether they add any information to the question and the accepted answer. We further discovered the patterns and types of such clarifying questions. The next phase of this research will then generate clarifying questions in conversational search systems. We will then employ neural network models to generate clarifying questions to maximise clarification in questions. The proposed model will be trained using the MIMICS data collection in addition to our collected dataset. We will also attempt to consider the recognised patterns from the analysis conducted in the first step to enhance the chance that a user will interact with the clarifying questions. Finally, we will aim to minimise the interaction between the search system and the user to reduce the risk of dropping the conversation by the user due to asking too many clarifying questions.