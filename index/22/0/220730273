Conventional models on Neural Text Generation (NTG) determine the output distribution by applying maximum likelihood estimation on training corpora. However, as user preference for generated content can be constantly changing, an optimized text generator needs to assimilate such non-static nature into the outcome adaptively. In this paper, our goal is to generate product descriptions on e-commerce platforms, and we explore this classic task from a novel perspective that allows the optimal output text to vary with ever-changing user preference. Specifically, we propose an evolutionary NTG model to enable its interactive environment to fine-tune the pre-trained generative policy via Reinforcement Learning (RL). To this end, a dynamic context of textual fitness is established based on the user click behavior associated with previously generated content to estimate reward/penalty signals for each output text. Our motivation is to leverage the click-through rate as a kind of user-centric measurement on text quality, by which we can assess how likely a product description attracts people's attention and follows shopping trends. Extensive experiments on a real e-commerce website demonstrate that the proposed approach achieves a significant superiority over two statically RL-based variants and four state-of-the-art NTG solutions.