Recently, large-scale pre-trained language models have made remarkable progress in knowledge-intensive natural language processing tasks. It seems to indicate that pretrained language models can naturally learn extensive knowledge from the corpus and implicitly encode it in the parameters. However, the underlying mechanisms behind the phenomenon remain unknown. Questions such as what knowledge has been acquired by language models, how to extract and utilize the knowledge, and how external knowledge can be incorporated to address the limitations of models, are all awaiting further exploration. In this tutorial, we will focus on introducing recent research advancements in the knowledge analysis, knowledge extraction, and knowledge enhancement of pre-trained language models. Speaker: Yubo Chen i s an Assoc ia te Researcher a t the Ins t i tu te of Automation, Chinese Academy of Sciences. His research interests include Knowledge Graph, Natural Language Processing and Large Language Model. He has published 40+ papers on ACL, EMNLP, COLING, CIKM, WWW and AAAI. His work has been cited over 4500 times on Google Scholar. Two of his papers have been selected as high-impact papers at ACL and EMNLP (Paper Digest selection), and he has received multiple Best Paper Awards (NLP-NABD 2016, CCKS 2017, CCL 2020, CCKS 2020). He was selected for the 5th China Association for Science and Technology Youth Talent Lifting Project in 2020, and was recognized as a Global Chinese AI Young Scholar in 2022, a member of the Youth Innovation Promotion Association of the Chinese Academy of Sciences in 2022. He serves as the Secretary-General of the Youth Working Committee of the Chinese Information Processing Society of China, Area Chair of the COLING 2022, Editorial Board Member of Data Intelligence. He was awarded the first prize of the "Qian Weichang Chinese Information Processing Science and Technology Award" by the Chinese Information Processing Society of China in 2018 and the first prize of the Beijing Science and Technology Progress Award in 2019. Knowledge Analysis, Extraction and Enhancement in Pre-trained Language Models Lecture 1 Tutorials: 12-13 Oct