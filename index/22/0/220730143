Classical ad-hoc retrieval models based on exact matches suffer from the issue of soft matching in text. Besides query expansion approaches, many existing neural IR approaches exploiting word embedding representation alleviate this issue to some extent. We observe that word embedding vectors are usually normalized in practice to retain cosine similarities that are used to construct the query-document interaction matrix for most neural ranking models. These vectors are in fact mapped to the surface of a high-dimensional hypersphere. Existing work in kernel-based ranking do not consider kernel to be a distribution on a certain geometry if the variable of a kernel is a geometric quantity. We propose a kernel-based neural ranking model based on a statistical manifold. We consider the interaction as geodesic on a manifold. We propose a smoothed kernel pooling scheme at different similarity levels based on Riemann normal distribution. Extensive experiments are conducted on the recent benchmark dataset with the state-of-the-art kernel-based neural ranking model, which demonstrate significant improvements brought by our model.