The primary goal of this paper is to analyze the impact of the convolution operation on the model performance. In this context, to avoid the mathematical complexities behind the Convolution Neural Network (CNN) model, the classical convolution operation is substituted by a new proposed matrix operation. The model considered is composed of one convolution layer in series with a set of fully connected hidden layers. The network parameters (filters, weights, and biases) are updated using the back propagation gradient descent algorithm. The model performance is improved through the variation of the width and height CNN hyper-parameters. MNIST data are considered here for the classification of handwritten numbers. With a simple modification of the CNN hyper-parameters using the new proposed matrix operation, a CNN performance of 98.83% was achieved.