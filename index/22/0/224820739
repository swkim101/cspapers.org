As the result of compression and the source of reconstruction, the latent space of Variational Auto-Encoders (VAEs) captures theessencesofthetrainingdataandhenceplaysafundamentalroleindataunderstandingandanalysis. Focusedonrevealing what data features/semantics are encoded and how they are related in the latent space, this paper proposes a visual analytics system, i.e., LatentVis , to interactively study the latent space for better understanding and diagnosing image-based VAEs. Specifically, we train a supervised linear model to relate the machine-learned latents with the human-understandable semantics. With this model, each important data feature is expressed along a unique direction in the latent space (i.e., semantic direction). Comparing the semantic directions of different features allows us to compare the feature similarity encoded in the latent space, and thus to better understand the encoding process of the corresponding VAE. Moreover, LatentVis empowers us to examine and compare latent spaces across various training stages, or different VAE models, which can provide useful insight into model diagnosis.