While so-called robotic guides have been studied thoroughly, the focus of these robots was more to open the road or accompany a person or a group until they reach their destination. Interaction was essentially limited to the initiation and ending of the task and implemented using a screen or speech. Providing route directions is a specific task that such robot is meant to realize. We claim that this task can be studied and tackled as a joint task where not only the robot as route direction provider but also the human as listener must be modeled and taken into account for planning. Interestingly, the pertinent way a speaker and a listener share their space, move and point accordingly to enable the understanding and completion of way-finding direction has not been very much studied in the spatial cognition literature and has not been yet tackled as such in the human-robot interaction community. We propose the SVP (Shared Visual Perspective) planner that searches for the right placements both for the robot and the human to enable efficient visual perspective sharing needed for providing route direction and enables to choose the best landmark when several are available. The shared perspective is chosen taking into account not only the visibility of the landmarks, but most importantly the whole guiding task.