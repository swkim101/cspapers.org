This paper describes a robotic architecture that uses visual attention mechanisms for autonomous navigation in unknown indoor environments. A foveation mechanism based on a bottom-up attention system allows the robot to autonomously select landmarks, defined as salient points in the camera images. Landmarks are memorized in a behavioral fashion by coupling sensing and acting to achieve a representation that is view and scale independent. Selected landmarks are stored in a topological map. During the navigation a top-down mechanism controls the attention system to achieve robot localization. Experiments and results show that our system is robust to noise and odometric errors, being at the same time able to deal with a wide range of different environments.