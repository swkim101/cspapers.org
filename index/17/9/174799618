The problem of estimating causal effects of treatments from observational data falls beyond the realm of supervised learning — because counter-factual data is inaccessible, we can never observe the true causal effects. In the absence of “super-vision”, how can we evaluate the performance of causal inference methods? In this paper, we use inﬂuence functions — the functional derivatives of a loss function — to develop a model validation procedure that estimates the estimation error of causal inference methods. Our procedure utilizes a Taylor-like expansion to approximate the loss function of a method on a given dataset in terms of the inﬂuence functions of its loss on a “synthesized”, proximal dataset with known causal effects. Under minimal regularity assumptions, we show that our procedure is √ n -consistent and efﬁcient. Experiments on 77 benchmark datasets show that using our procedure, we can accurately predict the comparative performances of state-of-the-art causal inference methods applied to a given observational study.