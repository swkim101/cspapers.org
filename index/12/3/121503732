This paper presents a framework for identification of the global optimum of Kriging models that have been tuned to approximate the response of some generic objective function and constraints. The framework is based on a branch and bound scheme for subdivision of the search space into hypercubes while constructing convex underestimators of the Kriging models. The convex underestimators, which are the key development in this paper, provide a relaxation of the original problem. The relaxed problem has two main features: (i) convex optimization algorithms such as sequential quadratic programming (SQP) are guaranteed to find the global optimum of the relaxed problem and (ii) objective value of the relaxed problem is a lower bound within a hypercube for the original (Kriging model) problem. As accuracy of the convex estimators improves with subdivision of a hypercube, termination of a branch happens when either: (i) solution of the relaxed problem within the hypercube is no better than current best solution of the original problem or (ii) best solution of the original problem and that of the relaxed problem are within tolerance limits. To assess the significance of the proposed framework, comparison studies against genetic algorithm (GA), particle swarm optimization (PSO), random multistart sequential quadratic programming (mSQP), and DIRECT are conducted. The studies include four standard nonlinear test functions and two design application problems of water desalination and vehicle crashworthiness. The studies show the proposed framework deterministically finding the optimum for all the test problems. Among the tested stochastic search techniques (GA, PSO, mSQP), mSQP had the best performance as it consistently found the optimum in less computational time than the proposed approach except on the water desalination problem. DIRECT deterministically found the optima for the nonlinear test functions, but completely failed to find it for the water desalination and vehicle crashworthiness problems.