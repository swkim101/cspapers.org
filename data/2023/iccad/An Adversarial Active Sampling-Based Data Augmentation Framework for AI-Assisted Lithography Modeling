Lithography modeling is a crucial problem in chip design to ensure the manufacturability of chip design masks. It requires rigorous simulations of optical and chemical models that are computationally expensive. Recent developments in machine learning have provided alternative solutions in replacing time-consuming lithography simulations with deep neural networks. However, considerable accuracy drop still impede its industrial adoption. Most importantly, the quality and quantity of the training dataset directly affects the model performance. To tackle this problem, we propose a Litho-Aware Data Augmentation (LADA) framework to resolve the limited data dilemma and improve the machine learning model performance. First, we pretrain the neural networks for lithography modeling and a gradient-friendly StyleGAN2 generator. We then perform adversarial active sampling to generate informative and synthetic in-distribution mask designs. These synthetic mask images augment the original limited training dataset used to finetune the lithography model for improved performance. Experimental results demonstrate that LADA can successfully improve the model robustness and exploit the neural network capacity by narrowing the performance gap between the training and testing data instances.