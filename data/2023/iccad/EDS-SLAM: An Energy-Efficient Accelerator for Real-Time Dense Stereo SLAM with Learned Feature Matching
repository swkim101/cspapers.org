Simultaneous Localization And Mapping (SLAM) is a fundamental component used in many applications, such as robotic navigation and augmented reality. To achieve on-line navigation on resource-constrained platforms, a fair amount of research has been devoted to develop real-time SLAM accelerators. However, most existing accelerators have the following limitations: (1) relying on hand-crafted visual features, which cannot offer robust feature association in complex environments; (2) only recovering sparse points of the observed scene, which are not adequate for high-level tasks such as obstacle avoidance and path planning. In this paper, we present EDS-SLAM, an energy-efficient and robust architecture for real-time dense stereo SLAM system based on learned feature matching to achieve real-time visual localization and dense mapping reconstruction. To achieve both resource efficiency and perception robustness, EDS-SLAM utilizes a share-used binary neural network (BNN) architecture to perform not only key-points association for computing robust camera poses, but also stereo matching for obtaining high-quality mapping. In EDS-SLAM, we design a set of dedicated, well optimized accelerators to achieve real-time implementations for the pipelines of stereo matching, feature extraction and key-point association. The effectiveness of EDS-SLAM is evaluated through comprehensive experiments. Compared to the state-of-the-art dense SLAM system with software-based implementation, EDS-SLAM achieves comparable accuracy on the localization but higher precision dense 3D mapping with up to $2.03\times$ speed-up as well as up to $23.1\times$ energy efficiency improvement, respectively.