Optical neural networks with Mach-Zender interferometers (MZIs) have demonstrated advantages over their electronic counterparts in computing efficiency and power consumption. However, implementing the computation with a weight matrix in DNNs using this technique requires the decomposition of the weight matrix into two unitary matrices, because an optical network can only realize a single unitary matrix due to its structural property. Accordingly, a direct implementation of DNNs onto optical networks suffer from a low area efficiency. To address this challenge, in this paper, a near-unitary training framework is proposed. In this framework, a weight matrix in DNNs is first partitioned into square submatrices to reduce the number of MZIs in the optical networks. Afterwards, training is adjusted to make the partitioned submatrices as close to unitary as possible. Such a matrix is then represented further by the sum of a unitary matrix and a sparse matrix. The latter implements the difference between the unitary matrix and the near-unitary matrix after training. In this way, only one optical network is needed to implement this unitary matrix and the low computation load in the sparse matrix can be implemented with area-efficient microring resonators (MRRs). Experimental results show that the area footprint can be reduced by 81.81%, 85.51%, 48.6% for ResNet34, VGG16, and fully connected neural networks, respectively, while the inference accuracy is still maintained on CIFAR100 and MNIST datasets.