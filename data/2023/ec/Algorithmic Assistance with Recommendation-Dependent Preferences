One important application of algorithms is to turn complex data into simple predictions or recommendations that help decision-makers take better decisions. Examples of this include risk assessments presented to judges or doctors. We typically think of such algorithmic assessments as providing additional information about which choices will lead to better outcomes. But when a decision-maker obtains algorithmic assistance, they may not only react to the information. The decision-maker may view the input of the algorithm as recommending a default action, making it costly for them to deviate. In this article, we consider the effect and design of algorithmic recommendations when they affect choices not just by shifting beliefs, but also by altering preferences. We show that recommendation dependence creates inefficiencies where the decision-maker is overly responsive to the recommendation, and propose changes to the design of recommendation algorithms to counteract this response.