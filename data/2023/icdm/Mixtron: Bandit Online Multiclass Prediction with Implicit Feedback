The exploitation and exploration dilemma is a crucial issue in bandit online multiclass prediction. Conventional algorithms typically resort to either random sample or estimate uncertainty for exploration. In contrast, we propose a novel scheme that focuses solely on exploitation with implicit feedback. To ensure efficient information feedback even when predictions are incorrect, we introduce mixed losses into our proposed scheme. We derive two mixed versions of the multiclass hinge loss and the logistic loss, along with their corresponding algorithms. Context-free and context-aware experiments are conducted to evaluate the performance of our proposed algorithms. Experiment results demonstrate that random sampling are unnecessary if a reasonable loss function is employed. By compared with several state-of-the-art baselines on both synthetic and real-world datasets, our proposed algorithms show their superior performance. Remarkably, they even outperform the Perceptron algorithm with full-information feedback in some cases.