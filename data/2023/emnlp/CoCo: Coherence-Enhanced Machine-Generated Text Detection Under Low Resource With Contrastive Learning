Machine-Generated Text (MGT) detection, a 001 task that discriminates MGT from Human-002 Written Text (HWT), plays a crucial role in 003 preventing misuse of text generative models, 004 which excel in mimicking human writing style 005 recently. Latest proposed detectors usually take 006 coarse text sequences as input and fine-tune 007 pretrained models with standard cross-entropy 008 loss. However, these methods fail to consider 009 the linguistic structure of texts. Moreover, they 010 lack the ability to handle the low-resource prob-011 lem which could often happen in practice con-012 sidering the enormous amount of textual data 013 online. In this paper, we present a co herence-014 based co ntrastive learning model named C O C O 015 to detect the possible MGT under low-resource 016 scenario. To exploit the linguistic feature, we 017 encode coherence information in form of graph 018 into text representation. To tackle the chal-019 lenges of low data resource, we employ a con-020 trastive learning framework and propose an im-021 proved contrastive loss for preventing perfor-022 mance degradation brought by simple samples. 023 The experiment results on two public datasets 024 and two self-constructed datasets prove our ap-025 proach outperforms the state-of-art methods 026 significantly. 027