ions and Model checking of Markovian Models (Aachen) We have applied three-valued abstraction techniques for probabilistic systems, in particular interval MDPs and their continuous-time variants, to case studies from systems biology and queuing networks. It has been shown that certain abstractions provide rather tight bounds. For tree-based queuing networks (that are strongly related to probabilistic pushdown automata), excessive state-space reductions have been achieved while preserving very good accuracy. In addition, we have considered compositional abstraction techniques for interactive Markov chains. Finally, we have shown that model checking of continuous-time Markov chains against linear real-time specifications given as deterministic timed automata can be reduced to computing reachability probabilities in piecewise deterministic Markov processes. We also developed an 214373 ArtistDesign NoE JPRA Year 2 (Jan-Dec 2009) Cluster: Modeling and Validation D6-(3.2)-Y2 Activity: Validation 13/48 algorithm to determine the (time-dependent) policy that maximises (or, dually minimises) the probability to reach a set of target states within a deadline in continuous-time MDPs. Distributed and Modular HTL (Salzburg + Uni. Porto + IST Austria + Uni. Trento) The Hierarchical Timing Language (HTL) is a real-time coordination language for distributed control systems. The desired key property of HTL programs is time-determinism, meaning that their functional and temporal behavior is repeatable (for every timed sequence of inputs, there is a unique timed sequence of outputs). HTL compilation proceeds in the following steps; (1) it checks whether an HTL program is time-deterministic on a given, possibly distributed target platform and (2) it generates code that runs of that particular platform. The time-determinism of an HTL program is ensured by checking well-formedness of its syntax, race-freedom of communicator updates, transmission-safety (schedulability of cross-host communication) and time-safety (schedulability of host computation). It follows that race-free, transmission-safe and time-safe execution of well-formed programs is time-deterministic, that is, the computed values and update times of communicators are input-determined and therefore predictable. In this work, we proposed a modular abstract syntax and semantics for HTL. We also developed modular checks for well-formedness, race-freedom, transmission-safety and modular code distribution. The last point is based on the modular transmission safety check, ensuring that each communicator value can be communicated within a single communicator period. Our contributions complete the distributed and modular design of HTL, except for time safety checking of top-level programs, which remains non-modular. Modularity in HTL is important for design scalability but also enables efficient program modifications at runtime, called runtime patches, while maintaining predictable behavior [HKMS09]. Compositional Safety Analysis (KTH with University of Hull and Volvo) The automotive industry has a growing demand for the seamless integration of safety analysis tools into the model-based development tool-chain for embedded systems. This requires translating concepts of the automotive domain to the safety domain. We automate such a translation between the automotive architecture description language EAST-ADL2 and the safety analysis tool HiP-HOPS by using model transformations and by leveraging the advantages of different model transformation techniques. In this work we have shown how we integrated the safety analysis tool HiP-HOPS into the automotive model-based development based on EAST-ADL2. We used different model transformation techniques to translate the relevant information from the automotive domain to the safety analysis domain. This link enables early safety analysis. Through this integration, the analysis can be conducted early in the development process, when the system can be redesigned to fulfil safety goals with relatively low effort and cost. The safety analysis techniques relies on so called error models which are specified for each component (and which may be used for components at different levels of abstraction). An error model constitutes a so called interface failure mode and effects analysis (FMEA) model. Based on such component models, fault-trees for an entire system considering different system failure modes can be automatically generated. Based on the fault-models in turn, cut-set analysis and other types of assessments can be performed. The work is still ongoing, and publications are under way. The resulting tool plugin is used in further work within the ATESST2 project. Further work will also explore back-annotating results from the safety analysis into the EAST-ADL2 models. 214373 ArtistDesign NoE JPRA Year 2 (Jan-Dec 2009) Cluster: Modeling and Validation D6-(3.2)-Y2 Activity: Validation 14/48 Compositional verification of probabilistic systems (CISS) A specification theory combines notions of specification and implementation with a satisfaction relation, a refinement relation and a set of operators that together support stepwise design. We propose a new abstraction, Constraint Markov Chains, and use it to construct a specification theory for Markov Chains. Constraint Markov Chains generalize previously known abstractions by allowing arbitrary constraints on probability distributions. Our theory is the first specification theory for Markov Chains closed under conjunction, parallel composition and synchronization. Moreover, all the operators and relations introduced are computable. Heterogeneous Composition (TRENTO + IST + Chennai Mathematical Institute, + UC Berkeley) In the area of heterogeneous composition, TRENTO and IST have been collaborating with Praskash Chandrasekaran, a Research Scholar at the Chennai Mathematical Institute, Chennai, India. The activities have been centered around the development of a formal model for specifying heterogeneous systems, based on the Coordinated Concurrent System (CCS) notation. In this activity, which is reported in more details in deliverable D1.1-Y2, we have extended our previous examples of heterogeneous interaction. In particular, we have addressed the definition of an interface process between an untimed model of computation and a timed one. Here, we have used Khan Process Networks (KPN) as an example for an untimed data flow model, and Finite State Machines (FSM) as a model for synchronous timed communication based on signals. In this work we have developed techniques to synthesize an interface between KPNs and FSMs, with some restrictions on the language of the FSMs. This work extends our previous investigation by identifying a common semantic domain, the CCS, which we use to develop our interface process between the incompatible models. We take this a step further, and use the model to specify global properties that we want the system to exhibit, with particular attention to end-to-end communication and interaction properties. This way, we take advantage of the existing connection to the Uppaal model checker from CCS to provide means to verify the correctness of the heterogeneous system composition. Sub-activity B: Quantitative Validation Automatic verification of programs with integer arrays (Verimag, LIAFA) Arrays are an important data structure in all common programming languages. Automatic verification of programs using arrays is a difficult task since they are of a finite, but often not a priori fixed length, and, moreover, their contents may be unbounded too. We have developed a verification technique for a class of programs working on integer arrays of finite, but not a priori bounded length [BIH*09]. We use the logic of integer arrays SIL (SingleIndex Array Logic) to specify preand post-conditions of programs and their parts. Effects of non-looping parts of code are computed syntactically on the level of SIL. Loop pre-conditions derived during the computation in SIL are converted into counter automata (CA). Loops are automatically translated purely on the syntactical level to transducers. Pre-condition CA and transducers are composed, and the composition over-approximated by flat automata with difference bound constraints, which are next converted back into SIL formulae, thus inferring 214373 ArtistDesign NoE JPRA Year 2 (Jan-Dec 2009) Cluster: Modeling and Validation D6-(3.2)-Y2 Activity: Validation 15/48 post-conditions of the loops. Finally, validity of post-conditions specified by the user in SIL may be checked as entailment is decidable for SIL [BIH*09]. Analysis of Energy related properties of sensor Networks (VERIMAG + FT) VERIMAG worked on analysis techniques to estimate the energy consumption of embedded systems. We applied these techniques in the context of Wireless Sensor Networks (WSN). Indeed, large scale industrial deployment of a WSN still requires to lowering the energy consumption in order to achieve long-term network lifetimes (typically more than 10 years). Hence, every layer of a WSN application (node hardware, communication protocols, autoorganization mechanisms) should be specifically designed to run in an utmost energy efficient manner. We addressed this problem by developing accurate prototypes of WSNs, that can be formally analyzed, and that can be transformed by dedicated abstraction mechanisms, able to simplify the model complexity while preserving (or at least over-approximating) the energy consumption. During the past year, we have improved the Glonemo simulator (http://wwwverimag.imag.fr/~samper/Glonemo/). This simulator can handle networks of up to several hundred thousands nodes, on typical monitoring application, running models of existing communication protocols (for the MAC and routing levels), while precisely evaluating the energy consumption of each node. We enhanced the simulator to allow modelling and simulation of more complex protocols. The whole simulat