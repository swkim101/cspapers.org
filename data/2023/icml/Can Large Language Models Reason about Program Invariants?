Identifying invariants is an important program analysis task with applications towards program understanding, bug ﬁnding, vulnerability analysis, and formal veriﬁcation. Existing tools for identifying program invariants rely on dynamic analysis, requiring traces collected from multiple executions in order to produce reliable invariants. We study the application of large language models to invariant prediction, ﬁnding that models trained on source code and ﬁne-tuned for invariant generation can perform invariant prediction as static rather than dynamic analysis. Using a scratch-pad approach where invariants are predicted sequentially through a program gives the best performance, ﬁnding invariants statically of quality comparable to those obtained by a dynamic analysis tool with access to ﬁve program traces.