As modern manufacturing lines embrace greater modularity and flexibility, the need to transition factory networks from wired to wireless grows. Yet the mission-critical nature of factory networks poses a key challenge - connecting numerous diverse machines with high QoS predictability. After formulating this challenge as predictable RAN optimization via Reinforcement Learning (RL), we highlight a major-yet-overlooked modeling issue: matching the packet handling mechanics of a production/real RAN software. In this paper, we show that these mismatches inside RAN simulators can cause non-trivial QoS gaps in production. Then, we present Twin5G, a novel training solution that brings scalable and near-discrete-time emulations to real RAN software, removing the need for RAN simulators. In a RAN Slicing example, Twin5G-trained policy outperforms simulator-trained and standard RL-trained policies in both QoS achieved (+16%) and predictability (+19%) during tests.