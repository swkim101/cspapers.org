Cloud-based machine learning inference is an emerging paradigm where users 1 query by sending their data through a service provider who runs an ML model 2 on that data and returns back the answer. Due to increased concerns over data 3 privacy, recent works have proposed Collaborative Inference (CI) to learn a privacy-4 preserving encoding of sensitive user data before it is shared with an untrusted 5 service provider. Existing works so far evaluate the privacy of these encodings 6 through empirical reconstruction attacks. In this work, we develop a new framework 7 that provides formal privacy guarantees for an arbitrarily trained neural network by 8 linking its local Lipschitz constant with its local sensitivity. To guarantee privacy 9 using local sensitivity, we extend the Propose-Test-Release (PTR) framework to 10 make it tractable for neural network queries. We verify the efficacy of our frame-11 work experimentally on real-world datasets and elucidate the role of Adversarial 12 Representation Learning (ARL) in improving the privacy-utility trade-off. 13