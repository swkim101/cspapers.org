Most of the presented results consist of applying our method with the editing technique of Prompt-to-Prompt [4]. However, we demonstrate that our method is not confined to a specific editing approach, by showing it improves the results of the SDEdit [7] editing technique. In Fig. 1 (top), we measure the fidelity to the original image using LPIPS perceptual distance [13] (lower is better), and the fidelity to the target text using CLIP similarity [8] (higher is better) over 100 examples. We use different values of the SDEdit parameter t0 (marked on the curve), i.e., we start the diffusion process from different t = t0 Â· T using a correspondingly noised input image. This parameter controls the trade-off between fidelity to the input image (low t0) and alignment to the text (high t0). We compare the standard SDEdit to first applying our inversion and then performing SDEdit while replacing the null-text embedding with our optimized embeddings. As shown, our inversion significantly improves the fidelity to the input image. This is visually demonstrated in Fig. 1 (bottom). Since the parameter t0 controls a reconstruction-editability tradeoff, we have used a different parameter for each method (SDEdit with and without our inversion) such that both achieve the same CLIP score. As can be seen, when using our method, the true identity of the baby is well preserved.