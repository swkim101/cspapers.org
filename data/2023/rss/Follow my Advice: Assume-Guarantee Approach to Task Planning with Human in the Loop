—We focus on correct-by-design robot task planning from ﬁnite Linear Temporal Logic (LTL f ) speciﬁcations with a human in the loop. Since provable guarantees are difﬁcult to obtain unconditionally, we take an assume-guarantee perspective. Along with guarantees on the robot’s task satisfaction, we compute the weakest sufﬁcient assumptions on the human’s behavior. We approach the problem via a stochastic game and leverage algorithmic synthesis of the weakest sufﬁcient assumptions. We turn the assumptions into runtime advice to be communicated to the human. We conducted an online user study and showed that the robot is perceived as safer, more intelligent and more compliant with our approach than a robot giving more frequent advice corresponding to stronger assumptions. In addition, we show that our approach leads to less violations of the speciﬁcation than not communicating with the participant at all.