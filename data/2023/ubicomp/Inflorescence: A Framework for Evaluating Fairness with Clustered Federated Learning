Measuring and ensuring machine learning model fairness is a challenging task that is especially difficult in federated learning (FL) settings where the model developer is not privy to clientsâ€™ local data. We propose Inflorescence, a framework that explores how the application of clustered FL strategies, which are designed to handle data distribution skew across federated clients, affects fairness. We share empirical simulation results quantifying the extent to which clustered FL impacts various group and individual fairness metrics, finding that it tends to improve fairness in terms of accuracy, precision, and error entropy, but not in terms of disparate impact or equal odds. We open-source the proposed framework as a Python package to facilitate research on fairness in distributed systems.