This research deals with how to build reliable AI models using shared sensitive data. Confidential computing is gaining attention in AI services for a ubiquitous computing field. It makes legal and social regulations strict, including protecting privacy and ensuring security for sensitive data and AI models. As is also the case in ubiquitous computing research. The research phase also requires a manual trial-and-error process to create value through new combinations of shared data and AI models. Conventional confidential computing cannot realize the human workflow. This paper proposes and verifies “Sandbox AI” that can build precise AI models through efficient manual processes without revealing the shared data or models to one another. Sandbox AI utilizes privacy-preserving synthetic data generation and active learning on a confidential computing architecture. Specifically, Sandbox AI works in a sandbox container and generates synthetic data on the basis of real data, interactively extracts synthetic data that are useful for efficient model training while considering the real data distribution, discloses only the extracted synthetic data for annotation, and re-trains the model on the labeled synthetic data. Experimental results show that the achieved model accuracy is as good as that of conventional learning using real data with privacy violations.