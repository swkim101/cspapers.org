In-storage computing with computational SSDs is emerging as one effective solution for I/O bottlenecks in big data applications such as AI learning model training. Specifically, with in-SSD computing, computation can be pushed down to SSDs and the volume of the output data that will be transferred back to the host can be greatly reduced. However, there are several fundamental issues for applications to fully exploit in-SSD computing with simple and efficient function offloading. In this paper, we present three challenges for in-SSD computing, namely, data model, programming framework, and storage/computing integration, and discuss possible research directions.