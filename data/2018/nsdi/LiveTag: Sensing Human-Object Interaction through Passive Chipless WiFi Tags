Information about the objects a person touches is an essential input to many applications in ubiquitous computing. The ability to sense touch in the physical world can form the basis of the tangible user interface [1], which allows humans to use omnipresent objects as a command-and-control interface to the digital world. On the other hand, the sequence of objects used can enable inference of human activities. Post-processing of this information can support many activity-aware applications, such as stroke rehabilitation assessment in homes, consumer analytics for retail stores, etc.