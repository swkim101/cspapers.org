The goal of the Sussex-Huawei Locomotion-Transportation (SHL) recognition challenge is to classify 8 modes of transportation and locomotion activities recorded using a smartphone inertial sensor. In this paper, Team Orion extracts 36 quantitative features per sensor (totalling 226 features) of the dataset provided in the SHL recognition challenge and provides a processing pipeline for training the classifiers embracing parallel computation and out-of-memory processing. One-vs-one quadratic Support Vector Machine (1-1 QSVM) and Bagged Decision Trees with 45 learners (EoC-45) were used for classification of the DU Mobility Dataset. The same features/pipeline provided 91% and 92% classification accuracies respectively on the SHL recognition challenge dataset. Using one-vs-one cubic Support Vector Machine (1-1 CSVM) on SHL, we received the highest classification accuracy of 92.8%. Afterwards, Artificial Neural Network (ANN) was applied on the dataset and accuracies of 93.6%, 88.18% and 90.05% were obtained for training, testing and validation phases. The results provide promising prospects of supervised and neural network classification for locomotion analysis.