General purpose automatic speech recognition

(gpASR) systems such as Google, Watson, etc.

sometimes output inaccurate sentences when used

in a domain specific scenario as it may not have had

enough training samples for that particular domain

and context. Further, the accent of the speaker and

the environmental conditions in which the speaker

speaks a sentence may influence the speech engine

to recognize certain words inaccurately. Many approaches

to improve the accuracy of ASR output

exist. However, in the context of a domain and

the environment in which a speaker speaks the sentences,

gpASR output needs a lot of improvement

in order to provide effective speech interfaces to

domain-specific systems. In this paper, we demonstrate

a method that combines bio-inspired artifi-

cial development (ArtDev) with machine learning

(ML) approaches to repair the output of a gpASR.

Our method factors in the environment to tailor the

repair process.