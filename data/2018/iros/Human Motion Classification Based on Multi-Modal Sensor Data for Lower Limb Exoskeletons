Intuitive exoskeleton control is fundamental since it contributes to improved user acceptance and wearability comfort. This requires the detection of user's motion intention and its incorporation into the exoskeleton control system. In this work, we propose a classification system based on Hidden Markov Models (HMMs), which facilitates the online classification of multi-modal sensor data acquired from a lower-limb exoskeleton based on previously defined motion patterns. For classification of these motion patterns at each time step, we consider the most recent sensor measurements by using a sliding window approach. We collected a training data set from a total number of 10 subjects performing 13 different motions with a passive exoskeleton equipped with 7 3D-force sensors and 3 inertial measurement units (IMUs). Our evaluation includes an analysis of the time needed for correct classification (latency), a validation for a training set containing all subjects and a leave-one-out validation to assess the generalization performance of the approach. The results indicate that our approach can classify motions of subjects included in the training set with an average accuracy of 92.80% and is able to achieve a generalization performance of 84.46%. With the selected parameters an average latency of 368.97 ms is achieved.