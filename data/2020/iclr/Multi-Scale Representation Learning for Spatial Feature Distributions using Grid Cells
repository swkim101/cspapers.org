Unsupervised text encoding models have recently fueled substantial progress in Natural Language Processing (NLP). The key idea is to use neural networks to convert words in texts to vector space representations (embeddings) based on word positions in a sentence and their contexts. We see a strikingly similar situation in spatial analysis, which focuses on incorporating both absolute positions and spatial contexts of geographic objects such as Points of Interest (POIs) into models. A general space encoding method is valuable for a multitude of tasks such asPOI search, land use classification, point-based spatial interpolation and locationaware image classification. However, no such general model exists to date beyond simply applying discretizing or feed forward nets to coordinates, and little effort has been put into jointly modeling distributions with vastly different characteristics, which commonly emerges from GIS data. Meanwhile, Nobel Prize-winning Neuroscience research shows that grid cells in mammals provide a multi-scale periodic representation that functions as a metric for encoding space and are critical for recognizing places and for path-integration. Inspired by this research, wepropose a representation learning model called Space2vec to encode the absolutepositions and spatial relationships of places. We conduct experiments on realworld geographic data and predict types of POIs at given positions based on their1) locations and 2) nearby POIs. Results show that because of its multi-scale representations Space2vec outperforms well-established ML approaches such as RBF kernels, multi-layer feed forward nets, and tile embedding approaches.