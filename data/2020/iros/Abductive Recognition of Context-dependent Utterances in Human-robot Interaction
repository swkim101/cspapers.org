Context-dependent meaning recognition in natural language utterances is one of the key problems of computational pragmatics. Abductive reasoning seems apt for modeling and understanding these phenomena. In fact, it presents observations through hypotheses, allowing us to understand subtexts and implied meanings without exact deductions. For this reason in this paper, we are going to explore abductive reasoning and context modeling in human-robot interaction. Rather than a radical inferential approach, we assumed a conventional approach towards context-depending meanings, i.e, they are conventionally encoded rather than inferred from the utterances. In order to address the problem, a case study is presented, analyzing whether such a system could manage correctly these linguistic phenomena. The results obtained confirm the validity of a conventional approach in context modeling and, on this basis, further models are proposed to work around the limitations of the case study.