In recent times, generative modeling (GM) has gained much popularity in machine intelligence methods, based on its similar likeness to human intelligence. They have demonstrated a remarkable capacity for creating very realistic bits of information in a variety of formats, including texts, images, and sounds. Generative models such as Generative adversarial networks (GANs) and variational auto-encoders (VAE) are the two methods that provide better solutions for generative tasks. However, VAE have certain limitations. But it might be more useful to learn using feature space distributions, rather than the more direct input space distribution. In this work, maximum mean discrepancy based auto-encoders with generative adversarial networks (MMDAEGAN) model is proposed. The proposed work introduces a novel set of loss functions for training such a network on generative tasks. The experimental results show that the proposed model produces better accuracy and less error value on reconstruction of sampled the MNIST and fashion datasets than the baseline model considered for comparison.