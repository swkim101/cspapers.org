Label Scarcity and Data Augmentation have long been challenging problems in the research of Human-oriented Artificial Intelligence. Following the trends of Deep Learning, Human Activity Recognition (HAR) tasks have been significantly optimized in the recent decade with handful of industrial applications on health evaluation and security monitoring. Nevertheless, data acquisition on human activities has been increasingly problematic considering the limited sensor resources and high cost of investment on labor of human volunteers. In this paper, we propose a pioneering unified architecture of convolutional generative adversarial networks, namely ActivityGAN, to effectively generate sensor-based data simulating human physical activities. This architecture comprises of a generation model which is a stack of one-dimensional convolution (1D-convolution) and transposed convolution (1D-transposed convolution) layers, and a discrimination model which employs two-dimensional convolution networks (2D-convolution) with reshaped input of time series. We train the proposed architecture on a collection of activity data and evaluate the generator's output, namely synthetic data, with three approaches of visualization. We then assess the usability of synthetic data by evaluating the test accuracy of models trained with mixed real and synthetic data or with synthetic data that substitutes real data. The study's results show that our proposed architecture is able to generate sufficient synthetic data which are distinguishable by visualization techniques and trainable for HAR machine learning models.