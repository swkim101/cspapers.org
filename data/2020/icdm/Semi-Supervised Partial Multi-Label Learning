Partial multi-label learning (PML) deals with problems where each instance is associated with a candidate label set, which contains multiple relevant labels and some noisy labels. In many real-world scenarios, it is impractical to annotate all examples for a huge-size dataset. Instead, a more common case is that only a small set of the data are annotated with partial labels, while most data are unlabeled. In this paper, we formalize such problems as a new learning framework called Semi-Supervised Partial Multi-label Learning (SSPML). To solve the SSPML problem, a latent label variable is introduced for each example as the low-dimensional embedding of the feature space. On one hand, label variables are recovered by encouraging consistent similarity measurement between the feature space and the label space; on the other hand, the similarities are adaptively updated based on the feedback from the label space. Meanwhile, the multi-label classifier is jointly trained under the supervision of label variables. Extensive experiments on multiple datasets from various real-world tasks validate the effectiveness of the proposed approach.