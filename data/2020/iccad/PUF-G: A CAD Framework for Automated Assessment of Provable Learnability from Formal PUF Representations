Physically Unclonable Functions (PUFs) are widely adopted in various lightweight authenticating devices due to their unique fingerprints - providing uniform, unpredictable and reliable nature of responses. However, with the growth of machine learning (ML) attacks in recent times, it is imperative that the PUFs need to be resilient to such modeling attacks as well. Consequently, analyzing the learnability of PUFs has initiated a new branch of study leading to establishing provable guarantees (and PAC-learnability) of various PUF designs. However, these derivations are often carried out manually while implementing the design and thereby cannot automatically adjust the changes in PUF designs or its various compositions. In this paper, for the first time, we present an automated framework, called PUF-G, to reason about the PAC-learnability of PUF designs from an architectural level. To enable this, we propose a formal PUF representation language by which any architectural PUF design and its compositions can be specified upfront. This PUF specification can be automatically analyzed through a CAD framework by translating the same to an interim model and then deriving the PAC-learnability bounds from the model. Such a tool will help the designer to explore various compositional architectures of PUFs and its resilience to ML attacks automatically before converging on a strong PUF design for implementation. We also show the efficacy of our proposed framework over a wide range of PUF architectures while automatically deriving their learnability guarantees. As a matter of independent interest, the framework presents the first reported proofs to show that Interpose-PUF (newly proposed), MUX-PUF, FF-APUF, FF-XOR APUF and DA-PUF, are all PAC-learnable.