We study the problem of coarse ranking in the multi-armed bandits (MAB) setting, where we have a set of arms each of which is associated with an unknown distribution. The task is to partition the arms into clusters of predeﬁned sizes, such that the mean of any arm in the i -th cluster is larger than that of any arm in the j -th cluster for any j > i . Coarse ranking generalizes a number of basic problems in MAB (e.g., best arm identiﬁcation) and has many real-world applications. We initiate the study of the problem in the batched model where we can only have a small number of policy changes. We study both the ﬁxed budget and ﬁxed conﬁdence variants in MAB, and propose algorithms and prove impossibility results which together give almost tight tradeoffs between the total number of arms pulls and the number of policy changes. We have tested our algorithms in both real and synthetic data; our experimental results have demonstrated the efﬁciency of the proposed methods.