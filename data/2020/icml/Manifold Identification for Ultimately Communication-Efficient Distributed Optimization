This work proposes a progressive manifold iden-tiﬁcation approach for distributed optimization with sound theoretical justiﬁcations to greatly reduce both the rounds of communication and the bytes communicated per round for partly-smooth regularized problems such as the (cid:96) 1 - and group-LASSO-regularized ones. Our two-stage method ﬁrst uses an inexact proximal quasi-Newton method to iteratively identify a sequence of low-dimensional manifolds in which the ﬁnal solution would lie, and restricts the model update within the current manifold to gradually lower the order of the per-round communication cost from the problem dimension to the dimension of the manifold that contains a solution and makes the problem within it smooth. After identifying this manifold, we take superlinear-convergent truncated semismooth Newton steps computed by pre-conditioned conjugate gradient to largely reduce the communication rounds by improving the convergence rate from the existing linear or sublinear ones to a superlinear rate. Experiments show that our method can be orders of magnitudes lower in the communication cost and an order of magnitude faster in the running time than the state of the art.