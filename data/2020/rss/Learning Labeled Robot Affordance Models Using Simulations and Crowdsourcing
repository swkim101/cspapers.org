—Affordance models are widely used in robotics to represent a robot’s possible interactions with its environment. However, robot affordance models are inherently quantitative, making them difﬁcult for humans to understand and interact with. To address this problem, previous works have constructed affordance models by grounding (connecting) them to natural language, but primarily used expert-deﬁned actions, effects, or labels to do so. In this paper, we use short text responses provided by humans and simple randomized robot manipulation actions to construct a labeled affordance model that deﬁnes a relationship between English-language labels and robots’ internal affordance representations. We ﬁrst collect label data from a combination of crowdsourced real-world human-robot interactions and online user studies. We then use this data to train classiﬁers predicting whether or not a particular quantitative affordance will receive a speciﬁc label from a person, achieving an average affordance prediction score of 0.87 (area under Receiver Operating Characteristic curve). Our results also show that labels are more accurately predicted by affordance effects than affordance actions—a result that has been hypothesized in prior work but has never been directly tested. Finally, we develop a technique for automatically constructing a hierarchy of labels from crowdsourced data, discovering structure within the learned labels and suggesting the existence of a more universal set of affordance primitives.