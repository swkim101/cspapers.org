Knowledge graph (KG) embedding aims to encode both entities and relations into a continuous vector space. Most existing methods require that all entities should be observed during training while ignoring the evolving nature of KG. Major recent efforts on this issue embed new entities by aggregating neighborhood information from existing entities and relations with Graph Neural Network (GNN). However, these methods rely on the neighbors seen during training and suffer from the embedding of new entities with insufficient triplets or triplets with the unseen-to-unseen form. To relieve this problem, we propose a two-stage learning model referred as Hyper-Relation Feature Learning Network (HRFN) for effective out-of-knowledge-base embedding. For the first stage, HRFN learns pre-representations for emerging entities using hyper-relation features meta-learned from the training set. A novel feature aggregating network that involves an entity-centered Graph Convolutional Network (GCN) and a relation-centered GCN is proposed to aggregate information from both new entities themselves and their neighbors. For stage two, a transductive learning network is employed to learn finer-grained embeddings based on above-mentioned pre-representations of new entities. Experimental results on the link prediction task demonstrate the superiority of our model. Further analysis is also done to validate the effectiveness and efficiency of pre-representing emerging entities with the hyper-relation feature.