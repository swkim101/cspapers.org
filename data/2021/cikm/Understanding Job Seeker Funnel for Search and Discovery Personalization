The search and discovery process of a job-seeker towards realizing the dream opportunity can be very complex. Given the dynamic nature of job postings, churn-rate of skills, and gaps in intent matches, professionals often find it hard to discover the right opportunity. Most often, they need guidance on the right search queries to issue or next-steps in the job-seeking funnel to reach a target job-apply. In this work, we experiment with job-sessions dataset from LinkedIn, to understand and represent user's job-seeking behavior. In particular using action sequences unified from various search and discovery channels, we pre-train language models, e.g. BERT (Bidirectional Encoder Representations from Transformers) to model user's activities. We further fine-tune the BERT based contextual session embeddings towards predicting entities from target sessions, in an eXtreme Multi-Label (XML) classification setting. We hypothesize that XML fine-tuning task enables dense-representation, and predicted entities to be used in multiple downstream tasks of job-search query recommendation, job-search ranking, job recommendation retrieval, and job-notification expansion, as shown in experiments. We demonstrate significant improvements in accuracy across tasks leading to reduced time to reach a given job-apply, as well as increase in total job-applies in the system. We also share the learning from deploying these models in production. To the best of our knowledge, this is the first work to efficiently model cross-channel activities at scale using self-attention mechanisms, leading to statistically significant improvement in job-seeker experience.