Online spoken language understanding is a challenging task for large-scale conversational agents. For a given user query, there would be several candidate skills capable to process it. It is critical to choose the desired one from them. Moreover, if the user expresses dissatisfaction for the chosen skill, the agent should be capable to adapt its policy accordingly. However, traditional conversational agents rarely pay attention to real-time user behaviors, which makes them relatively static, tending to distribute same queries to same skills even when there were negative behaviors captured. In this paper, we propose Adaptor, a real-time module for the conversational agents to adapt their policy based on real-time negative user behaviors. We collect both explicit and implicit negative user behaviors, and add punishing bias to corresponding skills accordingly. Online results demonstrate that Adaptor can help the conversational agents adapt their policy at conversational-turn level, bringing flexibility and robustness for the agents, and continued positive impacts on user experience.