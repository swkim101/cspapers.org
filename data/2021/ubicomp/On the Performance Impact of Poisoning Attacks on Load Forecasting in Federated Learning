This article examines a poisoning attack on federated learning. While recent studies are actively exploring this topic in classification models of learning such as image recognition, there are few studies that address the topic in regression models. In particular, this research investigates the impacts of poisoning attacks on the performance of load forecasting, which has hardly studied yet in academia. This research implements two poisoning attacks on a federated learning setting and runs experiments to enumerate their impacts on prediction accuracy of load forecasting. With initial results, we plan to bring a couple of research questions for open discussion to audience.