A number of frameworks (Abadi et al., 2016; Chen et al., 2015; 2018; Gulli & Pal, 2017; Jia et al., 2014; Paszke et al., 2017; Seide & Agarwal, 2016; Vasilache et al., 2018) have been developed for deep learning. Many (Abadi et al., 2016; Chen et al., 2015; Jia et al., 2014; Paszke et al., 2017) offer a dataflow DAG abstraction for specifying NN workloads and provide optimization support for inference as well as training with automatic differentiation. These frameworks significantly reduce development cycles for deep learning algorithms and thus facilitate innovations in deep learning. However, a majority of these frameworks (Chen et al., 2015; Jia et al., 2014; Paszke et al., 2017) adopt a library-based approach that maps the NN operations to hardware through existing high-performance libraries, such as cuDNN (Chetlur et al., 2014) for GPUs, and GEMMLOWP (Jacob et al., 2017) and NNPACK (Dukhan, 2016) for CPUs. These libraries currently do not support low-precision inference (INT4), and since they are not open source we could not add that functionality. As such, for our analysis we adopted to use TVM (Chen et al., 2018), which provides a general graph and a tensor expression intermediate representation (IR) to support automatic code transformation and generation. TVM also equips a QNN dialect (Jain et al., 2020) to compile the quantization-specific operators of a quantized model. We choose TVM as our deployment framework for several reasons including: (i) its extensive support in the frontend high-level frameworks and the backend hardware platforms; and (ii) its decoupled IR abstraction that separates the algorithm specifications and the scheduling decisions. Augmenting TVM with our mixed-precision quantization support allows this optimization to be used by NNs written in different frameworks as well as for various target hardware platforms. In addition, the decoupled IR design in TVM allows the mixed-precision quantization optimization to be applied without affecting the specification of algorithms.