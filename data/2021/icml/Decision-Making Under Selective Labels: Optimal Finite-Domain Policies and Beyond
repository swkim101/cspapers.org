Selective labels are a common feature of high-stakes decision-making applications, referring to the lack of observed outcomes under one of the possible decisions. This paper studies the learning of decision policies in the face of selective labels, in an online setting that balances learning costs against future utility. In the homogeneous case in which individuals’ features are disregarded, the optimal decision policy is shown to be a threshold policy. The threshold becomes more stringent as more labels are collected; the rate at which this occurs is characterized. In the case of features drawn from a ﬁnite domain, the optimal policy consists of multiple homogeneous policies in parallel. For the general inﬁnite-domain case, the homogeneous policy is extended by using a probabilistic classiﬁer and bootstrapping to provide its inputs. In experiments on synthetic and real data, the proposed policies achieve consistently superior utility with no parameter tuning in the ﬁnite-domain case and lower parameter sensitivity in the general case.