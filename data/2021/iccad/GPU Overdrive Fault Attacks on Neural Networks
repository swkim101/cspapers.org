Graphics processing units (GPUs) are commonly used to accelerate training and inference of deep neural networks (DNNs). Modern cloud nodes are shared by multiple users to execute workloads concurrently. However, the reliability and security of sharing the heterogeneous CPU-GPU have not been carefully evaluated. In this paper, we thoroughly characterize fault injections and propagation in a victim convolutional neural network (CNN) on a GPU, and analyze the controllability of the attack. We successfully launch an end-to-end misclassification attack during CNN inferences with careful timing control.