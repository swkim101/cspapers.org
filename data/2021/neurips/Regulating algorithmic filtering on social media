Through the algorithmic filtering (AF) of content, social media platforms (SMPs) have the ability to influence users' perceptions and behaviors. Attempts to regulate externalities of AF are often difficult to pass or enforce due to critical social, legal, financial, and user related considerations. In this work, we explore this multifaceted problem by proposing a unifying framework that considers the key stakeholders of AF regulation (or self-regulation). We mathematically formalize this framework, using it to construct a data-driven, statistically sound regulatory procedure that satisfies several important criteria. First, by design, it moderates the effect of AF on user learning and decision-making. Second, it has desirable properties of online governance, including being normative and user-driven. Third, by illustrating the regulatory procedure in linear dynamical systems, we prove that it can align social and financial interests. Specifically, we identify conditions under which the regulation imposes a low cost on the SMP's reward (e.g., profits) and incentivizes the SMP to increase content diversity.