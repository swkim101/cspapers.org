Many features of human and animal behavior can be understood in the framework of Bayesian inference and optimal decision making, but the biological substrate of such processes is not fully understood. Neural sampling provides a flexible code for probabilistic inference in high dimensions and explains key features of sensory responses under experimental manipulations of uncertainty. However, since it encodes uncertainty implicitly, across time and neurons, it remains unclear how such representations can be used for decision making. Here we propose a spiking network model that maps neural samples of a task-specific marginal distribution into an instantaneous representation of uncertainty via a procedure inspired by online kernel density estimation, so that its output can be readily used for decision making. Our model is consistent with experimental results at the level of single neurons and populations, and makes predictions for how neural responses and decisions could be modulated by uncertainty and prior biases. More generally, our work brings together conflicting perspectives on probabilistic brain computation. One of the central questions of perception is how organisms reliably estimate hidden or abstract quantities of interest using noisy and ambiguous sensory information. Almost equally important is representing the reliability of these estimates, especially in complex environments and situations of risk, where the uncertainty associated with a choice may radically change the optimal course of action. From basic functions, such as cue combination or motor control, to higher level cognitive tasks, such as decision making and planning, there is substantial evidence that both humans and animals represent and use uncertainty information to guide their actions [1]. Neural correlates have been identified in a number of regions, including the orbitofrontal cortex [2], the cingulate cortex [3], and the lateral intraparietal area (LIP) [4, 5], but the principles behind how uncertainty is represented in neural circuits to support circuit computations remain hotly debated. Since behavior has been shown to be Bayes-optimal in many situations [6], the problem of perception can be modelled in the framework of Bayesian inference, whereby an observer combines prior information with current observations according to an internal model to arrive at a posterior estimate of a quantity of interest (the ‘latent variable’). Moreover, natural statistics are strongly non-Gaussian and there is evidence that human subjects use varied, non-Gaussian prior representations to support behavior [7, 8], so observers must be able to perform inference flexibly, efficiently and adaptively. This raises two questions: which neural organizations allow for these kinds of computations, and how are the associated neural representations mapped into behaviorally relevant action plans? Currently there are several theories for how neural activity may represent probability distributions. One large class of models assume that neural responses encode parameters of underlying posterior distributions; this includes probabilistic population codes [9, 10], their predecessors, kernel density estimators and distributional population codes [11, 12], and most recently, distributed distributional codes (DDC) [13]. A second class of models relies on stochasticity in recurrent circuits to approxi35th Conference on Neural Information Processing Systems (NeurIPS 2021), . Γ2 Γ2 posterior marginal inference circuit kernels for parametric approximation posterior samples decision circuit = optimal decision estimate ground truth Figure 1: Schematic of sampling-based optimal decision making in spiking networks. Approximate inference is performed in a first spiking recurrent network by distributed sampling [22] (example trajectory from joint posterior shown in white). Samples from the task-relevant marginal posterior are read out linearly from this circuit and serve as input to a second network, which integrates them and converts them into a parametric representation. The associated parameters (bank of kernels in gray) are read out linearly from this second circuit and combined with a cost function, reflecting the potentially asymmetric cost of different errors, to generate the final optimal decision. mately encode probability distributions via sampling [14, 15]. This idea was originally motivated by the practical success of Markov Chain Monte Carlo (MCMC) sampling when performing inference in complex graphical models [14], and had the appeal of being able to flexibly represent complex probability distributions, something that parametric models could not achieve at the time.1 Sampling has been invoked to explain aspects of perceptual decision making [16], response variability in V1 neurons [17, 18] and structured spontaneous activity in the cortex [19]. Moreover, recent theoretical work has focused on improving the computational efficiency of neural sampling, by increasing sampling speed [20, 21] and improving the robustness of the representation [22]. Nonetheless, sampling-based codes represent uncertainty only implicitly, distributed across time and neurons [22]. How the brain maps neural sampling dynamics into uncertainty-calibrated decisions remains a key open question. Here, we propose the first spiking circuit for mapping neural samples into appropriate actions. At the core of our idea is the observation that although inference may involve complex high-dimensional posteriors, individual decisions are usually based on low-dimensional marginals of these distributions, which can be represented explicitly using a traditional parametric code. The proposed recurrent network model takes as inputs samples from the task-relevant posterior marginal and integrates them over time in a procedure inspired by online kernel density estimation [23]. We demonstrate the ability of this circuit to perform decision making in several toy examples. We also analyze the spiking activity of the network to look for signatures of uncertainty and probabilistic computation at the level of single neurons and population activity and find that our model recapitulates a variety of empirical observations in neural data. The model also makes predictions for how uncertainty and prior biases affect neural activity and population latent dynamics in this decision circuit. 1 Spiking neural network for sampling-based marginalization In a Bayesian framework, perceptual decision making involves several key computations. First, given a sensory stimulus, s, one needs to compute the posterior over the latent variables, x, that may have given rise to it, P(x|s). Second, uncertainty about nuisance variables is averaged out, to obtain a marginal distribution over the task-relevant latent xi, P(xi|s). Finally, this marginal is combined with a task-specific cost function to yield the final decision. The first two steps are straightforward under a sampling framework [22], but parametric representations are needed for the final step to convert the information represented by samples into a spatially and temporally localized code [9]. Our approach uses spike-based distributed sampling for approximate inference and marginalization, then converts the resulting samples into an instantaneous parametric representation that can be used Since recent DDCs are also able to represent complex multidimensional posteriors, the arguments in favor of sampling have moved away from representational flexibility, to its ability to explain many nontrivial features of neural variability in the cortex.