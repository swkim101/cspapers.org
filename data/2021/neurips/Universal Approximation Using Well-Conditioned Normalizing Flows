Afﬁne-coupling models (Dinh et al., 2014; 2016) are a particularly common type of normalizing ﬂows, for which the Jacobian of the latent-to-observable-variable transformation is triangular, allowing the likelihood to be computed in linear time. Despite the widespread usage of afﬁne couplings, the special structure of the architecture makes understanding their representational power challenging. The question of universal approximation was only recently resolved by three parallel papers (Huang et al., 2020; Zhang et al., 2020; Koehler et al., 2020) – who showed reasonably regular distributions can be approximated arbitrarily well using afﬁne couplings – albeit with networks with a nearly-singular Jacobian. As ill-conditioned Jacobians are an obstacle for likelihood-based training, the fundamental question remains: which distributions can be approximated using well-conditioned afﬁne coupling ﬂows? In this paper, we show that any log-concave distribution can be approximated us-ing well-conditioned afﬁne-coupling ﬂows. In terms of proof techniques, we uncover and leverage deep connections between afﬁne coupling architectures, underdamped Langevin dynamics (a stochastic differential equation often used to sample from Gibbs measures) and H ´ enon maps (a structured dynamical system that appears in the study of symplectic diffeomorphisms). In terms of informing practice, we approximate a padded version of the input distribution with iid Gaus-sians – a strategy which (Koehler et