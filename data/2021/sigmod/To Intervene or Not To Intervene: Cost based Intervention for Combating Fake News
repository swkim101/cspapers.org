Social media platforms provide valuable and powerful means with which users can share content, comment, and communicate. They also suffer from abuse through the dissemination of fake news and misinformation. While a fair amount of work has been done on detecting fake news, on the complementary problem of limiting its propagation, progress has been modest. Once an item is detected as fake, a social media company can intervene on the item and take an appropriate action, including hard intervention (e.g., removing an account) and soft intervention (e.g., labeling the item as "suspicious"). Given that fake news detectors are not 100% reliable, we study the problem of developing a cost aware intervention policy which decides whether to intervene based on the truthiness and popularity of the item. Our solution, Solomon, consists of three modular components - truthiness estimation, popularity estimation (with and without intervention), and intervention policy. Our extensive experiments on real and fake news from multiple domains show that Solomon can perform effective intervention.