Random forest has been widely used to classifying objects recently because of its efficiency and accuracy. On the other hand, nonvolatile memory has been regarded as a promising candidate to be a part of a hybrid memory architecture. For achieving the higher accuracy, random forest tends to construct lots of decision trees, and then conducts some post-pruning methods to fell low contribution trees for increasing the model accuracy and space utilization. However, the cost of writing operations is always very high on non-volatile memory. Therefore, writing the to-be-pruned trees into non-volatile memory will significantly waste both energy and time. This work proposed a framework to ease such hurt of training a random forest model. The main spirit of this work is to evaluate the importance of trees before constructing it, and then adopts different writing modes to write the trees to the non-volatile memory space. The experimental results show the proposed framework can significantly mitigate the waste of energy with high accuracy.