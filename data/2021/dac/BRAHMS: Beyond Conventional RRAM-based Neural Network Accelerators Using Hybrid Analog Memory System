Accelerating convolutional neural networks (CNNs) with resistive random-access memory (RRAM) based processing-in-memory systems has been recognized as a promising approach. However, conventional accelerators are usually mixed-signal circuits with digital-to-analog converters (DACs) and analog-to-digital converters (ADCs), which cause performance and energy efficiency degradation. In this work, we first analyze the problems in existing RRAM-based CNN accelerators and point out that there are redundant analog-to-digital (AD) conversions. To eliminate redundant AD conversions and also reduce AD conversion overhead, we propose the BRAHMS architecture, which is an RRAM-based CNN accelerator composed of reconfigurable RRAM crossbars and analog resistive content-addressable memory (ARCAM) arrays. We reorder the operations after a convolutional or fully-connected layer and form fused operators (FOPs), which are implemented as a whole by ARCAM arrays so that digital logic and ADCs are eliminated. BRAHMS realizes a mixed-signal pipeline which transmits data signals in the analog domain within an FOP and in the digital domain between FOPs to obtain high performance and energy efficiency. Detailed simulation results show that compared with an ISAAC-like architecture, BRAHMS improves the performance by several times and the energy efficiency by 10 + times on average.