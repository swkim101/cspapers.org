Vision-based systems for terrain detection are ubiquitous in mobile robotics, while such systems recently emerged for locomotion assistance of disabled people. For instance, wearable devices embedding vision sensors can assist people in navigation; or guide lower-limb prosthesis or exoskeleton controller to retrieve gait patterns being adapted to the executed task (overground walking, stairs, slopes, etc.). In this research, we present a vision-based algorithm achieving the detection of flat ground, steps, and ramps, using a depth camera. The raw point cloud data obtained from the depth camera passes through multiple processing steps to extract environmental features, and then achieves terrain detection by feeding these features into a classification tree. The camera was mounted on a custom-made wearable tool that can be placed on the chest of human users. This contribution reports a pilot validation study with 6 healthy subjects moving in an indoor environment containing a rich set of different types of terrains. Our method can predict the locomotion modes up to three steps in front of the user. Moreover, it is able to perform terrain detection even if the path is partially occluded by another walker. The method accuracy with a cleared path was found to be above 90% for all locomotion modes.