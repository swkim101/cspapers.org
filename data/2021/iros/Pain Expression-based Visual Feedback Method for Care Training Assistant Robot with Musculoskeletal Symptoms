A human patient simulator (HPS) can achieve effective visual-, auditory-, text-, and alarm-based feedback methods in care or nursing education. Among these, the method of visual feedback is important to design an HPS that can express emotions or feelings of pain like an actual human does because this method allows an immediate reaction between robots and humans. This study aims to develop an avatar-based visual feedback method for a care training assistant robot that can express pain states in joint care education. First, this study introduces its own pain facial expression database from Ritsumeikan University (RU-PITENS) for an avatar with pain expression. The RU-PITENS database contains pain images of 41 Japanese people in their 20s, 30s, 40s, and 60s, and an experiment of pain stimulus is conducted based on transcutaneous electrical nerve stimulation, which is low-cost and easy to use in daily life. Based on the pain images in the RU-PITENS database, we generated an avatar with pain expression to achieve the goal of our study. Since the RUPITENS database does not contain the quantitative pain level, the Siamese network was used to calculate the pain intensity. In addition, the care training assistant robot (CaTARo) developed in our previous study reproduces symptoms of musculoskeletal diseases, and the pain of CaTARo was measured using fuzzy logic theory. As a result, a visual feedback system was constructed to express five types of pain (no pain at all, very faint, weak, moderate, and strong pain) with avatars according to the intensity of the pain output of CaTARo in care training environments.