This paper studies the problem of language-guided re-flection separation, which aims at addressing the ill-posed reflection separation problem by introducing language de-scriptions to provide layer content. We propose a unified framework to solve this problem, which leverages the cross-attention mechanism with contrastive learning strategies to construct the correspondence between language descriptions and image layers. A gated network design and a ran-domized training strategy are employed to tackle the rec-ognizable layer ambiguity. The effectiveness of the pro-posed method is validated by the significant performance advantage over existing reflection separation methods on both quantitative and qualitative comparisons.