Partitioning of multi-block structured grids impacts the performance and scalability of numerical simulations. An optimal partitioner should achieve both load balance and minimize communication time. The state-of-art domain decomposition algorithms do a good job at balancing the load across processors. However, even if the work is well balanced, the communication cost might not be. The two main factors that impact communication cost are edge cuts and communication volume. The current partitioners primarily focus on reducing the total communication volume and rely on simple techniques such as cutting at the longest edge which does not capture the connectivity in the geometry. They also don't factor the effect of the network's latency and bandwidth for partitioning resulting in the same partition across all platforms. In addition, their performance tests mostly adopt a flat MPI model where the partition's effect on communication is hidden by the fast shared memory accesses between cores on the same node. In this paper, we present new partitioning algorithms for multi-block structured grids that address the above limitations of current partitioners. The new algorithms include a cost function which not only accounts for both the communication volume and edge cuts but also takes into account the network's latency and bandwidth. We minimize the overall cost among all processors in an effort to create optimum partitions. To demonstrate the efficiency of the proposed algorithms, we test the partitioners with an MPI+OpenMP hybrid model where MPI routines handle inter-node communication and OpenMP threads take advantage of the shared memory within a node. On the Mira supercomputer, our partitioners coupled with a Jacobi solver demonstrate 5.5 -- 15× speedup in communication against a greedy algorithm on a synthetic multi-block structured grid and 1.5× speedup on the Falcon Heavy Space-X grid consisting of 769 blocks.