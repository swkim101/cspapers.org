Contact detection is an important topic in contemporary humanoid robotic research. Up to date control and state estimation schemes readily assume that feet contact status is known in advance. In this work, we elaborate on a broader question: in which gait phase is the robot currently in? We introduce an unsupervised learning framework for gait phase estimation based solely on proprioceptive sensing, namely joint encoder, inertial measurement unit and force/torque data. Initially, a meaningful physical explanation on data acquisition is presented. Subsequently, dimensionality reduction is performed to obtain a compact low-dimensional feature representation followed by clustering into three groups, one for each gait phase. The proposed framework is qualitatively and quantitatively assessed in simulation with ground-truth data of uneven/rough terrain walking gaits and insights about the latent gait phase dynamics are drawn. Additionally, its efficacy and robustness is demonstrated when incorporated in leg odometry computation. Since our implementation is based on sensing that is commonly available on humanoids today, we release an open-source ROS/Python package to reinforce further research endeavors.