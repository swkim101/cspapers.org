The success of block-based programming environments like Scratch and Alice has resulted in a growing presence of the block-based modality in classrooms. For example, in the United States, a new, nationally-administered computer science exam is evaluating students' understanding of programming concepts using both block-based and text-based presentations of short programs written in a custom pseudocode. The presence of the block-based modality on a written exam in an unimplemented pseudocode is a far cry from the informal, creative, and live coding contexts where block-based programming initially gained popularity. Further, the design of the block-based pseudocode used on the exam includes few of the features cited in the research as contributing to positive learner experiences. In this paper, we seek to understand the implications of the inclusion of an unimplemented block-based pseudocode on a written exam. To do so, we analyze responses from over 5,000 students to a 20 item assessment that included both block-based and text-based questions written in the same pseudocode as the national exam. Our analysis shows students performing better on questions presented in the block-based form compared to text-based questions. Further analysis shows that this difference is consistent across conceptual categories. This paper contributes to our understanding of the affordances of block-based programming and if and how the modality can help learners succeed in early computer science learning experiences.