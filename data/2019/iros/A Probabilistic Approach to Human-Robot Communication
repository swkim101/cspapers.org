Since robots are increasingly expected to work in concert with humans in dynamic, unstructured environments, they will need to express information about their state and actions. We propose a formalism for planning robot communication that employs a probabilistic representation of the robots world. This representation takes on the form of a Markov Decision Process (MDP) and captures the uncertainty of interacting with humans. The key insight of this work is that humans preferences and time need to be carefully balanced against the robots in order to minimize human annoyance. The communication-MDP enables the robot to reason about the effects of its actions on a human interactor. We validated the model through a human subjects experiment (n=44) by learning communication policies for a loosely collaborative task. The results show that the communication-MDP improves participants’ perceptions of the robot’s thoughtfulness as an interactor.