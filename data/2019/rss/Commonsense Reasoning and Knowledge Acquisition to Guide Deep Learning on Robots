—Algorithms based on deep network models are being used for many pattern recognition and decision-making tasks in robotics and AI. Training these models requires a large labeled dataset and considerable computational resources, which are not readily available in many domains. Also, it is difﬁcult to under- stand the internal representations and reasoning mechanisms of these models. The architecture described in this paper attempts to address these limitations by drawing inspiration from research in cognitive systems. It uses non-monotonic logical reasoning with incomplete commonsense domain knowledge, and inductive learning of previously unknown constraints on the domain’s states, to guide the construction of deep network models based on a small number of relevant training examples. As a motivating example, we consider a robot reasoning about the stability and partial occlusion of conﬁgurations of objects in simulated images. Experimental results indicate that in comparison with an architecture based just on deep networks, our architecture improves reliability, and reduces the sample complexity and time complexity of training deep networks.