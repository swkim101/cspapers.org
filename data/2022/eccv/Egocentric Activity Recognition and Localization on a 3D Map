Data Processing. We resize all video frames to the short edge size of 256. For the coarse 3D map, we adopt a resolution of 28 × 28 × 8 for parent voxel, and M = 4 for children voxels. For training, our model takes an input of 8 frames (temporal sampling rate of 8) with a resolution of 224× 224. For inference, our model samples 30 clips from a video (3 along spatial dimension and 10 in time). Each clip has 8 frames with a resolution of 224× 224. We average the scores of all sampled clips for video level prediction.