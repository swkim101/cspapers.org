Annotating tens or hundreds of tiny objects in a given image is laborious yet crucial for a multitude of Computer Vision tasks. Such imagery typically contains objects from various categories, yet the multi-class interactive annotation setting for the detection task has thus far been unex-plored. To address these needs, we propose a novel interactive annotation method for multiple instances of tiny objects from multiple classes, based on a few point-based user in-puts. Our approach, C3Det, relates the full image context with annotator inputs in a local and global manner via late-fusion andfeature-correlation, respectively. We perform ex-periments on the Tiny-DOTA. and LCell datasets using both two-stage and one-stage object detection architectures to verify the efficacy of our approach. Our approach outper-forms existing approaches in interactive annotation, achieving higher mAP with fewer clicks. Furthermore, we validate the annotation efficiency of our approach in a user study where it is shown to be 2.85x faster and yield only 0.36x task load (NASA-TLX, lower is better) compared to manual annotation. The code is available at https://github.com/ChungYi347/Interactive-Multi-Class-Tiny-Object-Detection.