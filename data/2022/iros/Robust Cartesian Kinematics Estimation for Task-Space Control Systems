We discuss a novel method for estimating task Cartesian position and velocity in robot manipulators. This is done by model-based fusion of inertial measurement units with motor encoders. The model is developed to robustly handle the uncertainties in the trajectory. Thus, not only the approach benefits from high fidelity and bandwidth thanks to multiple-sensory fusion, but it also enforces stability despite poorly formulated motions. This empowers the method to be utilized in complex closed-loop applications, where both task position and velocity information is required.