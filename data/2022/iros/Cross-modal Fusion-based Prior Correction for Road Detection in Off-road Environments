Road detection plays a fundamental role in the visual navigation system of autonomous vehicles. However, it's still challenging to achieve robust road detection in off-road scenarios due to their complicated road appearances and ambiguous road structures. Therefore, existing image-based road detection approaches usually fail to extract the right routes due to the lack of the effective fusion of the image and prior reference paths(road guidances generated via map annotations and GPS localization). Besides, the reference paths are not always reliable because of GPS localization errors and mapping errors. To achieve robust road detection in off-road scenarios, we propose a prior-correction-based road detection network named PR-ROAD via fusing the cross-model information provided by both the reference path and the input image. These two heterogeneous data, prior and image, are deeply fused by a cross-attention module and formulate contextual inter-dependencies. We conduct experiments in our collected rural, off-road and urban datasets. The experimental results demonstrate the effectiveness of the proposed method both on unstructured and structured roads.