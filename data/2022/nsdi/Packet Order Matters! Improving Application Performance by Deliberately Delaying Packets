Data centers increasingly deploy commodity servers with high-speed network interfaces to enable low-latency communication. However, achieving low latency at high data rates crucially depends on how the incoming trafﬁc interacts with the system’s caches. When packets that need to be processed in the same way are consecutive, i.e., exhibit high temporal and spatial locality, caches deliver great beneﬁts. In this paper, we systematically study the impact of temporal and spatial trafﬁc locality on the performance of commodity servers equipped with high-speed network interfaces. Our results show that ( i ) the performance of a variety of widely deployed applications degrades substantially with even the slightest lack of trafﬁc locality, and ( ii ) a trafﬁc trace from our organization reveals poor trafﬁc locality as networking protocols, drivers, and the underlying switching/routing fabric spread packets out in time (reducing locality). To address these issues, we built Reframer, a software solution that de-liberately delays packets and reorders them to increase trafﬁc locality. Despite introducing µs-scale delays of some packets, we show that Reframer increases the throughput of a network service chain by up to 84% and reduces the ﬂow completion time of a web server by 11% while improving its throughput by 20%.