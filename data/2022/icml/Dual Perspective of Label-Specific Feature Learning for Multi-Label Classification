Label-speciﬁc features serve as an effective strategy to facilitate multi-label classiﬁcation, which account for the distinct discriminative properties of each class label via tailoring its own features. Existing approaches implement this strategy in a quite straightforward way, i.e. ﬁnding the most pertinent and discriminative features for each class label and directly inducing classiﬁers on constructed label-speciﬁc features. In this paper, we propose a dual perspective for label-speciﬁc feature learning, where label-speciﬁc discriminative properties are considered by identifying each label’s own non-informative features and making the discrimination process immutable to variations of these features. To instantiate it, we present a perturbation-based approach D ELA to provide classiﬁers with label-speciﬁc immutability on simultaneously identiﬁed non-informative features, which is optimized towards a probabilistically-relaxed expected risk minimization problem. Comprehensive experiments on 10 benchmark data sets show that our approach outperforms the state-of-the-art counter-parts.