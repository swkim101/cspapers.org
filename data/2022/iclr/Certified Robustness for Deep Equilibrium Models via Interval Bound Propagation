Deep equilibrium layers (DEQs) have demonstrated promising performance and are competitive with standard explicit models on many benchmarks. However, little is known about certifying robustness for these models. Inspired by interval bound propagation (IBP), we propose the IBP-MonDEQ layer, a DEQ layer whose robustness can be veriﬁed by computing upper and lower interval bounds on the output. Our key insights are that these interval bounds can be obtained as the ﬁxed-point solution to an IBP-inspired equilibrium equation, and furthermore, that this solution always exists and is unique when the layer obeys a certain parameterization. This ﬁxed point can be interpreted as the result of applying IBP to an inﬁnitely deep, weight-tied neural network, which may be of independent interest, as IBP bounds are typically unstable for deeper networks. Our empirical comparison reveals that models with IBP-MonDEQ layers can achieve comparable (cid:96) 8 certiﬁed robustness to similarly-sized fully explicit networks. 1