Wearable devices enable the continuous and unobtrusive monitoring of physiological data, e.g., electrodermal activity (EDA), and they allow to build machine learning models to recognize human emotions, stress, and more. However, the quality of the collected data can significantly impact the performance of such models. When wrist-worn sensors are used, this may happen due to differences in the signal collected on the left and right wrist. In this work, we quantify the impact of physiological signal lateralization in a laughter recognition task. Building upon an existing dataset from 34 users, we devise a laughter recognition classifier and compare the performance of models trained and tested with data from different wrists. Our results show that, when using EDA, classification performance might depend on the side used for training and testing. Our quantification of lateralization on model performance provides insights for the design of EDA-based models as well as of data collection studies.