With the advances in Body Sensor Networks (BSNs) and textile-integrated sensing, more sensor data becomes available from which human activities are recognised. However, some sensors may become unavailable unexpectedly in practice. Previous work proposed to complement the features of a missing sensor with regression-based methods but considered only up to one sensor missing and thus lacked a mechanism for selecting relevant sensors when multiple sensors were missing. The number of unique combinations of missing sensors increases exponentially when multiple sensors may be missing. To handle this, we propose a Hierarchical Feature Recovery (HFR) approach. We first assess the dependencies between sensors by comparing the feature mapping accuracy between each sensor and then evaluate the HFR approach on a dataset of activities of daily living with 17 gestures using 14 motion sensors. Our HFR method can alleviate classification performance drop by up to 8.3 pp compared to a baseline method.