We study m by m random matrices M with jointly Gaussian entries. Assuming a global small-ball probability bound infx,y∈ Sm−1 ℙ⎛ ⎝⎪ ⎪x* M y⎪ ⎪>m−O(1)⎞ ⎠≥ 1/2 and a polynomial bounded on the norm of M, we show that the minimum singular value of M has a polynomial lower bound. We also consider the problem with the additional self-adjoint assumption. We establish two matrix anti-concentration inequalities, which lower bound the minimum singular values of the sum of independent positive semidefinite self-adjoint matrices and the linear combination of independent random matrices with independent Gaussian coefficients. Both are under a global small-ball probability assumption. Two applications are discussed. First, we derive a better singular value bound for the Krylov space matrix. This leads to a faster and simpler algorithm for solving sparse linear systems. Our algorithm runs in Õ(n3ω−4/ω−1)=O(n2.2716) time where ω<2.37286 is the matrix multiplication exponent, improving on the previous fastest one in Õ(n5ω−4/ω+1)=O(n2.33165) time by Peng and Vempala. Second, in compressed sensing, we relax certain restrictions for constructing measurement matrix by the basis pursuit algorithm.